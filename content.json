{"pages":[{"title":"404","text":"","path":"404/index.html","date":"04-09","excerpt":""},{"title":"archives","text":"","path":"archives/index.html","date":"04-09","excerpt":""},{"title":"分类","text":"","path":"categories/index.html","date":"04-09","excerpt":""},{"title":"search","text":"","path":"search/index.html","date":"04-09","excerpt":""},{"title":"about","text":"","path":"about/index.html","date":"04-09","excerpt":""},{"title":"tags","text":"","path":"tags/index.html","date":"04-09","excerpt":""}],"posts":[{"title":"redis主从复制","text":"在redis中可以通过slaveof命令让一个服务器去复制另一个服务器，其中被复制的服务器叫做主服务器，对主服务器进行复制的叫做从服务器。graph LR A[从服务器] -->|复制| B(主服务器)旧版复制的实现redis的复制分为同步/命令传播两个操作 同步操作用于将从服务器的数据库状态更新至主服务器当前所处的数据库状态 命令传播操作则用于在主服务器的数据库状态被修改，导致主从服务器的数据库状态出现不一致时让主从服务器的数据库重新回到一致状态 同步当客户端向从服务器发送slaveof命令，要求从服务器复制主服务器时，从服务器首先需要执行同步操作，也就是将从服务器的数据库状态更新至主服务器当前所处的数据库状态。 同步操作需要sync命令来完成 从服务器向主服务器发送sync命令 收到sync命令的主服务器执行BGSAVE命令， 在后台生成一个RDB文件，并使用一个缓冲区记录现在开始所执行的所有命令 当主服务器的BGSAVE命令执行完毕时，主服务器会将生成的RDB文件发送给从服务器，从服务器接收并载入这个RDB文件，将自己的数据库状态更新至主服务器指定BGSAVE命令时的状态。 主服务器将缓冲区此期间记录的所有命令发送给从服务器，从服务器执行这些数据更新命令，将自己的数据库状态更新至主服务器数据库当前所处的状态 graph LR; B(从服务器)-->|发送SYNC命令|A(主服务器); A-->|发送RDB文件|B A-->|发送缓冲区保存的所有数据更改命令|B 命令传播同步命令执行完毕后，主从服务器处于一致状态。 当主服务器执行数据修改命令时，一致状态将会被打破，这个时候主从的数据不可能一致，所以，主服务器需要将导致数据不一致的命令发送给从服务器，从服务器通过执行这条命令，使数据重新达到一致。 graph LR A(客户端)-->|del key|B(主服务器) B-->|del b|C(从服务器) 复制功能缺陷复制可以分为两种情况 初次复制： 从服务器以前没有复制过任何主服务器， 或者从服务器当前要复制的主服务器与上一次复制的主服务器不同 断线后重复制：处于命令传播阶段的主从服务器因为某种原因断开复制，但从服务器通过自动重连重新连接上了主服务器，并且继续复制主服务器 在旧版复制中， 初次复制没有问题， 但是断线后重复制有很大重复性操作 sequenceDiagram 从服务器 -> 主服务器: 同步状态 客户端 ->> 主服务器: 发送set n命令 主服务器 ->> 从服务器: 传播set n命令 从服务器 ->> 主服务器: 断开链接 客户端 ->> 主服务器: 发送set n+1命令 从服务器 ->> 主服务器: 尝试链接 客户端 ->> 主服务器: 发送set n+2命令 从服务器 ->> 主服务器: 重新链接成功 从服务器 ->> 主服务器: sync命令 主服务器 ->> 从服务器: 执行同步操作 客户端 ->> 主服务器: 发送set n+3命令 从服务器 ->> 主服务器: 接收同步期间的修改命令 主服务器 -> 从服务器: 同步状态 上图中可以清晰看到， 断线重连后，同步操作这一步实际上并不是非做不可。 从服务器想要将自己更新至主服务器当前所处的状态，真正需要的是主从服务器链接中断期间，主服务器新添加的n+1, n+2两个键的数据。 所以， 主服务器执行同步操作， 将1——n+2 都打包成RDB发送给从服务器是不必要的. 一般来说，主服务器在断线期间执行修改命令会比整个数据库的数据量要少得多，在这种情况下，为了让从服务器补足一小部分缺失的数据，却要让主服务器重新执行一次SYNC命令， 这种做法是非常低效的。 新版复制实现为了解决旧版复制功能在处理断线重复制的低效问题，Redis使用PSYNC命令代替SYNC命令来执行复制时的同步操作 PSYNC具有完整重同步和部分重同步 完整重同步： 用于初次复制情况，执行步骤和sycn命令基本一样， 都是通过让主服务器创建并发送RDB文件，以及向从服务器发送保存在缓冲区里面的修改命令进行同步 部分重同步：用于断线后重复制情况，当从服务器在断线后重新连接上主服务器时，如果条件允许，主服务器可以将主从服务器断开期间执行的数据修改命令发送给从服务器，从服务器只要接受并执行这些命令，就可以将数据库更新至主服务器当前所处的数据库状态 sequenceDiagram 从服务器 -> 主服务器: 同步状态 客户端 ->> 主服务器: 发送set n命令 主服务器 ->> 从服务器: 传播set n命令 从服务器 ->> 主服务器: 断开链接 客户端 ->> 主服务器: 发送set n+1命令 从服务器 ->> 主服务器: 尝试链接 客户端 ->> 主服务器: 发送set n+2命令 从服务器 ->> 主服务器: 重新链接成功 从服务器 ->> 主服务器: 发送psync命令 主服务器 ->> 从服务器: 向从服务器返回+continue回复，表示执行部分重同步 从服务器 -> 从服务器: 接收+continue，准备执行部分重同步 主服务器 ->> 从服务器: 发送set n+1、n+2命令 从服务器 -> 从服务器: 接收并执行传过来的两个set命令 主服务器 -> 从服务器: 再次恢复同步 从上可以看出， psync相比较sync命令在断线重复制时所需资源要少得多，完成同步的速度也快得多，整个过程中， 不需要处理已经重复的数据。 部分重同步的实现部分重同步主要由三个部分构成： 主服务器的复制偏移量、从服务器的复制偏移量 主服务器的复制挤压缓冲区 服务器的运行id 复制偏移量主从服务器分别会维护一个复制偏移量 主服务器每次向从服务器传播N个字节数据时，就将自己的复制偏移量的值加N 从服务器每次接收到主服务器传播来的N个字节数据时，就将自己的复制偏移量的值加N graph LR A(客户端) -->|发送set命令 33字节| B(主服务器,目前10086字节) B ---|复制偏移量加33, 复制偏移量为10119| B B -->|传播33字节数据| C(从服务器1,目前10068字节) C ---|复制偏移量加33, 复制偏移量为10119| C B -->|传播33字节数据| D(从服务器2,目前10068字节) D ---|复制偏移量加33, 复制偏移量为10119| D B -->|传播33字节数据| E(从服务器3,目前10068字节) E ---|复制偏移量加33, 复制偏移量为10119| E 通过确认主从的复制偏移量就可以确认是否处于一致状态 如果传播时从服务器1断线，那么传播就只有从服务器2，从服务器3能够接收，在此之后就只有从服务器1复制偏移量为10086， 而其他都是10119， 待从服务器1重新连接后是执行部分重同步还是完全重同步需要涉及复制积压缓冲区 graph LR A(客户端) -->|发送set命令 33字节| B(主服务器,目前10086字节) B ---|复制偏移量加33, 复制偏移量为10119| B B -.-> |断线| C(从服务器1,目前10068字节) B -->|传播33字节数据| D(从服务器2,目前10068字节) D ---|复制偏移量加33, 复制偏移量为10119| D B -->|传播33字节数据| E(从服务器3,目前10068字节) E ---|复制偏移量加33, 复制偏移量为10119| E 复制积压缓冲区复制积压缓冲区是由主服务器维护的一个固定长度先进先出队列，默认大小为1MB， 当主服务器进行命令传播时，它不仅仅会将写命令发送给所有从服务器，还会将命令入队到复制积压缓冲区里面 graph TB subgraph 主服务器 A(命令传播程序) -->|将写命令放入队列| B(复制积压缓冲区) end A -->|发送写命令| C(从服务器A) A -->|发送写命令| D(从服务器B) 当从服务器重新连上主服务器后，会通过psync命令将自己的复制偏移量offset发送给主服务器，主服务器会根据这个复制偏移量来决定对从服务器执行何种同步操作 如果offset偏移量之后的数据任然存在于复制积压缓冲区里面，那么主服务器将对从服务器执行部分重同步操作 如果offset偏移量之后的数据已经不存在于复制积压缓冲区，那么主服务器将对从服务器执行完整同步操作 回到之前的例子： 从服务器1重新连接后，通过psync命令报告自己的复制偏移量10086 主服务器将检查偏移量10086之后的数据是否存在于复制积压缓冲区里面，发现这些数据任然存在，于是主服务器向从服务器发送+continue回复， 表示数据同步将以部分重同步模式进行 接着主服务器会将复制积压缓冲区10086偏移量之后的所有数据（10087-10119）都发送给从服务器1 从服务器只要接收这33字节的缺失数据，就可以回到与主服务器一直状态 服务器运行id除了复制偏移量和复制积压缓冲区外，实现部分重同步还需要用到服务器运行ID 每个redis服务器都会有自己的运行ID 运行ID在服务器启动时自动生成，由60个随机的十六进制字符组成 当从服务器对主服务器初次复制时，主服务器会将自己运行的id传送给从服务器，而从服务器则会将这个运行id保存起来， 从服务器断线重连时，从服务器将向当前连接的主服务器发送之前保存的ID 如果保存的ID和主服务器相同，说明断线前复制的就是当前主服务器，可以尝试执行部分重同步 如果ID不同， 说明从服务器断线前复制的主服务器并不是当前这台，应该进行完全同步操作 PSYNC命令实现调用方法 如果没有复制过任何主服务器，或者之前执行了slaveof no one ,那么这个从服务器在开始一次新的复制时要向主服务器发送PSYNC ? -1 命令， 主动请求主服务器完全同步操作 相反， 如果已经进行过复制操作，那么从服务器在开始时要发送PSYNC &lt;runid&gt; &lt;offset&gt;， 其中runid是上次复制的主服务器id，offset时目前复制偏移量， 接收到这个命令的主服务器会通过这两个参数来判断改对从服务器执行哪种同步操作 三种回复： 如果执行完整同步操作：回复+FULLRESYNC &lt;runid&gt; &lt;offset&gt;,其中runid是这个主服务器的id，从服务器会将这个id保存起来，在下一次发送PSYNC时使用，offset则是当前主服务器的复制偏移量，从服务器会将这个值作为自己的初始偏移量 部分重同步操作：回复+CONTINUE，从服务器只要等着主服务器将自己缺少的那部分数据发送过来就好了 版本过低：回复-ERR，表示服务器版本低于2.8，无法识别PSYNC命令，从服务器将向主服务器发送SYNC命令，并且与主服务器完整同步操作 SLAVEOF执行流程设置主服务器地址和端口例如执行命令：SLAVEOF 127.0.0.1 6379 从服务器首先要做的就是将客户端给定的主服务器IP地址127.0.0.1以及端口6379保存到服务器状态的masterhost属性和masterport属性里面： 12345678struct redisServer &#123; ... /* Replication (slave) */ char *masterauth; /* AUTH with this password with master */ char *masterhost; /* Hostname of master */ int masterport; /* Port of master */ ...&#125;； SLAVEOF命令是一个异步命令，在完成masterhost和masterport属性设置后向客户端返回OK，表示复制指令已经被接收，而实际的复制工作将在OK返回之后才正式开始 建立套接字连接从服务器将根据所设置的IP地址和端口创建连向主服务器的套接字 如果套接字成功连接主服务器，那么从服务器将为这个套接字关联一个专门用于处理复制工作的文件事件处理器，比如接收RDB和主服务器传播回来的写命令 而主服务器接受从服务器的套接字后，将该套接字创建相应的客户端状态，并将从服务器连接看做是一个连接到主服务器的客户端对待，这时从服务器将同时具有服务器和客户端两个身份。 发送PING命令从服务器成为主服务器客户端后第一件事就是向主服务器发送PING命令 检查套接字的读写状态时候正常 复制工作必须在主服务器可以正常处理命令请求的状态下才能进行，通过发送PING命令可以检查主服务器能否正常处理请求命令 如果主服务器返回了命令回复，而从服务器不能在规定时间内读取回复的内容， 说明当前网络不佳，不能继续后面的复制操作，所以应该断开并重新创建套接字 如果回复读取也正常，那么标识主从服务器连接正常，并且可以接受从服务器的请求，可以继续执行复制工作的下面步骤 身份验证如果从服务器设置了masterauth选项， 那么进行身份验证， 这时从服务器将向主服务器发送一条auth命令，验证时可能出现以下情况 如果主服务器没有设置requirepass选项， 并且从服务器也没有设置masterauth选项，那么主服务器将继续执行从服务器发送的命令， 复制工作继续 如果从服务器通过auth命令发送的密码和主服务器设置的requirepass选项所设置的密码相同，那么主服务器将继续执行从服务器发送的命令，复制工作继续执行。相反，如果明码不同，主服务器将返回invalid password错误 如果主服务器设置了requirepass选项， 而从服务器没有设置masterauth选项，那么主服务器将返回一个NOAUTH错误。如果主服务器没有设置requirepass选项，而从服务器设置了masterauth选项，那么主服务器返回一个 no password is set错误 任何错误情况都会令从服务器停止复制工作，并从创建套接字开始重新执行复制，直到身份验证通过，或者从服务器放弃执行复制为止 发送端口信息身份验证之后，从服务器执行命令REPLCONF listening-port &lt;port-number&gt;向主服务器发送服务器监听端口号 例如，从服务器的监听端口为12345，那么从服务器将向主服务器发送命令REPLCONF listening-port 12345 主服务器在接收到这个命令后，会将端口号记录在从服务器所对应客户端状态的slave_listening_port 属性中， 这个属性唯一的作用就是在主服务器执行INFO replication时打印出从服务器的端口号 同步这一步，从服务器将向主服务器发送PSYNC命令， 执行同步操作，并将自己的数据库更新至主服务器数据库当前所处状态 在同步操作之前，只有从服务器是主服务器的客户端，但是在执行同步操作之后，主服务器也会成为从服务器的客户端 如果执行完整同步操作，那么主服务器需要成为从服务器的客户端才能将保存在缓冲区里面的写命令发送给从服务器 如果是部分重同步操作，那么主服务器需要成为从服务器的客户端才能向从服务器发送保存在复制积压缓冲区里面的写命令 因此同步操作执行之后，主从服务器双方都是对方的客户端 命令传播完成同步后，主服务器就会进入命令传播阶段，这时主服务器只要一直将自己执行的写命令发送给从服务器，而从服务器只要一直接收主服务器发来的写命令就可以保证主从一致了 心跳检测从服务器默认会以每秒一次的频率向主服务器发送命令 REPLCONF ACK &lt;replication_offset&gt; 其中&lt;replicaion_offset&gt;是从服务器当前的复制偏移量 检测主从服务器的网络连接状态 主服务器可以通过发送和接收REPLCONF ACK命令来检查两者之间的网络连接是否正常， 如果主服务器超过一秒钟没有收到从服务器发来的REPLCONF ACK命令，那么主服务器就知道主从服务器链接出现了问题 辅助实现min-slaves选项 redis的min-slaves-to-write和min-slaves-max-lag两个选项可以防止主服务器不在安全的情况下执行写命令， 例如min-slaves-to-write 3 min-slaves-max-lag 10，在从服务器数量少于3个或者三个从服务器的延迟(lag)都大于或等于10秒时主服务器拒绝执行写命令 检测命令丢失 如果因为网络故障，主服务器传播给从服务器的写命令在半路丢失，那么当从服务器向主服务器告知replication_offset时，主服务器发觉从服务器当前的复制偏移量少于自己的复制偏移量，然后主服务器就会根据从服务器提交复制偏移量，在复制积压缓冲区找到缺少的数据重新发送给从服务器flowchat st=>start: 开始 e=>end: 结束 op1=>operation: 从服务器接到客户端发来的SLAVEOF命令 cond1=>condition: 这是从服务器第一次执行复制？ op2=>operation: 向主服务器发送PSYNC ? -1 op3=>operation: 向主服务器发送PSYNC cond2=>condition: 主服务器返回 +CONTINUE ? op4=>operation: 主服务器返回 +FULLRESYNC 执行完整重同步 op5=>operation: 执行部分重同步 st->op1 op1->cond1 cond1(yes)->op2 cond1(no)->op3 op3->cond2 cond2(no)->op4 cond2(yes)->op5 op2->op4 op4->e op5->e{\"scale\":1,\"line-width\":2,\"line-length\":50,\"text-margin\":10,\"font-size\":12} var code = document.getElementById(\"flowchart-0-code\").value; var options = JSON.parse(decodeURIComponent(document.getElementById(\"flowchart-0-options\").value)); var diagram = flowchart.parse(code); diagram.drawSVG(\"flowchart-0\", options);st=>start: 开始 en=>end: 结束 op1=>operation: 进入身份验证 op2=>operation: 执行复制工作的下一个步骤 op3=>operation: 主从服务器设置了不同的密码 或者 主服务器设置了密码从服务器没有设置密码 或者 从服务器设置了密码主服务器没有设置密码 op4=>operation: 重试 cond1=>condition: 主从服务器都没有设置密码 cond2=>condition: 主从服务器设置的密码相同 st->op1 op1->cond1 cond1(yes)->op2 cond1(no)->cond2 cond2(yes)->op2 cond2(no)->op3 op3->op4 op2->en{\"scale\":1,\"line-width\":2,\"line-length\":50,\"text-margin\":10,\"font-size\":12} var code = document.getElementById(\"flowchart-1-code\").value; var options = JSON.parse(decodeURIComponent(document.getElementById(\"flowchart-1-options\").value)); var diagram = flowchart.parse(code); diagram.drawSVG(\"flowchart-1\", options);","path":"2019/08/23/redis主从复制/","date":"08-23","excerpt":"在redis中可以通过slaveof命令让一个服务器去复制另一个服务器，其中被复制的服务器叫做主服务器，对主服务器进行复制的叫做从服务器。graph LR A[从服务器] -->|复制| B(主服务器)旧版复制的实现redis的复制分为同步/命令传播两个操作 同步操作用于将从服务器的数据库状态更新至主服务器当前所处的数据库状态 命令传播操作则用于在主服务器的数据库状态被修改，导致主从服务器的数据库状态出现不一致时让主从服务器的数据库重新回到一致状态","tags":[]},{"title":"ubuntu修改为阿里云镜像源","text":"备份源文件 使用cp命令备份/etc/apt/sources.list文件 1sudo cp /etc/apt/sources.list /etc/apt/sources.list.bak 查看目前版本信息 1lsb_release -c 不同的版本的系统代号不同 版本 代号 Ubuntu 12.04 (LTS) precise Ubuntu 14.04 (LTS) trusty Ubuntu 15.04 vivid Ubuntu 15.10 wily Ubuntu 16.04 (LTS) xenial Ubuntu 18.04 (LTS) bionic 修改配置文件 12345678910111213141516171819deb http://mirrors.aliyun.com/ubuntu/ [代号] main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ [代号] main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ [代号]-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ [代号]-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ [代号]-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ [代号]-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ [代号]-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ [代号]-backports main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ [代号]-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ [代号]-proposed main restricted universe multiverse 更新列表 1apt-get update 注意update和upgrade区别：update是更新软件列表，upgrade是更新软件。","path":"2019/08/20/ubuntu修改为阿里云镜像源/","date":"08-20","excerpt":"备份源文件 使用cp命令备份/etc/apt/sources.list文件 1sudo cp /etc/apt/sources.list /etc/apt/sources.list.bak 查看目前版本信息 1lsb_release -c 不同的版本的系统代号不同 版本 代号 Ubuntu 12.04 (LTS) precise Ubuntu 14.04 (LTS) trusty Ubuntu 15.04 vivid Ubuntu 15.10 wily Ubuntu 16.04 (LTS) xenial Ubuntu 18.04 (LTS) bionic","tags":[{"name":"系统配置","slug":"系统配置","permalink":"https://jijiking51.cn/tags/系统配置/"}]},{"title":"redis学习wiki","text":"第一天了解redis的数据库，了解相似的缓存数据库，redis的局限redis数据库 非关系型数据库 以键(key)和值(value)做映射(mapping) value类型： string：字符串对象 list：列表对象 hash：哈希对象 set：集合对象 zset：有序集合对象 类型(前缀：REDIS)编码(前缀：REDIS_ENCODING)对象结构的读写能力STRINGINT(long类型整数)整数值实现字符串对象对整个字符串或者字符串的其一部分执行操作，对整数的浮点数执行自增或者自减操作STRINGEMBSTR(embstr编码的简单字符串)embstr编码的简单动态字符串实现的字符串对象STRINGRAW(简单动态字符串)动态字符串实现的字符串对象LISTZIPLIST(压缩列表)压缩列表实现的列表对象从链表的两端推入或者弹出元素，根据偏移量对链表进行修剪，读取单个或者多个元素，根据值查找或者移除元素LISTLINKEDLIST(双端链表)双端链表实现的列表对象HASHZIPLIST(压缩列表)压缩列表实现的哈希对象添加、获取、移除单个键值对，获取所有键值对HASHHT(字典)字典实现的哈希对象SETINTSET(整数集合)整数集合实现的集合对象添加、获取、移除单个元素，检查一个元素是否存在与集合，计算交集，并集，差集，从集合里面随机获取元素SETHT(字典)字典实现的集合对象ZSETZIPLIST(压缩列表)压缩列表实现的有序集合对象添加、获取、移除单个元素，根据分值范围或者成员来获取元素ZSETSKIPLIST(跳跃表和字典)跳跃表和字典实现的有序集合对象 可以将内存中的数据进行落盘 存储命令 save：主线程将数据快照存储为rdb，存储期间redis不接受其他请求 bgsave：fork一个子进程进行快照存储，存储期间redis可以处理其他请求 存储方式 时间点转储：在指定时间内进行了指定次数的操作即可开始转储 AOF存储：每条修改命令都追加写入AOF文件， 可以设置成每秒追加或者每一条都追加 读性能扩展： 利用复制特性，例如主从服务器进行读写分离 写性能扩张： 利用客户端分片， 例如 mod( hash(id), n) = x, 通过这个方法就可以得到id在n台服务器的情况下存储到第x服务器上 速度快：10QPS/s 内存操作 C语言实现，最接近底层 单线程架构，预防多线程可能产生问题 redis的精细打磨 相似类型数据库对比 名称 类型 数据存储选项 查询类型 附加功能 Redis 使用内存存储的NoSql 字符串、列表、集合、散列表、有序集合 每种数据类型都有自己的专属命令，另外还有批量操作和不完全的事物支持 发布与订阅，主从复制，持久化，脚本（存储过程） memcached 使用内存存储的键值缓存 键值字符串映射 创建、读取、更新、删除等命令 为提升性能而设的多线程服务器 mysql 关系数据库 每个数据库可以包含多个表，每个表可以包含多个行，可以处理多个表的视图，支持空间和第三方扩展 SELECT、INSERT、UPDATE、DELETE、函数、存储过程 支持ACID性质、主从复制和主主复制 postgreSql 关系数据库 每个数据库可以包含多个表，每个表可以包含多个行，可以处理多个表的视图，支持空间和第三方扩展，支持可定制类型 SELECT、INSERT、UPDATE、DELETE、内置函数、自定义的存储过程 支持ACID性质，主从复制，第三方支持的多复制 MongoDB 使用硬盘存储的非关系文档存储 每个数据库可以包含多个表，每个表可以包含多个无schema的BSON文档 创建命令、读取命令、更新命令、删除命令、条件查询命令等 支持map-reduce操作、主从复制、分片、空间索引 redis对比其他数据库优势 列表管理：拥有List和Set两种类型可以直接添加或者删除元素 数据存储： 原子的INCR命令及其变种来计算聚合数据，因为数据存储在内存中，不需要经过查询分析器或者查询优化器处理 避免写入不必要的临时数据，也免去对临时数据进行扫描或者删除的麻烦 redis用途 缓存 减缓后端压力，加快访问速度 排行版系统 redis提供列表和有序集合数据结构 计数器应用 高并发特性，支持计数功能 社交网络 数据结构多样，适应多种数据存储类型 消息队列系统 发布订阅和阻塞队列功能可以满足基本的消息队列功能 redis局限 大量数据的存储局限性 冷热数据处理——热数据应该放置内存中，冷数据不应该放在内存中浪费内存 输出一个redis实例的linux环境安装文档，包括安装步骤，配置，启动关闭等安装流程 下载源码 12345wget http://download.redis.io/releases/redis-5.0.5.tar.gz# wget工具可以通过以下命令安装apt-get install wget 解压 1tar -zxvf redis-5.0.0.tar.gz 编译 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152# 进入redis文件夹cd redis-5.0.5make# 测试是否正确make test# 报错1cd src &amp;&amp; make allmake[1]: Entering directory '/root/redis-5.0.5/src' CC adlist.o/bin/sh: 1: cc: not foundMakefile:248: recipe for target 'adlist.o' failedmake[1]: *** [adlist.o] Error 127make[1]: Leaving directory '/root/redis-5.0.5/src'Makefile:6: recipe for target 'all' failedmake: *** [all] Error 2# 报错原因[1]——没有安装gccapt-get install gcc# 报错2cd src &amp;&amp; make allmake[1]: Entering directory '/root/redis-5.0.5/src' CC adlist.oIn file included from adlist.c:34:0:zmalloc.h:50:10: fatal error: jemalloc/jemalloc.h: No such file or directory #include &lt;jemalloc/jemalloc.h&gt; ^~~~~~~~~~~~~~~~~~~~~compilation terminated.Makefile:248: recipe for target 'adlist.o' failedmake[1]: *** [adlist.o] Error 1make[1]: Leaving directory '/root/redis-5.0.5/src'Makefile:6: recipe for target 'all' failedmake: *** [all] Error 2# 报错原因[2]——关于分配器allocator， 如果有MALLOC 这个 环境变量， 会有用这个环境变量的 去建立Redis。而且libc 并不是默认的 分配器， 默认的是jemalloc, 因为 jemalloc被证明比libc有更少的 碎片问题 。但是如果你又没有jemalloc 而只有 libc 当然 make 出错。 make MALLOC=libc# 报错3You need tcl 8.5 or newer in order to run the Redis testmake:# 解决方法——安装tclapt-get install tcl 安装 1make install 配置文件翻译123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287######################### 引用 ########################## 不同redis server可以使用同一个模版配置作为主配置，并引用其它配置文件用于本server的个性# 化设置# include并不会被CONFIG REWRITE命令覆盖。但是主配置文件的选项会被覆盖。# 想故意覆盖主配置的话就把include放文件前面，否则最好放末尾# include /path/to/local.conf# include /path/to/other.conf######################### 网络 ########################## 不指定bind的话redis将会监听所有网络接口。这个配置是肯定需要指定的。# Examples:# bind 192.168.1.100 10.0.0.1# bind 127.0.0.1 ::1# 下面这个配置是只允许本地客户端访问。bind 127.0.0.1# 是否开启保护模式。默认开启，如果没有设置bind项的ip和redis密码的话，服务将只允许本地访 问。protected-mode yes# 端口设置，默认为 6379 # 如果port设置为0 redis将不会监听tcp socketport 6379# 在高并发环境下需要一个高backlog值来避免慢客户端连接问题。注意Linux内核默默将这个值减小到/proc/sys/net/core/somaxconn的值，所以需要确认增大somaxconn和tcp_max_syn_backlog 两个值来达到需要的效果。tcp-backlog 511# 指定用来监听Unix套套接字的路径。没有默认值，没有指定的情况下Redis不会监听Unix socket# unixsocket /tmp/redis.sock# unixsocketperm 700# 客户端空闲多少秒后关闭连接（0为不关闭）timeout 0# tcp-keepalive设置。如果非零，则设置SO_KEEPALIVE选项来向空闲连接的客户端发送ACK，用途如下：# 1）能够检测无响应的对端# 2）让该连接中间的网络设备知道这个连接还存活# 在Linux上，这个指定的值(单位秒)就是发送ACK的时间间隔。# 注意：要关闭这个连接需要两倍的这个时间值。# 在其他内核上这个时间间隔由内核配置决定# 从redis3.2.1开始默认值为300秒tcp-keepalive 300######################### 通用 ########################## 是否将Redis作为守护进程运行。如果需要的话配置成&apos;yes&apos;# 注意配置成守护进程后Redis会将进程号写入文件/var/run/redis.piddaemonize no# 是否通过upstart或systemd管理守护进程。默认no没有服务监控，其它选项有upstart, systemd, autosupervised no# pid文件在redis启动时创建，退出时删除。最佳实践为配置该项。pidfile /var/run/redis_6379.pid# 配置日志级别。选项有debug, verbose, notice, warningloglevel notice# 日志名称。空字符串表示标准输出。注意如果redis配置为后台进程，标准输出中信息会发送到/dev/nulllogfile &quot;&quot;# 是否启动系统日志记录。# syslog-enabled no# 指定系统日志身份。# syslog-ident redis# 指定syslog设备。必须是user或LOCAL0 ~ LOCAL7之一。# syslog-facility local0# 设置数据库个数。默认数据库是 DB 0# 可以通过SELECT where dbid is a number between 0 and &apos;databases&apos;-1为每个连接使用不同的数据库。databases 16######################### 备份 ########################## 持久化设置:# 下面的例子将会进行把数据写入磁盘的操作:# 900秒（15分钟）之后，且至少1次变更# 300秒（5分钟）之后，且至少10次变更# 60秒之后，且至少10000次变更# 不写磁盘的话就把所有 &quot;save&quot; 设置注释掉就行了。# 通过添加一条带空字符串参数的save指令也能移除之前所有配置的save指令，如: save &quot;&quot;save 900 1save 300 10save 60 10000# 默认情况下如果上面配置的RDB模式开启且最后一次的保存失败，redis 将停止接受写操作，让用户知道问题的发生。# 如果后台保存进程重新启动工作了，redis 也将自动的允许写操作。如果有其它监控方式也可关闭。stop-writes-on-bgsave-error yes# 是否在备份.rdb文件时是否用LZF压缩字符串，默认设置为yes。如果想节约cpu资源可以把它设置为no。rdbcompression yes# 因为版本5的RDB有一个CRC64算法的校验和放在了文件的末尾。这将使文件格式更加可靠,# 但在生产和加载RDB文件时，这有一个性能消耗(大约10%)，可以关掉它来获取最好的性能。# 生成的关闭校验的RDB文件有一个0的校验和，它将告诉加载代码跳过检查rdbchecksum yes# rdb文件名称dbfilename dump.rdb# 备份文件目录，文件名就是上面的 &quot;dbfilename&quot; 的值。累加文件也放这里。# 注意你这里指定的必须是目录，不是文件名。dir /your data path/######################### 主从同步 ########################## 主从同步配置。# 1) redis主从同步是异步的，但是可以配置在没有指定slave连接的情况下使master停止写入数据。# 2) 连接中断一定时间内，slave可以执行部分数据重新同步。# 3) 同步是自动的，slave可以自动重连且同步数据。# slaveof &lt;masterip&gt; &lt;masterport&gt;# master连接密码# masterauth &lt;master-password&gt;# 当一个slave失去和master的连接，或者同步正在进行中，slave的行为有两种可能：# 1) 如果 slave-serve-stale-data 设置为 &quot;yes&quot; (默认值)，slave会继续响应客户端请求，可能是正常数据，也可能是还没获得值的空数据。# 2) 如果 slave-serve-stale-data 设置为 &quot;no&quot;，slave会回复&quot;正在从master同步（SYNC with master in progress）&quot;来处理各种请求，除了 INFO 和 SLAVEOF 命令。slave-serve-stale-data yes# 你可以配置salve实例是否接受写操作。可写的slave实例可能对存储临时数据比较有用(因为写入salve# 的数据在同master同步之后将很容被删除)，但是如果客户端由于配置错误在写入时也可能产生一些问题。# 从Redis2.6默认所有的slave为只读# 注意:只读的slave不是为了暴露给互联网上不可信的客户端而设计的。它只是一个防止实例误用的保护层。# 一个只读的slave支持所有的管理命令比如config,debug等。为了限制你可以用&apos;rename-command&apos;来隐藏所有的管理和危险命令来增强只读slave的安全性。slave-read-only yes# 同步策略: 磁盘或socket，默认磁盘方式repl-diskless-sync no# 如果非磁盘同步方式开启，可以配置同步延迟时间，以等待master产生子进程通过socket传输RDB数据给slave。# 默认值为5秒，设置为0秒则每次传输无延迟。repl-diskless-sync-delay 5# slave根据指定的时间间隔向master发送ping请求。默认10秒。# repl-ping-slave-period 10# 同步的超时时间# 1）slave在与master SYNC期间有大量数据传输，造成超时# 2）在slave角度，master超时，包括数据、ping等# 3）在master角度，slave超时，当master发送REPLCONF ACK pings# 确保这个值大于指定的repl-ping-slave-period，否则在主从间流量不高时每次都会检测到超时# repl-timeout 60# 是否在slave套接字发送SYNC之后禁用 TCP_NODELAY# 如果选择yes，Redis将使用更少的TCP包和带宽来向slaves发送数据。但是这将使数据传输到slave上有延迟，Linux内核的默认配置会达到40毫秒。# 如果选择no，数据传输到salve的延迟将会减少但要使用更多的带宽。# 默认我们会为低延迟做优化，但高流量情况或主从之间的跳数过多时，可以设置为“yes”。repl-disable-tcp-nodelay no# 设置数据备份的backlog大小。backlog是一个slave在一段时间内断开连接时记录salve数据的缓冲，所以一个slave在重新连接时，不必要全量的同步，而是一个增量同步就足够了，将在断开连接的这段# 时间内把slave丢失的部分数据传送给它。# 同步的backlog越大，slave能够进行增量同步并且允许断开连接的时间就越长。# backlog只分配一次并且至少需要一个slave连接。# repl-backlog-size 1mb# 当master在一段时间内不再与任何slave连接，backlog将会释放。以下选项配置了从最后一个# slave断开开始计时多少秒后，backlog缓冲将会释放。# 0表示永不释放backlog# repl-backlog-ttl 3600# slave的优先级是一个整数展示在Redis的Info输出中。如果master不再正常工作了，sentinel将用它来选择一个slave提升为master。# 优先级数字小的salve会优先考虑提升为master，所以例如有三个slave优先级分别为10，100，25，sentinel将挑选优先级最小数字为10的slave。# 0作为一个特殊的优先级，标识这个slave不能作为master，所以一个优先级为0的slave永远不会被# sentinel挑选提升为master。# 默认优先级为100slave-priority 100# 如果master少于N个延时小于等于M秒的已连接slave，就可以停止接收写操作。# N个slave需要是“oneline”状态。# 延时是以秒为单位，并且必须小于等于指定值，是从最后一个从slave接收到的ping（通常每秒发送）开始计数。# 该选项不保证N个slave正确同步写操作，但是限制数据丢失的窗口期。# 例如至少需要3个延时小于等于10秒的slave用下面的指令：# min-slaves-to-write 3# min-slaves-max-lag 10# 两者之一设置为0将禁用这个功能。# 默认 min-slaves-to-write 值是0（该功能禁用）并且 min-slaves-max-lag 值是10。######################### 安全 ########################## 要求客户端在处理任何命令时都要验证身份和密码。# requirepass foobared# 命令重命名# 在共享环境下，可以为危险命令改变名字。比如，你可以为 CONFIG 改个其他不太容易猜到的名字，这样内部的工具仍然可以使用。# 例如：# rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52# 也可以通过改名为空字符串来完全禁用一个命令# rename-command CONFIG &quot;&quot;# 请注意：改变命令名字被记录到AOF文件或被传送到从服务器可能产生问题。######################### 限制 ########################## 设置最多同时连接的客户端数量。默认这个限制是10000个客户端，然而如果Redis服务器不能配置# 处理文件的限制数来满足指定的值，那么最大的客户端连接数就被设置成当前文件限制数减32（因为Redis服务器保留了一些文件描述符作为内部使用）# 一旦达到这个限制，Redis会关闭所有新连接并发送错误&apos;max number of clients reached&apos;# maxclients 10000# 不要使用比设置的上限更多的内存。一旦内存使用达到上限，Redis会根据选定的回收策略（参见：maxmemmory-policy）删除key。# 如果因为删除策略Redis无法删除key，或者策略设置为 &quot;noeviction&quot;，Redis会回复需要更多内存的错误信息给命令。例如，SET,LPUSH等等，但是会继续响应像Get这样的只读命令。# 在使用Redis作为LRU缓存，或者为实例设置了硬性内存限制的时候（使用 &quot;noeviction&quot; 策略）的时候，这个选项通常事很有用的。# 警告：当有多个slave连上达到内存上限时，master为同步slave的输出缓冲区所需内存不计算在使用内存中。这样当移除key时，就不会因网络问题 / 重新同步事件触发移除key的循环，反过来slaves的输出缓冲区充满了key被移除的DEL命令，这将触发删除更多的key，直到这个数据库完全被清空为止。# 总之，如果你需要附加多个slave，建议你设置一个稍小maxmemory限制，这样系统就会有空闲的内存作为slave的输出缓存区(但是如果最大内存策略设置为&quot;noeviction&quot;的话就没必要了)# maxmemory &lt;bytes&gt;# 最大内存策略：如果达到内存限制了，Redis如何选择删除key。# volatile-lru -&gt; 根据LRU算法删除设置过期时间的key# allkeys-lru -&gt; 根据LRU算法删除任何key# volatile-random -&gt; 随机移除设置过过期时间的key# allkeys-random -&gt; 随机移除任何key# volatile-ttl -&gt; 移除即将过期的key(minor TTL)# noeviction -&gt; 不移除任何key，只返回一个写错误# 注意：对所有策略来说，如果Redis找不到合适的可以删除的key都会在写操作时返回一个错误。# 目前为止涉及的命令：set setnx setex append incr decr rpush lpush rpushx lpushx linsert lset rpoplpush sadd sinter sinterstore sunion sunionstore sdiff sdiffstore zadd zincrby zunionstore zinterstore hset hsetnx hmset hincrby incrby decrby getset mset msetnx exec sort# 默认策略:# maxmemory-policy noeviction# LRU和最小TTL算法的实现都不是很精确，但是很接近（为了省内存），所以你可以用样本量做检测。 例如：默认Redis会检查3个key然后取最旧的那个，你可以通过下面的配置指令来设置样本的个数。# 默认值为5，数字越大结果越精确但是会消耗更多CPU。# maxmemory-samples 5######################### APPEND ONLY MODE ########################## 默认情况下，Redis是异步的把数据导出到磁盘上。这种模式在很多应用里已经足够好，但Redis进程出问题或断电时可能造成一段时间的写操作丢失(这取决于配置的save指令)。# AOF是一种提供了更可靠的替代持久化模式，例如使用默认的数据写入文件策略（参见后面的配置）。# 在遇到像服务器断电或单写情况下Redis自身进程出问题但操作系统仍正常运行等突发事件时，Redis能只丢失1秒的写操作。# AOF和RDB持久化能同时启动并且不会有问题。# 如果AOF开启，那么在启动时Redis将加载AOF文件，它更能保证数据的可靠性。appendonly no# AOF文件名（默认：&quot;appendonly.aof&quot;）appendfilename &quot;appendonly.aof&quot;# fsync() 系统调用告诉操作系统把数据写到磁盘上，而不是等更多的数据进入输出缓冲区。# 有些操作系统会真的把数据马上刷到磁盘上；有些则会尽快去尝试这么做。# Redis支持三种不同的模式：# no：不要立刻刷，只有在操作系统需要刷的时候再刷。比较快。# always：每次写操作都立刻写入到aof文件。慢，但是最安全。# everysec：每秒写一次。折中方案。# 默认的 &quot;everysec&quot; 通常来说能在速度和数据安全性之间取得比较好的平衡。# appendfsync alwaysappendfsync everysec# appendfsync no# 如果AOF的同步策略设置成 &quot;always&quot; 或者 &quot;everysec&quot;，并且后台的存储进程（后台存储或写入AOF 日志）会产生很多磁盘I/O开销。某些Linux的配置下会使Redis因为 fsync()系统调用而阻塞很久。# 注意，目前对这个情况还没有完美修正，甚至不同线程的 fsync() 会阻塞我们同步的write(2)调用。# 为了缓解这个问题，可以用下面这个选项。它可以在 BGSAVE 或 BGREWRITEAOF 处理时阻止fsync()。# 这就意味着如果有子进程在进行保存操作，那么Redis就处于&quot;不可同步&quot;的状态。# 这实际上是说，在最差的情况下可能会丢掉30秒钟的日志数据。（默认Linux设定）# 如果把这个设置成&quot;yes&quot;带来了延迟问题，就保持&quot;no&quot;，这是保存持久数据的最安全的方式。no-appendfsync-on-rewrite no# 自动重写AOF文件。如果AOF日志文件增大到指定百分比，Redis能够通过 BGREWRITEAOF 自动重写AOF日志文件。# 工作原理：Redis记住上次重写时AOF文件的大小（如果重启后还没有写操作，就直接用启动时的AOF大小）# 这个基准大小和当前大小做比较。如果当前大小超过指定比例，就会触发重写操作。你还需要指定被重写日志的最小尺寸，这样避免了达到指定百分比但尺寸仍然很小的情况还要重写。# 指定百分比为0会禁用AOF自动重写特性。auto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mb# 如果设置为yes，如果一个因异常被截断的AOF文件被redis启动时加载进内存，redis将会发送日志通知用户。如果设置为no，erdis将会拒绝启动。此时需要用&quot;redis-check-aof&quot;工具修复文件。aof-load-truncated yes######################### 集群 ########################## 只有开启了以下选项，redis才能成为集群服务的一部分# cluster-enabled yes# 配置redis自动生成的集群配置文件名。确保同一系统中运行的各redis实例该配置文件不要重名。# cluster-config-file nodes-6379.conf# 集群节点超时毫秒数。超时的节点将被视为不可用状态。# cluster-node-timeout 15000# 如果数据太旧，集群中的不可用master的slave节点会避免成为备用master。如果slave和master失联时间超过:(node-timeout * slave-validity-factor) + repl-ping-slave-period则不会被提升为master。# 如node-timeout为30秒，slave-validity-factor为10, 默认default repl-ping-slave-period为10秒,失联时间超过310秒slave就不会成为master。# 较大的slave-validity-factor值可能允许包含过旧数据的slave成为master，同时较小的值可能会阻止集群选举出新master。#为了达到最大限度的高可用性，可以设置为0，即slave不管和master失联多久都可以提升为master# cluster-slave-validity-factor 10# 只有在之前master有其它指定数量的工作状态下的slave节点时，slave节点才能提升为master。默认为1（即该集群至少有3个节点，1 master＋2 slaves，master宕机，仍有另外1个slave的情况下其中1个slave可以提升）# 测试环境可设置为0，生成环境中至少设置为1# cluster-migration-barrier 1# 默认情况下如果redis集群如果检测到至少有1个hash slot不可用，集群将停止查询数据。# 如果所有slot恢复则集群自动恢复。# 如果需要集群部分可用情况下仍可提供查询服务，设置为no。# cluster-require-full-coverage yes######################### 慢查询日志 ########################## 慢查询日志，记录超过多少微秒的查询命令。查询的执行时间不包括客户端的IO执行和网络通信时间，只是查询命令执行时间。# 1000000等于1秒，设置为0则记录所有命令slowlog-log-slower-than 10000# 记录大小，可通过SLOWLOG RESET命令重置slowlog-max-len 128 启动与关闭redis 建立redis数据存储目录 1mkdir /root/redis_data 建立redis日志存储目录 1mkdir /root/redis_log 修改配置文件中的数据存储路径和日志存储路径 启动redis 1redis-server /root/redis-5.0.5/redis.conf 连接并关闭 1234567891011# 方法1redis-cli -h [ip] -p [port]shutdown [command]# 方法2redis-cli -h [ip] -p [port] shutdown [command]# command 是可选参数save：持久化数据nosave： 不持久化数据 第二天全局命令 查看所有键值 1234keys *# 生产环境中可能会有很多键值，这个命令不要用 键总数 1dbsize 检查键是否存在 1exists key 删除键 1del key [key ...] 设置过期时间 1expire key seconds 获取键过期剩余时间 12345ttl key# 大于0 代表过期剩余时间# -1 没有设置过过期时间# -2 键不存在 键的数据结构类型 123type key# 如果键不存在返回none 字符串命令 设置值 1234567set key value [ex seconds] [px milliseconds] [nx | xx]# 同时有setnx 和 setex两个命令setnx = set key value nxsetex = set key value ex# setnx 可以用于分布式锁， 因为redis是单线程处理机制， setnx key value 命令只会有一个用户设置成功 ex seconds: 设置过期时间，秒 px milliseconds: 设置过期时间， 毫秒 nx: 键必须不存在才能被设置成功，用于添加 xx: 键必须存在才能被设置成功，用于更新 获取值 1get key 批量设置值 1mset key value [key value ...] 批量获取值 1mget key [key ...] 计数 123456789101112131415161718# 整数自增加1incr key# 整数自减减1decr key# 整数自增指定数incrby key increment# 整数自减指定数 decrby key decrement# 自增浮点数 如果要减就设置负数incrbyfloat key increment# 情况1. 值不是整数， 返回错误# 情况2. 键不存在， 按照值为0， 自增# 情况3. 值是整数，返回自增后结果 追加值 1append key value 字符串字节长度 1234strlen key# 如果key不存在返回0# 中文占三个字节， 所以一个中文长度为3 设置并返回值 12345getset key value# 首先获取这个key目前的内容值# 然后设置这个key的值为value# 如果没有这个key 则返回值为nil， 否则为设置之前获取的值 设置指定位置的字符 123setrange key offeset value# 指定位置的字符会被替换， 如果指定的offeset大于目前字符串长度，中间缺少的长度会用\\x00填充 获取部分字符串 123getrange key start end# 如果start为负数将从最后开始计数 哈希 设置值 1234hset key field value# 哈希操作也提供了hsetnx命令，和string操作中的setnx用法相同只是vulue变成field 获取值 1hget key field 删除field 123hdel key field [field ...]# 返回的数字是删除个数 计算field个数 1hlen key 批量设置获取field-value 12hmget key field [field ...]hmset key field value [field value ...] 判断field是否存在 1hexists key field 获取所有field 1hkey key 获取所有的value 1hvals key 获取所有的field-value 123hgetall key# hgetall如果field过多会导致阻塞， 如果要获取全部用hscan命令， hscan会渐进式遍历哈希 哈希计数 1234567hincrby key fieldhicrbyfloat key field# hincrby 等同于 incrby# hincrbyfloat 等同于 incrby 计算value的字符串长度 1hstrlen key field 列表添加操作 从右边插入元素 1rpush key value [value ...] 从左边插入元素 1lpush key value [value ...] 向第一个相同元素的前或者后插入元素 123linsert key before|after pivot value# linsert 只会匹配第一个相同的pivot， 修改成功后就会借书 查找 获取指定范围内的元素列表 1234lrange key start end# 从左到右获取是0 —— n-1， 从右到左获取是 -1 到 -n，， 获取所有的内容 lrange key 0 -1# lrange的start和end都包括了自身 获取列表指定索引下标的元素 1234lindex key index# index &gt;= 0 从左往右# index &lt; 0 从右往左 获取列表长度 1llen key 删除 从左往右删除 1lpop key 从右往左删除 1rpop key 删除指定元素 12345lrem key count value# count&gt;0 从左往右删除最多count个匹配的结果# count&lt;0 从右往左删除最多count个匹配的结果# count=0 删除所有匹配的结果 按照索引范围修剪列表 123ltrim key start end# 只会保留start 到 end 的内容， 如果这个范围为空， 则列表也会为空 修改 修改指定索引下标的元素 123lset key index value# 如果这个key 或者index 超过这个list的长度，会报错 阻塞操作 12345678910blpop key [key ... ] timeoutbrpop key [key ... ] timeout# 阻塞操作是弹出操作的阻塞版本# timeout 是阻塞的时间# 如果列表不为空会立马返回# 如果列表为空， 那么就要将阻塞timeout时间， 当timeout=0时会一直阻塞# 如果在阻塞期间添加了数据，阻塞端会立即返回数据# 如果是多个key， 那么阻塞期间会从左至右遍历key， 一旦有一个key不为空则立马返回# 如果是多个客户端同时阻塞获取同一个key， 会按照请求的时间顺序返回，先来先服务 集合集合内操作 添加元素 1sadd key element [element ...] 删除元素 1srem key element [element ...] 计算元素个数 1scard key 判断元素是否在集合中 1sismember key element 随机从集合返回指定个数元素 1srandmember key [count] # count不写 默认为1 从集合随机弹出元素 1spop key [count] # count不写 默认为1 获取所有元素 12smembers key# 返回结果是无序结果 集合间操作 求多个集合的交集 1sinter key [key ...] 求多个集合的并集 1sunion key [key ...] 求多个集合的差集 1sdiff key [key ...] 将交集、并集、差集的结果保存 12345678sinterstore destination key [key ...]sunionstore destination key [key ...]sdiffstore destination key [key ...]# 命令=原命令+store# destination： 给结果value一个key名称# key [key ...] :需要进行的操作集合 有序集合集合内 添加成员 123456789zadd key score member [score member ...]# zadd 后有四个可选项# nx：member必须不存在才可以设置成功，用于添加# xx：member必须存在才可以设置成功， 用于修改# ch：返回此次操作后有序集合元素和分数发生变化的个数# incr：对score做增加，相当于zincrby# add的时间复杂度为log n 计算成员个数 1zcard key 获取某个成员的分数 1zscore key member 计算某个成员的排名 1234567zrank key memberzrevrank key member# zrank 是从低到高# zrevrank 是从高到低# 第一位是0， 没找到为nil 删除成员 1zrem key member [member ...] 增加成员的分数 1234zincrby key increment member# increment：增加的分数# 如果key不存在则会添加这个key，并将increment设置为初始分数 返回指定排名范围的成员 12345zrange key start end [withscores]zrevrange key start end [withscores]# zrange从低到高， zrevrange从高到低# 如果加上withscores会加上分数一并返回 返回指定分数范围的成员 12345zrangebyscore key min max [withscores] [limit offset count]zrevrangebyscore key min max [withscores] [limit offset count]# zrangebyscore从低到高， zrevrangebyscore 从高到低# min 和 max 表示 min &lt;= score &lt;= max, 如果想使用开区间， 也就是 min &lt; score &lt;= max 可以使用小括号， 即 (min max, 如果想表达无限， 使用负无穷 -inf， 正无穷+inf 返回指定分数范围成员个数 1zcount key min max 删除指定排名内的升序元素 1zremrangebyrank key start end 删除指定分数范围的成员 1zremrangebyscore key min max 集合间的操作 交集 1234567zinterstore destination numkeys key [key ...] [weights weight [weight ...]] [aggregate sum | min | max]# destination 交集计算结果保存到这个键# numkeys 需要做交集计算键的个数# key [key ...]# weights weight [weight ...] 每个键的权重，在做交集计算时，每个键中的每个member会将自己分数乘以这个权重， 每个键的权重默认是1# aggregate sum | min | max :计算成员交集后，分值可以按照sum， min， max做汇总，默认值是sum 并集 123zunionstore destination numkeys key [key ... ] [weights weight [weight ...]] [ aggregate sum|min|max ]# 命令参数与zinsertstore一致 HyperLogLog命令HyperLogLog是用来做基数统计的算法，HyperLogLog的优点是在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定的，并且很小很小，只需要12KB内存就可以计算接近2^64个不同元素的基数，但是HyperLogLog只能依据输入的元素算出基数，而不能向set一样输出 添加基数 123pfadd key element [element ...]# 如果HyperLogLog更改了就返回1 否则返回0 返回近似基数 1234pfcount key [key ...]# 返回的基数并不是精确值， 而是一个带有0.81%标准错误，所以这个只能返回近似值 合并HyperLogLog 123pfmerge destkey sourcekey [sourcekey ...]# 合并后保存的名称 sourcekey需要合并的key 第三天复制原理redis主从复制 第四天redis的持久化rdb和aof的方式各自怎么配置开启RDB12345678910111213141516save 900 1save 300 10save 60 10000dbfilename xxxx# 分别表示每900秒进行了1次修改操作则进行RDB快照保存每300秒进行了10次修改操作则进行RDB快照保存每60秒进行了10000次修改操作则进行RDB快照保存保存的名称为xxxx# RDB没有载入命令， 服务器启动时检测到有RDB文件就会自动载入# 载入时日志输出 DB loaded from disk：.... AOF123456789appendonly yesappendfilename xxxx# 第一个参数表示开启AOF# 第二个参数表示AOF文件的名称# AOF保存的路径和dir配置的一致。# 因为AOF文件更新频率通常比RDB文件的更新频率高，所以如果服务器开启了AOF持久化功能，那么服务器就会优先使用AOF文件来还原数据库数据# 只有在AOF持久化功能关闭状态时，服务器才会使用RDB文件来还原数据库状态 各自的特点是什么，持久化的过程RDB持久化流程graph TB A(bgsave) -->|1| B(父进程) B-->C(有其他子进程正在执行,直接返回) style C fill:#cec,stroke:#f66,stroke-width:2px,stroke-dasharray: 5, 5; B-->H(BGREWRITEAOF正在执行,拒绝此次BGSVE) style H fill:#dec,stroke:#f66,stroke-width:2px,stroke-dasharray: 5, 5; B-->|2| D(fork) D--> E(子进程) D -->|3| F((响应其他命令)) E -->|4| G(生成RDB文件) E-->|5信号通知父进程| B I(发送BGREWRITEAOF命令)-->|冲突命令|F F-->|冲突解决|J(BGSAVE命令结束后再继续执行BGREWRITEAOF) 如果已经存在RDB/AOF子进程则直接返回 fork过程父进程会阻塞，通过info stats命令查看latest_fork_usec可以看到最近一次fork耗时多少微秒 fork完成后会返回Background saving started信息，并不在阻塞 创建RDB文件，根据父进程内存生成临时快照文件，完成后对原有文件进行原子替换。执行lastsave命令可以得到上次生成RDB的时间，对应Info Persistence命令中的rdb_last_save_time参数 进程发送信号给父进程表示完成， 父进程更新info Persistence 关于rdb_*的统计信息 文件的处理RDB文件保存在dir配置指定的目录下，文件名和dbfilename配置相同，可以通过config set dir{newDir} / config set dbfilename {newFileName}在运行期间动态更新配置。 RDB文件默认使用LZF算法进行压缩，压缩后的文件大小远远小于内存中的大小，可以通过修改rdbcompression参数修改，或者执行命令config set rdbcompression {yes|no}动态修改 优缺点优点： 是一个紧凑压缩的二进制文件，代表Redis在某个时间点上的数据快照，适用于备份， 全量复制等场景 加载RDB恢复的速度远远快于AOF 缺点： 没有办法做到实时持久化\\秒级持久化。因为bgsave每次运行都要fork子进程，频繁操作成本过高 RDB文件使用二进制格式保存，Redis版本演进过程中有多个redis格式版本，存在新老版本不兼容问题 RDB文件结构123456789|REDIS|db_version|databases|EOF|check_sum|REDIS:长度为5字节的‘REDIS’五个字符，用于快速检查所有载入的文件是否RDB文件db_version:长度为4字节，他的值是一个字符串表示的整数，这个是整数记录了RDB文件的版本号，比如0006，就代表RDB文件的版本为第六版databases：包含着0个或者任意多个数据库，以及各个数据库中的键值对数据 如果服务器数据库状态为空，那么这个部分也为空，长度为0字节 如果服务器有至少一个数据库非空，那么这个部分也非空，根据数据库所保存键值对的数量，类型和内容不同， 这个部分的长度也有所不同EOF：常量的长度为1字节，这个常量标志者RDB文件正文内容的借书，当读入程序遇到这个值的时候他知道所有数据库的所有键值对都已经载入完毕了check_sum:是一个8字节长的无符号整数，保存着一个校验和，这个校验和是程序通过对REDIS，db_version, databases,EOF四个部分的内容进行计算得出的。服务器在载入RDB文件时，会将再如数据所计算出的校验与check_sum所记录的校验和进行对比，以此来检测是否有出错或者损坏情况 databases部分如果一个数据库0/3非空，那么服务器将创建一个以下结构的RDB文件 1|REDIS|db_version|database 0|database 3|EOF|check_sum| 每个databases部分都是以下三个部分 123456789|SELECTDB | db_number | key_value_pairs|SELECTDB: 常亮长度为1字节，当读入程序遇到这个值的时候知道接下来要读入的将是一个数据库号码db_number: 保存者一个数据库号码，根据号码的大小不同，这个部分的长度可以是1字节，2字节，5字节。当程序读入db_number部分之后，服务器会调用select命令根据读入的数据库号码进行数据库切换，使得之后读入的键值对可以载入到正确的数据库中key_value_pairs: 部分保存了数据库中所有键值对数据，如果键值对带有过期时间，那么过期时间也会和键值对保存在一起，根据键值对的数量、类型、内容、以及是否过期等条件不同，key_value_pairs部分的长度也会有所不同所以上面这个例子的结构又可以是|REDIS|db_version|SELECTDB | 0 | key_value_pairs|SELECTDB | 3 | key_value_pairs|EOF|check_sum| key_value_pairs部分key_value_pairs结构 1234567891011121314151617181920212223不带过期时间的键值对|TYPE|KEY|VALUE|TYPE： REDIS_RDB_TYPE_STRING REDIS_RDB_TYPE_LIST REDIS_RDB_TYPE_SET REDIS_RDB_TYPE_ZSET REDIS_RDB_TYPE_HASH REDIS_RDB_TYPE_LIST_ZIPLIST REDIS_RDB_TYPE_SET_INTSET REDIS_RDB_TYPE_ZSET_ZIPLIST REDIS_RDB_TYPE_HASH_ZIPLISTKEY: 是一个字符串对象，编码方式和REDIS_RDB_TYPE_STRING类型的value一样，根据内容长度不同， key长度也有所不同VALUE：根据保存的结构不同， 保存的形式和长度都会有所不同带有过期时间的键值对|EXPIRETIME_MS|ms|TYPE|KEY|VALUE|EXPIRETIME_MS: 常量长度，告知读入程序接下来读入的将是一个以毫秒为单位的过期时间ms:是一个8字节的带符号整数，记录一个以毫秒为单位的unix时间戳，这个时间戳是这个键的过期时间 value编码每个value部分都保存了一个值对象, 根据TYPE不同，value部分的结构长度也不同 REDIS_ENCODING_*编码 字符串对象 如果TYPE的值为REDIS_RDB_TYPE_STRING, 那么value保存的就是一个字符串对象，字符串对象的编码可以是REDIS_ENCODING_INT, REDIS_ENCODING_RAW。 如果字符串对象的编码为REDIS_ENCODING_INT，那么说明对象中保存的是长度不超过32位的整数，这种编码的对象以以下格式保存 1234|ENCODING|content|# 例如 用8位保存的整数123| REDIS_RDB_ENC_INT8 | 123 | 如果字符串编码为REDIS_ENCODING_RAW，那么说明保存的是一个字符串，根据长度不同，有压缩和不压缩两种方式保存（手动关闭压缩选项情况除外） 如果字符串的长度小于20字节，那么这个字符串将原样保存 如果这个字符串长度大于20字节， 那么这个字符串会被压缩保存 如果没有被压缩将以下格式保存 1234| len | string |# 例如 ”hello“| 5 | hello | 如果压缩后将按照以下格式保存 123456789| REDIS_RDB_ENC_LZF | compressed_len | orgin_len | compressed_string |REDIS_RDB_ENC_LZF:标志字符串已经被LZF算法压缩过了compressed_len：被压缩之后长度orgin_len：原来的长度compressed_string： 被压缩后的字符串内容# 例如| REDIS_RDB_ENC_LZF | 6 | 21 | ?aa??? | 列表对象 如果TYPE的值是REDIS_RDB_TYPE_LIST，那么value保存的就是一个REDIS_ENCODING_LINKEDLIST编码的列表对象，RDB文件保存这种对象的结构 1234567| list_length | item1 | item2 | ... | itemn|# list_length记录了列表的长度， 记录列表item的个数# 因为item项都是字符串对象，所以程序会以处理字符串对象的方式来保存读入列表项# 示例 一个list中有三个项 hello world ！|3|5|hello|5|world|1|!| 集合对象 当TYPE为REDIS_RDB_TYPE_SET，那么value保存的就是一个REDIS_ENCODING_HT编码的集合对象，RDB文件保存这种对象结构图 1234567| set_size | elem1 | elem2 | ... | elemN |set_size:表示集合的大小，记录了有多少个elem对象elem：表示集合元素，因为每个集合元素都是一个字符串对象，所以程序会以处理字符串对象的方式来保存和读入集合元素# 示例 集合中有四个对象 apple banana cat dog| 4 | 5 | apple | 6 | banana | 3 | cat | 3 | dog | 哈希表对象 当TYPE为REDIS_RDB_TYPE_HASH, 那么value保存的就是一个REDIS_ENCODING_HT, 结构如下 123456789| hash_size | key_value_pair 1 | key_value_pair 2 | ... | key_value_pair n |hash_size: 记录了哈希表的大小key_value_pair： 开头部分代表哈希表中的键值对，键值对都是字符串对象，所以程序会已处理字符串对象的方式来保存和读入键值对key_value_pair：存储格式 |key1|value1|key2|value2|...|keyn|valuen|# 示例 两个键值对 a apple b banana| 2 | 1 | a | 5 | apple | 1 | b | 6 | bannana | 有序集合对象 当TYPE为REDIS_RDB_TYPE_ZSET，那么value保存的就是一个REDIS_ENCODING_SKIPLIST编码的有序集合对象， 结构如下 12345678910| sorted_set_size | element1 | element2 | ... | elementN | sorted_set_size:记录有序集合数量element： 分成两个部分， 一个为score， 另一个member， memeber是一个字符串对象，score是一个double类型的浮点数，但是程序会在转换的时候将double转换成字符串对象， 然后再用保存字符串对象的方法将score和member保存起来| sorted_set_size | member1 | score1 | member2 | score2 | ... | memberN | scoreN | # 示例 有序集合含有两个对象 pi 3.14 e 2.7| 2 | 2 | pi | 4 | 3.14 | 1 | e | 3 | 2.7 | INTSET编码集合 如果TYPE的值为REDIS_RDB_TYPE_SET_INTSET, 那么value保存的就是一个整数集合对象.RDB文件保存这种对象的方法是,先将整数集合转换为宇符串对象，然后将这个字符串对象保存到RDB文件里面。如果程序在读入RDB文件的过程中，碰到由整数集合对象转换成的宇符串对象，那么程序会根据TYPE值的指示.先读人字符串对象，再将这个宇符串对象转换成原来的整数集合对象。 ZIPLIST编码的列表、哈希表或者有序集合如果 TYPE 的值为 REDIS_RDB_TYPE_LIST_ZIPLIST、 REDIS_RDB_TYPE_HASH _ZIPLIST 或者 REDIS_RDB_TYPE_SET_ZIPLIST,那么 value 保存的就是一个压縮列表对象，RDB文件保存这种对象的方法是： 将压缩列表转换成一个宇符串对象。 将转换所得的字符串对象保存到RDB文件。 如果程序在读人RDB文件的过程中，碰到由任缩列表对象转换成的宇符串对象，那么程序会根据TYPE值的指示，执行以下操作： 读入字符串对象，并将它转换成原来的压缩列表对象 根据TYPE的值，设置压缩列表对象的类型：如果TYPE的值为REDIS_RDB_ TXPE_LIST_ZIPLIST,那么压缩列表对象的类型为列表 ；如果TYPE的值为REDIS _ RDB_TYPE_HASH_ZIPLIST,那么压缩列表对象的类型为哈希表；如果TYPE的值为 REDIS_RDB_TYPE_ZSET_ZIPLIST,那么压缩列表对象的类型为有序集合。 从步骤2可以看出，由于TYPE的存在，即使列表 、哈希表和有序集合三种类型都使用压缩列表来保存，RDB读入程序也总可以将读入并转换之后得出的压缩列表设置成原来的类型。 AOF持久化流程graph TB A(命令写入) -->|1.append| B(AOF缓冲) B-->|2.sync|C(AOF文件) C-->|3.rewrite|C D(重启)-->|4.load|C 所有的写入命令会追加到aof_buf（缓冲区) AOF缓冲区根据对应的策略向硬盘做同步操作 随着AOF文件越来越大，需要定期对AOF文件进行重写，达到压缩的目的 当redis服务器重启时，可以加载AOF文件进行数据恢复 命令写入rdb和aof持久化和写盘的触发机制设置， 手动触发持久化的方法RDB手动触发命令：save和bgsave save：阻塞当前Redis服务器，直到RDB过程完成位置，对于内存比较大的实例会造成长时间阻塞，线上环境不建议使用，save命令对应的Redis日志 DB saved on disk bgsave：Redis进程fork操作创建子进程，RDB持久化过程由子进程负责，完成后自动结束。阻塞只发生在fork阶段，一般时间很短。运行bgsave命令对应的Redis日志 Background saving started by pid xxxx DB saved on disk RDB: 0 MB of memory used by copy-on-write Background saving terminated with success 自动触发RDB机制 使用save相关配置save m n ,在m秒内数据集存在n次修改时，自动触发bgsave 从节点执行全量复制操作，主节点自动执行bgsave生成RDB 执行debug reload命令重新加载redis时会自动触发save操作 默认情况下执行shutdown命令时， 如果没有开启AOF持久化功能，则自动执行bgsave 设置保存条件在redisServer结构中saveparams属性保存了条件数组 123456struct redisServer&#123; // ... //保存条件数组 struct saveparam *saveparams; // ...&#125;; 每个saveparam结构保存了一个save选项设置的条件 1234567struct saveparam&#123; // 秒数 time_t seconds; // 修改量 int changes;&#125; 记录属性除此之外，还维护了一个dirty计数器，以及一个lastsave属性 dirty计数器记录距离上一次成功执行save命令或者bgsave命令之后服务器对数据库状态进行了多少次修改 lastsave属性是一个unix时间戳，记录了服务器上一次成功执行save命令或者bgsave命令时间 12345678910struct redisServer&#123; // ... // 修改计数器 每次成功执行一个数据库修改命令后程序就会对dirty计数器进行更新 long long dirty; time_t lastsave; // ...&#125;; 检查条件是否满足redis的服务器周期性操作函数serverCron默认每隔100毫秒就会执行一次，该函数用于对正在运行的服务器进行维护，他的其中一项工作就是检查save选项所设置的保存条件是否已经满足，如果满足就会执行bgsave命令 AOFAOF持久化可以分为追加， 文件写入，文件同步 追加当aof打开时，服务器执行完一次写命令后会以协议格式将被执行的写命令追加到服务器的aof_buf缓冲区的末尾 redis&gt; SET KEY VALUE 执行set命令后， 会将内容根据协议追加到aof_buf末尾 *3\\r\\n$3\\r\\nSET\\r\\n$3\\r\\n$5\\r\\nVALUE\\r\\n 写入与同步redis服务器进程就是一个事件循环，循环中的文件时间负责接收客户端的命令请求以及向客户端发送命令回复，在这些请求中可能会执行写命令，使得一些内容被追加到aof_buf缓冲区里面，所以在服务器每次结束一个事件循环前都会考虑是否需要将aof_buf缓冲区的内容写入和保存到AOF文件里面 持久化的进度怎么看aof文件的protocal协议的理解(能够达到修改aof文件并恢复数据文件的程度)了解redis-check-aof/dump工具熟悉线上备份熟悉备份的策略，备份方式熟练数据备份恢复达到修改线上重写时间，备份时间，修改备份脚本的能力st=>start: 开始 op1=>operation: 服务器启动 op2=>operation: 执行在如程序 cond1=>condition: 已开启AOF持久化功能 op3=>operation: 载入AOF文件 op4=>operation: 载入RDB文件 st->op1->op2->cond1 cond1(yes)->op3 cond1(no)->op4{\"scale\":1,\"line-width\":2,\"line-length\":50,\"text-margin\":10,\"font-size\":12} var code = document.getElementById(\"flowchart-0-code\").value; var options = JSON.parse(decodeURIComponent(document.getElementById(\"flowchart-0-options\").value)); var diagram = flowchart.parse(code); diagram.drawSVG(\"flowchart-0\", options);","path":"2019/08/19/redis学习wiki/","date":"08-19","excerpt":"第一天了解redis的数据库，了解相似的缓存数据库，redis的局限redis数据库 非关系型数据库 以键(key)和值(value)做映射(mapping) value类型： string：字符串对象 list：列表对象 hash：哈希对象 set：集合对象 zset：有序集合对象 类型(前缀：REDIS)编码(前缀：REDIS_ENCODING)对象结构的读写能力STRINGINT(long类型整数)整数值实现字符串对象对整个字符串或者字符串的其一部分执行操作，对整数的浮点数执行自增或者自减操作STRINGEMBSTR(embstr编码的简单字符串)embstr编码的简单动态字符串实现的字符串对象STRINGRAW(简单动态字符串)动态字符串实现的字符串对象LISTZIPLIST(压缩列表)压缩列表实现的列表对象从链表的两端推入或者弹出元素，根据偏移量对链表进行修剪，读取单个或者多个元素，根据值查找或者移除元素LISTLINKEDLIST(双端链表)双端链表实现的列表对象HASHZIPLIST(压缩列表)压缩列表实现的哈希对象添加、获取、移除单个键值对，获取所有键值对HASHHT(字典)字典实现的哈希对象SETINTSET(整数集合)整数集合实现的集合对象添加、获取、移除单个元素，检查一个元素是否存在与集合，计算交集，并集，差集，从集合里面随机获取元素SETHT(字典)字典实现的集合对象ZSETZIPLIST(压缩列表)压缩列表实现的有序集合对象添加、获取、移除单个元素，根据分值范围或者成员来获取元素ZSETSKIPLIST(跳跃表和字典)跳跃表和字典实现的有序集合对象","tags":[{"name":"学习记录","slug":"学习记录","permalink":"https://jijiking51.cn/tags/学习记录/"}]},{"title":"mysql学习笔记","text":"SQL基础SQL分类 DDL(Date Definition Languages)： 数据定义语句，这些语句定义了不同的数据段、数据库、表、列、索性等数据库对象，常用的语句关键字主要包括create、drop、alter DML(Date Manipulation Language)：数据操纵语句, 用于添加、删除、更新和查询数据库记录，并检查数据完整新。常用关键字包括 insert、delete、 update、select。 DCL(Date Control Language): 数据控制语句， 用于控制不同数据段直接的许可和访问级别的语句，这些语句定义了数据库、表、字段、用户的访问权限和安全级别。主要关键字包括grant、 revoke等。 DDL语句常用DDL语句的使用方法 创建数据库1create datebase test1; 删除数据库1drop database test1; 创建表1234567891011# 创建语句create table emp( ename varchar(10), hiredate date, sal decimal(10, 2), deptno int(2));# 查看定义desc [tablename]# 查看创建语句show create table [tablename] \\G; 删除表1drop table [tablename] 修改表修改表类型12345# 修改语法， column可以省略， first | after也可以省略alter table [tablename] modify `column` [column_name] &#123; first | after col_name&#125;;# 示例alter table emp modify ename varchar(20); 增加表字段12345# 增加字段语法alter table [tablename] add `column` [column_definition] &#123; first | after col_name &#125;;# 示例alter table emp add column age int(3); 删除表字段12345# 删除字段语法alter table [tablename] drop `column` col_name;# 示例alter table emp drop column age; 字段改名12345# 字段改名语法alter table [tablename] change [column] old_col_name column_definition &#123; first | after col_name &#125;;# 示例alter table emp change age age1 int(4); change 和 modify都可以修改表的定义， 不同的是change后面需要写两次列名， 不方便， 但是change的优点是可以修改列名称，modify则不能 修改字段排序字段增加和修改语法中都有一个可选项{first | after col_name}, 这个选项可以用来修改字段在表中的位置， add增加的新字段默认是加载表最后，change、modify默认都会不改变字段的位置。 12345# 将新增的字段birth date 加在ename之后alter table emp add birth date after ename;# 修改age字段， 将他放在最前面alter table emp modify age int(3) first; change/ first | after column 属于mysql 在标准sql上扩展， 其他数据库不一定适用 更改表名12345# 修改表名语法alter table [tablename] rename `to` new_tablename;# 示例alter table emp rename emp1; DML语句主要包括inset, update, delete, select 插入记录12345678910111213# 插入记录语法insert into [tablename](field1, field2 ... fieldn) values(value1, value2 ... valuen);# 多条记录插入语法insert into [tablename](field1, field2 ... fieldn) values (value1, value2 ... valuen),(value1, value2 ... valuen),(value1, value2 ... valuen)...(value1, value2 ... valuen);# 示例insert into emp(ename, hiredate, sal, deptno) values(&apos;zzx1&apos;, &apos;2019-08-08&apos;, &apos;2000&apos;, 1); 插入语句可以不用指定字段名称，但是values后面的顺序应该和字段的排列顺序一致 含可空字段，非空但是含有默认值的字段、自增字段，可以不用在insert后的字段列表里出现，，没写的字段可以自动设置NULL。 更新记录12345678# 更新记录语法update [tablename] set field1=value1, field2=value2,...fieldn=valuen [where condition];# 更新多表数据update t1,t2,...tn set t1,field1=expr1, ... tn.fieldn=exprn [where condition];# 示例update emp a, dept b set a.sal=a.sal*b.deptno, b.deptname=a.ename where a.deptno=b.deptno; 删除记录1234567891011# 删除语法delete from [tablename] [where condition]# 示例delete from emp where ename=&apos;dony&apos;;# 删除多个数据表数据delete t1, t2, ... tn from t1, t2, ... tn [where condition];# 示例delete a, b from emp a,dept b where a.deptno=b.deptno and a.deptno = 3; 不加where会删除整表 查询记录1234567891011121314151617181920212223242526272829303132333435363738# 基本查询语法select * from [tablename] [where condition];# 示例select * from emp;# 查询不重复记录语法select distinct field from [tablename];# 查询值排序, 如果排序字段的值一样， 则值相同的字段按照第二个排序字段进行排序，以此类推select * from [tablename] [where condition] [order by field1 desc | asc ], [order by field1 desc | asc ], ... [order by field1 desc | asc ];# limit截取部分内容select ... [limit offset_start, row_count];# 聚合语法select [field1, field2, ... fieldn] fun_name from tablename [where where_condition] [group by field1, field2, ... fieldn] [with rollup] [having where_condition];* fun_name 聚合函数（sum， count， max， min）* group by 需要聚合的字段* with rollup 可选， 表明是否分类后的结果进行再汇总* having 关键字表示对分类后的结果在进行条件过滤- having 和 where 的区别在于， having是对聚合后的结果进行条件的过滤， 而where是在聚合前就对记录进行过滤， 如果逻辑允许， 尽可能用where先过滤记录， 这样因为结果集减小， 将对聚合的效率大大提高，最后根据逻辑看是否用having进行过滤# 示例select deotno, count(1) from emp group by deptno having count(1) &gt; 1;# 表连接 表连接分两种，外链接和内连接，内连接仅选出两张表中互相匹配的记录，外链接选出其他不匹配的记录select ename, deptname from emp, dept where emp.deptno = dept.deptno;* 左连接： 包含所有的左边表中的记录甚至是右边表中没有和他匹配的记录* 右连接：包含所有的右边表中的记录甚至是左边表中没有和他匹配的记录# 子查询select * from emp where deptno in(select deptno from dept);# 记录联合* union all 把结果集直接合并在一起* union 将union all 后的结果进行一次distinct，去除重复记录后的结果select deptno from emp union all selet deptno from dept; DCL语句DBA系统中的对象权限时使用 12345# 创建zl具有对sakila数据库中所有表的select、insert权限grant select, insert on sakila.* to &apos;z1&apos;@&apos;localhost&apos; identified by &apos;123&apos;;# 去除插入权限revoke insert on sakila.* from &apos;z1&apos;@&apos;localhost&apos;; 数据类型数值类型 整数类型 字节 最小值(有符号/无符号) 最大值(有符号/无符号) tinyint 1 -1280 127255 smallint 2 327680 3276765535 mediumint 3 -83886080 838860816777215 int, integer 4 -21474836480 21474836474294967295 bigint 8 -92233720368547758080 922337203685477580718446744073709551615 浮点数类型 字节 最小值 最大值 float 4 ±1.175494351E-38 ±3.402823466E+38 double 8 ±2.2250738585072014E-308 ±1.7976931348623157E+308 定点数类型 字节 描述 dec(m,d)decimal(m,d) M+2 最大取值范围与double相同，给定decimal的有效取值范围由M和D决定 位类型 字节 最小值 最大值 bit(m) 1~8 bit(1) bit(64) 整型数据还支持在类型名称后面的小括号内指定显示宽度，例如int(5)当数值宽度小于5位的时候在数字前面填满宽度，如果不显示置顶宽度则默认为int(11)。一般配合zerofill使用，用0填充，也就是在数字位数不够的空间用字符0填满。 field_name int zerofill 插入超过位数长度的时候不会影响真正存储，只是长度定义就没有意义。 无符号类型使用 unsigned 自动生成序号 auto_increment 小数表示可以有浮点数和定点数。浮点数：float，double，定点数：decimal。 小数都可追加”(M, D)“表示，M表示一共显示M位数字， D位位于小数点后面， M和D又称为精度和标度。 bit类型用于存放位字段，可以指定长度1-64， 如果不指定则为1，select无法查询到结果， 可以用bin()显示二进制格式，或者hex()显示十六进制格式。 日期类型 年 月 入用date表示 年 月 日 时 分 秒 用datetime表示 时 分 秒 用time表示 日期和时间类型 字节 最小值 最大值 date 4 1000-01-01 9999-12-31 datetime 8 1000-01-01 00:00:00 9999-12-31 23:59:59 timestamp 4 19700101080001 2038年某刻 time 3 -838:59:59 838:59:59 year 1 1901 2155 Timestamp存放时会先转换为本地时区后存放，取出时同样需要将时间日期转换成本地时区后显示。这样两个时区的用户看到的同一个日期可能是不一样的 12345# 查看当前时区show variables like &apos;time_zone&apos;;# 修改时区set time_zone=&apos;+9:00&apos;; 字符串类型 字符串类型 字节 描述及存储需求 char(m) m m为0~255之间的整数 varchar(m) m为0~65535之间的整数，值的长度+1个字节 tinyblob 允许长度0~255字节，值的长度+1个字节 blob 允许长度0~65535字节，值的长度+2字节 mediumblob 允许长度0～~167772150字节。值的长度+3个字节 longblob 允许长度0~4294967295字节，值的长度+4个字节 tinytext 允许长度0~255字节，值的长度+2个字节 text 允许长度0~65535字节，值的长度+2字节 mediumtext 允许长度0～~167772150字节。值的长度+3个字节 longtext 允许长度0~4294967295字节，值的长度+4个字节 varbinary(M) 允许长度0～M个字节的变长字节字符串，值的长度+1个字节 binary(M) M 允许长度0～M个字节的定长字符串 varchar、char：char删除内容尾空格，varchar保留尾部空格 枚举类型：对于1~255个成员的枚举需要一个字节，对于255~65535个成员需要2个字节存储。最多允许65535个成员。 12345# 创建枚举类型create table t(gender enum(&apos;m&apos;, &apos;f&apos;));# 插入测试记录insert into t values(&apos;m&apos;), (&apos;1&apos;), (&apos;f&apos;), (null); set类型：set里面可以包含0~64个成员。根据成员的不同，存储也不同 1~8， 1字节 9~16， 2字节 17~24， 3字节 25~32， 4字节 33~64， 8字节 enum类型只可以选择一个对象，set可以选取多个成员 12345# 创建表create table t(col set(&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;));# 插入内容insert into t values(&apos;a, b&apos;), (&apos;a, d, a&apos;), (&apos;a, b&apos;), (&apos;a, c&apos;), (&apos;a&apos;); 运算符算数运算符 运算符 作用 + 加 - 减 * 乘 /，div 除 %，mod 余 比较运算符 运算符 作用 = 等于 &lt;&gt;或!= 不等于 &lt;=&gt; null安全的等于 &lt; 小于 &lt;= 小于等于 &gt; 大于 =&gt; 大于等于 between 存在于指定范围 in 存在于指定集合 is null 为null is not null 不为null like 通配符匹配 regexp 或者 rlike 正则表达式 逻辑运算符 运算符 作用 not 或 ! 逻辑非 and 或 &amp;&amp; 逻辑与 or 或 \\ \\ 逻辑或 xor 逻辑异或 not 和 ! 表示逻辑非，除了not null 返回值为null 其他的判断返回值均由1或者0 and 和 &amp;&amp; 标识逻辑与， 必须都为非null或者非0的时候才能返回1 or 和 || 标识逻辑或，如果有一个1则返回1， 如果都是null则返回null xor标识逻辑异或，任意一个操作数为null返回null， 对于非null的操作， 如果两个的逻辑真假值相异，则返回1，否则返回0 位运算符 运算符 作用 &amp; 位与 \\ 位或 ^ 位异或 ～ 位取反 &gt;&gt; 位右移 &lt;&lt; 位左移 运算符的优先 := ||、OR、 XOR &amp;&amp; 、AND NOT BETWEEN、CASE、WHEN、THEN ELSE =、 &lt;=&gt; 、 &gt;= 、 &gt; 、&lt;=、&lt;&gt;、!=、IS、LIKE、REGEXP、IN | &amp; &lt;&lt;、&gt;&gt; -、+ *、/、DIV、%、MOD ^ -（一元减号）、~（一元比特反转） ! 表类型存储引擎概述存储引擎包括：MyISAM、InnoDB、BDB、MEMORY、MERGE、EXAMPLE、NDB Cluster、ARCHIVE、CSV、BLACKHOLE、FEDERATED。 以上引擎只有InnoDB和BDB提供事务安全表，其他引擎都是非事物安全表 1234567# 查看当前默认存储引擎show variables like &apos;table_type&apos;;# 查看当前数据库支持的存储引擎(方法1)show engines \\G# (方法2)show variables like &apos;have%&apos;;","path":"2019/08/19/mysql学习笔记/","date":"08-19","excerpt":"SQL基础SQL分类 DDL(Date Definition Languages)： 数据定义语句，这些语句定义了不同的数据段、数据库、表、列、索性等数据库对象，常用的语句关键字主要包括create、drop、alter DML(Date Manipulation Language)：数据操纵语句, 用于添加、删除、更新和查询数据库记录，并检查数据完整新。常用关键字包括 insert、delete、 update、select。 DCL(Date Control Language): 数据控制语句， 用于控制不同数据段直接的许可和访问级别的语句，这些语句定义了数据库、表、字段、用户的访问权限和安全级别。主要关键字包括grant、 revoke等。","tags":[{"name":"学习记录","slug":"学习记录","permalink":"https://jijiking51.cn/tags/学习记录/"}]},{"title":"deepin修改启动项","text":"问题说明boot里面的启动项是根据其它文件生成的，如果改boot里面，会在你更新grub后再次回到原来的状态。（之后 我（有显卡驱动问题的用户）通过在开机时选择系统页面按e在倒数第二行ro quiet splash 后面加上acpi_osi=! acpi_osi=”Windows 2009”可以从最新内核进入系统。在/etc/default/grub 文件里面相同位置也加上这一句后会让系统不能自己更新grub，之后你就可以在boot/grub里面直接更改启动项内容而不必担心系统回滚） 更改配置更改启动项主要从两个文件夹改：/etc/default/grub和/etc/grub.d，下面解释一下这两个文件夹的内容。. /etc/default/grub： 12345678GRUB_BACKGROUND=&quot;/boot/grub/themes/deepin/background.png&quot; #背景图片的路径GRUB_CMDLINE_LINUX_DEFAULT=&quot;splash quiet&quot; #开机的开机动画(貌似是，需要加载显卡)有显卡驱动问题的可以在后面加上 nomodeset(此选项只会追加在一般模式后）GRUB_DEFAULT=0 #默认启动项，这个值为0就是默认启动第一个，为1默认启动第二个GRUB_DISABLE_RECOVERY=&quot;true&quot; #禁止显示救援模式（这个不太懂）GRUB_DISTRIBUTOR=&quot;`/usr/bin/lsb_release -d -s 2&gt;/dev/null || echo Deepin`&quot; #获得发行版本（此行将追加到所有的linux 定义内核行的后面，不论是救援模式还是一般模式）GRUB_GFXMODE=&quot;1920x1080&quot; #启动的分辨率GRUB_THEME=&quot;/boot/grub/themes/deepin/theme.txt&quot; #启动的主题，是各种图片和各种显示的字体GRUB_TIMEOUT=5 #等待时间，5秒未操作直接进入默认系统。改为-1是一直等待。 /etc/grub.d： 1234567891000_header # 配置初始的显示项目，如默认选项，时间限制等，一般由/etc/default/grub导入，一般不需要配置05_debian_theme # 配置引导画面，文字颜色等主题10_linux #定位当前操作系统使用中的root设备内核的位置,包含deepin 启动项和advanced里面的启动项15_linux_bar # 救援模式的启动项20_linux_xen # 虚拟机监视器的东西，（暂时不知有什么用30_uefi-firmware # “system setup” 的启动项35_os-prober # windows的启动项一般在这个里面40_custom # 用来加入用户自定义的启动项，将会在执行update-grub时更新至grub.cfg中41_custom # 判断custom.cfg此配置文件是否存在，如果存在就加载它前面的数字是对文件排列执行的顺序进行排序，可进行更改，比如你想把windows启动项调到第一个，就把35_os-prober前面那个数字改成5到10的数字，比如06、07、08、09. 想更改deepin系统的启动内核（有这个需求是不少人在新内核上有显卡驱动问题，而从advanced里面进不能默认进入） （deepin默认的应该是最新的启动内核，你在boot/grub/grub.cfg里面更改的话只要一更新grub就会回到原来的内核）因此是要改10_linux文件的，但是里面是汇编命令看不懂， 这时40_custom 提供了一个在启动页面加一个新的启动项的简单方法，具体操作如下： 打开boot/grub/grub.cfg，找到你默认的启动项（或者你想要改到外面的advanced里面的启动项）（这些启动项都在10_linux里面），大概如下： 123456789101112131415menuentry &apos;Deepin 15.6 GNU/Linux（名字在这里改）&apos; --class deepin --class gnu-linux --class gnu --class os $menuentry_id_option &apos;gnulinux-simple-6873bab1-cdf1-4931-8717-d2258cb3ad87&apos; load_video insmod gzio if [ x$grub_platform = xxen ]; then insmod xzio; insmod lzopio; fi insmod part_gpt insmod ext2 set root=&apos;hd0,gpt4&apos; if [ x$feature_platform_search_hint = xy ]; then search --no-floppy --fs-uuid --set=root --hint-bios=hd0,gpt4 --hint-efi=hd0,gpt4 --hint-baremetal=ahci0,gpt4 6873bab1-cdf1-4931-8717-d2258cb3ad87 else search --no-floppy --fs-uuid --set=root 6873bab1-cdf1-4931-8717-d2258cb3ad87 fi linux /boot/vmlinuz-4.15.0-21deepin-generic root=UUID=6873bab1-cdf1-4931-8717-d2258cb3ad87 ro splash quiet initrd /boot/initrd.img-4.15.0-21deepin-generic&#125; 复制粘贴到40_custom那三行字下面（需要以管理员身份打开） 然后把名字改一下（为了避免重复嘛，你要是在advanced里面复制的就不用改了），最后两行是启动内核，改一下（当然，你要是复制的advanced里面你想改的内核启动项就直接粘贴就行了） 保存 之后sudo update-grub就可以了。之后再根据你的需要改顺序和默认启动项就行。","path":"2019/06/25/deepin修改启动项/","date":"06-25","excerpt":"问题说明boot里面的启动项是根据其它文件生成的，如果改boot里面，会在你更新grub后再次回到原来的状态。（之后 我（有显卡驱动问题的用户）通过在开机时选择系统页面按e在倒数第二行ro quiet splash 后面加上acpi_osi=! acpi_osi=”Windows 2009”可以从最新内核进入系统。在/etc/default/grub 文件里面相同位置也加上这一句后会让系统不能自己更新grub，之后你就可以在boot/grub里面直接更改启动项内容而不必担心系统回滚）","tags":[{"name":"踩坑","slug":"踩坑","permalink":"https://jijiking51.cn/tags/踩坑/"},{"name":"deepin","slug":"deepin","permalink":"https://jijiking51.cn/tags/deepin/"}]},{"title":"redis源码-压缩列表","text":"压缩列表是列表键和哈希键的底层实现之一。 当一个列表建只包含少量列表项，并且如果每个列表项是小整数值或者长度比较短的字符串，那么redis就会使用压缩列表来做列表键的底层实现。 当一个哈希键只包含少量键值对，并且每个键值对的键和值要么就是小整数值，要么就是长度比较短的字符串，那么redis会使用压缩列表来做哈希键的底层实现 压缩列表的构成压缩列表是为了节约内存而开发的，是由一系列特殊编码的连续内存块组成的顺序性数据结构。一个压缩列表可以包含任意多个节点，每个节点可以保存一个字节数组或一个整数值。 压缩列表的组成： 属性 类型 长度 用途 zlbytes uint32_t 4 字节 记录整个压缩列表占用的内存字节数：在对压缩列表进行内存重分配， 或者计算 zlend 的位置时使用。 zltail uint32_t 4 字节 记录压缩列表表尾节点距离压缩列表的起始地址有多少字节： 通过这个偏移量，程序无须遍历整个压缩列表就可以确定表尾节点的地址。 zllen uint16_t 2 字节 记录了压缩列表包含的节点数量： 当这个属性的值小于 UINT16_MAX （65535）时， 这个属性的值就是压缩列表包含节点的数量； 当这个值等于 UINT16_MAX 时， 节点的真实数量需要遍历整个压缩列表才能计算得出。 entryX 列表节点 不定 压缩列表包含的各个节点，节点的长度由节点保存的内容决定。 zlend uint8_t 1 字节 特殊值 0xFF （十进制 255 ），用于标记压缩列表的末端。 1234567891011121314151617181920/* * ziplist 属性宏 */// 定位到 ziplist 的 bytes 属性，该属性记录了整个 ziplist 所占用的内存字节数// 用于取出 bytes 属性的现有值，或者为 bytes 属性赋予新值#define ZIPLIST_BYTES(zl) (*((uint32_t*)(zl)))// 定位到 ziplist 的 offset 属性，该属性记录了到达表尾节点的偏移量// 用于取出 offset 属性的现有值，或者为 offset 属性赋予新值#define ZIPLIST_TAIL_OFFSET(zl) (*((uint32_t*)((zl)+sizeof(uint32_t))))// 定位到 ziplist 的 length 属性，该属性记录了 ziplist 包含的节点数量// 用于取出 length 属性的现有值，或者为 length 属性赋予新值#define ZIPLIST_LENGTH(zl) (*((uint16_t*)((zl)+sizeof(uint32_t)*2)))// 返回 ziplist 表头的大小#define ZIPLIST_HEADER_SIZE (sizeof(uint32_t)*2+sizeof(uint16_t))// 返回指向 ziplist 第一个节点（的起始位置）的指针#define ZIPLIST_ENTRY_HEAD(zl) ((zl)+ZIPLIST_HEADER_SIZE)// 返回指向 ziplist 最后一个节点（的起始位置）的指针#define ZIPLIST_ENTRY_TAIL(zl) ((zl)+intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl)))// 返回指向 ziplist 末端 ZIP_END （的起始位置）的指针#define ZIPLIST_ENTRY_END(zl) ((zl)+intrev32ifbe(ZIPLIST_BYTES(zl))-1) 下图展示了一个包含三个节点的压缩列表示例： 列表 zlbytes 属性的值为 0x50 （十进制 80）， 表示压缩列表的总长为 80 字节。 列表 zltail 属性的值为 0x3（十进制 60）， 这表示如果我们有一个指向压缩列表起始地址的指针 p ， 那么只要用指针 p 加上偏移量 60 ， 就可以计算出表尾节点 entry3 的地址。 列表 zllen 属性的值为 0x3 （十进制 3）， 表示压缩列表包含三个节点。 展示了一个包含五个节点压缩列表示例： 列表 zlbytes 属性的值为 0xd2 （十进制 210）， 表示压缩列表的总长为 210 字节。 列表 zltail 属性的值为 0xb3 （十进制 179）， 这表示如果我们有一个指向压缩列表起始地址的指针 p ， 那么只要用指针 p 加上偏移量 179 ， 就可以计算出表尾节点 entry5 的地址。 列表 zllen 属性的值为 0x5（十进制 5）， 表示压缩列表包含五个节点。 压缩列表节点的构成每个压缩列表可以保存一个字节数组或者一个整数值，其中，字节数组可以是一下三种长度的其中一种： 长度小于等于63（2^6-1）字节的字节数组 长度小于等于16383（2^14-1）字节的字节数组 长度小于等于4294967295（2^32-1）字节的字节数组 整数值可以是一下六种长度的其中一种： 4位长，介于0至12之间的无符号整数 1字节的有符号整数 3字节长的有符号整数 int16_t类型整数 int32_t类型整数 int64_t类型整数 每个压缩列表都是由previous_entry_length/encoding/content三个部分组成 123456789101112131415161718192021222324/* * 保存 ziplist 节点信息的结构 */typedef struct zlentry &#123; // prevrawlen ：前置节点的长度 // prevrawlensize ：编码 prevrawlen 所需的字节大小 unsigned int prevrawlensize, prevrawlen; // len ：当前节点值的长度 // lensize ：编码 len 所需的字节大小 unsigned int lensize, len; // 当前节点 header 的大小 // 等于 prevrawlensize + lensize unsigned int headersize; // 当前节点值所使用的编码类型 unsigned char encoding; // 指向当前节点的指针 unsigned char *p;&#125; zlentry; previous_entry_length节点的previous_entry_length属性以字节为单位，记录了压缩列表中前一个节点的长度。previous_entry_length属性的长度可以是1字节或者5字节 123456789101112131415/* Decode the number of bytes required to store the length of the previous * element, from the perspective of the entry pointed to by 'ptr'. * * 解码 ptr 指针， * 取出编码前置节点长度所需的字节数，并将它保存到 prevlensize 变量中。 * * T = O(1) */#define ZIP_DECODE_PREVLENSIZE(ptr, prevlensize) do &#123; \\ if ((ptr)[0] &lt; ZIP_BIGLEN) &#123; \\ (prevlensize) = 1; \\ &#125; else &#123; \\ (prevlensize) = 5; \\ &#125; \\&#125; while(0); 如果前一个节点的长度小于254字节，那么previous_entry_length属性的长度，为1字节，前一个节点的长度就保存在这个字节里面 如果前一节点的长度大于等于254字节，那么previous_entry_length属性的长度为5字节：其中属性的第一个字节会被设置为0xFE(十进制254)，之后的四个字节则用于保存前一节点的长度 第一幅图表示一个属性值为0x05的previous_entry_length，表示前一个节点的长度为5字节 第二幅图表示一个属性为0xFE00002766的previous_entry_length，最高位的0xFE表示这是五个字节的属性，后面的0x00002766才是表示节点长度的值(十进制10086) 因为节点的previous_entry_length属性记录了前一个节点的长度，所以程序可以通过指针运算，更具当前节点的起始地址来计算出前一个节点的起始地址。例如： 我们有一个指向当前节点起始地址的指针C，那么我们只要用c减去当前节点的previous_entry_length属性的值，就可以得出一个指向前一个节点起始地址的指针P 压缩列表的从表尾向表头便利操作就是适用这个原理实现的，只要我们拥有了一个指向某个节点起始地址的指针，那么通过这个指针以及这个节点的previous_entry_length属性，程序就可以一直想前一个节点回溯，最终到达压缩列表的头结点。 首先我们拥有指向压缩列表表尾节点entry4起始地址的指针p1（指向表尾节点的指针可以通过指向压缩列表起始地址的指针加上zltail属性的值得出） 通过p1减去entry4节点的previous_entry_length属性的值，我们得到一个指向entry4前一节点entry3起始地址的指针p2 通过用p2减去entry3节点previous_entry_length属性的值，我们得到一个指向entry3前一节点entry2起始地址的指针p3 通过用p3减去entry2节点previous_entry_length属性的值，我们得到一个指向entry2前一节点entry1起始地址的指针p4，entry1为压缩列表的表头节点 最终我们从表尾节点向表头节点遍历了整个列表 encoding节点的encoding属性记录了节点的content属性所保存数据的类型以及长度 1234567891011/* Extract the encoding from the byte pointed by 'ptr' and set it into * 'encoding'. * * 从 ptr 中取出节点值的编码类型，并将它保存到 encoding 变量中。 * * T = O(1) */#define ZIP_ENTRY_ENCODING(ptr, encoding) do &#123; \\ (encoding) = (ptr[0]); \\ if ((encoding) &lt; ZIP_STR_MASK) (encoding) &amp;= ZIP_STR_MASK; \\&#125; while(0) 一字节、两字节或者五字节长，值得最高位为00、01或者10的是字节数组编码：这种编码表示节点的content属性保存着字节数组","path":"2019/04/22/redis源码-压缩列表/","date":"04-22","excerpt":"压缩列表是列表键和哈希键的底层实现之一。 当一个列表建只包含少量列表项，并且如果每个列表项是小整数值或者长度比较短的字符串，那么redis就会使用压缩列表来做列表键的底层实现。 当一个哈希键只包含少量键值对，并且每个键值对的键和值要么就是小整数值，要么就是长度比较短的字符串，那么redis会使用压缩列表来做哈希键的底层实现","tags":[{"name":"源码","slug":"源码","permalink":"https://jijiking51.cn/tags/源码/"}],"preview":"http://img.jijiking51.cn/redis源码-压缩列表.jpg"},{"title":"redis源码-整数集合","text":"整数集合整数集合是集合键的底层实现之一， 当一个集合只包含整数值元素，并且这个集合的元素数量不多时，redis会使用整数集合键实现整数集合的实现整数集合是用于保存整数值的集合抽象数据结构，可以保存int16_t / int32_t / int64_t的整数值123456789101112typedef struct intset &#123; // 编码方式 uint32_t encoding; // 集合包含的元素数量 uint32_t length; // 保存元素的数组 int8_t contents[];&#125; intset; contents数组是整数集合的底层实现，每个数据项按从大到小有序排列，并且数组中不包含重复数据 length属性记录了整数集合元素个数，也就是contents长度 虽然contents结构属性声明为int8_t类型数组，但是数组并不保存任何int8_t类型值，contents属性其实是由encoding决定 如果encoding属性的值为INTSET_ENC_INT16，那么contents就是一个int16_t类型的数组，数组里面每一项都是int16_t类型整数 如果encoding属性的值为INTSET_ENC_INT32，那么contents就是一个int32_t类型的数组，数组里面每个项都是一个int32_t类型的整数 如果encoding属性的值为INTSET_ENC_INT64，那么contents就是一个int64_t类型的数组，数组里面每个项都是一个int64_t类型的整数 contents数组中，只要有一个整数需要用到int64_t(大类型)， 那么所有的都必须升级为int64_t(大类型) 升级当我们要将一个新的元素添加到整数集合里面，并且新的元素比目前数组中所有元素的类型都要长的时候，整数集合需要先升级，然后才能将这个整数添加到整数集合。升级一共分为三个步骤： 根据新元素的类型，扩张整个数集合底层数组的空间大小，并为新元素分配空间。 将底层数组现有的所有元素都转换成新元素相同的类型，并将转换后的元素放到正确位置上，并且整个过程要维持底层数组的有序性不变。 将新元素放到底层数组 下面图片表示了升级流程： 初始状态下， 这是一个int16_t的数组，但是如果我们要插入int32_t的一个元素，所以我们先分配空间给它升级 因为升级过程中要保证数组序列的有序性，所以，四个数字中，3还是排第三位，所以要移到第三位所在的空间 二号位移动到二号位所在空间 一号位空间重新扩充 新元素插入到数组的对应位置 更改encoding类型，修改length长度，新元素插入完成 因为每次向整数集合添加新元素都可能会引起升级，而每次升级都需要对底层数组中已有的所有元素进行类型转换，所以向整数集合添加新元素的时间复杂度为O(N)。 升级的好出 提升整数集合的灵活性 尽可能的节省内存 提升灵活性因为c是静态类型语言，为了避免类型错误，我们通常不会将两种不同类型的值放在同一个数据结构里面。 我们一般只用int16_t来保存int16_t类型的值，也只用int32_t保存int32_t类型的值。 但是整数集合可以通过自动升级底层来适应新元素，所以我们可以随意的将int16_t、int32_t、int64_t添加到集合中，不用担心类型错误。 节约内存要同时保存int16_t、int32_t、int64_t类型的值，最简单的方法就是使用int64_t的类型数组。不过这样一来，即使整数集合中全是int16_t类型的元素也会占用int64_t的空间去保存他们，这样会出现内存浪费的情况。 动态的升级类型，可以有效避免上述的内存浪费情况 整数集合不支持降级操作，一旦对数组进行了升级，编码会一直保持升级后的状态 整数集合API常用API列表 函数 作用 时间复杂度 intsetNew 创建一个新的整数集合。 O(1) intsetAdd 将给定元素添加到整数集合里面。 O(N) intsetRemove 从整数集合中移除给定元素。 O(N) intsetFind 检查给定值是否存在于集合。 因为底层数组有序，查找可以通过二分查找法来进行， 所以复杂度为 O(\\log N) 。 intsetRandom 从整数集合中随机返回一个元素。 O(1) intsetGet 取出底层数组在给定索引上的元素。 O(1) intsetLen 返回整数集合包含的元素个数。 O(1) intsetBlobLen 返回整数集合占用的内存字节数。 O(1) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566/* Return the required encoding for the provided value. * * 返回适用于传入值 v 的编码方式 * * T = O(1) */static uint8_t _intsetValueEncoding(int64_t v) &#123; if (v &lt; INT32_MIN || v &gt; INT32_MAX) return INTSET_ENC_INT64; else if (v &lt; INT16_MIN || v &gt; INT16_MAX) return INTSET_ENC_INT32; else return INTSET_ENC_INT16;&#125;/* Return the value at pos, given an encoding. * * 根据给定的编码方式 enc ，返回集合的底层数组在 pos 索引上的元素。 * * T = O(1) */static int64_t _intsetGetEncoded(intset *is, int pos, uint8_t enc) &#123; int64_t v64; int32_t v32; int16_t v16; // ((ENCODING*)is-&gt;contents) 首先将数组转换回被编码的类型 // 然后 ((ENCODING*)is-&gt;contents)+pos 计算出元素在数组中的正确位置 // 之后 member(&amp;vEnc, ..., sizeof(vEnc)) 再从数组中拷贝出正确数量的字节 // 如果有需要的话， memrevEncifbe(&amp;vEnc) 会对拷贝出的字节进行大小端转换 // 最后将值返回 if (enc == INTSET_ENC_INT64) &#123; memcpy(&amp;v64,((int64_t*)is-&gt;contents)+pos,sizeof(v64)); memrev64ifbe(&amp;v64); return v64; &#125; else if (enc == INTSET_ENC_INT32) &#123; memcpy(&amp;v32,((int32_t*)is-&gt;contents)+pos,sizeof(v32)); memrev32ifbe(&amp;v32); return v32; &#125; else &#123; memcpy(&amp;v16,((int16_t*)is-&gt;contents)+pos,sizeof(v16)); memrev16ifbe(&amp;v16); return v16; &#125;&#125;/* Return the value at pos, using the configured encoding. * * 根据集合的编码方式，返回底层数组在 pos 索引上的值 * * T = O(1) */static int64_t _intsetGet(intset *is, int pos) &#123; return _intsetGetEncoded(is,pos,intrev32ifbe(is-&gt;encoding));&#125;/* Set the value at pos, using the configured encoding. * * 根据集合的编码方式，将底层数组在 pos 位置上的值设为 value 。 * * T = O(1) */static void _intsetSet(intset *is, int pos, int64_t value) &#123; // 取出集合的编码方式 uint32_t encoding = intrev32ifbe(is-&gt;encoding); // 根据编码 ((Enc_t*)is-&gt;contents) 将数组转换回正确的类型 // 然后 ((Enc_t*)is-&gt;contents)[pos] 定位到数组索引上 // 接着 ((Enc_t*)is-&gt;contents)[pos] = value 将值赋给数组 // 最后， ((Enc_t*)is-&gt;contents)+pos 定位到刚刚设置的新值上 // 如果有需要的话， memrevEncifbe 将对值进行大小端转换 if (encoding == INTSET_ENC_INT64) &#123; ((int64_t*)is-&gt;contents)[pos] = value; memrev64ifbe(((int64_t*)is-&gt;contents)+pos); &#125; else if (encoding == INTSET_ENC_INT32) &#123; ((int32_t*)is-&gt;contents)[pos] = value; memrev32ifbe(((int32_t*)is-&gt;contents)+pos); &#125; else &#123; ((int16_t*)is-&gt;contents)[pos] = value; memrev16ifbe(((int16_t*)is-&gt;contents)+pos); &#125;&#125;/* Create an empty intset. * * 创建并返回一个新的空整数集合 * * T = O(1) */intset *intsetNew(void) &#123; // 为整数集合结构分配空间 intset *is = zmalloc(sizeof(intset)); // 设置初始编码 is-&gt;encoding = intrev32ifbe(INTSET_ENC_INT16); // 初始化元素数量 is-&gt;length = 0; return is;&#125;/* Resize the intset * * 调整整数集合的内存空间大小 * * 如果调整后的大小要比集合原来的大小要大， * 那么集合中原有元素的值不会被改变。 * * 返回值：调整大小后的整数集合 * * T = O(N) */static intset *intsetResize(intset *is, uint32_t len) &#123; // 计算数组的空间大小 uint32_t size = len*intrev32ifbe(is-&gt;encoding); // 根据空间大小，重新分配空间 // 注意这里使用的是 zrealloc ， // 所以如果新空间大小比原来的空间大小要大， // 那么数组原有的数据会被保留 is = zrealloc(is,sizeof(intset)+size); return is;&#125;/* Search for the position of \"value\". * * 在集合 is 的底层数组中查找值 value 所在的索引。 * * Return 1 when the value was found and * sets \"pos\" to the position of the value within the intset. * * 成功找到 value 时，函数返回 1 ，并将 *pos 的值设为 value 所在的索引。 * * Return 0 when the value is not present in the intset * and sets \"pos\" to the position where \"value\" can be inserted. * * 当在数组中没找到 value 时，返回 0 。 * 并将 *pos 的值设为 value 可以插入到数组中的位置。 * * T = O(log N) */static uint8_t intsetSearch(intset *is, int64_t value, uint32_t *pos) &#123; int min = 0, max = intrev32ifbe(is-&gt;length)-1, mid = -1; int64_t cur = -1; /* The value can never be found when the set is empty */ // 处理 is 为空时的情况 if (intrev32ifbe(is-&gt;length) == 0) &#123; if (pos) *pos = 0; return 0; &#125; else &#123; /* Check for the case where we know we cannot find the value, * but do know the insert position. */ // 因为底层数组是有序的，如果 value 比数组中最后一个值都要大 // 那么 value 肯定不存在于集合中， // 并且应该将 value 添加到底层数组的最末端 if (value &gt; _intsetGet(is,intrev32ifbe(is-&gt;length)-1)) &#123; if (pos) *pos = intrev32ifbe(is-&gt;length); return 0; // 因为底层数组是有序的，如果 value 比数组中最前一个值都要小 // 那么 value 肯定不存在于集合中， // 并且应该将它添加到底层数组的最前端 &#125; else if (value &lt; _intsetGet(is,0)) &#123; if (pos) *pos = 0; return 0; &#125; &#125; // 在有序数组中进行二分查找 // T = O(log N) while(max &gt;= min) &#123; mid = (min+max)/2; cur = _intsetGet(is,mid); if (value &gt; cur) &#123; min = mid+1; &#125; else if (value &lt; cur) &#123; max = mid-1; &#125; else &#123; break; &#125; &#125; // 检查是否已经找到了 value if (value == cur) &#123; if (pos) *pos = mid; return 1; &#125; else &#123; if (pos) *pos = min; return 0; &#125;&#125;/* Upgrades the intset to a larger encoding and inserts the given integer. * * 根据值 value 所使用的编码方式，对整数集合的编码进行升级， * 并将值 value 添加到升级后的整数集合中。 * * 返回值：添加新元素之后的整数集合 * * T = O(N) */static intset *intsetUpgradeAndAdd(intset *is, int64_t value) &#123; // 当前的编码方式 uint8_t curenc = intrev32ifbe(is-&gt;encoding); // 新值所需的编码方式 uint8_t newenc = _intsetValueEncoding(value); // 当前集合的元素数量 int length = intrev32ifbe(is-&gt;length); // 根据 value 的值，决定是将它添加到底层数组的最前端还是最后端 // 注意，因为 value 的编码比集合原有的其他元素的编码都要大 // 所以 value 要么大于集合中的所有元素，要么小于集合中的所有元素 // 因此，value 只能添加到底层数组的最前端或最后端 int prepend = value &lt; 0 ? 1 : 0; /* First set new encoding and resize */ // 更新集合的编码方式 is-&gt;encoding = intrev32ifbe(newenc); // 根据新编码对集合（的底层数组）进行空间调整 // T = O(N) is = intsetResize(is,intrev32ifbe(is-&gt;length)+1); /* Upgrade back-to-front so we don't overwrite values. * Note that the \"prepend\" variable is used to make sure we have an empty * space at either the beginning or the end of the intset. */ // 根据集合原来的编码方式，从底层数组中取出集合元素 // 然后再将元素以新编码的方式添加到集合中 // 当完成了这个步骤之后，集合中所有原有的元素就完成了从旧编码到新编码的转换 // 因为新分配的空间都放在数组的后端，所以程序先从后端向前端移动元素 // 举个例子，假设原来有 curenc 编码的三个元素，它们在数组中排列如下： // | x | y | z | // 当程序对数组进行重分配之后，数组就被扩容了（符号 ？ 表示未使用的内存）： // | x | y | z | ? | ? | ? | // 这时程序从数组后端开始，重新插入元素： // | x | y | z | ? | z | ? | // | x | y | y | z | ? | // | x | y | z | ? | // 最后，程序可以将新元素添加到最后 ？ 号标示的位置中： // | x | y | z | new | // 上面演示的是新元素比原来的所有元素都大的情况，也即是 prepend == 0 // 当新元素比原来的所有元素都小时（prepend == 1），调整的过程如下： // | x | y | z | ? | ? | ? | // | x | y | z | ? | ? | z | // | x | y | z | ? | y | z | // | x | y | x | y | z | // 当添加新值时，原本的 | x | y | 的数据将被新值代替 // | new | x | y | z | // T = O(N) while(length--) _intsetSet(is,length+prepend,_intsetGetEncoded(is,length,curenc)); /* Set the value at the beginning or the end. */ // 设置新值，根据 prepend 的值来决定是添加到数组头还是数组尾 if (prepend) _intsetSet(is,0,value); else _intsetSet(is,intrev32ifbe(is-&gt;length),value); // 更新整数集合的元素数量 is-&gt;length = intrev32ifbe(intrev32ifbe(is-&gt;length)+1); return is;&#125;/* * 向前或先后移动指定索引范围内的数组元素 * * 函数名中的 MoveTail 其实是一个有误导性的名字， * 这个函数可以向前或向后移动元素， * 而不仅仅是向后 * * 在添加新元素到数组时，就需要进行向后移动， * 如果数组表示如下（？表示一个未设置新值的空间）： * | x | y | z | ? | * |&lt;-----&gt;| * 而新元素 n 的 pos 为 1 ，那么数组将移动 y 和 z 两个元素 * | x | y | y | z | * |&lt;-----&gt;| * 接着就可以将新元素 n 设置到 pos 上了： * | x | n | y | z | * * 当从数组中删除元素时，就需要进行向前移动， * 如果数组表示如下，并且 b 为要删除的目标： * | a | b | c | d | * |&lt;-----&gt;| * 那么程序就会移动 b 后的所有元素向前一个元素的位置， * 从而覆盖 b 的数据： * | a | c | d | d | * |&lt;-----&gt;| * 最后，程序再从数组末尾删除一个元素的空间： * | a | c | d | * 这样就完成了删除操作。 * * T = O(N) */static void intsetMoveTail(intset *is, uint32_t from, uint32_t to) &#123; void *src, *dst; // 要移动的元素个数 uint32_t bytes = intrev32ifbe(is-&gt;length)-from; // 集合的编码方式 uint32_t encoding = intrev32ifbe(is-&gt;encoding); // 根据不同的编码 // src = (Enc_t*)is-&gt;contents+from 记录移动开始的位置 // dst = (Enc_t*)is_.contents+to 记录移动结束的位置 // bytes *= sizeof(Enc_t) 计算一共要移动多少字节 if (encoding == INTSET_ENC_INT64) &#123; src = (int64_t*)is-&gt;contents+from; dst = (int64_t*)is-&gt;contents+to; bytes *= sizeof(int64_t); &#125; else if (encoding == INTSET_ENC_INT32) &#123; src = (int32_t*)is-&gt;contents+from; dst = (int32_t*)is-&gt;contents+to; bytes *= sizeof(int32_t); &#125; else &#123; src = (int16_t*)is-&gt;contents+from; dst = (int16_t*)is-&gt;contents+to; bytes *= sizeof(int16_t); &#125; // 进行移动 // T = O(N) memmove(dst,src,bytes);&#125;/* Insert an integer in the intset * * 尝试将元素 value 添加到整数集合中。 * * *success 的值指示添加是否成功： * - 如果添加成功，那么将 *success 的值设为 1 。 * - 因为元素已存在而造成添加失败时，将 *success 的值设为 0 。 * * T = O(N) */intset *intsetAdd(intset *is, int64_t value, uint8_t *success) &#123; // 计算编码 value 所需的长度 uint8_t valenc = _intsetValueEncoding(value); uint32_t pos; // 默认设置插入为成功 if (success) *success = 1; /* Upgrade encoding if necessary. If we need to upgrade, we know that * this value should be either appended (if &gt; 0) or prepended (if &lt; 0), * because it lies outside the range of existing values. */ // 如果 value 的编码比整数集合现在的编码要大 // 那么表示 value 必然可以添加到整数集合中 // 并且整数集合需要对自身进行升级，才能满足 value 所需的编码 if (valenc &gt; intrev32ifbe(is-&gt;encoding)) &#123; /* This always succeeds, so we don't need to curry *success. */ // T = O(N) return intsetUpgradeAndAdd(is,value); &#125; else &#123; // 运行到这里，表示整数集合现有的编码方式适用于 value /* Abort if the value is already present in the set. * This call will populate \"pos\" with the right position to insert * the value when it cannot be found. */ // 在整数集合中查找 value ，看他是否存在： // - 如果存在，那么将 *success 设置为 0 ，并返回未经改动的整数集合 // - 如果不存在，那么可以插入 value 的位置将被保存到 pos 指针中 // 等待后续程序使用 if (intsetSearch(is,value,&amp;pos)) &#123; if (success) *success = 0; return is; &#125; // 运行到这里，表示 value 不存在于集合中 // 程序需要将 value 添加到整数集合中 // 为 value 在集合中分配空间 is = intsetResize(is,intrev32ifbe(is-&gt;length)+1); // 如果新元素不是被添加到底层数组的末尾 // 那么需要对现有元素的数据进行移动，空出 pos 上的位置，用于设置新值 // 举个例子 // 如果数组为： // | x | y | z | ? | // |&lt;-----&gt;| // 而新元素 n 的 pos 为 1 ，那么数组将移动 y 和 z 两个元素 // | x | y | y | z | // |&lt;-----&gt;| // 这样就可以将新元素设置到 pos 上了： // | x | n | y | z | // T = O(N) if (pos &lt; intrev32ifbe(is-&gt;length)) intsetMoveTail(is,pos,pos+1); &#125; // 将新值设置到底层数组的指定位置中 _intsetSet(is,pos,value); // 增一集合元素数量的计数器 is-&gt;length = intrev32ifbe(intrev32ifbe(is-&gt;length)+1); // 返回添加新元素后的整数集合 return is; /* p.s. 上面的代码可以重构成以下更简单的形式： if (valenc &gt; intrev32ifbe(is-&gt;encoding)) &#123; return intsetUpgradeAndAdd(is,value); &#125; if (intsetSearch(is,value,&amp;pos)) &#123; if (success) *success = 0; return is; &#125; else &#123; is = intsetResize(is,intrev32ifbe(is-&gt;length)+1); if (pos &lt; intrev32ifbe(is-&gt;length)) intsetMoveTail(is,pos,pos+1); _intsetSet(is,pos,value); is-&gt;length = intrev32ifbe(intrev32ifbe(is-&gt;length)+1); return is; &#125; */&#125;/* Delete integer from intset * * 从整数集合中删除值 value 。 * * *success 的值指示删除是否成功： * - 因值不存在而造成删除失败时该值为 0 。 * - 删除成功时该值为 1 。 * * T = O(N) */intset *intsetRemove(intset *is, int64_t value, int *success) &#123; // 计算 value 的编码方式 uint8_t valenc = _intsetValueEncoding(value); uint32_t pos; // 默认设置标识值为删除失败 if (success) *success = 0; // 当 value 的编码大小小于或等于集合的当前编码方式（说明 value 有可能存在于集合） // 并且 intsetSearch 的结果为真，那么执行删除 // T = O(log N) if (valenc &lt;= intrev32ifbe(is-&gt;encoding) &amp;&amp; intsetSearch(is,value,&amp;pos)) &#123; // 取出集合当前的元素数量 uint32_t len = intrev32ifbe(is-&gt;length); /* We know we can delete */ // 设置标识值为删除成功 if (success) *success = 1; /* Overwrite value with tail and update length */ // 如果 value 不是位于数组的末尾 // 那么需要对原本位于 value 之后的元素进行移动 // // 举个例子，如果数组表示如下，而 b 为删除的目标 // | a | b | c | d | // 那么 intsetMoveTail 将 b 之后的所有数据向前移动一个元素的空间， // 覆盖 b 原来的数据 // | a | c | d | d | // 之后 intsetResize 缩小内存大小时， // 数组末尾多出来的一个元素的空间将被移除 // | a | c | d | if (pos &lt; (len-1)) intsetMoveTail(is,pos+1,pos); // 缩小数组的大小，移除被删除元素占用的空间 // T = O(N) is = intsetResize(is,len-1); // 更新集合的元素数量 is-&gt;length = intrev32ifbe(len-1); &#125; return is;&#125;/* Determine whether a value belongs to this set * * 检查给定值 value 是否集合中的元素。 * * 是返回 1 ，不是返回 0 。 * * T = O(log N) */uint8_t intsetFind(intset *is, int64_t value) &#123; // 计算 value 的编码 uint8_t valenc = _intsetValueEncoding(value); // 如果 value 的编码大于集合的当前编码，那么 value 一定不存在于集合 // 当 value 的编码小于等于集合的当前编码时， // 才再使用 intsetSearch 进行查找 return valenc &lt;= intrev32ifbe(is-&gt;encoding) &amp;&amp; intsetSearch(is,value,NULL);&#125;/* Return random member * * 从整数集合中随机返回一个元素 * * 只能在集合非空时使用 * * T = O(1) */int64_t intsetRandom(intset *is) &#123; // intrev32ifbe(is-&gt;length) 取出集合的元素数量 // 而 rand() % intrev32ifbe(is-&gt;length) 根据元素数量计算一个随机索引 // 然后 _intsetGet 负责根据随机索引来查找值 return _intsetGet(is,rand()%intrev32ifbe(is-&gt;length));&#125;/* Sets the value to the value at the given position. When this position is * out of range the function returns 0, when in range it returns 1. *//* * 取出集合底层数组指定位置中的值，并将它保存到 value 指针中。 * * 如果 pos 没超出数组的索引范围，那么返回 1 ，如果超出索引，那么返回 0 。 * * p.s. 上面原文的文档说这个函数用于设置值，这是错误的。 * * T = O(1) */uint8_t intsetGet(intset *is, uint32_t pos, int64_t *value) &#123; // pos &lt; intrev32ifbe(is-&gt;length) // 检查 pos 是否符合数组的范围 if (pos &lt; intrev32ifbe(is-&gt;length)) &#123; // 保存值到指针 *value = _intsetGet(is,pos); // 返回成功指示值 return 1; &#125; // 超出索引范围 return 0;&#125;/* Return intset length * * 返回整数集合现有的元素个数 * * T = O(1) */uint32_t intsetLen(intset *is) &#123; return intrev32ifbe(is-&gt;length);&#125;/* Return intset blob size in bytes. * * 返回整数集合现在占用的字节总数量 * 这个数量包括整数集合的结构大小，以及整数集合所有元素的总大小 * * T = O(1) */size_t intsetBlobLen(intset *is) &#123; return sizeof(intset)+intrev32ifbe(is-&gt;length)*intrev32ifbe(is-&gt;encoding);&#125;","path":"2019/04/21/redis源码-整数集合/","date":"04-21","excerpt":"整数集合整数集合是集合键的底层实现之一， 当一个集合只包含整数值元素，并且这个集合的元素数量不多时，redis会使用整数集合键实现整数集合的实现整数集合是用于保存整数值的集合抽象数据结构，可以保存int16_t / int32_t / int64_t的整数值123456789101112typedef struct intset &#123; // 编码方式 uint32_t encoding; // 集合包含的元素数量 uint32_t length; // 保存元素的数组 int8_t contents[];&#125; intset;","tags":[{"name":"源码","slug":"源码","permalink":"https://jijiking51.cn/tags/源码/"}],"preview":"http://img.jijiking51.cn/redis-整数集合.jpg"},{"title":"redis源码-skiplist","text":"跳跃表概念跳跃表是一种有序数据结构，他通过在每个节点中维持多个指向其他节点的指针，从而达到快速访问的目的。跳跃表支持平均O(logN)、最坏O(N)复杂度的节点查找，还可以通过顺序性操作来批量处理节点。Redis使用跳跃表作为有序集合键的底层实现之一，如果一个有序集合包含的元素数量比较多，又或者有序集合中元素的成员是比较长的字符串时，redis就会使用跳跃表作为有序集合键的底层实现。redis只有两个地方使用了跳跃表，一个是实现有序集合键，另一个是在集群节点中用作内部数据结构。 跳跃表的实现1234567891011121314151617181920212223242526/* * 跳跃表节点 */typedef struct zskiplistNode &#123; // 成员对象 robj *obj; // 分值 double score; // 后退指针 struct zskiplistNode *backward; // 层 struct zskiplistLevel &#123; // 前进指针 struct zskiplistNode *forward; // 跨度 unsigned int span; &#125; level[];&#125; zskiplistNode; level: 节点中的层，可以有多个层，每个层都有两个属性，前进指针和跨度。前进指针用于访问位于表尾方向的其他节点，而跨度则记录了前进指针所指向节点和当前节点的距离。当程序从头表进行遍历的时候，访问会沿着层的前进指针进行。 一般来说，层数越多，访问其他节点速度就越快，每次创建一个新的跳跃表的时候，程序都根据幂次定律（越大的数出现几率越小）随机生成一个1-32的值作为level数组大小，这个数就是层的高度 每个层都有一个指向表尾方向的前进指针 迭代程序首先访问跳跃表的第一个节点（表头）， 然后从第四层的前进指针移动到表中的第二个节点。 在第二个节点时， 程序沿着第二层的前进指针移动到表中的第三个节点。 在第三个节点时， 程序同样沿着第二层的前进指针移动到表中的第四个节点。 当程序再次沿着第四个节点的前进指针移动时， 它碰到一个 NULL ， 程序知道这时已经到达了跳跃表的表尾， 于是结束这次遍历。 层的跨度用于记录两个节点之间的距离：两个节点之间的跨度越大， 它们相距得就越远。指向 NULL 的所有前进指针的跨度都为 0 ， 因为它们没有连向任何节点。初看上去， 很容易以为跨度和遍历操作有关， 但实际上并不是这样,遍历操作只使用前进指针就可以完成了， 跨度实际上是用来计算排位（rank）的： 在查找某个节点的过程中， 将沿途访问过的所有层的跨度累计起来， 得到的结果就是目标节点在跳跃表中的排位。 举个例子， 下图用虚线标记了在跳跃表中查找分值为 3.0 、 成员对象为 o3 的节点时， 沿途经历的层： 查找的过程只经过了一个层， 并且层的跨度为 3 ， 所以目标节点在跳跃表中的排位为 3 。 backward: 节点中指向位于当前节点的前一个节点。后退指针在程序从表尾向表头遍历时使用 倒数第四个是头表，不包含对象 score: 各个节点中保存的分值，节点按照分值从小到大排列 obj: 各个节点保存的成员对象，指向一个字符串对象，而字符串对象则保存一个SDS值 同一个跳跃表中，保存的成员对象是唯一的，但是多个节点保存的分值可以相同，分值相同的节点将按照成员对象在字典序中的大小来进行排序，成员对象小的将会靠近表头方向（从小到大)例如：o1&lt;=o2&lt;=o3 分值相同的情况下排序如下 123456789101112131415/* * 跳跃表 */typedef struct zskiplist &#123; // 表头节点和表尾节点 struct zskiplistNode *header, *tail; // 表中节点的数量 unsigned long length; // 表中层数最大的节点的层数 int level;&#125; zskiplist; header: 指向跳跃表的表头节点 tail: 指向跳跃表的表尾节点 level: 记录目前跳跃表内，层数最大的那个节点的层数(表头节点的层数不计算在内) length: 记录跳跃表的长度，跳跃表目前包含节点的数量(表头节点不计算在内) 跳跃表API常用API 函数 作用 时间复杂度 zslCreate 创建一个新的跳跃表。 O(1) zslFree 释放给定跳跃表，以及表中包含的所有节点。 O(N) ， N 为跳跃表的长度。 zslInsert 将包含给定成员和分值的新节点添加到跳跃表中。 平均 O(N) ， N 为跳跃表长度。 zslDelete 删除跳跃表中包含给定成员和分值的节点。 平均 O(N) ， N 为跳跃表长度。 zslGetRank 返回包含给定成员和分值的节点在跳跃表中的排位。 平均 O(N) ， N 为跳跃表长度。 zslGetElementByRank 返回跳跃表在给定排位上的节点。 平均 O(N) ， N 为跳跃表长度。 zslIsInRange 给定一个分值范围（range）， 比如 0 到 15 ， 20 到 28，诸如此类， 如果给定的分值范围包含在跳跃表的分值范围之内， 那么返回 1 ，否则返回 0 。 通过跳跃表的表头节点和表尾节点， 这个检测可以用 O(1) 复杂度完成。 zslFirstInRange 给定一个分值范围， 返回跳跃表中第一个符合这个范围的节点。 平均 O(N) 。 N 为跳跃表长度。 zslLastInRange 给定一个分值范围， 返回跳跃表中最后一个符合这个范围的节点。 平均 O(N) 。 N 为跳跃表长度。 zslDeleteRangeByScore 给定一个分值范围， 删除跳跃表中所有在这个范围之内的节点。 O(N) ， N 为被删除节点数量。 zslDeleteRangeByRank 给定一个排位范围， 删除跳跃表中所有在这个范围之内的节点。 O(N) ， N 为被删除节点数量。 API注解123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728729730731732733734735736737738739/* * 创建一个层数为 level 的跳跃表节点， * 并将节点的成员对象设置为 obj ，分值设置为 score 。 * * 返回值为新创建的跳跃表节点 * * T = O(1) */zskiplistNode *zslCreateNode(int level, double score, robj *obj) &#123; // 分配空间 zskiplistNode *zn = zmalloc(sizeof(*zn)+level*sizeof(struct zskiplistLevel)); // 设置属性 zn-&gt;score = score; zn-&gt;obj = obj; return zn;&#125;/* * 创建并返回一个新的跳跃表 * * T = O(1) */zskiplist *zslCreate(void) &#123; int j; zskiplist *zsl; // 分配空间 zsl = zmalloc(sizeof(*zsl)); // 设置高度和起始层数 zsl-&gt;level = 1; zsl-&gt;length = 0; // 初始化表头节点 // T = O(1) zsl-&gt;header = zslCreateNode(ZSKIPLIST_MAXLEVEL,0,NULL); for (j = 0; j &lt; ZSKIPLIST_MAXLEVEL; j++) &#123; zsl-&gt;header-&gt;level[j].forward = NULL; zsl-&gt;header-&gt;level[j].span = 0; &#125; zsl-&gt;header-&gt;backward = NULL; // 设置表尾 zsl-&gt;tail = NULL; return zsl;&#125;/* * 释放给定的跳跃表节点 * * T = O(1) */void zslFreeNode(zskiplistNode *node) &#123; decrRefCount(node-&gt;obj); zfree(node);&#125;/* * 释放给定跳跃表，以及表中的所有节点 * * T = O(N) */void zslFree(zskiplist *zsl) &#123; zskiplistNode *node = zsl-&gt;header-&gt;level[0].forward, *next; // 释放表头 zfree(zsl-&gt;header); // 释放表中所有节点 // T = O(N) while(node) &#123; next = node-&gt;level[0].forward; zslFreeNode(node); node = next; &#125; // 释放跳跃表结构 zfree(zsl);&#125;/* Returns a random level for the new skiplist node we are going to create. * * 返回一个随机值，用作新跳跃表节点的层数。 * * The return value of this function is between 1 and ZSKIPLIST_MAXLEVEL * (both inclusive), with a powerlaw-alike distribution where higher * levels are less likely to be returned. * * 返回值介乎 1 和 ZSKIPLIST_MAXLEVEL 之间（包含 ZSKIPLIST_MAXLEVEL）， * 根据随机算法所使用的幂次定律，越大的值生成的几率越小。 * * T = O(N) */int zslRandomLevel(void) &#123; int level = 1; while ((random()&amp;0xFFFF) &lt; (ZSKIPLIST_P * 0xFFFF)) level += 1; return (level&lt;ZSKIPLIST_MAXLEVEL) ? level : ZSKIPLIST_MAXLEVEL;&#125;/* * 创建一个成员为 obj ，分值为 score 的新节点， * 并将这个新节点插入到跳跃表 zsl 中。 * * 函数的返回值为新节点。 * * T_wrost = O(N^2), T_avg = O(N log N) */zskiplistNode *zslInsert(zskiplist *zsl, double score, robj *obj) &#123; zskiplistNode *update[ZSKIPLIST_MAXLEVEL], *x; unsigned int rank[ZSKIPLIST_MAXLEVEL]; int i, level; redisAssert(!isnan(score)); // 在各个层查找节点的插入位置 // T_wrost = O(N^2), T_avg = O(N log N) x = zsl-&gt;header; for (i = zsl-&gt;level-1; i &gt;= 0; i--) &#123; /* store rank that is crossed to reach the insert position */ // 如果 i 不是 zsl-&gt;level-1 层 // 那么 i 层的起始 rank 值为 i+1 层的 rank 值 // 各个层的 rank 值一层层累积 // 最终 rank[0] 的值加一就是新节点的前置节点的排位 // rank[0] 会在后面成为计算 span 值和 rank 值的基础 rank[i] = i == (zsl-&gt;level-1) ? 0 : rank[i+1]; // 沿着前进指针遍历跳跃表 // T_wrost = O(N^2), T_avg = O(N log N) while (x-&gt;level[i].forward &amp;&amp; (x-&gt;level[i].forward-&gt;score &lt; score || // 比对分值 (x-&gt;level[i].forward-&gt;score == score &amp;&amp; // 比对成员， T = O(N) compareStringObjects(x-&gt;level[i].forward-&gt;obj,obj) &lt; 0))) &#123; // 记录沿途跨越了多少个节点 rank[i] += x-&gt;level[i].span; // 移动至下一指针 x = x-&gt;level[i].forward; &#125; // 记录将要和新节点相连接的节点 update[i] = x; &#125; /* we assume the key is not already inside, since we allow duplicated * scores, and the re-insertion of score and redis object should never * happen since the caller of zslInsert() should test in the hash table * if the element is already inside or not. * * zslInsert() 的调用者会确保同分值且同成员的元素不会出现， * 所以这里不需要进一步进行检查，可以直接创建新元素。 */ // 获取一个随机值作为新节点的层数 // T = O(N) level = zslRandomLevel(); // 如果新节点的层数比表中其他节点的层数都要大 // 那么初始化表头节点中未使用的层，并将它们记录到 update 数组中 // 将来也指向新节点 if (level &gt; zsl-&gt;level) &#123; // 初始化未使用层 // T = O(1) for (i = zsl-&gt;level; i &lt; level; i++) &#123; rank[i] = 0; update[i] = zsl-&gt;header; update[i]-&gt;level[i].span = zsl-&gt;length; &#125; // 更新表中节点最大层数 zsl-&gt;level = level; &#125; // 创建新节点 x = zslCreateNode(level,score,obj); // 将前面记录的指针指向新节点，并做相应的设置 // T = O(1) for (i = 0; i &lt; level; i++) &#123; // 设置新节点的 forward 指针 x-&gt;level[i].forward = update[i]-&gt;level[i].forward; // 将沿途记录的各个节点的 forward 指针指向新节点 update[i]-&gt;level[i].forward = x; /* update span covered by update[i] as x is inserted here */ // 计算新节点跨越的节点数量 x-&gt;level[i].span = update[i]-&gt;level[i].span - (rank[0] - rank[i]); // 更新新节点插入之后，沿途节点的 span 值 // 其中的 +1 计算的是新节点 update[i]-&gt;level[i].span = (rank[0] - rank[i]) + 1; &#125; /* increment span for untouched levels */ // 未接触的节点的 span 值也需要增一，这些节点直接从表头指向新节点 // T = O(1) for (i = level; i &lt; zsl-&gt;level; i++) &#123; update[i]-&gt;level[i].span++; &#125; // 设置新节点的后退指针 x-&gt;backward = (update[0] == zsl-&gt;header) ? NULL : update[0]; if (x-&gt;level[0].forward) x-&gt;level[0].forward-&gt;backward = x; else zsl-&gt;tail = x; // 跳跃表的节点计数增一 zsl-&gt;length++; return x;&#125;/* Internal function used by zslDelete, zslDeleteByScore and zslDeleteByRank * * 内部删除函数， * 被 zslDelete 、 zslDeleteRangeByScore 和 zslDeleteByRank 等函数调用。 * * T = O(1) */void zslDeleteNode(zskiplist *zsl, zskiplistNode *x, zskiplistNode **update) &#123; int i; // 更新所有和被删除节点 x 有关的节点的指针，解除它们之间的关系 // T = O(1) for (i = 0; i &lt; zsl-&gt;level; i++) &#123; if (update[i]-&gt;level[i].forward == x) &#123; update[i]-&gt;level[i].span += x-&gt;level[i].span - 1; update[i]-&gt;level[i].forward = x-&gt;level[i].forward; &#125; else &#123; update[i]-&gt;level[i].span -= 1; &#125; &#125; // 更新被删除节点 x 的前进和后退指针 if (x-&gt;level[0].forward) &#123; x-&gt;level[0].forward-&gt;backward = x-&gt;backward; &#125; else &#123; zsl-&gt;tail = x-&gt;backward; &#125; // 更新跳跃表最大层数（只在被删除节点是跳跃表中最高的节点时才执行） // T = O(1) while(zsl-&gt;level &gt; 1 &amp;&amp; zsl-&gt;header-&gt;level[zsl-&gt;level-1].forward == NULL) zsl-&gt;level--; // 跳跃表节点计数器减一 zsl-&gt;length--;&#125;/* Delete an element with matching score/object from the skiplist. * * 从跳跃表 zsl 中删除包含给定节点 score 并且带有指定对象 obj 的节点。 * * T_wrost = O(N^2), T_avg = O(N log N) */int zslDelete(zskiplist *zsl, double score, robj *obj) &#123; zskiplistNode *update[ZSKIPLIST_MAXLEVEL], *x; int i; // 遍历跳跃表，查找目标节点，并记录所有沿途节点 // T_wrost = O(N^2), T_avg = O(N log N) x = zsl-&gt;header; for (i = zsl-&gt;level-1; i &gt;= 0; i--) &#123; // 遍历跳跃表的复杂度为 T_wrost = O(N), T_avg = O(log N) while (x-&gt;level[i].forward &amp;&amp; (x-&gt;level[i].forward-&gt;score &lt; score || // 比对分值 (x-&gt;level[i].forward-&gt;score == score &amp;&amp; // 比对对象，T = O(N) compareStringObjects(x-&gt;level[i].forward-&gt;obj,obj) &lt; 0))) // 沿着前进指针移动 x = x-&gt;level[i].forward; // 记录沿途节点 update[i] = x; &#125; /* We may have multiple elements with the same score, what we need * is to find the element with both the right score and object. * * 检查找到的元素 x ，只有在它的分值和对象都相同时，才将它删除。 */ x = x-&gt;level[0].forward; if (x &amp;&amp; score == x-&gt;score &amp;&amp; equalStringObjects(x-&gt;obj,obj)) &#123; // T = O(1) zslDeleteNode(zsl, x, update); // T = O(1) zslFreeNode(x); return 1; &#125; else &#123; return 0; /* not found */ &#125; return 0; /* not found */&#125;/* * 检测给定值 value 是否大于（或大于等于）范围 spec 中的 min 项。 * * 返回 1 表示 value 大于等于 min 项，否则返回 0 。 * * T = O(1) */static int zslValueGteMin(double value, zrangespec *spec) &#123; return spec-&gt;minex ? (value &gt; spec-&gt;min) : (value &gt;= spec-&gt;min);&#125;/* * 检测给定值 value 是否小于（或小于等于）范围 spec 中的 max 项。 * * 返回 1 表示 value 小于等于 max 项，否则返回 0 。 * * T = O(1) */static int zslValueLteMax(double value, zrangespec *spec) &#123; return spec-&gt;maxex ? (value &lt; spec-&gt;max) : (value &lt;= spec-&gt;max);&#125;/* Returns if there is a part of the zset is in range. * * 如果给定的分值范围包含在跳跃表的分值范围之内， * 那么返回 1 ，否则返回 0 。 * * T = O(1) */int zslIsInRange(zskiplist *zsl, zrangespec *range) &#123; zskiplistNode *x; /* Test for ranges that will always be empty. */ // 先排除总为空的范围值 if (range-&gt;min &gt; range-&gt;max || (range-&gt;min == range-&gt;max &amp;&amp; (range-&gt;minex || range-&gt;maxex))) return 0; // 检查最大分值 x = zsl-&gt;tail; if (x == NULL || !zslValueGteMin(x-&gt;score,range)) return 0; // 检查最小分值 x = zsl-&gt;header-&gt;level[0].forward; if (x == NULL || !zslValueLteMax(x-&gt;score,range)) return 0; return 1;&#125;/* Find the first node that is contained in the specified range. * * 返回 zsl 中第一个分值符合 range 中指定范围的节点。 * Returns NULL when no element is contained in the range. * * 如果 zsl 中没有符合范围的节点，返回 NULL 。 * * T_wrost = O(N), T_avg = O(log N) */zskiplistNode *zslFirstInRange(zskiplist *zsl, zrangespec *range) &#123; zskiplistNode *x; int i; /* If everything is out of range, return early. */ if (!zslIsInRange(zsl,range)) return NULL; // 遍历跳跃表，查找符合范围 min 项的节点 // T_wrost = O(N), T_avg = O(log N) x = zsl-&gt;header; for (i = zsl-&gt;level-1; i &gt;= 0; i--) &#123; /* Go forward while *OUT* of range. */ while (x-&gt;level[i].forward &amp;&amp; !zslValueGteMin(x-&gt;level[i].forward-&gt;score,range)) x = x-&gt;level[i].forward; &#125; /* This is an inner range, so the next node cannot be NULL. */ x = x-&gt;level[0].forward; redisAssert(x != NULL); /* Check if score &lt;= max. */ // 检查节点是否符合范围的 max 项 // T = O(1) if (!zslValueLteMax(x-&gt;score,range)) return NULL; return x;&#125;/* Find the last node that is contained in the specified range. * Returns NULL when no element is contained in the range. * * 返回 zsl 中最后一个分值符合 range 中指定范围的节点。 * * 如果 zsl 中没有符合范围的节点，返回 NULL 。 * * T_wrost = O(N), T_avg = O(log N) */zskiplistNode *zslLastInRange(zskiplist *zsl, zrangespec *range) &#123; zskiplistNode *x; int i; /* If everything is out of range, return early. */ // 先确保跳跃表中至少有一个节点符合 range 指定的范围， // 否则直接失败 // T = O(1) if (!zslIsInRange(zsl,range)) return NULL; // 遍历跳跃表，查找符合范围 max 项的节点 // T_wrost = O(N), T_avg = O(log N) x = zsl-&gt;header; for (i = zsl-&gt;level-1; i &gt;= 0; i--) &#123; /* Go forward while *IN* range. */ while (x-&gt;level[i].forward &amp;&amp; zslValueLteMax(x-&gt;level[i].forward-&gt;score,range)) x = x-&gt;level[i].forward; &#125; /* This is an inner range, so this node cannot be NULL. */ redisAssert(x != NULL); /* Check if score &gt;= min. */ // 检查节点是否符合范围的 min 项 // T = O(1) if (!zslValueGteMin(x-&gt;score,range)) return NULL; // 返回节点 return x;&#125;/* Delete all the elements with score between min and max from the skiplist. * * 删除所有分值在给定范围之内的节点。 * * Min and max are inclusive, so a score &gt;= min || score &lt;= max is deleted. * * min 和 max 参数都是包含在范围之内的，所以分值 &gt;= min 或 &lt;= max 的节点都会被删除。 * * Note that this function takes the reference to the hash table view of the * sorted set, in order to remove the elements from the hash table too. * * 节点不仅会从跳跃表中删除，而且会从相应的字典中删除。 * * 返回值为被删除节点的数量 * * T = O(N) */unsigned long zslDeleteRangeByScore(zskiplist *zsl, zrangespec *range, dict *dict) &#123; zskiplistNode *update[ZSKIPLIST_MAXLEVEL], *x; unsigned long removed = 0; int i; // 记录所有和被删除节点（们）有关的节点 // T_wrost = O(N) , T_avg = O(log N) x = zsl-&gt;header; for (i = zsl-&gt;level-1; i &gt;= 0; i--) &#123; while (x-&gt;level[i].forward &amp;&amp; (range-&gt;minex ? x-&gt;level[i].forward-&gt;score &lt;= range-&gt;min : x-&gt;level[i].forward-&gt;score &lt; range-&gt;min)) x = x-&gt;level[i].forward; update[i] = x; &#125; /* Current node is the last with score &lt; or &lt;= min. */ // 定位到给定范围开始的第一个节点 x = x-&gt;level[0].forward; /* Delete nodes while in range. */ // 删除范围中的所有节点 // T = O(N) while (x &amp;&amp; (range-&gt;maxex ? x-&gt;score &lt; range-&gt;max : x-&gt;score &lt;= range-&gt;max)) &#123; // 记录下个节点的指针 zskiplistNode *next = x-&gt;level[0].forward; zslDeleteNode(zsl,x,update); dictDelete(dict,x-&gt;obj); zslFreeNode(x); removed++; x = next; &#125; return removed;&#125;unsigned long zslDeleteRangeByLex(zskiplist *zsl, zlexrangespec *range, dict *dict) &#123; zskiplistNode *update[ZSKIPLIST_MAXLEVEL], *x; unsigned long removed = 0; int i; x = zsl-&gt;header; for (i = zsl-&gt;level-1; i &gt;= 0; i--) &#123; while (x-&gt;level[i].forward &amp;&amp; !zslLexValueGteMin(x-&gt;level[i].forward-&gt;obj,range)) x = x-&gt;level[i].forward; update[i] = x; &#125; /* Current node is the last with score &lt; or &lt;= min. */ x = x-&gt;level[0].forward; /* Delete nodes while in range. */ while (x &amp;&amp; zslLexValueLteMax(x-&gt;obj,range)) &#123; zskiplistNode *next = x-&gt;level[0].forward; // 从跳跃表中删除当前节点 zslDeleteNode(zsl,x,update); // 从字典中删除当前节点 dictDelete(dict,x-&gt;obj); // 释放当前跳跃表节点的结构 zslFreeNode(x); // 增加删除计数器 removed++; // 继续处理下个节点 x = next; &#125; // 返回被删除节点的数量 return removed;&#125;/* Delete all the elements with rank between start and end from the skiplist. * * 从跳跃表中删除所有给定排位内的节点。 * * Start and end are inclusive. Note that start and end need to be 1-based * * start 和 end 两个位置都是包含在内的。注意它们都是以 1 为起始值。 * * 函数的返回值为被删除节点的数量。 * * T = O(N) */unsigned long zslDeleteRangeByRank(zskiplist *zsl, unsigned int start, unsigned int end, dict *dict) &#123; zskiplistNode *update[ZSKIPLIST_MAXLEVEL], *x; unsigned long traversed = 0, removed = 0; int i; // 沿着前进指针移动到指定排位的起始位置，并记录所有沿途指针 // T_wrost = O(N) , T_avg = O(log N) x = zsl-&gt;header; for (i = zsl-&gt;level-1; i &gt;= 0; i--) &#123; while (x-&gt;level[i].forward &amp;&amp; (traversed + x-&gt;level[i].span) &lt; start) &#123; traversed += x-&gt;level[i].span; x = x-&gt;level[i].forward; &#125; update[i] = x; &#125; // 移动到排位的起始的第一个节点 traversed++; x = x-&gt;level[0].forward; // 删除所有在给定排位范围内的节点 // T = O(N) while (x &amp;&amp; traversed &lt;= end) &#123; // 记录下一节点的指针 zskiplistNode *next = x-&gt;level[0].forward; // 从跳跃表中删除节点 zslDeleteNode(zsl,x,update); // 从字典中删除节点 dictDelete(dict,x-&gt;obj); // 释放节点结构 zslFreeNode(x); // 为删除计数器增一 removed++; // 为排位计数器增一 traversed++; // 处理下个节点 x = next; &#125; // 返回被删除节点的数量 return removed;&#125;/* Find the rank for an element by both score and key. * * 查找包含给定分值和成员对象的节点在跳跃表中的排位。 * * Returns 0 when the element cannot be found, rank otherwise. * * 如果没有包含给定分值和成员对象的节点，返回 0 ，否则返回排位。 * * Note that the rank is 1-based due to the span of zsl-&gt;header to the * first element. * * 注意，因为跳跃表的表头也被计算在内，所以返回的排位以 1 为起始值。 * * T_wrost = O(N), T_avg = O(log N) */unsigned long zslGetRank(zskiplist *zsl, double score, robj *o) &#123; zskiplistNode *x; unsigned long rank = 0; int i; // 遍历整个跳跃表 x = zsl-&gt;header; for (i = zsl-&gt;level-1; i &gt;= 0; i--) &#123; // 遍历节点并对比元素 while (x-&gt;level[i].forward &amp;&amp; (x-&gt;level[i].forward-&gt;score &lt; score || // 比对分值 (x-&gt;level[i].forward-&gt;score == score &amp;&amp; // 比对成员对象 compareStringObjects(x-&gt;level[i].forward-&gt;obj,o) &lt;= 0))) &#123; // 累积跨越的节点数量 rank += x-&gt;level[i].span; // 沿着前进指针遍历跳跃表 x = x-&gt;level[i].forward; &#125; /* x might be equal to zsl-&gt;header, so test if obj is non-NULL */ // 必须确保不仅分值相等，而且成员对象也要相等 // T = O(N) if (x-&gt;obj &amp;&amp; equalStringObjects(x-&gt;obj,o)) &#123; return rank; &#125; &#125; // 没找到 return 0;&#125;/* Finds an element by its rank. The rank argument needs to be 1-based. * * 根据排位在跳跃表中查找元素。排位的起始值为 1 。 * * 成功查找返回相应的跳跃表节点，没找到则返回 NULL 。 * * T_wrost = O(N), T_avg = O(log N) */zskiplistNode* zslGetElementByRank(zskiplist *zsl, unsigned long rank) &#123; zskiplistNode *x; unsigned long traversed = 0; int i; // T_wrost = O(N), T_avg = O(log N) x = zsl-&gt;header; for (i = zsl-&gt;level-1; i &gt;= 0; i--) &#123; // 遍历跳跃表并累积越过的节点数量 while (x-&gt;level[i].forward &amp;&amp; (traversed + x-&gt;level[i].span) &lt;= rank) &#123; traversed += x-&gt;level[i].span; x = x-&gt;level[i].forward; &#125; // 如果越过的节点数量已经等于 rank // 那么说明已经到达要找的节点 if (traversed == rank) &#123; return x; &#125; &#125; // 没找到目标节点 return NULL;&#125;/* Populate the rangespec according to the objects min and max. * * 对 min 和 max 进行分析，并将区间的值保存在 spec 中。 * * 分析成功返回 REDIS_OK ，分析出错导致失败返回 REDIS_ERR 。 * * T = O(N) */static int zslParseRange(robj *min, robj *max, zrangespec *spec) &#123; char *eptr; // 默认为闭区间 spec-&gt;minex = spec-&gt;maxex = 0; /* Parse the min-max interval. If one of the values is prefixed * by the \"(\" character, it's considered \"open\". For instance * ZRANGEBYSCORE zset (1.5 (2.5 will match min &lt; x &lt; max * ZRANGEBYSCORE zset 1.5 2.5 will instead match min &lt;= x &lt;= max */ if (min-&gt;encoding == REDIS_ENCODING_INT) &#123; // min 的值为整数，开区间 spec-&gt;min = (long)min-&gt;ptr; &#125; else &#123; // min 对象为字符串，分析 min 的值并决定区间 if (((char*)min-&gt;ptr)[0] == '(') &#123; // T = O(N) spec-&gt;min = strtod((char*)min-&gt;ptr+1,&amp;eptr); if (eptr[0] != '\\0' || isnan(spec-&gt;min)) return REDIS_ERR; spec-&gt;minex = 1; &#125; else &#123; // T = O(N) spec-&gt;min = strtod((char*)min-&gt;ptr,&amp;eptr); if (eptr[0] != '\\0' || isnan(spec-&gt;min)) return REDIS_ERR; &#125; &#125; if (max-&gt;encoding == REDIS_ENCODING_INT) &#123; // max 的值为整数，开区间 spec-&gt;max = (long)max-&gt;ptr; &#125; else &#123; // max 对象为字符串，分析 max 的值并决定区间 if (((char*)max-&gt;ptr)[0] == '(') &#123; // T = O(N) spec-&gt;max = strtod((char*)max-&gt;ptr+1,&amp;eptr); if (eptr[0] != '\\0' || isnan(spec-&gt;max)) return REDIS_ERR; spec-&gt;maxex = 1; &#125; else &#123; // T = O(N) spec-&gt;max = strtod((char*)max-&gt;ptr,&amp;eptr); if (eptr[0] != '\\0' || isnan(spec-&gt;max)) return REDIS_ERR; &#125; &#125; return REDIS_OK;&#125; 跳跃表是有序集合实现的底层之一跳跃表层数是1-32随机数节点内容对象唯一，分数不唯一","path":"2019/04/18/redis源码-skiplist/","date":"04-18","excerpt":"跳跃表概念跳跃表是一种有序数据结构，他通过在每个节点中维持多个指向其他节点的指针，从而达到快速访问的目的。跳跃表支持平均O(logN)、最坏O(N)复杂度的节点查找，还可以通过顺序性操作来批量处理节点。Redis使用跳跃表作为有序集合键的底层实现之一，如果一个有序集合包含的元素数量比较多，又或者有序集合中元素的成员是比较长的字符串时，redis就会使用跳跃表作为有序集合键的底层实现。redis只有两个地方使用了跳跃表，一个是实现有序集合键，另一个是在集群节点中用作内部数据结构。","tags":[{"name":"源码","slug":"源码","permalink":"https://jijiking51.cn/tags/源码/"}],"preview":"http://img.jijiking51.cn/redis源码-skiplist.jpg"},{"title":"redis源码-字典","text":"字典的实现概念Redis的字典是使用哈希表作为底层实现原理的，一个哈希表可以有多个哈希表节点，而每个哈希表节点就保存了字典中的一个键值对。哈希表1234567891011121314151617181920212223/* This is our hash table structure. Every dictionary has two of this as we * implement incremental rehashing, for the old to the new table. *//* * 哈希表 * * 每个字典都使用两个哈希表，从而实现渐进式 rehash 。 */typedef struct dictht &#123; // 哈希表数组 dictEntry **table; // 哈希表大小 unsigned long size; // 哈希表大小掩码，用于计算索引值 // 总是等于 size - 1 unsigned long sizemask; // 该哈希表已有节点的数量 unsigned long used;&#125; dictht; table是一个数组，数组中的每个元素都是一个哈希节点，哈希表中的size属性记录了哈希表的大小，也就是table数组的大小，而used属性记录了目前已有节点的数量。sizemask属性的值总是等于size-1，这个属性和哈希值一起决定一个键应该被放到table数组的哪个索引上面。 哈希表节点12345678910111213141516171819/* * 哈希表节点 */typedef struct dictEntry &#123; // 键 void *key; // 值 union &#123; void *val; uint64_t u64; int64_t s64; &#125; v; // 指向下个哈希表节点，形成链表 struct dictEntry *next;&#125; dictEntry; key属性保存着键值对中的键，而v属性则保存键值对中的值，其中键值对的值可以是一个指针或者一个unint64_t整数或者int64_t整数。next属性是指向另一个哈希表节点的指针，这个指针可以将多个哈希值相同的键值对链接在一起，以此解决冲突问题。例如k1和k0的索引值相同将会如下图： 字典12345678910111213141516171819202122/* * 字典 */typedef struct dict &#123; // 类型特定函数 dictType *type; // 私有数据 void *privdata; // 哈希表 dictht ht[2]; // rehash 索引 // 当 rehash 不在进行时，值为 -1 int rehashidx; /* rehashing not in progress if rehashidx == -1 */ // 目前正在运行的安全迭代器的数量 int iterators; /* number of iterators currently running */&#125; dict; type属性和privdata属性针对不同类型的键值对，为创建多态字典而设置的 type属性是一个指向dictType结构的指针，每个dictType结构保存了一簇用于操作特定类型键值对的函数，redis会为用途不同的字典设置不同的类型特定函数 privdata属性则保存了需要传给哪些类型特定函数的可选参数 ht是一个包含两个项的数组，数组中的每个项都是一个dictht哈希表，一般情况下，字典只使用ht[0]哈希表，ht[1]哈希表只会在对ht[0]哈希表进行rehash时使用。除了ht[1]之外，另一个rehash有关的属性就是rehashidx，它记录了rehash目前的进度，如果目前没有在进行rehash，那么他的值为-1。 123456789101112131415161718192021222324/* * 字典类型特定函数 */typedef struct dictType &#123; // 计算哈希值的函数 unsigned int (*hashFunction)(const void *key); // 复制键的函数 void *(*keyDup)(void *privdata, const void *key); // 复制值的函数 void *(*valDup)(void *privdata, const void *obj); // 对比键的函数 int (*keyCompare)(void *privdata, const void *key1, const void *key2); // 销毁键的函数 void (*keyDestructor)(void *privdata, void *key); // 销毁值的函数 void (*valDestructor)(void *privdata, void *obj);&#125; dictType; hash算法hash实现当一个新的键值对添加到字典里面时，程序需要先根据键值对的键值计算出哈希值和索引值，然后再根据索引值，将包含新键值对的哈希表节点放到哈希表数组的指定索引上面。 redis计算hash值和索引值的方法: 123456# 使用字典设置的哈希函数，计算键key的哈希值hash = dict-&gt;type-&gt;hashFunction(key);# 使用hash表的sizemask属性和哈希值，计算出索引值# 根据情况不同，ht[x]可以是ht[0]或者ht[1]index = hash &amp; dict-&gt;ht[x].sizemask; 如果我们要将键值对k0和v0添加到字典里面，流程如下： hash = dict-&gt;type-&gt;hashFunction(k0); 计算k0的哈希值。如果计算为8 index = hash&amp;dict-&gt;ht[0].sizemask = 8 &amp; 3 = 0; 计算出键k0的索引值0，这表示包含键值对k0和v0的节点应该被放置到哈希表数组的索引0位置上 当字典被用作数据库底层实现，或者哈希键的底层是现时，redis使用murmurHash2算法来计算键的哈希值 解决键冲突当有两个或以上数量的键被分配到了哈希表数组的同一个索引上面时，我们称这些键发生了冲突。redis的哈希表使用链地址法来解决键冲突，每个哈希表节点都有一个next指针，多个哈希表节点可以用next指针构成一个单向链表，被分配到同一个索引上的多个节点可以用这个单向链表连接起来，这就解决了键冲突的问题。例如将键值对k2和v2添加到哈希表中，并且计算出k2的索引为2，与k1冲突，那么解决冲突的办法就是使用next指针将键k2和k1所在的节点连接起来。因为dictEntry节点组成的链表没有指向链表表尾的指针，所以为了速度考虑，程序总是将新节点添加到链表的头位置，排在其他已有的节点前面。 rehash随着操作的执行，哈希表保存的键值对会逐渐增多或者减少，为了让哈希表的负载因子位置在一个合理的范围之内，当哈希表保存的键值对数量太多或者太少时，程序需要对哈希表的大小进行相应的扩展或者收缩。rehash操作流程： 为字典的ht[1]哈希表分配空间，这个哈希表的空间大小取决于要执行的操作，以及ht[0]当前包含的键值对数量(也即是ht[0].used属性的值)： 如果执行的是扩展操作，那么ht[1]的大小为第一个大小等于ht[0].used*2的2^n 如果执行的是收缩操作，那么ht[1]的大小为第一个大于等于ht[0].used的2^n。 将保存在ht[0]中所有键值对rehash到ht[1]上面：rehash指的是重新计算键的哈希值和索引值，然后将键值对放置到ht[1]哈希表的指定位置上 当ht[0]包含的所有键值对都迁移到了ht[1]之后，石方ht[0]，将ht[1]设置为ht[0]，并且在ht[1]新创建一个空哈希表为下一次rehash做准备 例如，要对下图的ht[0]进行扩展操作，那么程序将执行以下步骤： ht[0].used 当前的值为 4 ， 4 * 2 = 8 ， 而 8 （2^3）恰好是第一个大于等于 4 的 2 的 n 次方， 所以程序会将 ht[1] 哈希表的大小设置为 8 。 将 ht[0] 包含的四个键值对都 rehash 到 ht[1] ， 释放 ht[0] ，并将 ht[1] 设置为 ht[0] ，然后为 ht[1] 分配一个空白哈希表， 至此，对哈希表的扩展操作执行完毕， 程序成功将哈希表的大小从原来的4改为了现在的8。 哈希表的扩展与收缩当以下条件中的任意一个被满足时， 程序会自动开始对哈希表执行扩展操作： 服务器目前没有在执行 BGSAVE 命令或者 BGREWRITEAOF 命令， 并且哈希表的负载因子大于等于 1 ； 服务器目前正在执行 BGSAVE 命令或者 BGREWRITEAOF 命令， 并且哈希表的负载因子大于等于 5 ；其中哈希表的负载因子可以通过公式： #负载因子 = 哈希表已保存节点数量 / 哈希表大小 load_factor = ht[0].used / ht[0].size计算得出。 比如说， 对于一个大小为 4 ， 包含 4 个键值对的哈希表来说， 这个哈希表的负载因子为： load_factor = 4 / 4 = 1 又比如说， 对于一个大小为 512 ， 包含 256 个键值对的哈希表来说， 这个哈希表的负载因子为： load_factor = 256 / 512 = 0.5 根据 BGSAVE 命令或 BGREWRITEAOF 命令是否正在执行， 服务器执行扩展操作所需的负载因子并不相同， 这是因为在执行 BGSAVE 命令或BGREWRITEAOF 命令的过程中， Redis 需要创建当前服务器进程的子进程， 而大多数操作系统都采用写时复制（copy-on-write）技术来优化子进程的使用效率， 所以在子进程存在期间， 服务器会提高执行扩展操作所需的负载因子， 从而尽可能地避免在子进程存在期间进行哈希表扩展操作， 这可以避免不必要的内存写入操作， 最大限度地节约内存。 另一方面， 当哈希表的负载因子小于 0.1 时， 程序自动开始对哈希表执行收缩操作。 渐进式rehash扩展或者搜索哈希表需要将ht[0]里面的所有键值对rehash到ht[1]，但是这个动作并不是一次性、集中式的完成的，二十分多次、渐进式地完成的。这样做的原因在于，如果ht[0]里面保存大量键值对时，一次将这些键值对rehash到ht[1]的话，庞大的计算量可能会导致服务器在一段时间内暂停服务。因此为了避免rehash对服务器的性能造成太大影响，服务器将进行多次rehash。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106/* * 在给定毫秒数内，以 100 步为单位，对字典进行 rehash 。 * * T = O(N) */int dictRehashMilliseconds(dict *d, int ms) &#123; // 记录开始时间 long long start = timeInMilliseconds(); int rehashes = 0; while(dictRehash(d,100)) &#123; rehashes += 100; // 如果时间已过，跳出 if (timeInMilliseconds()-start &gt; ms) break; &#125; return rehashes;&#125;/* Performs N steps of incremental rehashing. Returns 1 if there are still * keys to move from the old to the new hash table, otherwise 0 is returned. * * 执行 N 步渐进式 rehash 。 * * 返回 1 表示仍有键需要从 0 号哈希表移动到 1 号哈希表， * 返回 0 则表示所有键都已经迁移完毕。 * * Note that a rehashing step consists in moving a bucket (that may have more * than one key as we use chaining) from the old to the new hash table. * * 注意，每步 rehash 都是以一个哈希表索引（桶）作为单位的， * 一个桶里可能会有多个节点， * 被 rehash 的桶里的所有节点都会被移动到新哈希表。 * * T = O(N) */int dictRehash(dict *d, int n) &#123; // 只可以在 rehash 进行中时执行 if (!dictIsRehashing(d)) return 0; // 进行 N 步迁移 // T = O(N) while(n--) &#123; dictEntry *de, *nextde; /* Check if we already rehashed the whole table... */ // 如果 0 号哈希表为空，那么表示 rehash 执行完毕 // T = O(1) if (d-&gt;ht[0].used == 0) &#123; // 释放 0 号哈希表 zfree(d-&gt;ht[0].table); // 将原来的 1 号哈希表设置为新的 0 号哈希表 d-&gt;ht[0] = d-&gt;ht[1]; // 重置旧的 1 号哈希表 _dictReset(&amp;d-&gt;ht[1]); // 关闭 rehash 标识 d-&gt;rehashidx = -1; // 返回 0 ，向调用者表示 rehash 已经完成 return 0; &#125; /* Note that rehashidx can't overflow as we are sure there are more * elements because ht[0].used != 0 */ // 确保 rehashidx 没有越界 assert(d-&gt;ht[0].size &gt; (unsigned)d-&gt;rehashidx); // 略过数组中为空的索引，找到下一个非空索引 while(d-&gt;ht[0].table[d-&gt;rehashidx] == NULL) d-&gt;rehashidx++; // 指向该索引的链表表头节点 de = d-&gt;ht[0].table[d-&gt;rehashidx]; /* Move all the keys in this bucket from the old to the new hash HT */ // 将链表中的所有节点迁移到新哈希表 // T = O(1) while(de) &#123; unsigned int h; // 保存下个节点的指针 nextde = de-&gt;next; /* Get the index in the new hash table */ // 计算新哈希表的哈希值，以及节点插入的索引位置 h = dictHashKey(d, de-&gt;key) &amp; d-&gt;ht[1].sizemask; // 插入节点到新哈希表 de-&gt;next = d-&gt;ht[1].table[h]; d-&gt;ht[1].table[h] = de; // 更新计数器 d-&gt;ht[0].used--; d-&gt;ht[1].used++; // 继续处理下个节点 de = nextde; &#125; // 将刚迁移完的哈希表索引的指针设为空 d-&gt;ht[0].table[d-&gt;rehashidx] = NULL; // 更新 rehash 索引 d-&gt;rehashidx++; &#125; return 1;&#125; 步骤： 为ht[1]分配空间，让字典同时持有ht[0]、ht[1]两个哈希表 在字典中维持一个索引计数器变量rehashidx，并且它的值设置为0，表示rehash正式开始 在rehash期间，每次对字典执行添加、删除、查找或者更新操作时，程序除了执行指定的操作以外，还会顺带将ht[0]哈希表在rehashidx索引上的所有键值对rehash到ht[1]，当rehash工作完成之后，程序将rehashidx属性的值增1 在某个时间点上，ht[0]的所有键值对都会被rehash到ht[1]，这时设置rehashidx为-1，表示rehash已经完成 渐进式是采用分治的方式，将rehash键值对所需要的计算工作均摊到对字典的每个添加、删除、查找和更新操作上，从而避免庞大的计算量 rehash期间的哈希表操作 因为在进行渐进式rehash的过程中，字典会同时使用 ht[0]和ht[1]两个哈希表，所以在渐进式rehash进行期间，字典的删除（delete）、查找（find）、更新（update）等操作会在两个哈希表上进行：比如说， 要在字典里面查找一个键的话，程序会先在ht[0]里面进行查找，如果没找到的话，就会继续到ht[1]里面进行查找，诸如此类。 另外，在渐进式rehash执行期间，新添加到字典的键值对一律会被保存到ht[1]里面，而ht[0]则不再进行任何添加操作：这一措施保证了ht[0]包含的键值对数量会只减不增，并随着rehash操作的执行而最终变成空表 字典API常用API 函数 作用 时间复杂度 dictCreate 创建一个新的字典。 O(1) dictAdd 将给定的键值对添加到字典里面。 O(1) dictReplace 将给定的键值对添加到字典里面，如果键已经存在于字典，那么用新值取代原有的值。 O(1) dictFetchValue 返回给定键的值。 O(1) dictGetRandomKey 从字典中随机返回一个键值对。 O(1) dictDelete 从字典中删除给定键所对应的键值对。 O(1) dictRelease 释放给定字典，以及字典中包含的所有键值对。 O(N)，N为字典包含的键值对数量。 代码注解123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728729730731732733734735736737738739740741742743744745746747748749750751752753754755756757758759760761762763764765766767768769770771772773774775776777778779780781782783784785786787788789790791792793794795796797798799800801802803804805806807808809810811812813814815816817818819820821822823824825826827828829830831832833834835836837838839840841842843844845846847848849850851852853854855856857858859860861862863864865866867868869870871872873874875876877878879880881882883884885886887888889890891892893894895896897898899900901902903904905906907908909910911912913914915916917918919920921922923924925926927928929930931932933934935936937938939940941942943944945946947948949950951952953954955956957958959960961962963964965966967968969970971972973974975976977978979980981982983984985986987988989990991992993994995996997998999100010011002100310041005100610071008100910101011101210131014101510161017101810191020102110221023102410251026102710281029103010311032103310341035103610371038103910401041104210431044104510461047104810491050105110521053105410551056105710581059106010611062106310641065106610671068106910701071107210731074107510761077107810791080108110821083108410851086108710881089109010911092109310941095109610971098109911001101110211031104110511061107110811091110111111121113111411151116111711181119112011211122112311241125112611271128112911301131113211331134113511361137113811391140114111421143114411451146114711481149115011511152115311541155115611571158115911601161116211631164116511661167116811691170117111721173117411751176117711781179118011811182118311841185118611871188118911901191119211931194119511961197119811991200120112021203120412051206120712081209121012111212121312141215121612171218121912201221122212231224122512261227122812291230123112321233123412351236123712381239124012411242124312441245124612471248124912501251125212531254125512561257125812591260126112621263126412651266126712681269127012711272127312741275127612771278127912801281128212831284128512861287128812891290129112921293129412951296129712981299130013011302130313041305130613071308130913101311131213131314131513161317131813191320132113221323132413251326132713281329133013311332133313341335133613371338133913401341134213431344134513461347134813491350135113521353135413551356/* * 重置（或初始化）给定哈希表的各项属性值 * * p.s. 上面的英文注释已经过期 * * T = O(1) */static void _dictReset(dictht *ht)&#123; ht-&gt;table = NULL; ht-&gt;size = 0; ht-&gt;sizemask = 0; ht-&gt;used = 0;&#125;/* Create a new hash table *//* * 创建一个新的字典 * * T = O(1) */dict *dictCreate(dictType *type, void *privDataPtr)&#123; dict *d = zmalloc(sizeof(*d)); _dictInit(d,type,privDataPtr); return d;&#125;/* Initialize the hash table *//* * 初始化哈希表 * * T = O(1) */int _dictInit(dict *d, dictType *type, void *privDataPtr)&#123; // 初始化两个哈希表的各项属性值 // 但暂时还不分配内存给哈希表数组 _dictReset(&amp;d-&gt;ht[0]); _dictReset(&amp;d-&gt;ht[1]); // 设置类型特定函数 d-&gt;type = type; // 设置私有数据 d-&gt;privdata = privDataPtr; // 设置哈希表 rehash 状态 d-&gt;rehashidx = -1; // 设置字典的安全迭代器数量 d-&gt;iterators = 0; return DICT_OK;&#125;/* Resize the table to the minimal size that contains all the elements, * but with the invariant of a USED/BUCKETS ratio near to &lt;= 1 *//* * 缩小给定字典 * 让它的已用节点数和字典大小之间的比率接近 1:1 * * 返回 DICT_ERR 表示字典已经在 rehash ，或者 dict_can_resize 为假。 * * 成功创建体积更小的 ht[1] ，可以开始 resize 时，返回 DICT_OK。 * * T = O(N) */int dictResize(dict *d)&#123; int minimal; // 不能在关闭 rehash 或者正在 rehash 的时候调用 if (!dict_can_resize || dictIsRehashing(d)) return DICT_ERR; // 计算让比率接近 1：1 所需要的最少节点数量 minimal = d-&gt;ht[0].used; if (minimal &lt; DICT_HT_INITIAL_SIZE) minimal = DICT_HT_INITIAL_SIZE; // 调整字典的大小 // T = O(N) return dictExpand(d, minimal);&#125;/* Expand or create the hash table *//* * 创建一个新的哈希表，并根据字典的情况，选择以下其中一个动作来进行： * * 1) 如果字典的 0 号哈希表为空，那么将新哈希表设置为 0 号哈希表 * 2) 如果字典的 0 号哈希表非空，那么将新哈希表设置为 1 号哈希表， * 并打开字典的 rehash 标识，使得程序可以开始对字典进行 rehash * * size 参数不够大，或者 rehash 已经在进行时，返回 DICT_ERR 。 * * 成功创建 0 号哈希表，或者 1 号哈希表时，返回 DICT_OK 。 * * T = O(N) */int dictExpand(dict *d, unsigned long size)&#123; // 新哈希表 dictht n; /* the new hash table */ // 根据 size 参数，计算哈希表的大小 // T = O(1) unsigned long realsize = _dictNextPower(size); /* the size is invalid if it is smaller than the number of * elements already inside the hash table */ // 不能在字典正在 rehash 时进行 // size 的值也不能小于 0 号哈希表的当前已使用节点 if (dictIsRehashing(d) || d-&gt;ht[0].used &gt; size) return DICT_ERR; /* Allocate the new hash table and initialize all pointers to NULL */ // 为哈希表分配空间，并将所有指针指向 NULL n.size = realsize; n.sizemask = realsize-1; // T = O(N) n.table = zcalloc(realsize*sizeof(dictEntry*)); n.used = 0; /* Is this the first initialization? If so it's not really a rehashing * we just set the first hash table so that it can accept keys. */ // 如果 0 号哈希表为空，那么这是一次初始化： // 程序将新哈希表赋给 0 号哈希表的指针，然后字典就可以开始处理键值对了。 if (d-&gt;ht[0].table == NULL) &#123; d-&gt;ht[0] = n; return DICT_OK; &#125; /* Prepare a second hash table for incremental rehashing */ // 如果 0 号哈希表非空，那么这是一次 rehash ： // 程序将新哈希表设置为 1 号哈希表， // 并将字典的 rehash 标识打开，让程序可以开始对字典进行 rehash d-&gt;ht[1] = n; d-&gt;rehashidx = 0; return DICT_OK; /* 顺带一提，上面的代码可以重构成以下形式： if (d-&gt;ht[0].table == NULL) &#123; // 初始化 d-&gt;ht[0] = n; &#125; else &#123; // rehash d-&gt;ht[1] = n; d-&gt;rehashidx = 0; &#125; return DICT_OK; */&#125;/* Performs N steps of incremental rehashing. Returns 1 if there are still * keys to move from the old to the new hash table, otherwise 0 is returned. * * 执行 N 步渐进式 rehash 。 * * 返回 1 表示仍有键需要从 0 号哈希表移动到 1 号哈希表， * 返回 0 则表示所有键都已经迁移完毕。 * * Note that a rehashing step consists in moving a bucket (that may have more * than one key as we use chaining) from the old to the new hash table. * * 注意，每步 rehash 都是以一个哈希表索引（桶）作为单位的， * 一个桶里可能会有多个节点， * 被 rehash 的桶里的所有节点都会被移动到新哈希表。 * * T = O(N) */int dictRehash(dict *d, int n) &#123; // 只可以在 rehash 进行中时执行 if (!dictIsRehashing(d)) return 0; // 进行 N 步迁移 // T = O(N) while(n--) &#123; dictEntry *de, *nextde; /* Check if we already rehashed the whole table... */ // 如果 0 号哈希表为空，那么表示 rehash 执行完毕 // T = O(1) if (d-&gt;ht[0].used == 0) &#123; // 释放 0 号哈希表 zfree(d-&gt;ht[0].table); // 将原来的 1 号哈希表设置为新的 0 号哈希表 d-&gt;ht[0] = d-&gt;ht[1]; // 重置旧的 1 号哈希表 _dictReset(&amp;d-&gt;ht[1]); // 关闭 rehash 标识 d-&gt;rehashidx = -1; // 返回 0 ，向调用者表示 rehash 已经完成 return 0; &#125; /* Note that rehashidx can't overflow as we are sure there are more * elements because ht[0].used != 0 */ // 确保 rehashidx 没有越界 assert(d-&gt;ht[0].size &gt; (unsigned)d-&gt;rehashidx); // 略过数组中为空的索引，找到下一个非空索引 while(d-&gt;ht[0].table[d-&gt;rehashidx] == NULL) d-&gt;rehashidx++; // 指向该索引的链表表头节点 de = d-&gt;ht[0].table[d-&gt;rehashidx]; /* Move all the keys in this bucket from the old to the new hash HT */ // 将链表中的所有节点迁移到新哈希表 // T = O(1) while(de) &#123; unsigned int h; // 保存下个节点的指针 nextde = de-&gt;next; /* Get the index in the new hash table */ // 计算新哈希表的哈希值，以及节点插入的索引位置 h = dictHashKey(d, de-&gt;key) &amp; d-&gt;ht[1].sizemask; // 插入节点到新哈希表 de-&gt;next = d-&gt;ht[1].table[h]; d-&gt;ht[1].table[h] = de; // 更新计数器 d-&gt;ht[0].used--; d-&gt;ht[1].used++; // 继续处理下个节点 de = nextde; &#125; // 将刚迁移完的哈希表索引的指针设为空 d-&gt;ht[0].table[d-&gt;rehashidx] = NULL; // 更新 rehash 索引 d-&gt;rehashidx++; &#125; return 1;&#125;/* * 返回以毫秒为单位的 UNIX 时间戳 * * T = O(1) */long long timeInMilliseconds(void) &#123; struct timeval tv; gettimeofday(&amp;tv,NULL); return (((long long)tv.tv_sec)*1000)+(tv.tv_usec/1000);&#125;/* Rehash for an amount of time between ms milliseconds and ms+1 milliseconds *//* * 在给定毫秒数内，以 100 步为单位，对字典进行 rehash 。 * * T = O(N) */int dictRehashMilliseconds(dict *d, int ms) &#123; // 记录开始时间 long long start = timeInMilliseconds(); int rehashes = 0; while(dictRehash(d,100)) &#123; rehashes += 100; // 如果时间已过，跳出 if (timeInMilliseconds()-start &gt; ms) break; &#125; return rehashes;&#125;/* This function performs just a step of rehashing, and only if there are * no safe iterators bound to our hash table. When we have iterators in the * middle of a rehashing we can't mess with the two hash tables otherwise * some element can be missed or duplicated. * * 在字典不存在安全迭代器的情况下，对字典进行单步 rehash 。 * * 字典有安全迭代器的情况下不能进行 rehash ， * 因为两种不同的迭代和修改操作可能会弄乱字典。 * * This function is called by common lookup or update operations in the * dictionary so that the hash table automatically migrates from H1 to H2 * while it is actively used. * * 这个函数被多个通用的查找、更新操作调用， * 它可以让字典在被使用的同时进行 rehash 。 * * T = O(1) */static void _dictRehashStep(dict *d) &#123; if (d-&gt;iterators == 0) dictRehash(d,1);&#125;/* Add an element to the target hash table *//* * 尝试将给定键值对添加到字典中 * * 只有给定键 key 不存在于字典时，添加操作才会成功 * * 添加成功返回 DICT_OK ，失败返回 DICT_ERR * * 最坏 T = O(N) ，平滩 O(1) */int dictAdd(dict *d, void *key, void *val)&#123; // 尝试添加键到字典，并返回包含了这个键的新哈希节点 // T = O(N) dictEntry *entry = dictAddRaw(d,key); // 键已存在，添加失败 if (!entry) return DICT_ERR; // 键不存在，设置节点的值 // T = O(1) dictSetVal(d, entry, val); // 添加成功 return DICT_OK;&#125;/* Low level add. This function adds the entry but instead of setting * a value returns the dictEntry structure to the user, that will make * sure to fill the value field as he wishes. * * This function is also directly exposed to user API to be called * mainly in order to store non-pointers inside the hash value, example: * * entry = dictAddRaw(dict,mykey); * if (entry != NULL) dictSetSignedIntegerVal(entry,1000); * * Return values: * * If key already exists NULL is returned. * If key was added, the hash entry is returned to be manipulated by the caller. *//* * 尝试将键插入到字典中 * * 如果键已经在字典存在，那么返回 NULL * * 如果键不存在，那么程序创建新的哈希节点， * 将节点和键关联，并插入到字典，然后返回节点本身。 * * T = O(N) */dictEntry *dictAddRaw(dict *d, void *key)&#123; int index; dictEntry *entry; dictht *ht; // 如果条件允许的话，进行单步 rehash // T = O(1) if (dictIsRehashing(d)) _dictRehashStep(d); /* Get the index of the new element, or -1 if * the element already exists. */ // 计算键在哈希表中的索引值 // 如果值为 -1 ，那么表示键已经存在 // T = O(N) if ((index = _dictKeyIndex(d, key)) == -1) return NULL; // T = O(1) /* Allocate the memory and store the new entry */ // 如果字典正在 rehash ，那么将新键添加到 1 号哈希表 // 否则，将新键添加到 0 号哈希表 ht = dictIsRehashing(d) ? &amp;d-&gt;ht[1] : &amp;d-&gt;ht[0]; // 为新节点分配空间 entry = zmalloc(sizeof(*entry)); // 将新节点插入到链表表头 entry-&gt;next = ht-&gt;table[index]; ht-&gt;table[index] = entry; // 更新哈希表已使用节点数量 ht-&gt;used++; /* Set the hash entry fields. */ // 设置新节点的键 // T = O(1) dictSetKey(d, entry, key); return entry;&#125;/* Add an element, discarding the old if the key already exists. * * 将给定的键值对添加到字典中，如果键已经存在，那么删除旧有的键值对。 * * Return 1 if the key was added from scratch, 0 if there was already an * element with such key and dictReplace() just performed a value update * operation. * * 如果键值对为全新添加，那么返回 1 。 * 如果键值对是通过对原有的键值对更新得来的，那么返回 0 。 * * T = O(N) */int dictReplace(dict *d, void *key, void *val)&#123; dictEntry *entry, auxentry; /* Try to add the element. If the key * does not exists dictAdd will suceed. */ // 尝试直接将键值对添加到字典 // 如果键 key 不存在的话，添加会成功 // T = O(N) if (dictAdd(d, key, val) == DICT_OK) return 1; /* It already exists, get the entry */ // 运行到这里，说明键 key 已经存在，那么找出包含这个 key 的节点 // T = O(1) entry = dictFind(d, key); /* Set the new value and free the old one. Note that it is important * to do that in this order, as the value may just be exactly the same * as the previous one. In this context, think to reference counting, * you want to increment (set), and then decrement (free), and not the * reverse. */ // 先保存原有的值的指针 auxentry = *entry; // 然后设置新的值 // T = O(1) dictSetVal(d, entry, val); // 然后释放旧值 // T = O(1) dictFreeVal(d, &amp;auxentry); return 0;&#125;/* dictReplaceRaw() is simply a version of dictAddRaw() that always * returns the hash entry of the specified key, even if the key already * exists and can't be added (in that case the entry of the already * existing key is returned.) * * See dictAddRaw() for more information. *//* * dictAddRaw() 根据给定 key 释放存在，执行以下动作： * * 1) key 已经存在，返回包含该 key 的字典节点 * 2) key 不存在，那么将 key 添加到字典 * * 不论发生以上的哪一种情况， * dictAddRaw() 都总是返回包含给定 key 的字典节点。 * * T = O(N) */dictEntry *dictReplaceRaw(dict *d, void *key) &#123; // 使用 key 在字典中查找节点 // T = O(1) dictEntry *entry = dictFind(d,key); // 如果节点找到了直接返回节点，否则添加并返回一个新节点 // T = O(N) return entry ? entry : dictAddRaw(d,key);&#125;/* Search and remove an element *//* * 查找并删除包含给定键的节点 * * 参数 nofree 决定是否调用键和值的释放函数 * 0 表示调用，1 表示不调用 * * 找到并成功删除返回 DICT_OK ，没找到则返回 DICT_ERR * * T = O(1) */static int dictGenericDelete(dict *d, const void *key, int nofree)&#123; unsigned int h, idx; dictEntry *he, *prevHe; int table; // 字典（的哈希表）为空 if (d-&gt;ht[0].size == 0) return DICT_ERR; /* d-&gt;ht[0].table is NULL */ // 进行单步 rehash ，T = O(1) if (dictIsRehashing(d)) _dictRehashStep(d); // 计算哈希值 h = dictHashKey(d, key); // 遍历哈希表 // T = O(1) for (table = 0; table &lt;= 1; table++) &#123; // 计算索引值 idx = h &amp; d-&gt;ht[table].sizemask; // 指向该索引上的链表 he = d-&gt;ht[table].table[idx]; prevHe = NULL; // 遍历链表上的所有节点 // T = O(1) while(he) &#123; if (dictCompareKeys(d, key, he-&gt;key)) &#123; // 超找目标节点 /* Unlink the element from the list */ // 从链表中删除 if (prevHe) prevHe-&gt;next = he-&gt;next; else d-&gt;ht[table].table[idx] = he-&gt;next; // 释放调用键和值的释放函数？ if (!nofree) &#123; dictFreeKey(d, he); dictFreeVal(d, he); &#125; // 释放节点本身 zfree(he); // 更新已使用节点数量 d-&gt;ht[table].used--; // 返回已找到信号 return DICT_OK; &#125; prevHe = he; he = he-&gt;next; &#125; // 如果执行到这里，说明在 0 号哈希表中找不到给定键 // 那么根据字典是否正在进行 rehash ，决定要不要查找 1 号哈希表 if (!dictIsRehashing(d)) break; &#125; // 没找到 return DICT_ERR; /* not found */&#125;/* * 从字典中删除包含给定键的节点 * * 并且调用键值的释放函数来删除键值 * * 找到并成功删除返回 DICT_OK ，没找到则返回 DICT_ERR * T = O(1) */int dictDelete(dict *ht, const void *key) &#123; return dictGenericDelete(ht,key,0);&#125;/* * 从字典中删除包含给定键的节点 * * 但不调用键值的释放函数来删除键值 * * 找到并成功删除返回 DICT_OK ，没找到则返回 DICT_ERR * T = O(1) */int dictDeleteNoFree(dict *ht, const void *key) &#123; return dictGenericDelete(ht,key,1);&#125;/* Destroy an entire dictionary *//* * 删除哈希表上的所有节点，并重置哈希表的各项属性 * * T = O(N) */int _dictClear(dict *d, dictht *ht, void(callback)(void *)) &#123; unsigned long i; /* Free all the elements */ // 遍历整个哈希表 // T = O(N) for (i = 0; i &lt; ht-&gt;size &amp;&amp; ht-&gt;used &gt; 0; i++) &#123; dictEntry *he, *nextHe; if (callback &amp;&amp; (i &amp; 65535) == 0) callback(d-&gt;privdata); // 跳过空索引 if ((he = ht-&gt;table[i]) == NULL) continue; // 遍历整个链表 // T = O(1) while(he) &#123; nextHe = he-&gt;next; // 删除键 dictFreeKey(d, he); // 删除值 dictFreeVal(d, he); // 释放节点 zfree(he); // 更新已使用节点计数 ht-&gt;used--; // 处理下个节点 he = nextHe; &#125; &#125; /* Free the table and the allocated cache structure */ // 释放哈希表结构 zfree(ht-&gt;table); /* Re-initialize the table */ // 重置哈希表属性 _dictReset(ht); return DICT_OK; /* never fails */&#125;/* Clear &amp; Release the hash table *//* * 删除并释放整个字典 * * T = O(N) */void dictRelease(dict *d)&#123; // 删除并清空两个哈希表 _dictClear(d,&amp;d-&gt;ht[0],NULL); _dictClear(d,&amp;d-&gt;ht[1],NULL); // 释放节点结构 zfree(d);&#125;/* * 返回字典中包含键 key 的节点 * * 找到返回节点，找不到返回 NULL * * T = O(1) */dictEntry *dictFind(dict *d, const void *key)&#123; dictEntry *he; unsigned int h, idx, table; // 字典（的哈希表）为空 if (d-&gt;ht[0].size == 0) return NULL; /* We don't have a table at all */ // 如果条件允许的话，进行单步 rehash if (dictIsRehashing(d)) _dictRehashStep(d); // 计算键的哈希值 h = dictHashKey(d, key); // 在字典的哈希表中查找这个键 // T = O(1) for (table = 0; table &lt;= 1; table++) &#123; // 计算索引值 idx = h &amp; d-&gt;ht[table].sizemask; // 遍历给定索引上的链表的所有节点，查找 key he = d-&gt;ht[table].table[idx]; // T = O(1) while(he) &#123; if (dictCompareKeys(d, key, he-&gt;key)) return he; he = he-&gt;next; &#125; // 如果程序遍历完 0 号哈希表，仍然没找到指定的键的节点 // 那么程序会检查字典是否在进行 rehash ， // 然后才决定是直接返回 NULL ，还是继续查找 1 号哈希表 if (!dictIsRehashing(d)) return NULL; &#125; // 进行到这里时，说明两个哈希表都没找到 return NULL;&#125;/* * 获取包含给定键的节点的值 * * 如果节点不为空，返回节点的值 * 否则返回 NULL * * T = O(1) */void *dictFetchValue(dict *d, const void *key) &#123; dictEntry *he; // T = O(1) he = dictFind(d,key); return he ? dictGetVal(he) : NULL;&#125;/* A fingerprint is a 64 bit number that represents the state of the dictionary * at a given time, it's just a few dict properties xored together. * When an unsafe iterator is initialized, we get the dict fingerprint, and check * the fingerprint again when the iterator is released. * If the two fingerprints are different it means that the user of the iterator * performed forbidden operations against the dictionary while iterating. */long long dictFingerprint(dict *d) &#123; long long integers[6], hash = 0; int j; integers[0] = (long) d-&gt;ht[0].table; integers[1] = d-&gt;ht[0].size; integers[2] = d-&gt;ht[0].used; integers[3] = (long) d-&gt;ht[1].table; integers[4] = d-&gt;ht[1].size; integers[5] = d-&gt;ht[1].used; /* We hash N integers by summing every successive integer with the integer * hashing of the previous sum. Basically: * * Result = hash(hash(hash(int1)+int2)+int3) ... * * This way the same set of integers in a different order will (likely) hash * to a different number. */ for (j = 0; j &lt; 6; j++) &#123; hash += integers[j]; /* For the hashing step we use Tomas Wang's 64 bit integer hash. */ hash = (~hash) + (hash &lt;&lt; 21); // hash = (hash &lt;&lt; 21) - hash - 1; hash = hash ^ (hash &gt;&gt; 24); hash = (hash + (hash &lt;&lt; 3)) + (hash &lt;&lt; 8); // hash * 265 hash = hash ^ (hash &gt;&gt; 14); hash = (hash + (hash &lt;&lt; 2)) + (hash &lt;&lt; 4); // hash * 21 hash = hash ^ (hash &gt;&gt; 28); hash = hash + (hash &lt;&lt; 31); &#125; return hash;&#125;/* * 创建并返回给定字典的不安全迭代器 * * T = O(1) */dictIterator *dictGetIterator(dict *d)&#123; dictIterator *iter = zmalloc(sizeof(*iter)); iter-&gt;d = d; iter-&gt;table = 0; iter-&gt;index = -1; iter-&gt;safe = 0; iter-&gt;entry = NULL; iter-&gt;nextEntry = NULL; return iter;&#125;/* * 创建并返回给定节点的安全迭代器 * * T = O(1) */dictIterator *dictGetSafeIterator(dict *d) &#123; dictIterator *i = dictGetIterator(d); // 设置安全迭代器标识 i-&gt;safe = 1; return i;&#125;/* * 返回迭代器指向的当前节点 * * 字典迭代完毕时，返回 NULL * * T = O(1) */dictEntry *dictNext(dictIterator *iter)&#123; while (1) &#123; // 进入这个循环有两种可能： // 1) 这是迭代器第一次运行 // 2) 当前索引链表中的节点已经迭代完（NULL 为链表的表尾） if (iter-&gt;entry == NULL) &#123; // 指向被迭代的哈希表 dictht *ht = &amp;iter-&gt;d-&gt;ht[iter-&gt;table]; // 初次迭代时执行 if (iter-&gt;index == -1 &amp;&amp; iter-&gt;table == 0) &#123; // 如果是安全迭代器，那么更新安全迭代器计数器 if (iter-&gt;safe) iter-&gt;d-&gt;iterators++; // 如果是不安全迭代器，那么计算指纹 else iter-&gt;fingerprint = dictFingerprint(iter-&gt;d); &#125; // 更新索引 iter-&gt;index++; // 如果迭代器的当前索引大于当前被迭代的哈希表的大小 // 那么说明这个哈希表已经迭代完毕 if (iter-&gt;index &gt;= (signed) ht-&gt;size) &#123; // 如果正在 rehash 的话，那么说明 1 号哈希表也正在使用中 // 那么继续对 1 号哈希表进行迭代 if (dictIsRehashing(iter-&gt;d) &amp;&amp; iter-&gt;table == 0) &#123; iter-&gt;table++; iter-&gt;index = 0; ht = &amp;iter-&gt;d-&gt;ht[1]; // 如果没有 rehash ，那么说明迭代已经完成 &#125; else &#123; break; &#125; &#125; // 如果进行到这里，说明这个哈希表并未迭代完 // 更新节点指针，指向下个索引链表的表头节点 iter-&gt;entry = ht-&gt;table[iter-&gt;index]; &#125; else &#123; // 执行到这里，说明程序正在迭代某个链表 // 将节点指针指向链表的下个节点 iter-&gt;entry = iter-&gt;nextEntry; &#125; // 如果当前节点不为空，那么也记录下该节点的下个节点 // 因为安全迭代器有可能会将迭代器返回的当前节点删除 if (iter-&gt;entry) &#123; /* We need to save the 'next' here, the iterator user * may delete the entry we are returning. */ iter-&gt;nextEntry = iter-&gt;entry-&gt;next; return iter-&gt;entry; &#125; &#125; // 迭代完毕 return NULL;&#125;/* * 释放给定字典迭代器 * * T = O(1) */void dictReleaseIterator(dictIterator *iter)&#123; if (!(iter-&gt;index == -1 &amp;&amp; iter-&gt;table == 0)) &#123; // 释放安全迭代器时，安全迭代器计数器减一 if (iter-&gt;safe) iter-&gt;d-&gt;iterators--; // 释放不安全迭代器时，验证指纹是否有变化 else assert(iter-&gt;fingerprint == dictFingerprint(iter-&gt;d)); &#125; zfree(iter);&#125;/* Return a random entry from the hash table. Useful to * implement randomized algorithms *//* * 随机返回字典中任意一个节点。 * * 可用于实现随机化算法。 * * 如果字典为空，返回 NULL 。 * * T = O(N)*/dictEntry *dictGetRandomKey(dict *d)&#123; dictEntry *he, *orighe; unsigned int h; int listlen, listele; // 字典为空 if (dictSize(d) == 0) return NULL; // 进行单步 rehash if (dictIsRehashing(d)) _dictRehashStep(d); // 如果正在 rehash ，那么将 1 号哈希表也作为随机查找的目标 if (dictIsRehashing(d)) &#123; // T = O(N) do &#123; h = random() % (d-&gt;ht[0].size+d-&gt;ht[1].size); he = (h &gt;= d-&gt;ht[0].size) ? d-&gt;ht[1].table[h - d-&gt;ht[0].size] : d-&gt;ht[0].table[h]; &#125; while(he == NULL); // 否则，只从 0 号哈希表中查找节点 &#125; else &#123; // T = O(N) do &#123; h = random() &amp; d-&gt;ht[0].sizemask; he = d-&gt;ht[0].table[h]; &#125; while(he == NULL); &#125; /* Now we found a non empty bucket, but it is a linked * list and we need to get a random element from the list. * The only sane way to do so is counting the elements and * select a random index. */ // 目前 he 已经指向一个非空的节点链表 // 程序将从这个链表随机返回一个节点 listlen = 0; orighe = he; // 计算节点数量, T = O(1) while(he) &#123; he = he-&gt;next; listlen++; &#125; // 取模，得出随机节点的索引 listele = random() % listlen; he = orighe; // 按索引查找节点 // T = O(1) while(listele--) he = he-&gt;next; // 返回随机节点 return he;&#125;/* This is a version of dictGetRandomKey() that is modified in order to * return multiple entries by jumping at a random place of the hash table * and scanning linearly for entries. * * Returned pointers to hash table entries are stored into 'des' that * points to an array of dictEntry pointers. The array must have room for * at least 'count' elements, that is the argument we pass to the function * to tell how many random elements we need. * * The function returns the number of items stored into 'des', that may * be less than 'count' if the hash table has less than 'count' elements * inside. * * Note that this function is not suitable when you need a good distribution * of the returned items, but only when you need to \"sample\" a given number * of continuous elements to run some kind of algorithm or to produce * statistics. However the function is much faster than dictGetRandomKey() * at producing N elements, and the elements are guaranteed to be non * repeating. */int dictGetRandomKeys(dict *d, dictEntry **des, int count) &#123; int j; /* internal hash table id, 0 or 1. */ int stored = 0; if (dictSize(d) &lt; count) count = dictSize(d); while(stored &lt; count) &#123; for (j = 0; j &lt; 2; j++) &#123; /* Pick a random point inside the hash table 0 or 1. */ unsigned int i = random() &amp; d-&gt;ht[j].sizemask; int size = d-&gt;ht[j].size; /* Make sure to visit every bucket by iterating 'size' times. */ while(size--) &#123; dictEntry *he = d-&gt;ht[j].table[i]; while (he) &#123; /* Collect all the elements of the buckets found non * empty while iterating. */ *des = he; des++; he = he-&gt;next; stored++; if (stored == count) return stored; &#125; i = (i+1) &amp; d-&gt;ht[j].sizemask; &#125; /* If there is only one table and we iterated it all, we should * already have 'count' elements. Assert this condition. */ assert(dictIsRehashing(d) != 0); &#125; &#125; return stored; /* Never reached. */&#125;/* Function to reverse bits. Algorithm from: * http://graphics.stanford.edu/~seander/bithacks.html#ReverseParallel */static unsigned long rev(unsigned long v) &#123; unsigned long s = 8 * sizeof(v); // bit size; must be power of 2 unsigned long mask = ~0; while ((s &gt;&gt;= 1) &gt; 0) &#123; mask ^= (mask &lt;&lt; s); v = ((v &gt;&gt; s) &amp; mask) | ((v &lt;&lt; s) &amp; ~mask); &#125; return v;&#125;/* dictScan() is used to iterate over the elements of a dictionary. * * dictScan() 函数用于迭代给定字典中的元素。 * * Iterating works in the following way: * * 迭代按以下方式执行： * * 1) Initially you call the function using a cursor (v) value of 0. * 一开始，你使用 0 作为游标来调用函数。 * 2) The function performs one step of the iteration, and returns the * new cursor value that you must use in the next call. * 函数执行一步迭代操作， * 并返回一个下次迭代时使用的新游标。 * 3) When the returned cursor is 0, the iteration is complete. * 当函数返回的游标为 0 时，迭代完成。 * * The function guarantees that all the elements that are present in the * dictionary from the start to the end of the iteration are returned. * However it is possible that some element is returned multiple time. * * 函数保证，在迭代从开始到结束期间，一直存在于字典的元素肯定会被迭代到， * 但一个元素可能会被返回多次。 * * For every element returned, the callback 'fn' passed as argument is * called, with 'privdata' as first argument and the dictionar entry * 'de' as second argument. * * 每当一个元素被返回时，回调函数 fn 就会被执行， * fn 函数的第一个参数是 privdata ，而第二个参数则是字典节点 de 。 * * HOW IT WORKS. * 工作原理 * * The algorithm used in the iteration was designed by Pieter Noordhuis. * The main idea is to increment a cursor starting from the higher order * bits, that is, instead of incrementing the cursor normally, the bits * of the cursor are reversed, then the cursor is incremented, and finally * the bits are reversed again. * * 迭代所使用的算法是由 Pieter Noordhuis 设计的， * 算法的主要思路是在二进制高位上对游标进行加法计算 * 也即是说，不是按正常的办法来对游标进行加法计算， * 而是首先将游标的二进制位翻转（reverse）过来， * 然后对翻转后的值进行加法计算， * 最后再次对加法计算之后的结果进行翻转。 * * This strategy is needed because the hash table may be resized from one * call to the other call of the same iteration. * * 这一策略是必要的，因为在一次完整的迭代过程中， * 哈希表的大小有可能在两次迭代之间发生改变。 * * dict.c hash tables are always power of two in size, and they * use chaining, so the position of an element in a given table is given * always by computing the bitwise AND between Hash(key) and SIZE-1 * (where SIZE-1 is always the mask that is equivalent to taking the rest * of the division between the Hash of the key and SIZE). * * 哈希表的大小总是 2 的某个次方，并且哈希表使用链表来解决冲突， * 因此一个给定元素在一个给定表的位置总可以通过 Hash(key) &amp; SIZE-1 * 公式来计算得出， * 其中 SIZE-1 是哈希表的最大索引值， * 这个最大索引值就是哈希表的 mask （掩码）。 * * For example if the current hash table size is 16, the mask is * (in binary) 1111. The position of a key in the hash table will be always * the last four bits of the hash output, and so forth. * * 举个例子，如果当前哈希表的大小为 16 ， * 那么它的掩码就是二进制值 1111 ， * 这个哈希表的所有位置都可以使用哈希值的最后四个二进制位来记录。 * * WHAT HAPPENS IF THE TABLE CHANGES IN SIZE? * 如果哈希表的大小改变了怎么办？ * * If the hash table grows, elements can go anyway in one multiple of * the old bucket: for example let's say that we already iterated with * a 4 bit cursor 1100, since the mask is 1111 (hash table size = 16). * * 当对哈希表进行扩展时，元素可能会从一个槽移动到另一个槽， * 举个例子，假设我们刚好迭代至 4 位游标 1100 ， * 而哈希表的 mask 为 1111 （哈希表的大小为 16 ）。 * * If the hash table will be resized to 64 elements, and the new mask will * be 111111, the new buckets that you obtain substituting in ??1100 * either 0 or 1, can be targeted only by keys that we already visited * when scanning the bucket 1100 in the smaller hash table. * * 如果这时哈希表将大小改为 64 ，那么哈希表的 mask 将变为 111111 ， * * By iterating the higher bits first, because of the inverted counter, the * cursor does not need to restart if the table size gets bigger, and will * just continue iterating with cursors that don't have '1100' at the end, * nor any other combination of final 4 bits already explored. * * Similarly when the table size shrinks over time, for example going from * 16 to 8, If a combination of the lower three bits (the mask for size 8 * is 111) was already completely explored, it will not be visited again * as we are sure that, we tried for example, both 0111 and 1111 (all the * variations of the higher bit) so we don't need to test it again. * * WAIT... YOU HAVE *TWO* TABLES DURING REHASHING! * 等等。。。在 rehash 的时候可是会出现两个哈希表的阿！ * * Yes, this is true, but we always iterate the smaller one of the tables, * testing also all the expansions of the current cursor into the larger * table. So for example if the current cursor is 101 and we also have a * larger table of size 16, we also test (0)101 and (1)101 inside the larger * table. This reduces the problem back to having only one table, where * the larger one, if exists, is just an expansion of the smaller one. * * LIMITATIONS * 限制 * * This iterator is completely stateless, and this is a huge advantage, * including no additional memory used. * 这个迭代器是完全无状态的，这是一个巨大的优势， * 因为迭代可以在不使用任何额外内存的情况下进行。 * * The disadvantages resulting from this design are: * 这个设计的缺陷在于： * * 1) It is possible that we return duplicated elements. However this is usually * easy to deal with in the application level. * 函数可能会返回重复的元素，不过这个问题可以很容易在应用层解决。 * 2) The iterator must return multiple elements per call, as it needs to always * return all the keys chained in a given bucket, and all the expansions, so * we are sure we don't miss keys moving. * 为了不错过任何元素， * 迭代器需要返回给定桶上的所有键， * 以及因为扩展哈希表而产生出来的新表， * 所以迭代器必须在一次迭代中返回多个元素。 * 3) The reverse cursor is somewhat hard to understand at first, but this * comment is supposed to help. * 对游标进行翻转（reverse）的原因初看上去比较难以理解， * 不过阅读这份注释应该会有所帮助。 */unsigned long dictScan(dict *d, unsigned long v, dictScanFunction *fn, void *privdata)&#123; dictht *t0, *t1; const dictEntry *de; unsigned long m0, m1; // 跳过空字典 if (dictSize(d) == 0) return 0; // 迭代只有一个哈希表的字典 if (!dictIsRehashing(d)) &#123; // 指向哈希表 t0 = &amp;(d-&gt;ht[0]); // 记录 mask m0 = t0-&gt;sizemask; /* Emit entries at cursor */ // 指向哈希桶 de = t0-&gt;table[v &amp; m0]; // 遍历桶中的所有节点 while (de) &#123; fn(privdata, de); de = de-&gt;next; &#125; // 迭代有两个哈希表的字典 &#125; else &#123; // 指向两个哈希表 t0 = &amp;d-&gt;ht[0]; t1 = &amp;d-&gt;ht[1]; /* Make sure t0 is the smaller and t1 is the bigger table */ // 确保 t0 比 t1 要小 if (t0-&gt;size &gt; t1-&gt;size) &#123; t0 = &amp;d-&gt;ht[1]; t1 = &amp;d-&gt;ht[0]; &#125; // 记录掩码 m0 = t0-&gt;sizemask; m1 = t1-&gt;sizemask; /* Emit entries at cursor */ // 指向桶，并迭代桶中的所有节点 de = t0-&gt;table[v &amp; m0]; while (de) &#123; fn(privdata, de); de = de-&gt;next; &#125; /* Iterate over indices in larger table that are the expansion * of the index pointed to by the cursor in the smaller table */ // Iterate over indices in larger table // 迭代大表中的桶 // that are the expansion of the index pointed to // 这些桶被索引的 expansion 所指向 // by the cursor in the smaller table // do &#123; /* Emit entries at cursor */ // 指向桶，并迭代桶中的所有节点 de = t1-&gt;table[v &amp; m1]; while (de) &#123; fn(privdata, de); de = de-&gt;next; &#125; /* Increment bits not covered by the smaller mask */ v = (((v | m0) + 1) &amp; ~m0) | (v &amp; m0); /* Continue while bits covered by mask difference is non-zero */ &#125; while (v &amp; (m0 ^ m1)); &#125; /* Set unmasked bits so incrementing the reversed cursor * operates on the masked bits of the smaller table */ v |= ~m0; /* Increment the reverse cursor */ v = rev(v); v++; v = rev(v); return v;&#125;/* ------------------------- private functions ------------------------------ *//* Expand the hash table if needed *//* * 根据需要，初始化字典（的哈希表），或者对字典（的现有哈希表）进行扩展 * * T = O(N) */static int _dictExpandIfNeeded(dict *d)&#123; /* Incremental rehashing already in progress. Return. */ // 渐进式 rehash 已经在进行了，直接返回 if (dictIsRehashing(d)) return DICT_OK; /* If the hash table is empty expand it to the initial size. */ // 如果字典（的 0 号哈希表）为空，那么创建并返回初始化大小的 0 号哈希表 // T = O(1) if (d-&gt;ht[0].size == 0) return dictExpand(d, DICT_HT_INITIAL_SIZE); /* If we reached the 1:1 ratio, and we are allowed to resize the hash * table (global setting) or we should avoid it but the ratio between * elements/buckets is over the \"safe\" threshold, we resize doubling * the number of buckets. */ // 一下两个条件之一为真时，对字典进行扩展 // 1）字典已使用节点数和字典大小之间的比率接近 1：1 // 并且 dict_can_resize 为真 // 2）已使用节点数和字典大小之间的比率超过 dict_force_resize_ratio if (d-&gt;ht[0].used &gt;= d-&gt;ht[0].size &amp;&amp; (dict_can_resize || d-&gt;ht[0].used/d-&gt;ht[0].size &gt; dict_force_resize_ratio)) &#123; // 新哈希表的大小至少是目前已使用节点数的两倍 // T = O(N) return dictExpand(d, d-&gt;ht[0].used*2); &#125; return DICT_OK;&#125;/* Our hash table capability is a power of two *//* * 计算第一个大于等于 size 的 2 的 N 次方，用作哈希表的值 * * T = O(1) */static unsigned long _dictNextPower(unsigned long size)&#123; unsigned long i = DICT_HT_INITIAL_SIZE; if (size &gt;= LONG_MAX) return LONG_MAX; while(1) &#123; if (i &gt;= size) return i; i *= 2; &#125;&#125;/* Returns the index of a free slot that can be populated with * a hash entry for the given 'key'. * If the key already exists, -1 is returned. * * 返回可以将 key 插入到哈希表的索引位置 * 如果 key 已经存在于哈希表，那么返回 -1 * * Note that if we are in the process of rehashing the hash table, the * index is always returned in the context of the second (new) hash table. * * 注意，如果字典正在进行 rehash ，那么总是返回 1 号哈希表的索引。 * 因为在字典进行 rehash 时，新节点总是插入到 1 号哈希表。 * * T = O(N) */static int _dictKeyIndex(dict *d, const void *key)&#123; unsigned int h, idx, table; dictEntry *he; /* Expand the hash table if needed */ // 单步 rehash // T = O(N) if (_dictExpandIfNeeded(d) == DICT_ERR) return -1; /* Compute the key hash value */ // 计算 key 的哈希值 h = dictHashKey(d, key); // T = O(1) for (table = 0; table &lt;= 1; table++) &#123; // 计算索引值 idx = h &amp; d-&gt;ht[table].sizemask; /* Search if this slot does not already contain the given key */ // 查找 key 是否存在 // T = O(1) he = d-&gt;ht[table].table[idx]; while(he) &#123; if (dictCompareKeys(d, key, he-&gt;key)) return -1; he = he-&gt;next; &#125; // 如果运行到这里时，说明 0 号哈希表中所有节点都不包含 key // 如果这时 rehahs 正在进行，那么继续对 1 号哈希表进行 rehash if (!dictIsRehashing(d)) break; &#125; // 返回索引值 return idx;&#125;/* * 清空字典上的所有哈希表节点，并重置字典属性 * * T = O(N) */void dictEmpty(dict *d, void(callback)(void*)) &#123; // 删除两个哈希表上的所有节点 // T = O(N) _dictClear(d,&amp;d-&gt;ht[0],callback); _dictClear(d,&amp;d-&gt;ht[1],callback); // 重置属性 d-&gt;rehashidx = -1; d-&gt;iterators = 0;&#125;/* * 开启自动 rehash * * T = O(1) */void dictEnableResize(void) &#123; dict_can_resize = 1;&#125;/* * 关闭自动 rehash * * T = O(1) */void dictDisableResize(void) &#123; dict_can_resize = 0;&#125;","path":"2019/04/16/redis源码-字典/","date":"04-16","excerpt":"字典的实现概念Redis的字典是使用哈希表作为底层实现原理的，一个哈希表可以有多个哈希表节点，而每个哈希表节点就保存了字典中的一个键值对。哈希表1234567891011121314151617181920212223/* This is our hash table structure. Every dictionary has two of this as we * implement incremental rehashing, for the old to the new table. *//* * 哈希表 * * 每个字典都使用两个哈希表，从而实现渐进式 rehash 。 */typedef struct dictht &#123; // 哈希表数组 dictEntry **table; // 哈希表大小 unsigned long size; // 哈希表大小掩码，用于计算索引值 // 总是等于 size - 1 unsigned long sizemask; // 该哈希表已有节点的数量 unsigned long used;&#125; dictht;","tags":[{"name":"源码","slug":"源码","permalink":"https://jijiking51.cn/tags/源码/"}],"preview":"http://img.jijiking51.cn/redis源码-字典.jpg"},{"title":"redis源码-adlist","text":"Redis链表和链表节点的实现链表的每个节点用listNode结构表示12345678typedef struct listNode &#123; // 前置节点 struct listNode *prev; // 后置节点 struct listNode *next; // 节点值 void *value;&#125; listNode; 多个listNode可以通过prev和next指针组成双端链表 仅使用listNode就可以组成链表，但是还是实现了list来持有链表操作会更加方便12345678910111213typedef struct list &#123; // 链表头结点 listNode *head; // 链表尾节点 listNode *tail; // 函数用于复制链表节点所保存的值 void *(*dup)(void *ptr); // 函数用于释放链表节点所保存的值 void (*free)(void *ptr); // 函数用于对比链表节点所保存的值和另一个输入值是否相等 int (*match)(void *ptr, void *key); unsigned long len;&#125; list; 这是一个list结构的由三个listNode结构组成的链表 redis链表的特性： 双端： 链表节点带有prev和next指针， 获取某个节点的前置节点和后置节点的复杂度都是 O(1) 。 无环： 表头节点的prev指针和表尾节点的next指针都指向NULL， 对链表的访问以NULL为终点。 带表头指针和表尾指针： 通过list结构的head指针和tail指针， 程序获取链表的表头节点和表尾节点的复杂度为 O(1) 。 带链表长度计数器： 程序使用list结构的len属性来对list持有的链表节点进行计数， 程序获取链表中节点数量的复杂度为 O(1)。 多态： 链表节点使用void*指针来保存节点值， 并且可以通过list结构的dup、free、match三个属性为节点值设置类型特定函数， 所以链表可以用于保存各种不同类型的值。 Redis链表API常用API接口 函数 作用 时间复杂度 listSetDupMethod 将给定的函数设置为链表的节点值复制函数。 O(1)。 listGetDupMethod 返回链表当前正在使用的节点值复制函数。 复制函数可以通过链表的dup属性直接获得，O(1) listSetFreeMethod 将给定的函数设置为链表的节点值释放函数。 O(1)。 listGetFree 返回链表当前正在使用的节点值释放函数。 释放函数可以通过链表的free属性直接获得， O(1) listSetMatchMethod 将给定的函数设置为链表的节点值对比函数。 O(1) listGetMatchMethod 返回链表当前正在使用的节点值对比函数。对比函数可以通过链表的match属性直接获得，O(1) listLength 返回链表的长度（包含了多少个节点）。 链表长度可以通过链表的len属性直接获得，O(1) 。 listFirst 返回链表的表头节点。 表头节点可以通过链表的head属性直接获得，O(1)。 listLast 返回链表的表尾节点。 表尾节点可以通过链表的tail属性直接获得， O(1)。 listPrevNode 返回给定节点的前置节点。 前置节点可以通过节点的prev属性直接获得，O(1)。 listNextNode 返回给定节点的后置节点。 后置节点可以通过节点的next属性直接获得，O(1)。 listNodeValue 返回给定节点目前正在保存的值。 节点值可以通过节点的value属性直接获得， O(1)。 listCreate 创建一个不包含任何节点的新链表。 O(1) listAddNodeHead 将一个包含给定值的新节点添加到给定链表的表头。 O(1) listAddNodeTail 将一个包含给定值的新节点添加到给定链表的表尾。 O(1) listInsertNode 将一个包含给定值的新节点添加到给定节点的之前或者之后。 O(1) listSearchKey 查找并返回链表中包含给定值的节点。 O(N)，N为链表长度。 listIndex 返回链表在给定索引上的节点。 O(N) ，N为链表长度。 listDelNode 从链表中删除给定节点。 O(1)。 listRotate 将链表的表尾节点弹出，然后将被弹出的节点插入到链表的表头，成为新的表头节点。 O(1) listDup 复制一个给定链表的副本。 O(N)，N 为链表长度。 listRelease 释放给定链表，以及链表中的所有节点。 O(N)，N为链表长度。 adlist代码注解123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521/* Create a new list. The created list can be freed with * AlFreeList(), but private value of every node need to be freed * by the user before to call AlFreeList(). * * On error, NULL is returned. Otherwise the pointer to the new list. *//* * 创建一个新的链表 * * 创建成功返回链表，失败返回 NULL 。 * * T = O(1) */list *listCreate(void)&#123; struct list *list; // 分配内存 if ((list = zmalloc(sizeof(*list))) == NULL) return NULL; // 初始化属性 list-&gt;head = list-&gt;tail = NULL; list-&gt;len = 0; list-&gt;dup = NULL; list-&gt;free = NULL; list-&gt;match = NULL; return list;&#125;/* Free the whole list. * * This function can't fail. *//* * 释放整个链表，以及链表中所有节点 * * T = O(N) */void listRelease(list *list)&#123; unsigned long len; listNode *current, *next; // 指向头指针 current = list-&gt;head; // 遍历整个链表 len = list-&gt;len; while(len--) &#123; next = current-&gt;next; // 如果有设置值释放函数，那么调用它 if (list-&gt;free) list-&gt;free(current-&gt;value); // 释放节点结构 zfree(current); current = next; &#125; // 释放链表结构 zfree(list);&#125;/* Add a new node to the list, to head, contaning the specified 'value' * pointer as value. * * On error, NULL is returned and no operation is performed (i.e. the * list remains unaltered). * On success the 'list' pointer you pass to the function is returned. *//* * 将一个包含有给定值指针 value 的新节点添加到链表的表头 * * 如果为新节点分配内存出错，那么不执行任何动作，仅返回 NULL * * 如果执行成功，返回传入的链表指针 * * T = O(1) */list *listAddNodeHead(list *list, void *value)&#123; listNode *node; // 为节点分配内存 if ((node = zmalloc(sizeof(*node))) == NULL) return NULL; // 保存值指针 node-&gt;value = value; // 添加节点到空链表 if (list-&gt;len == 0) &#123; list-&gt;head = list-&gt;tail = node; node-&gt;prev = node-&gt;next = NULL; // 添加节点到非空链表 &#125; else &#123; node-&gt;prev = NULL; node-&gt;next = list-&gt;head; list-&gt;head-&gt;prev = node; list-&gt;head = node; &#125; // 更新链表节点数 list-&gt;len++; return list;&#125;/* Add a new node to the list, to tail, containing the specified 'value' * pointer as value. * * On error, NULL is returned and no operation is performed (i.e. the * list remains unaltered). * On success the 'list' pointer you pass to the function is returned. *//* * 将一个包含有给定值指针 value 的新节点添加到链表的表尾 * * 如果为新节点分配内存出错，那么不执行任何动作，仅返回 NULL * * 如果执行成功，返回传入的链表指针 * * T = O(1) */list *listAddNodeTail(list *list, void *value)&#123; listNode *node; // 为新节点分配内存 if ((node = zmalloc(sizeof(*node))) == NULL) return NULL; // 保存值指针 node-&gt;value = value; // 目标链表为空 if (list-&gt;len == 0) &#123; list-&gt;head = list-&gt;tail = node; node-&gt;prev = node-&gt;next = NULL; // 目标链表非空 &#125; else &#123; node-&gt;prev = list-&gt;tail; node-&gt;next = NULL; list-&gt;tail-&gt;next = node; list-&gt;tail = node; &#125; // 更新链表节点数 list-&gt;len++; return list;&#125;/* * 创建一个包含值 value 的新节点，并将它插入到 old_node 的之前或之后 * * 如果 after 为 0 ，将新节点插入到 old_node 之前。 * 如果 after 为 1 ，将新节点插入到 old_node 之后。 * * T = O(1) */list *listInsertNode(list *list, listNode *old_node, void *value, int after) &#123; listNode *node; // 创建新节点 if ((node = zmalloc(sizeof(*node))) == NULL) return NULL; // 保存值 node-&gt;value = value; // 将新节点添加到给定节点之后 if (after) &#123; node-&gt;prev = old_node; node-&gt;next = old_node-&gt;next; // 给定节点是原表尾节点 if (list-&gt;tail == old_node) &#123; list-&gt;tail = node; &#125; // 将新节点添加到给定节点之前 &#125; else &#123; node-&gt;next = old_node; node-&gt;prev = old_node-&gt;prev; // 给定节点是原表头节点 if (list-&gt;head == old_node) &#123; list-&gt;head = node; &#125; &#125; // 更新新节点的前置指针 if (node-&gt;prev != NULL) &#123; node-&gt;prev-&gt;next = node; &#125; // 更新新节点的后置指针 if (node-&gt;next != NULL) &#123; node-&gt;next-&gt;prev = node; &#125; // 更新链表节点数 list-&gt;len++; return list;&#125;/* Remove the specified node from the specified list. * It's up to the caller to free the private value of the node. * * This function can't fail. *//* * 从链表 list 中删除给定节点 node * * 对节点私有值(private value of the node)的释放工作由调用者进行。 * * T = O(1) */void listDelNode(list *list, listNode *node)&#123; // 调整前置节点的指针 if (node-&gt;prev) node-&gt;prev-&gt;next = node-&gt;next; else list-&gt;head = node-&gt;next; // 调整后置节点的指针 if (node-&gt;next) node-&gt;next-&gt;prev = node-&gt;prev; else list-&gt;tail = node-&gt;prev; // 释放值 if (list-&gt;free) list-&gt;free(node-&gt;value); // 释放节点 zfree(node); // 链表数减一 list-&gt;len--;&#125;/* Returns a list iterator 'iter'. After the initialization every * call to listNext() will return the next element of the list. * * This function can't fail. *//* * 为给定链表创建一个迭代器， * 之后每次对这个迭代器调用 listNext 都返回被迭代到的链表节点 * * direction 参数决定了迭代器的迭代方向： * AL_START_HEAD ：从表头向表尾迭代 * AL_START_TAIL ：从表尾想表头迭代 * * T = O(1) */listIter *listGetIterator(list *list, int direction)&#123; // 为迭代器分配内存 listIter *iter; if ((iter = zmalloc(sizeof(*iter))) == NULL) return NULL; // 根据迭代方向，设置迭代器的起始节点 if (direction == AL_START_HEAD) iter-&gt;next = list-&gt;head; else iter-&gt;next = list-&gt;tail; // 记录迭代方向 iter-&gt;direction = direction; return iter;&#125;/* Release the iterator memory *//* * 释放迭代器 * * T = O(1) */void listReleaseIterator(listIter *iter) &#123; zfree(iter);&#125;/* Create an iterator in the list private iterator structure *//* * 将迭代器的方向设置为 AL_START_HEAD ， * 并将迭代指针重新指向表头节点。 * * T = O(1) */void listRewind(list *list, listIter *li) &#123; li-&gt;next = list-&gt;head; li-&gt;direction = AL_START_HEAD;&#125;/* * 将迭代器的方向设置为 AL_START_TAIL ， * 并将迭代指针重新指向表尾节点。 * * T = O(1) */void listRewindTail(list *list, listIter *li) &#123; li-&gt;next = list-&gt;tail; li-&gt;direction = AL_START_TAIL;&#125;/* Return the next element of an iterator. * It's valid to remove the currently returned element using * listDelNode(), but not to remove other elements. * * The function returns a pointer to the next element of the list, * or NULL if there are no more elements, so the classical usage patter * is: * * iter = listGetIterator(list,&lt;direction&gt;); * while ((node = listNext(iter)) != NULL) &#123; * doSomethingWith(listNodeValue(node)); * &#125; * * *//* * 返回迭代器当前所指向的节点。 * * 删除当前节点是允许的，但不能修改链表里的其他节点。 * * 函数要么返回一个节点，要么返回 NULL ，常见的用法是： * * iter = listGetIterator(list,&lt;direction&gt;); * while ((node = listNext(iter)) != NULL) &#123; * doSomethingWith(listNodeValue(node)); * &#125; * * T = O(1) */listNode *listNext(listIter *iter)&#123; listNode *current = iter-&gt;next; if (current != NULL) &#123; // 根据方向选择下一个节点 if (iter-&gt;direction == AL_START_HEAD) // 保存下一个节点，防止当前节点被删除而造成指针丢失 iter-&gt;next = current-&gt;next; else // 保存下一个节点，防止当前节点被删除而造成指针丢失 iter-&gt;next = current-&gt;prev; &#125; return current;&#125;/* Duplicate the whole list. On out of memory NULL is returned. * On success a copy of the original list is returned. * * The 'Dup' method set with listSetDupMethod() function is used * to copy the node value. Otherwise the same pointer value of * the original node is used as value of the copied node. * * The original list both on success or error is never modified. *//* * 复制整个链表。 * * 复制成功返回输入链表的副本， * 如果因为内存不足而造成复制失败，返回 NULL 。 * * 如果链表有设置值复制函数 dup ，那么对值的复制将使用复制函数进行， * 否则，新节点将和旧节点共享同一个指针。 * * 无论复制是成功还是失败，输入节点都不会修改。 * * T = O(N) */list *listDup(list *orig)&#123; list *copy; listIter *iter; listNode *node; // 创建新链表 if ((copy = listCreate()) == NULL) return NULL; // 设置节点值处理函数 copy-&gt;dup = orig-&gt;dup; copy-&gt;free = orig-&gt;free; copy-&gt;match = orig-&gt;match; // 迭代整个输入链表 iter = listGetIterator(orig, AL_START_HEAD); while((node = listNext(iter)) != NULL) &#123; void *value; // 复制节点值到新节点 if (copy-&gt;dup) &#123; value = copy-&gt;dup(node-&gt;value); if (value == NULL) &#123; listRelease(copy); listReleaseIterator(iter); return NULL; &#125; &#125; else value = node-&gt;value; // 将节点添加到链表 if (listAddNodeTail(copy, value) == NULL) &#123; listRelease(copy); listReleaseIterator(iter); return NULL; &#125; &#125; // 释放迭代器 listReleaseIterator(iter); // 返回副本 return copy;&#125;/* Search the list for a node matching a given key. * The match is performed using the 'match' method * set with listSetMatchMethod(). If no 'match' method * is set, the 'value' pointer of every node is directly * compared with the 'key' pointer. * * On success the first matching node pointer is returned * (search starts from head). If no matching node exists * NULL is returned. *//* * 查找链表 list 中值和 key 匹配的节点。 * * 对比操作由链表的 match 函数负责进行， * 如果没有设置 match 函数， * 那么直接通过对比值的指针来决定是否匹配。 * * 如果匹配成功，那么第一个匹配的节点会被返回。 * 如果没有匹配任何节点，那么返回 NULL 。 * * T = O(N) */listNode *listSearchKey(list *list, void *key)&#123; listIter *iter; listNode *node; // 迭代整个链表 iter = listGetIterator(list, AL_START_HEAD); while((node = listNext(iter)) != NULL) &#123; // 对比 if (list-&gt;match) &#123; if (list-&gt;match(node-&gt;value, key)) &#123; listReleaseIterator(iter); // 找到 return node; &#125; &#125; else &#123; if (key == node-&gt;value) &#123; listReleaseIterator(iter); // 找到 return node; &#125; &#125; &#125; listReleaseIterator(iter); // 未找到 return NULL;&#125;/* Return the element at the specified zero-based index * where 0 is the head, 1 is the element next to head * and so on. Negative integers are used in order to count * from the tail, -1 is the last element, -2 the penultimate * and so on. If the index is out of range NULL is returned. *//* * 返回链表在给定索引上的值。 * * 索引以 0 为起始，也可以是负数， -1 表示链表最后一个节点，诸如此类。 * * 如果索引超出范围（out of range），返回 NULL 。 * * T = O(N) */listNode *listIndex(list *list, long index) &#123; listNode *n; // 如果索引为负数，从表尾开始查找 if (index &lt; 0) &#123; index = (-index)-1; n = list-&gt;tail; while(index-- &amp;&amp; n) n = n-&gt;prev; // 如果索引为正数，从表头开始查找 &#125; else &#123; n = list-&gt;head; while(index-- &amp;&amp; n) n = n-&gt;next; &#125; return n;&#125;/* Rotate the list removing the tail node and inserting it to the head. *//* * 取出链表的表尾节点，并将它移动到表头，成为新的表头节点。 * * T = O(1) */void listRotate(list *list) &#123; listNode *tail = list-&gt;tail; if (listLength(list) &lt;= 1) return; /* Detach current tail */ // 取出表尾节点 list-&gt;tail = tail-&gt;prev; list-&gt;tail-&gt;next = NULL; /* Move it as head */ // 插入到表头 list-&gt;head-&gt;prev = tail; tail-&gt;prev = NULL; tail-&gt;next = list-&gt;head; list-&gt;head = tail;&#125;","path":"2019/04/16/redis源码-adlist/","date":"04-16","excerpt":"Redis链表和链表节点的实现链表的每个节点用listNode结构表示12345678typedef struct listNode &#123; // 前置节点 struct listNode *prev; // 后置节点 struct listNode *next; // 节点值 void *value;&#125; listNode;","tags":[{"name":"源码","slug":"源码","permalink":"https://jijiking51.cn/tags/源码/"}],"preview":"http://img.jijiking51.cn/redis源码-adlist.jpg"},{"title":"redis源码-sds","text":"SDS-动态字符串定义SDS定义于sds.h/sds.c文件12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/* * 这个版本中， 不同的字符串长度使用的都是同一个结构体， * 这样会造成一定的内存浪费 * version 3.0 */ struct sdshdr &#123; // 字符串的长度 unsigned int len; // 记录buf中未使用字节的数量 unsigned int free; // 字节数组，用于保存字符串 char buf[];&#125;;/* * 提供五种header定义，满足各种字符串大小 * len：字符串的长度 * alloc：字符串最大容量 * flags：标记header的类型 * buf： 字节数组，用于保存字符串 * version 5.0 */typedef char *sds;/* Note: sdshdr5 is never used, we just access the flags byte directly. * However is here to document the layout of type 5 SDS strings. */struct __attribute__ ((__packed__)) sdshdr5 &#123; unsigned char flags; /* 3 lsb of type, and 5 msb of string length */ char buf[];&#125;;struct __attribute__ ((__packed__)) sdshdr8 &#123; uint8_t len; /* used */ uint8_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[];&#125;;struct __attribute__ ((__packed__)) sdshdr16 &#123; uint16_t len; /* used */ uint16_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[];&#125;;struct __attribute__ ((__packed__)) sdshdr32 &#123; uint32_t len; /* used */ uint32_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[];&#125;;struct __attribute__ ((__packed__)) sdshdr64 &#123; uint64_t len; /* used */ uint64_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[];&#125;; 例如： 目前：free=0、len=5、buf是一个char类型数组，我们向里面存入redis五个字符，则buf里面将会存入’r’,’e’,’d’,’i’,’s’,’\\0’,最后一个是空字符，这个并不会被len所记录，并且为空字符分配额外的1字节空间，以及添加空字符到字符串末尾等操作都是SDS函数自动完成的，所以这个空字符对于SDS的使用者是完全透明的，这个空字符对于但是却很重要，关系到我们重用C字符串函数库里面的函数 SDS与C的字符串区别常数复杂度获取字符串长度场景：C字符串长度为N，则需要N+1长度数组存储（最后一位存空字符），现在需要获取字符串长度需要的复杂度是多少？答案：O(n)， 过程是我们遍历整个字符串，对每个字符进行计数，直到遇到代表字符串结尾的空字符。 如果是SDS呢，那么我们的时间复杂度是O(1),因为我们的len属性中记录了SDS本身的长度。 杜绝缓冲区溢出除了获取字符串长度的复杂度搞之外，C字符串不记录自身长度带来的另一个问题是容易造成缓冲区溢出例如：1char *strcat(char *dest, const char *src); 我们将src字符串中的内容配接到dest字符串的末尾的时候，因为C字符串不记录自身的长度，所以strcat假定用户在执行这个函数时已经为dest分配了足够多的内存，可以容纳src字符串中的所有内容，如果上述条件不成立，则会产生缓冲区溢出 例如：程序中有两个在内存中紧邻的两个字符串s1,s2分别是’redis’,’mongodb’ 如果这个时候执行strcat(s1,&quot; Cluster&quot;);将s1中的内容修改为’Redis Cluster’，忘记为s1分配足够的空间，那么将会导致s2内容被意外地修改 SDS的空间分配策略完全杜绝了发生缓冲区溢出的可能性，当SDS API需要对SDS进行修改时，API会先检查SDS的空间是否满足修改所需的要求，如果不满足的话API会自动将SDS的空间扩展至执行修改所需的大小，所以SDS不需要手动修改SDS的空间大小也不会出现缓冲区溢出问题。 SDS空间分配策略减少修改字符串时带来的内存重分配次数前面说过，C字符串并不记录自身的长度，对于包含了N个字符的C字符串来说，这个C字符串的底层实现总是一个N+1个字符长的数组，所以每次增长或者缩短一个C字符串都需要一次内存重分配。如果不重新分配会造成两种情况 如果程序增长没有重新分配内存空间大小，会产生缓冲区溢出 如果缩短字符串操作没有重新分配空间，会产生内存泄漏 空间预分配 如果对 SDS 进行修改之后， SDS 的长度（也即是 len 属性的值）将小于 1 MB ， 那么程序分配和 len 属性同样大小的未使用空间， 这时 SDS len 属性的值将和 free 属性的值相同。 举个例子， 如果进行修改之后， SDS 的 len 将变成 13 字节， 那么程序也会分配13 字节的未使用空间， SDS 的 buf 数组的实际长度将变成 13 + 13 + 1 = 27 字节（额外的一字节用于保存空字符）。 如果对 SDS 进行修改之后， SDS 的长度将大于等于 1 MB ， 那么程序会分配 1 MB 的未使用空间。 举个例子， 如果进行修改之后， SDS 的 len 将变成 30 MB ， 那么程序会分配 1 MB 的未使用空间， SDS 的 buf 数组的实际长度将为 30 MB + 1 MB + 1 byte 。 例如： sdscat(s, &quot; Cluster&quot;);,那么 sdscat 将执行一次内存重分配操作， 将 SDS 的长度修改为 13 字节， 并将 SDS 的未使用空间同样修改为 13 字节， 如果这个时候我们再执行sdscat(s, &quot; Tutorial&quot;); 这是因为我们已经有13字节足以保存9字节的” Tutorial”,在扩展 SDS 空间之前， SDS API 会先检查未使用空间是否足够， 如果足够的话， API 就会直接使用未使用空间， 而无须执行内存重分配。 通过这种预分配策略， SDS 将连续增长 N 次字符串所需的内存重分配次数从必定 N 次降低为最多 N 次。 惰性空间释放惰性空间释放用于优化 SDS 的字符串缩短操作： 当 SDS 的 API 需要缩短 SDS 保存的字符串时， 程序并不立即使用内存重分配来回收缩短后多出来的字节， 而是使用 free 属性将这些字节的数量记录起来， 并等待将来使用。例如： S=”XYXXYabcXYY”，我们执行sdstrim(s, &quot;XY&quot;);移除S字符串中的所有 ‘X’ 和 ‘Y’。 这个时候SDS并没有释放多出来的8个字节，而是将这8个字节空间保留在了SDS里面，如果之后对SDS进行增长操作的话，这些空间就能派上用场。 同时，SDS也提供了相应的API，让我们可以在有需要时真正的释放SDS里面的未使用空间，所以不用担心惰性空间释放策略会造成内存浪费。 二进制安全在C字符串中， 除了字符串末尾外，字符串里面不能包含空字符，否则最先被程序读入的空字符将被误认为是字符串结尾，所以不能用来保存二进制数据等一些特殊数据。但是SDS使用buf保存二进制数据，特殊格式等对其无影响，因为SDS使用len属性的值而不是空字符串来判断字符串是否结束。 兼容部分C字符串函数SDS的API是二进制安全的，但它一样遵循C字符串以空字符结尾的惯例，这些API总会将SDS保存的数据的末尾设置为空字符，并且会为buf数组分配空一格字节的空间容纳这个空字符，这是为了让那些文本数据的SDS可以重用一部分&lt;string.h&gt;定义的函数 SDS&nbsp;API常用API 函数 作用 时间复杂度 sdsnew 创建一个包含给定 C 字符串的SDS 。 O(N) ， N 为给定 C 字符串的长度。 sdsempty 创建一个不包含任何内容的空SDS 。 O(1) sdsfree 释放给定的 SDS 。 O(1) sdslen 返回 SDS 的已使用空间字节数。 这个值可以通过读取 SDS 的 len 属性来直接获得，复杂度为 O(1). sdsavail 返回 SDS 的未使用空间字节数。 这个值可以通过读取 SDS 的 free 属性来直接获得， 复杂度为 O(1)。 sdsdup 创建一个给定 SDS 的副本（copy）。 O(N) ， N 为给定 SDS 的长度。 sdsclear 清空 SDS 保存的字符串内容。 因为惰性空间释放策略，复杂度为 O(1)。 sdscat 将给定 C 字符串拼接到 SDS 字符串的末尾。 O(N) ， N 为被拼接 C 字符串的长度。 sdscatsds 将给定 SDS 字符串拼接到另一个 SDS 字符串的末尾。 O(N) ， N 为被拼接 SDS 字符串的长度。 sdscpy 将给定的 C 字符串复制到 SDS 里面， 覆盖 SDS 原有的字符串。 O(N) ， N 为被复制 C 字符串的长度。 sdsgrowzero 用空字符将 SDS 扩展至给定长度。 O(N) ， N 为扩展新增的字节数。 sdsrange 保留 SDS 给定区间内的数据， 不在区间内的数据会被覆盖或清除。 O(N) ， N 为被保留数据的字节数。 sdstrim 接受一个SDS和一个C字符串作为参数， 从 SDS 左右两端分别移除所有在C字符串中出现过的字符。 O(M*N)，M为 SDS的长度，N为给定C字符串的长度。 sdscmp 对比两个SDS字符串是否相同。 O(N)，N为两个SDS中较短的那个 SDS 的长度。 API原码注解 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989910010110210310410510610710810911011111211311411511611711811912012112212312412512612712812913013113213313413513613713813914014114214314414514614714814915015115215315415515615715815916016116216316416516616716816917017117217317417517617717817918018118218318418518618718818919019119219319419519619719819920020120220320420520620720820921021121221321421521621721821922022122222322422522622722822923023123223323423523623723823924024124224324424524624724824925025125225325425525625725825926026126226326426526626726826927027127227327427527627727827928028128228328428528628728828929029129229329429529629729829930030130230330430530630730830931031131231331431531631731831932032132232332432532632732832933033133233333433533633733833934034134234334434534634734834935035135235335435535635735835936036136236336436536636736836937037137237337437537637737837938038138238338438538638738838939039139239339439539639739839940040140240340440540640740840941041141241341441541641741841942042142242342442542642742842943043143243343443543643743843944044144244344444544644744844945045145245345445545645745845946046146246346446546646746846947047147247347447547647747847948048148248348448548648748848949049149249349449549649749849950050150250350450550650750850951051151251351451551651751851952052152252352452552652752852953053153253353453553653753853954054154254354454554654754854955055155255355455555655755855956056156256356456556656756856957057157257357457557657757857958058158258358458558658758858959059159259359459559659759859960060160260360460560660760860961061161261361461561661761861962062162262362462562662762862963063163263363463563663763863964064164264364464564664764864965065165265365465565665765865966066166266366466566666766866967067167267367467567667767867968068168268368468568668768868969069169269369469569669769869970070170270370470570670770870971071171271371471571671771871972072172272372472572672772872973073173273373473573673773873974074174274374474574674774874975075175275375475575675775875976076176276376476576676776876977077177277377477577677777877978078178278378478578678778878979079179279379479579679779879980080180280380480580680780880981081181281381481581681781881982082182282382482582682782882983083183283383483583683783883984084184284384484584684784884985085185285385485585685785885986086186286386486586686786886987087187287387487587687787887988088188288388488588688788888989089189289389489589689789889990090190290390490590690790890991091191291391491591691791891992092192292392492592692792892993093193293393493593693793893994094194294394494594694794894995095195295395495595695795895996096196296396496596696796896997097197297397497597697797897998098198298398498598698798898999099199299399499599699799899910001001100210031004100510061007100810091010101110121013101410151016101710181019102010211022102310241025102610271028102910301031103210331034103510361037103810391040104110421043104410451046104710481049105010511052105310541055105610571058105910601061106210631064106510661067106810691070107110721073107410751076107710781079108010811082108310841085108610871088108910901091109210931094109510961097109810991100110111021103110411051106110711081109111011111112111311141115111611171118111911201121112211231124112511261127112811291130113111321133113411351136113711381139114011411142114311441145114611471148114911501151115211531154115511561157115811591160116111621163116411651166116711681169117011711172117311741175117611771178117911801181118211831184118511861187118811891190119111921193119411951196119711981199120012011202120312041205120612071208120912101211121212131214121512161217121812191220122112221223122412251226122712281229123012311232123312341235123612371238123912401241124212431244124512461247124812491250125112521253125412551256125712581259126012611262126312641265126612671268126912701271127212731274127512761277127812791280128112821283128412851286128712881289129012911292129312941295129612971298129913001301130213031304130513061307130813091310131113121313131413151316131713181319132013211322132313241325132613271328132913301331133213331334133513361337133813391340/* * 根据给定的初始化字符串 init 和字符串长度 initlen * 创建一个新的 sds * * 参数 * init ：初始化字符串指针 * initlen ：初始化字符串的长度 * * 返回值 * sds ：创建成功返回 sdshdr 相对应的 sds * 创建失败返回 NULL * * 复杂度 * T = O(N) *//* Create a new sds string with the content specified by the 'init' pointer * and 'initlen'. * If NULL is used for 'init' the string is initialized with zero bytes. * * The string is always null-termined (all the sds strings are, always) so * even if you create an sds string with: * * mystring = sdsnewlen(\"abc\",3\"); * * You can print the string with printf() as there is an implicit \\0 at the * end of the string. However the string is binary safe and can contain * \\0 characters in the middle, as the length is stored in the sds header. */sds sdsnewlen(const void *init, size_t initlen) &#123; struct sdshdr *sh; // 根据是否有初始化内容，选择适当的内存分配方式 // T = O(N) if (init) &#123; // zmalloc 不初始化所分配的内存 sh = zmalloc(sizeof(struct sdshdr)+initlen+1); &#125; else &#123; // zcalloc 将分配的内存全部初始化为 0 sh = zcalloc(sizeof(struct sdshdr)+initlen+1); &#125; // 内存分配失败，返回 if (sh == NULL) return NULL; // 设置初始化长度 sh-&gt;len = initlen; // 新 sds 不预留任何空间 sh-&gt;free = 0; // 如果有指定初始化内容，将它们复制到 sdshdr 的 buf 中 // T = O(N) if (initlen &amp;&amp; init) memcpy(sh-&gt;buf, init, initlen); // 以 \\0 结尾 sh-&gt;buf[initlen] = '\\0'; // 返回 buf 部分，而不是整个 sdshdr return (char*)sh-&gt;buf;&#125;/* * 创建并返回一个只保存了空字符串 \"\" 的 sds * * 返回值 * sds ：创建成功返回 sdshdr 相对应的 sds * 创建失败返回 NULL * * 复杂度 * T = O(1) *//* Create an empty (zero length) sds string. Even in this case the string * always has an implicit null term. */sds sdsempty(void) &#123; return sdsnewlen(\"\",0);&#125;/* * 根据给定字符串 init ，创建一个包含同样字符串的 sds * * 参数 * init ：如果输入为 NULL ，那么创建一个空白 sds * 否则，新创建的 sds 中包含和 init 内容相同字符串 * * 返回值 * sds ：创建成功返回 sdshdr 相对应的 sds * 创建失败返回 NULL * * 复杂度 * T = O(N) *//* Create a new sds string starting from a null termined C string. */sds sdsnew(const char *init) &#123; size_t initlen = (init == NULL) ? 0 : strlen(init); return sdsnewlen(init, initlen);&#125;/* * 复制给定 sds 的副本 * * 返回值 * sds ：创建成功返回输入 sds 的副本 * 创建失败返回 NULL * * 复杂度 * T = O(N) *//* Duplicate an sds string. */sds sdsdup(const sds s) &#123; return sdsnewlen(s, sdslen(s));&#125;/* * 释放给定的 sds * * 复杂度 * T = O(N) *//* Free an sds string. No operation is performed if 's' is NULL. */void sdsfree(sds s) &#123; if (s == NULL) return; zfree(s-sizeof(struct sdshdr));&#125;// 未使用函数，可能已废弃/* Set the sds string length to the length as obtained with strlen(), so * considering as content only up to the first null term character. * * This function is useful when the sds string is hacked manually in some * way, like in the following example: * * s = sdsnew(\"foobar\"); * s[2] = '\\0'; * sdsupdatelen(s); * printf(\"%d\\n\", sdslen(s)); * * The output will be \"2\", but if we comment out the call to sdsupdatelen() * the output will be \"6\" as the string was modified but the logical length * remains 6 bytes. */void sdsupdatelen(sds s) &#123; struct sdshdr *sh = (void*) (s-(sizeof(struct sdshdr))); int reallen = strlen(s); sh-&gt;free += (sh-&gt;len-reallen); sh-&gt;len = reallen;&#125;/* * 在不释放 SDS 的字符串空间的情况下， * 重置 SDS 所保存的字符串为空字符串。 * * 复杂度 * T = O(1) *//* Modify an sds string on-place to make it empty (zero length). * However all the existing buffer is not discarded but set as free space * so that next append operations will not require allocations up to the * number of bytes previously available. */void sdsclear(sds s) &#123; // 取出 sdshdr struct sdshdr *sh = (void*) (s-(sizeof(struct sdshdr))); // 重新计算属性 sh-&gt;free += sh-&gt;len; sh-&gt;len = 0; // 将结束符放到最前面（相当于惰性地删除 buf 中的内容） sh-&gt;buf[0] = '\\0';&#125;/* Enlarge the free space at the end of the sds string so that the caller * is sure that after calling this function can overwrite up to addlen * bytes after the end of the string, plus one more byte for nul term. * * Note: this does not change the *length* of the sds string as returned * by sdslen(), but only the free buffer space we have. *//* * 对 sds 中 buf 的长度进行扩展，确保在函数执行之后， * buf 至少会有 addlen + 1 长度的空余空间 * （额外的 1 字节是为 \\0 准备的） * * 返回值 * sds ：扩展成功返回扩展后的 sds * 扩展失败返回 NULL * * 复杂度 * T = O(N) */sds sdsMakeRoomFor(sds s, size_t addlen) &#123; struct sdshdr *sh, *newsh; // 获取 s 目前的空余空间长度 size_t free = sdsavail(s); size_t len, newlen; // s 目前的空余空间已经足够，无须再进行扩展，直接返回 if (free &gt;= addlen) return s; // 获取 s 目前已占用空间的长度 len = sdslen(s); sh = (void*) (s-(sizeof(struct sdshdr))); // s 最少需要的长度 newlen = (len+addlen); // 根据新长度，为 s 分配新空间所需的大小 if (newlen &lt; SDS_MAX_PREALLOC) // 如果新长度小于 SDS_MAX_PREALLOC // 那么为它分配两倍于所需长度的空间 newlen *= 2; else // 否则，分配长度为目前长度加上 SDS_MAX_PREALLOC newlen += SDS_MAX_PREALLOC; // T = O(N) newsh = zrealloc(sh, sizeof(struct sdshdr)+newlen+1); // 内存不足，分配失败，返回 if (newsh == NULL) return NULL; // 更新 sds 的空余长度 newsh-&gt;free = newlen - len; // 返回 sds return newsh-&gt;buf;&#125;/* * 回收 sds 中的空闲空间， * 回收不会对 sds 中保存的字符串内容做任何修改。 * * 返回值 * sds ：内存调整后的 sds * * 复杂度 * T = O(N) *//* Reallocate the sds string so that it has no free space at the end. The * contained string remains not altered, but next concatenation operations * will require a reallocation. * * After the call, the passed sds string is no longer valid and all the * references must be substituted with the new pointer returned by the call. */sds sdsRemoveFreeSpace(sds s) &#123; struct sdshdr *sh; sh = (void*) (s-(sizeof(struct sdshdr))); // 进行内存重分配，让 buf 的长度仅仅足够保存字符串内容 // T = O(N) sh = zrealloc(sh, sizeof(struct sdshdr)+sh-&gt;len+1); // 空余空间为 0 sh-&gt;free = 0; return sh-&gt;buf;&#125;/* * 返回给定 sds 分配的内存字节数 * * 复杂度 * T = O(1) *//* Return the total size of the allocation of the specifed sds string, * including: * 1) The sds header before the pointer. * 2) The string. * 3) The free buffer at the end if any. * 4) The implicit null term. */size_t sdsAllocSize(sds s) &#123; struct sdshdr *sh = (void*) (s-(sizeof(struct sdshdr))); return sizeof(*sh)+sh-&gt;len+sh-&gt;free+1;&#125;/* Increment the sds length and decrements the left free space at the * end of the string according to 'incr'. Also set the null term * in the new end of the string. * * 根据 incr 参数，增加 sds 的长度，缩减空余空间， * 并将 \\0 放到新字符串的尾端 * * This function is used in order to fix the string length after the * user calls sdsMakeRoomFor(), writes something after the end of * the current string, and finally needs to set the new length. * * 这个函数是在调用 sdsMakeRoomFor() 对字符串进行扩展， * 然后用户在字符串尾部写入了某些内容之后， * 用来正确更新 free 和 len 属性的。 * * Note: it is possible to use a negative increment in order to * right-trim the string. * * 如果 incr 参数为负数，那么对字符串进行右截断操作。 * * Usage example: * * Using sdsIncrLen() and sdsMakeRoomFor() it is possible to mount the * following schema, to cat bytes coming from the kernel to the end of an * sds string without copying into an intermediate buffer: * * 以下是 sdsIncrLen 的用例： * * oldlen = sdslen(s); * s = sdsMakeRoomFor(s, BUFFER_SIZE); * nread = read(fd, s+oldlen, BUFFER_SIZE); * ... check for nread &lt;= 0 and handle it ... * sdsIncrLen(s, nread); * * 复杂度 * T = O(1) */void sdsIncrLen(sds s, int incr) &#123; struct sdshdr *sh = (void*) (s-(sizeof(struct sdshdr))); // 确保 sds 空间足够 assert(sh-&gt;free &gt;= incr); // 更新属性 sh-&gt;len += incr; sh-&gt;free -= incr; // 这个 assert 其实可以忽略 // 因为前一个 assert 已经确保 sh-&gt;free - incr &gt;= 0 了 assert(sh-&gt;free &gt;= 0); // 放置新的结尾符号 s[sh-&gt;len] = '\\0';&#125;/* Grow the sds to have the specified length. Bytes that were not part of * the original length of the sds will be set to zero. * * if the specified length is smaller than the current length, no operation * is performed. *//* * 将 sds 扩充至指定长度，未使用的空间以 0 字节填充。 * * 返回值 * sds ：扩充成功返回新 sds ，失败返回 NULL * * 复杂度： * T = O(N) */sds sdsgrowzero(sds s, size_t len) &#123; struct sdshdr *sh = (void*)(s-(sizeof(struct sdshdr))); size_t totlen, curlen = sh-&gt;len; // 如果 len 比字符串的现有长度小， // 那么直接返回，不做动作 if (len &lt;= curlen) return s; // 扩展 sds // T = O(N) s = sdsMakeRoomFor(s,len-curlen); // 如果内存不足，直接返回 if (s == NULL) return NULL; /* Make sure added region doesn't contain garbage */ // 将新分配的空间用 0 填充，防止出现垃圾内容 // T = O(N) sh = (void*)(s-(sizeof(struct sdshdr))); memset(s+curlen,0,(len-curlen+1)); /* also set trailing \\0 byte */ // 更新属性 totlen = sh-&gt;len+sh-&gt;free; sh-&gt;len = len; sh-&gt;free = totlen-sh-&gt;len; // 返回新的 sds return s;&#125;/* * 将长度为 len 的字符串 t 追加到 sds 的字符串末尾 * * 返回值 * sds ：追加成功返回新 sds ，失败返回 NULL * * 复杂度 * T = O(N) *//* Append the specified binary-safe string pointed by 't' of 'len' bytes to the * end of the specified sds string 's'. * * After the call, the passed sds string is no longer valid and all the * references must be substituted with the new pointer returned by the call. */sds sdscatlen(sds s, const void *t, size_t len) &#123; struct sdshdr *sh; // 原有字符串长度 size_t curlen = sdslen(s); // 扩展 sds 空间 // T = O(N) s = sdsMakeRoomFor(s,len); // 内存不足？直接返回 if (s == NULL) return NULL; // 复制 t 中的内容到字符串后部 // T = O(N) sh = (void*) (s-(sizeof(struct sdshdr))); memcpy(s+curlen, t, len); // 更新属性 sh-&gt;len = curlen+len; sh-&gt;free = sh-&gt;free-len; // 添加新结尾符号 s[curlen+len] = '\\0'; // 返回新 sds return s;&#125;/* * 将给定字符串 t 追加到 sds 的末尾 * * 返回值 * sds ：追加成功返回新 sds ，失败返回 NULL * * 复杂度 * T = O(N) *//* Append the specified null termianted C string to the sds string 's'. * * After the call, the passed sds string is no longer valid and all the * references must be substituted with the new pointer returned by the call. */sds sdscat(sds s, const char *t) &#123; return sdscatlen(s, t, strlen(t));&#125;/* * 将另一个 sds 追加到一个 sds 的末尾 * * 返回值 * sds ：追加成功返回新 sds ，失败返回 NULL * * 复杂度 * T = O(N) *//* Append the specified sds 't' to the existing sds 's'. * * After the call, the modified sds string is no longer valid and all the * references must be substituted with the new pointer returned by the call. */sds sdscatsds(sds s, const sds t) &#123; return sdscatlen(s, t, sdslen(t));&#125;/* * 将字符串 t 的前 len 个字符复制到 sds s 当中， * 并在字符串的最后添加终结符。 * * 如果 sds 的长度少于 len 个字符，那么扩展 sds * * 复杂度 * T = O(N) * * 返回值 * sds ：复制成功返回新的 sds ，否则返回 NULL *//* Destructively modify the sds string 's' to hold the specified binary * safe string pointed by 't' of length 'len' bytes. */sds sdscpylen(sds s, const char *t, size_t len) &#123; struct sdshdr *sh = (void*) (s-(sizeof(struct sdshdr))); // sds 现有 buf 的长度 size_t totlen = sh-&gt;free+sh-&gt;len; // 如果 s 的 buf 长度不满足 len ，那么扩展它 if (totlen &lt; len) &#123; // T = O(N) s = sdsMakeRoomFor(s,len-sh-&gt;len); if (s == NULL) return NULL; sh = (void*) (s-(sizeof(struct sdshdr))); totlen = sh-&gt;free+sh-&gt;len; &#125; // 复制内容 // T = O(N) memcpy(s, t, len); // 添加终结符号 s[len] = '\\0'; // 更新属性 sh-&gt;len = len; sh-&gt;free = totlen-len; // 返回新的 sds return s;&#125;/* * 将字符串复制到 sds 当中， * 覆盖原有的字符。 * * 如果 sds 的长度少于字符串的长度，那么扩展 sds 。 * * 复杂度 * T = O(N) * * 返回值 * sds ：复制成功返回新的 sds ，否则返回 NULL *//* Like sdscpylen() but 't' must be a null-termined string so that the length * of the string is obtained with strlen(). */sds sdscpy(sds s, const char *t) &#123; return sdscpylen(s, t, strlen(t));&#125;/* Helper for sdscatlonglong() doing the actual number -&gt; string * conversion. 's' must point to a string with room for at least * SDS_LLSTR_SIZE bytes. * * The function returns the lenght of the null-terminated string * representation stored at 's'. */#define SDS_LLSTR_SIZE 21int sdsll2str(char *s, long long value) &#123; char *p, aux; unsigned long long v; size_t l; /* Generate the string representation, this method produces * an reversed string. */ v = (value &lt; 0) ? -value : value; p = s; do &#123; *p++ = '0'+(v%10); v /= 10; &#125; while(v); if (value &lt; 0) *p++ = '-'; /* Compute length and add null term. */ l = p-s; *p = '\\0'; /* Reverse the string. */ p--; while(s &lt; p) &#123; aux = *s; *s = *p; *p = aux; s++; p--; &#125; return l;&#125;/* Identical sdsll2str(), but for unsigned long long type. */int sdsull2str(char *s, unsigned long long v) &#123; char *p, aux; size_t l; /* Generate the string representation, this method produces * an reversed string. */ p = s; do &#123; *p++ = '0'+(v%10); v /= 10; &#125; while(v); /* Compute length and add null term. */ l = p-s; *p = '\\0'; /* Reverse the string. */ p--; while(s &lt; p) &#123; aux = *s; *s = *p; *p = aux; s++; p--; &#125; return l;&#125;/* Create an sds string from a long long value. It is much faster than: * * sdscatprintf(sdsempty(),\"%lld\\n\", value); */// 根据输入的 long long 值 value ，创建一个 SDSsds sdsfromlonglong(long long value) &#123; char buf[SDS_LLSTR_SIZE]; int len = sdsll2str(buf,value); return sdsnewlen(buf,len);&#125;/* * 打印函数，被 sdscatprintf 所调用 * * T = O(N^2) *//* Like sdscatpritf() but gets va_list instead of being variadic. */sds sdscatvprintf(sds s, const char *fmt, va_list ap) &#123; va_list cpy; char staticbuf[1024], *buf = staticbuf, *t; size_t buflen = strlen(fmt)*2; /* We try to start using a static buffer for speed. * If not possible we revert to heap allocation. */ if (buflen &gt; sizeof(staticbuf)) &#123; buf = zmalloc(buflen); if (buf == NULL) return NULL; &#125; else &#123; buflen = sizeof(staticbuf); &#125; /* Try with buffers two times bigger every time we fail to * fit the string in the current buffer size. */ while(1) &#123; buf[buflen-2] = '\\0'; va_copy(cpy,ap); // T = O(N) vsnprintf(buf, buflen, fmt, cpy); if (buf[buflen-2] != '\\0') &#123; if (buf != staticbuf) zfree(buf); buflen *= 2; buf = zmalloc(buflen); if (buf == NULL) return NULL; continue; &#125; break; &#125; /* Finally concat the obtained string to the SDS string and return it. */ t = sdscat(s, buf); if (buf != staticbuf) zfree(buf); return t;&#125;/* * 打印任意数量个字符串，并将这些字符串追加到给定 sds 的末尾 * * T = O(N^2) *//* Append to the sds string 's' a string obtained using printf-alike format * specifier. * * After the call, the modified sds string is no longer valid and all the * references must be substituted with the new pointer returned by the call. * * Example: * * s = sdsempty(\"Sum is: \"); * s = sdscatprintf(s,\"%d+%d = %d\",a,b,a+b). * * Often you need to create a string from scratch with the printf-alike * format. When this is the need, just use sdsempty() as the target string: * * s = sdscatprintf(sdsempty(), \"... your format ...\", args); */sds sdscatprintf(sds s, const char *fmt, ...) &#123; va_list ap; char *t; va_start(ap, fmt); // T = O(N^2) t = sdscatvprintf(s,fmt,ap); va_end(ap); return t;&#125;/* This function is similar to sdscatprintf, but much faster as it does * not rely on sprintf() family functions implemented by the libc that * are often very slow. Moreover directly handling the sds string as * new data is concatenated provides a performance improvement. * * However this function only handles an incompatible subset of printf-alike * format specifiers: * * %s - C String * %S - SDS string * %i - signed int * %I - 64 bit signed integer (long long, int64_t) * %u - unsigned int * %U - 64 bit unsigned integer (unsigned long long, uint64_t) * %% - Verbatim \"%\" character. */sds sdscatfmt(sds s, char const *fmt, ...) &#123; struct sdshdr *sh = (void*) (s-(sizeof(struct sdshdr))); size_t initlen = sdslen(s); const char *f = fmt; int i; va_list ap; va_start(ap,fmt); f = fmt; /* Next format specifier byte to process. */ i = initlen; /* Position of the next byte to write to dest str. */ while(*f) &#123; char next, *str; size_t l; long long num; unsigned long long unum; /* Make sure there is always space for at least 1 char. */ if (sh-&gt;free == 0) &#123; s = sdsMakeRoomFor(s,1); sh = (void*) (s-(sizeof(struct sdshdr))); &#125; switch(*f) &#123; case '%': next = *(f+1); f++; switch(next) &#123; case 's': case 'S': str = va_arg(ap,char*); l = (next == 's') ? strlen(str) : sdslen(str); if (sh-&gt;free &lt; l) &#123; s = sdsMakeRoomFor(s,l); sh = (void*) (s-(sizeof(struct sdshdr))); &#125; memcpy(s+i,str,l); sh-&gt;len += l; sh-&gt;free -= l; i += l; break; case 'i': case 'I': if (next == 'i') num = va_arg(ap,int); else num = va_arg(ap,long long); &#123; char buf[SDS_LLSTR_SIZE]; l = sdsll2str(buf,num); if (sh-&gt;free &lt; l) &#123; s = sdsMakeRoomFor(s,l); sh = (void*) (s-(sizeof(struct sdshdr))); &#125; memcpy(s+i,buf,l); sh-&gt;len += l; sh-&gt;free -= l; i += l; &#125; break; case 'u': case 'U': if (next == 'u') unum = va_arg(ap,unsigned int); else unum = va_arg(ap,unsigned long long); &#123; char buf[SDS_LLSTR_SIZE]; l = sdsull2str(buf,unum); if (sh-&gt;free &lt; l) &#123; s = sdsMakeRoomFor(s,l); sh = (void*) (s-(sizeof(struct sdshdr))); &#125; memcpy(s+i,buf,l); sh-&gt;len += l; sh-&gt;free -= l; i += l; &#125; break; default: /* Handle %% and generally %&lt;unknown&gt;. */ s[i++] = next; sh-&gt;len += 1; sh-&gt;free -= 1; break; &#125; break; default: s[i++] = *f; sh-&gt;len += 1; sh-&gt;free -= 1; break; &#125; f++; &#125; va_end(ap); /* Add null-term */ s[i] = '\\0'; return s;&#125;/* * 对 sds 左右两端进行修剪，清除其中 cset 指定的所有字符 * * 比如 sdsstrim(xxyyabcyyxy, \"xy\") 将返回 \"abc\" * * 复杂性： * T = O(M*N)，M 为 SDS 长度， N 为 cset 长度。 *//* Remove the part of the string from left and from right composed just of * contiguous characters found in 'cset', that is a null terminted C string. * * After the call, the modified sds string is no longer valid and all the * references must be substituted with the new pointer returned by the call. * * Example: * * s = sdsnew(\"AA...AA.a.aa.aHelloWorld :::\"); * s = sdstrim(s,\"A. :\"); * printf(\"%s\\n\", s); * * Output will be just \"Hello World\". */sds sdstrim(sds s, const char *cset) &#123; struct sdshdr *sh = (void*) (s-(sizeof(struct sdshdr))); char *start, *end, *sp, *ep; size_t len; // 设置和记录指针 sp = start = s; ep = end = s+sdslen(s)-1; // 修剪, T = O(N^2) while(sp &lt;= end &amp;&amp; strchr(cset, *sp)) sp++; while(ep &gt; start &amp;&amp; strchr(cset, *ep)) ep--; // 计算 trim 完毕之后剩余的字符串长度 len = (sp &gt; ep) ? 0 : ((ep-sp)+1); // 如果有需要，前移字符串内容 // T = O(N) if (sh-&gt;buf != sp) memmove(sh-&gt;buf, sp, len); // 添加终结符 sh-&gt;buf[len] = '\\0'; // 更新属性 sh-&gt;free = sh-&gt;free+(sh-&gt;len-len); sh-&gt;len = len; // 返回修剪后的 sds return s;&#125;/* * 按索引对截取 sds 字符串的其中一段 * start 和 end 都是闭区间（包含在内） * * 索引从 0 开始，最大为 sdslen(s) - 1 * 索引可以是负数， sdslen(s) - 1 == -1 * * 复杂度 * T = O(N) *//* Turn the string into a smaller (or equal) string containing only the * substring specified by the 'start' and 'end' indexes. * * start and end can be negative, where -1 means the last character of the * string, -2 the penultimate character, and so forth. * * The interval is inclusive, so the start and end characters will be part * of the resulting string. * * The string is modified in-place. * * Example: * * s = sdsnew(\"Hello World\"); * sdsrange(s,1,-1); =&gt; \"ello World\" */void sdsrange(sds s, int start, int end) &#123; struct sdshdr *sh = (void*) (s-(sizeof(struct sdshdr))); size_t newlen, len = sdslen(s); if (len == 0) return; if (start &lt; 0) &#123; start = len+start; if (start &lt; 0) start = 0; &#125; if (end &lt; 0) &#123; end = len+end; if (end &lt; 0) end = 0; &#125; newlen = (start &gt; end) ? 0 : (end-start)+1; if (newlen != 0) &#123; if (start &gt;= (signed)len) &#123; newlen = 0; &#125; else if (end &gt;= (signed)len) &#123; end = len-1; newlen = (start &gt; end) ? 0 : (end-start)+1; &#125; &#125; else &#123; start = 0; &#125; // 如果有需要，对字符串进行移动 // T = O(N) if (start &amp;&amp; newlen) memmove(sh-&gt;buf, sh-&gt;buf+start, newlen); // 添加终结符 sh-&gt;buf[newlen] = 0; // 更新属性 sh-&gt;free = sh-&gt;free+(sh-&gt;len-newlen); sh-&gt;len = newlen;&#125;/* * 将 sds 字符串中的所有字符转换为小写 * * T = O(N) *//* Apply tolower() to every character of the sds string 's'. */void sdstolower(sds s) &#123; int len = sdslen(s), j; for (j = 0; j &lt; len; j++) s[j] = tolower(s[j]);&#125;/* * 将 sds 字符串中的所有字符转换为大写 * * T = O(N) *//* Apply toupper() to every character of the sds string 's'. */void sdstoupper(sds s) &#123; int len = sdslen(s), j; for (j = 0; j &lt; len; j++) s[j] = toupper(s[j]);&#125;/* * 对比两个 sds ， strcmp 的 sds 版本 * * 返回值 * int ：相等返回 0 ，s1 较大返回正数， s2 较大返回负数 * * T = O(N) *//* Compare two sds strings s1 and s2 with memcmp(). * * Return value: * * 1 if s1 &gt; s2. * -1 if s1 &lt; s2. * 0 if s1 and s2 are exactly the same binary string. * * If two strings share exactly the same prefix, but one of the two has * additional characters, the longer string is considered to be greater than * the smaller one. */int sdscmp(const sds s1, const sds s2) &#123; size_t l1, l2, minlen; int cmp; l1 = sdslen(s1); l2 = sdslen(s2); minlen = (l1 &lt; l2) ? l1 : l2; cmp = memcmp(s1,s2,minlen); if (cmp == 0) return l1-l2; return cmp;&#125;/* Split 's' with separator in 'sep'. An array * of sds strings is returned. *count will be set * by reference to the number of tokens returned. * * 使用分隔符 sep 对 s 进行分割，返回一个 sds 字符串的数组。 * *count 会被设置为返回数组元素的数量。 * * On out of memory, zero length string, zero length * separator, NULL is returned. * * 如果出现内存不足、字符串长度为 0 或分隔符长度为 0 * 的情况，返回 NULL * * Note that 'sep' is able to split a string using * a multi-character separator. For example * sdssplit(\"foo_-_bar\",\"_-_\"); will return two * elements \"foo\" and \"bar\". * * 注意分隔符可以的是包含多个字符的字符串 * * This version of the function is binary-safe but * requires length arguments. sdssplit() is just the * same function but for zero-terminated strings. * * 这个函数接受 len 参数，因此它是二进制安全的。 * （文档中提到的 sdssplit() 已废弃） * * T = O(N^2) */sds *sdssplitlen(const char *s, int len, const char *sep, int seplen, int *count) &#123; int elements = 0, slots = 5, start = 0, j; sds *tokens; if (seplen &lt; 1 || len &lt; 0) return NULL; tokens = zmalloc(sizeof(sds)*slots); if (tokens == NULL) return NULL; if (len == 0) &#123; *count = 0; return tokens; &#125; // T = O(N^2) for (j = 0; j &lt; (len-(seplen-1)); j++) &#123; /* make sure there is room for the next element and the final one */ if (slots &lt; elements+2) &#123; sds *newtokens; slots *= 2; newtokens = zrealloc(tokens,sizeof(sds)*slots); if (newtokens == NULL) goto cleanup; tokens = newtokens; &#125; /* search the separator */ // T = O(N) if ((seplen == 1 &amp;&amp; *(s+j) == sep[0]) || (memcmp(s+j,sep,seplen) == 0)) &#123; tokens[elements] = sdsnewlen(s+start,j-start); if (tokens[elements] == NULL) goto cleanup; elements++; start = j+seplen; j = j+seplen-1; /* skip the separator */ &#125; &#125; /* Add the final element. We are sure there is room in the tokens array. */ tokens[elements] = sdsnewlen(s+start,len-start); if (tokens[elements] == NULL) goto cleanup; elements++; *count = elements; return tokens;cleanup: &#123; int i; for (i = 0; i &lt; elements; i++) sdsfree(tokens[i]); zfree(tokens); *count = 0; return NULL; &#125;&#125;/* * 释放 tokens 数组中 count 个 sds * * T = O(N^2) *//* Free the result returned by sdssplitlen(), or do nothing if 'tokens' is NULL. */void sdsfreesplitres(sds *tokens, int count) &#123; if (!tokens) return; while(count--) sdsfree(tokens[count]); zfree(tokens);&#125;/* * 将长度为 len 的字符串 p 以带引号（quoted）的格式 * 追加到给定 sds 的末尾 * * T = O(N) *//* Append to the sds string \"s\" an escaped string representation where * all the non-printable characters (tested with isprint()) are turned into * escapes in the form \"\\n\\r\\a....\" or \"\\x&lt;hex-number&gt;\". * * After the call, the modified sds string is no longer valid and all the * references must be substituted with the new pointer returned by the call. */sds sdscatrepr(sds s, const char *p, size_t len) &#123; s = sdscatlen(s,\"\\\"\",1); while(len--) &#123; switch(*p) &#123; case '\\\\': case '\"': s = sdscatprintf(s,\"\\\\%c\",*p); break; case '\\n': s = sdscatlen(s,\"\\\\n\",2); break; case '\\r': s = sdscatlen(s,\"\\\\r\",2); break; case '\\t': s = sdscatlen(s,\"\\\\t\",2); break; case '\\a': s = sdscatlen(s,\"\\\\a\",2); break; case '\\b': s = sdscatlen(s,\"\\\\b\",2); break; default: if (isprint(*p)) s = sdscatprintf(s,\"%c\",*p); else s = sdscatprintf(s,\"\\\\x%02x\",(unsigned char)*p); break; &#125; p++; &#125; return sdscatlen(s,\"\\\"\",1);&#125;/* Helper function for sdssplitargs() that returns non zero if 'c' * is a valid hex digit. *//* * 如果 c 为十六进制符号的其中一个，返回正数 * * T = O(1) */int is_hex_digit(char c) &#123; return (c &gt;= '0' &amp;&amp; c &lt;= '9') || (c &gt;= 'a' &amp;&amp; c &lt;= 'f') || (c &gt;= 'A' &amp;&amp; c &lt;= 'F');&#125;/* Helper function for sdssplitargs() that converts a hex digit into an * integer from 0 to 15 *//* * 将十六进制符号转换为 10 进制 * * T = O(1) */int hex_digit_to_int(char c) &#123; switch(c) &#123; case '0': return 0; case '1': return 1; case '2': return 2; case '3': return 3; case '4': return 4; case '5': return 5; case '6': return 6; case '7': return 7; case '8': return 8; case '9': return 9; case 'a': case 'A': return 10; case 'b': case 'B': return 11; case 'c': case 'C': return 12; case 'd': case 'D': return 13; case 'e': case 'E': return 14; case 'f': case 'F': return 15; default: return 0; &#125;&#125;/* Split a line into arguments, where every argument can be in the * following programming-language REPL-alike form: * * 将一行文本分割成多个参数，每个参数可以有以下的类编程语言 REPL 格式： * * foo bar \"newline are supported\\n\" and \"\\xff\\x00otherstuff\" * * The number of arguments is stored into *argc, and an array * of sds is returned. * * 参数的个数会保存在 *argc 中，函数返回一个 sds 数组。 * * The caller should free the resulting array of sds strings with * sdsfreesplitres(). * * 调用者应该使用 sdsfreesplitres() 来释放函数返回的 sds 数组。 * * Note that sdscatrepr() is able to convert back a string into * a quoted string in the same format sdssplitargs() is able to parse. * * sdscatrepr() 可以将一个字符串转换为一个带引号（quoted）的字符串， * 这个带引号的字符串可以被 sdssplitargs() 分析。 * * The function returns the allocated tokens on success, even when the * input string is empty, or NULL if the input contains unbalanced * quotes or closed quotes followed by non space characters * as in: \"foo\"bar or \"foo' * * 即使输入出现空字符串， NULL ，或者输入带有未对应的括号， * 函数都会将已成功处理的字符串先返回。 * * 这个函数主要用于 config.c 中对配置文件进行分析。 * 例子： * sds *arr = sdssplitargs(\"timeout 10086\\r\\nport 123321\\r\\n\"); * 会得出 * arr[0] = \"timeout\" * arr[1] = \"10086\" * arr[2] = \"port\" * arr[3] = \"123321\" * * T = O(N^2) */sds *sdssplitargs(const char *line, int *argc) &#123; const char *p = line; char *current = NULL; char **vector = NULL; *argc = 0; while(1) &#123; /* skip blanks */ // 跳过空白 // T = O(N) while(*p &amp;&amp; isspace(*p)) p++; if (*p) &#123; /* get a token */ int inq=0; /* set to 1 if we are in \"quotes\" */ int insq=0; /* set to 1 if we are in 'single quotes' */ int done=0; if (current == NULL) current = sdsempty(); // T = O(N) while(!done) &#123; if (inq) &#123; if (*p == '\\\\' &amp;&amp; *(p+1) == 'x' &amp;&amp; is_hex_digit(*(p+2)) &amp;&amp; is_hex_digit(*(p+3))) &#123; unsigned char byte; byte = (hex_digit_to_int(*(p+2))*16)+ hex_digit_to_int(*(p+3)); current = sdscatlen(current,(char*)&amp;byte,1); p += 3; &#125; else if (*p == '\\\\' &amp;&amp; *(p+1)) &#123; char c; p++; switch(*p) &#123; case 'n': c = '\\n'; break; case 'r': c = '\\r'; break; case 't': c = '\\t'; break; case 'b': c = '\\b'; break; case 'a': c = '\\a'; break; default: c = *p; break; &#125; current = sdscatlen(current,&amp;c,1); &#125; else if (*p == '\"') &#123; /* closing quote must be followed by a space or * nothing at all. */ if (*(p+1) &amp;&amp; !isspace(*(p+1))) goto err; done=1; &#125; else if (!*p) &#123; /* unterminated quotes */ goto err; &#125; else &#123; current = sdscatlen(current,p,1); &#125; &#125; else if (insq) &#123; if (*p == '\\\\' &amp;&amp; *(p+1) == '\\'') &#123; p++; current = sdscatlen(current,\"'\",1); &#125; else if (*p == '\\'') &#123; /* closing quote must be followed by a space or * nothing at all. */ if (*(p+1) &amp;&amp; !isspace(*(p+1))) goto err; done=1; &#125; else if (!*p) &#123; /* unterminated quotes */ goto err; &#125; else &#123; current = sdscatlen(current,p,1); &#125; &#125; else &#123; switch(*p) &#123; case ' ': case '\\n': case '\\r': case '\\t': case '\\0': done=1; break; case '\"': inq=1; break; case '\\'': insq=1; break; default: current = sdscatlen(current,p,1); break; &#125; &#125; if (*p) p++; &#125; /* add the token to the vector */ // T = O(N) vector = zrealloc(vector,((*argc)+1)*sizeof(char*)); vector[*argc] = current; (*argc)++; current = NULL; &#125; else &#123; /* Even on empty input string return something not NULL. */ if (vector == NULL) vector = zmalloc(sizeof(void*)); return vector; &#125; &#125;err: while((*argc)--) sdsfree(vector[*argc]); zfree(vector); if (current) sdsfree(current); *argc = 0; return NULL;&#125;/* Modify the string substituting all the occurrences of the set of * characters specified in the 'from' string to the corresponding character * in the 'to' array. * * 将字符串 s 中， * 所有在 from 中出现的字符，替换成 to 中的字符 * * For instance: sdsmapchars(mystring, \"ho\", \"01\", 2) * will have the effect of turning the string \"hello\" into \"0ell1\". * * 比如调用 sdsmapchars(mystring, \"ho\", \"01\", 2) * 就会将 \"hello\" 转换为 \"0ell1\" * * The function returns the sds string pointer, that is always the same * as the input pointer since no resize is needed. * 因为无须对 sds 进行大小调整， * 所以返回的 sds 输入的 sds 一样 * * T = O(N^2) */sds sdsmapchars(sds s, const char *from, const char *to, size_t setlen) &#123; size_t j, i, l = sdslen(s); // 遍历输入字符串 for (j = 0; j &lt; l; j++) &#123; // 遍历映射 for (i = 0; i &lt; setlen; i++) &#123; // 替换字符串 if (s[j] == from[i]) &#123; s[j] = to[i]; break; &#125; &#125; &#125; return s;&#125;/* Join an array of C strings using the specified separator (also a C string). * Returns the result as an sds string. */sds sdsjoin(char **argv, int argc, char *sep) &#123; sds join = sdsempty(); int j; for (j = 0; j &lt; argc; j++) &#123; join = sdscat(join, argv[j]); if (j != argc-1) join = sdscat(join,sep); &#125; return join;&#125;","path":"2019/04/15/redis源码-sds/","date":"04-15","excerpt":"SDS-动态字符串定义SDS定义于sds.h/sds.c文件12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/* * 这个版本中， 不同的字符串长度使用的都是同一个结构体， * 这样会造成一定的内存浪费 * version 3.0 */ struct sdshdr &#123; // 字符串的长度 unsigned int len; // 记录buf中未使用字节的数量 unsigned int free; // 字节数组，用于保存字符串 char buf[];&#125;;/* * 提供五种header定义，满足各种字符串大小 * len：字符串的长度 * alloc：字符串最大容量 * flags：标记header的类型 * buf： 字节数组，用于保存字符串 * version 5.0 */typedef char *sds;/* Note: sdshdr5 is never used, we just access the flags byte directly. * However is here to document the layout of type 5 SDS strings. */struct __attribute__ ((__packed__)) sdshdr5 &#123; unsigned char flags; /* 3 lsb of type, and 5 msb of string length */ char buf[];&#125;;struct __attribute__ ((__packed__)) sdshdr8 &#123; uint8_t len; /* used */ uint8_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[];&#125;;struct __attribute__ ((__packed__)) sdshdr16 &#123; uint16_t len; /* used */ uint16_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[];&#125;;struct __attribute__ ((__packed__)) sdshdr32 &#123; uint32_t len; /* used */ uint32_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[];&#125;;struct __attribute__ ((__packed__)) sdshdr64 &#123; uint64_t len; /* used */ uint64_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[];&#125;;","tags":[{"name":"源码","slug":"源码","permalink":"https://jijiking51.cn/tags/源码/"}],"preview":"http://img.jijiking51.cn/redis%E5%8E%9F%E7%A0%81_sds.jpg"},{"title":"deepin开机后假死","text":"思路参考：https://blog.csdn.net/fdqw_sph/article/details/78759529首先，我的电脑是显卡和Linux不兼容（多种版本Linux，例如：manjaro三个版本均无法使用，Ubuntu除17.10之外均无法使用——17.10还无法正常关机，需要手动关闭所有软件才可以关机，deepin开机登陆后假死，dock无反应，单cpu飙升100，kill不掉那个100%的进程） 今天折腾了一下黑苹果无果，然后回来试试deepin 看了很多官方论坛后肯定了我的显卡问题（其实主要是主板LZ，无法禁用独显） 知道原因了就问了Google 发现了上面这个大佬的帖子， 话不多说： 1.下载对应的显卡驱动https://www.geforce.cn/drivers 2.（最关键的地方） 1lsmod | grep nouveau 如果有输出则代表nouveau正在加载。则需要禁用nouveau，在/etc/modprobe.d中创建文件blacklist-nouveau.conf，再用getid打开 123cd /etc/modprobe.d/etc/modprobe.d$ sudo touch blacklist-nouveau.confsudo gedit blacklist-nouveau.conf 在文件中输入以下内容并保存： 12blacklist nouveau options nouveau modeset=0 然后更新 1sudo update-initramfs -u 这种方式也可能不能彻底禁用nouveau，在此基础上可以移除以下文件：nouveau.ko；nouveau.ko.org，此文件一般是隐藏的具体操作 123456789101112131415cd /lib/modules/4.14.0-deepin2-amd64/kernel/drivers/gpu/drm/nouveau sudo rm -rf nouveau.ko sudo rm -rf nouveau.ko.org/* * 我这里有两个选项在 &gt; /lib/modules$ ls &gt; 4.14.0-deepin2-amd64 4.9.0-deepin13-amd64 * 注意，我也不知道要删除哪个才管用，只好两个的都删除了 * /cd /lib/modules/4.9.0-deepin13-amd64/kernel/drivers/gpu/drm/nouveau sudo rm -rf nouveau.ko sudo rm -rf nouveau.ko.org 继续更新下 1sudo update-initramfs –u 重启，也许你现在运行reboot或者shutdown会死机， 不过没关系， 强制关机就好 开机运行 1lsmod | grep nouveau 如果没输出，那就是禁用成功 重启 不用输入密码，开机按Ctrl + Alt + F2输入用户名，密码，进入下载NVIDIA的目录下 1sudo sh XXXXXXXXXXXXXXXX.run 重启 然后就可以使用了。 本教程也许只对我一个人有用","path":"2019/04/11/deepin开机后假死/","date":"04-11","excerpt":"思路参考：https://blog.csdn.net/fdqw_sph/article/details/78759529首先，我的电脑是显卡和Linux不兼容（多种版本Linux，例如：manjaro三个版本均无法使用，Ubuntu除17.10之外均无法使用——17.10还无法正常关机，需要手动关闭所有软件才可以关机，deepin开机登陆后假死，dock无反应，单cpu飙升100，kill不掉那个100%的进程）","tags":[{"name":"踩坑","slug":"踩坑","permalink":"https://jijiking51.cn/tags/踩坑/"},{"name":"deepin","slug":"deepin","permalink":"https://jijiking51.cn/tags/deepin/"}],"preview":"http://img.jijiking51.cn/deepin开机后假死.jpg"},{"title":"Python深复制和浅复制","text":"python中赋值是引用传递——&gt;例子中的 c 复制要使用copy浅复制（浅拷贝）是复制对象本身，并不对对象内部的子对象进行复制。——&gt;例子中的b深复制（深拷贝）将对象的本身以及子对象全部拷贝——&gt;例子中的d 12345678910111213141516171819202122232425262728293031323334353637#初始对象a = [1,2,3,4,5,6,[0,0,0,0]]#b 进行浅赋值b = copy.copy(a)#c 直接引用ac = a#d进行深度复制d = copy.deepcopy(a)&quot;&quot;&quot; a 中添加新的元素 受影响的有c&quot;&quot;&quot;a.append(7)&quot;&quot;&quot; a的子对象中添加新的元素 受影响的有 b ，c&quot;&quot;&quot;a[6].append(1)print(a)print(b)print(c)print(d)&quot;&quot;&quot;[1, 2, 3, 4, 5, 6, [0, 0, 0, 0, 1], 7][1, 2, 3, 4, 5, 6, [0, 0, 0, 0, 1]][1, 2, 3, 4, 5, 6, [0, 0, 0, 0, 1], 7][1, 2, 3, 4, 5, 6, [0, 0, 0, 0]]&quot;&quot;&quot;","path":"2019/04/11/Python深复制和浅复制/","date":"04-11","excerpt":"","tags":[{"name":"基础","slug":"基础","permalink":"https://jijiking51.cn/tags/基础/"}],"preview":"http://img.jijiking51.cn/Python 深复制和浅复制.jpg"},{"title":"python连接mysql","text":"首先安装mysql驱动1pip3 install mysql-connector-python --allow-external mysql-connector-pythonmysql连接实例：123456789101112131415161718192021#加载驱动import mysql.connector#建立连接conn = mysql.connector.connect(user=&apos;root&apos;,password=&apos;123456&apos;,database=&apos;school&apos;)#获取连接的游标cursor = conn.cursor()#执行Sqlcursor.execute(&quot;show tables&quot;)#获取返回列表（list）a = cursor.fetchall()#遍历for i in a: print(re.match(tables_name,str(i)).group(1))#关闭游标cursor.close()#提交未提交事物conn.commit()#关闭连接conn.close() 使用sqlalchemy对数据库生成映射对象安装驱动 1pip3 install sqlalchemy sqlalchemy使用实例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748from sqlalchemy import Column , String , create_enginefrom sqlalchemy.orm import sessionmakerfrom sqlalchemy.ext.declarative import declarative_base#创建一个对象的基类Base = declarative_base()#创建对象class User(Base): &quot;&quot;&quot;Test for sqlalachemy&quot;&quot;&quot; #数据库表名 __tablename__ = &apos;students&apos; #表的结构 &apos;&apos;&apos; +----------+----------------------------------------------------------------------------------------------------------------------------------------------------------+ | Table | Create Table | +----------+----------------------------------------------------------------------------------------------------------------------------------------------------------+ | students | CREATE TABLE `students` ( `sid` varchar(10) NOT NULL, `sname` varchar(10) DEFAULT NULL, PRIMARY KEY (`sid`) ) ENGINE=InnoDB DEFAULT CHARSET=latin1 | +----------+----------------------------------------------------------------------------------------------------------------------------------------------------------+ &apos;&apos;&apos; sid = Column(String(10),primary_key=True) sname = Column(String(10))#创建连接 格式： 数据库类型+数据库驱动名称://用户名：密码@及其地址:端口/数据库名字engine = create_engine(&apos;mysql+mysqlconnector://root:123456@localhost:3306/school&apos;)#创建DBSession类型DBSession = sessionmaker(bind=engine)#建立连接session = DBSession()# 创建新的对象new_user = User(sid = &apos;5&apos;,sname = &apos;Bob&apos;)# 添加到sessionsession.add(new_user)# 提交事物session.commit()# 关闭连接session.close() 利用sqlalchemy将数据内容映射到User对象 12345678910111213141516171819202122232425from sqlalchemy import Column ,String,create_enginefrom sqlalchemy.orm import sessionmakerfrom sqlalchemy.ext.declarative import declarative_baseBase = declarative_base()class User(Base): __tablename__ = &apos;students&apos; sid = Column(String(10),primary_key = True) sname = Column(String(10))engine = create_engine(&apos;mysql+mysqlconnector://root:123456@localhost:3306/school&apos;)DBSession = sessionmaker(bind = engine)session = DBSession()#创建Query查询，filter是where条件，最后是返回一行， 如果是all()则返回所有行#此处 session.query(User).filter(User.sid == &apos;5&apos;).one()#如果是多表查询可以是#session.query(User,address).filter(User.sid == address.sid).one()user = session.query(User).filter(User.sid==&apos;5&apos;).one()print(&apos;type:&apos;,type(user))print(&apos;name:&apos;,user.sname)session.close()","path":"2019/04/11/python连接mysql/","date":"04-11","excerpt":"首先安装mysql驱动1pip3 install mysql-connector-python --allow-external mysql-connector-pythonmysql连接实例：123456789101112131415161718192021#加载驱动import mysql.connector#建立连接conn = mysql.connector.connect(user=&apos;root&apos;,password=&apos;123456&apos;,database=&apos;school&apos;)#获取连接的游标cursor = conn.cursor()#执行Sqlcursor.execute(&quot;show tables&quot;)#获取返回列表（list）a = cursor.fetchall()#遍历for i in a: print(re.match(tables_name,str(i)).group(1))#关闭游标cursor.close()#提交未提交事物conn.commit()#关闭连接conn.close()","tags":[{"name":"基础","slug":"基础","permalink":"https://jijiking51.cn/tags/基础/"}],"preview":"http://img.jijiking51.cn/python连接mysql.jpg"},{"title":"Django2.0使用","text":"准备 首先下载安装django1pip3 install djangopycharm可以直接建立django的项目，也可以执行命令1django-admin startproject mysite这样就建立了一个mysite的django项目。下面是新建项目的目录文件列表1234567mysite/ manage.py mysite/ __init__.py settings.py urls.py wsgi.py 其中，settings.py是项目各种配置的文件urls.py是url目录文件manage.py是管理工具 尝试运行（pycharm可以直接点击Django项目运行）也可以shell运行命令 1234567891011121314python manage.py runserver运行成功后的输出Performing system checks...System check identified no issues (0 silenced).You have unapplied migrations; your app may not work properly until they are applied.Run &apos;python manage.py migrate&apos; to apply them.六月 01, 2018 - 15:50:53Django version 2.0, using settings &apos;mysite.settings&apos;Starting development server at http://127.0.0.1:8000/Quit the server with CONTROL-C. 2.创建一个应用1python manage.py startapp polls 创建完成后会在mysite目录下看到一个polls文件目录 123456789polls/ __init__.py admin.py apps.py migrations/ __init__.py models.py tests.py views.py 应用创建完成了不过，等下模型的学习中还要使用 3.视图现在创建我们的第一个视图应用 12345from django.http import HttpResponse,request# Create your views here.def hello(request): html = &apos;&lt;html&gt;&lt;body&gt;hello world&lt;/body&gt;&lt;/heml&gt;&apos; return HttpResponse(html) 同时配置我们的polls/urls.py 12345678910111213添加：path(&quot;&quot;,views.hello,name=&apos;index&apos;)完成后是这个样子：from django.urls import path,includefrom . import viewsurlpatterns =[ #首页设置 path(&quot;&quot;,views.hello,name=&apos;index&apos;),] 这仅仅是polls下的配置，mysite还无法知道这是什么意思，所以我们还要配置mysite/urls.py打开mysite/urls.py后里面已经有内容了，在其中添加 123456789101112path(&apos;polls/&apos;,include(&apos;polls.urls&apos;)),配置好以后的样子from django.contrib import adminfrom django.urls import path,includeurlpatterns = [ path(&apos;admin/&apos;, admin.site.urls), path(&apos;polls/&apos;,include(&apos;polls.urls&apos;)),] 然后就可以打开浏览器输入链接：http://127.0.0.1:8000/polls/ 这里面用到了include在官方文档中是这样写的： 函数 include() 允许引用其它 URLconfs。每当 Django 遇到 :func：~django.urls.include时，它会截断与此项匹配的 URL 的部分，并将剩余的字符串发送到 URLconf 以供进一步处理。 我们设计 include()的理念是使其可以即插即用。因为投票应用有它自己的 URLconf( polls/urls.py )，他们能够被放在 “/polls/“ ，“/fun_polls/“ ，”/content/polls/“，或者其他任何路径下，这个应用都能够正常工作。 接下来理解一下path： 1234567891011121314151617def _path(route, view, kwargs=None, name=None, Pattern=None): if isinstance(view, (list, tuple)): # For include(...) processing. pattern = Pattern(route, is_endpoint=False) urlconf_module, app_name, namespace = view return URLResolver( pattern, urlconf_module, kwargs, app_name=app_name, namespace=namespace, ) elif callable(view): pattern = Pattern(route, name=name, is_endpoint=True) return URLPattern(pattern, view, kwargs, name) else: raise TypeError(&apos;view must be a callable or a list/tuple in the case of include().&apos;) 这是path的函数，我们可以看到传递进去的参数： route：route 是一个匹配 URL 的准则（类似正则表达式）。当 Django 响应一个请求时，它会从 urlpatterns 的第一项开始，按顺序依次匹配列表中的项，直到找到匹配的项。这些准则不会匹配 GET 和 POST 参数或域名。例如，URLconf 在处理请求 https://www.example.com/myapp/ 时，它会尝试匹配 myapp/ 。处理请求 https://www.example.com/myapp/?page=3 时，也只会尝试匹配 myapp/。view：当 Django 找到了一个匹配的准则，就会调用这个特定的视图函数，并传入一个 HttpRequest 对象作为第一个参数，被“捕获”的参数以关键字参数的形式传入。kwargs=None：任意个关键字参数可以作为一个字典传递给目标视图函数 name=None：为你的 URL 取名能使你在 Django 的任意地方唯一地引用它，尤其是在模板中。这个有用的特性允许你只改一个文件就能全局地修改某个 URL 模式。 Pattern=None：官方文档并没有给解释 其中，博主也只知道使用route和view，设置name之后怎么使用name博主也不知道，如果哪位大大翻了博主的牌，望告知 4.数据库配置python默认使用的是SQLite，但是博主使用的是mysql，所以接下来都是mysql的配置，如果是其他数据库请看官方文档在此之前，请确认：1.安装好mysql数据库2.已经下载好了mysqlclient（pip/pip3 install mysqlclient）3.设置好时间在mysite/settings.pyTIME_ZONE = ‘Asia/Shanghai’ 看到下面的内容， 我们打开mysite/settings.py sqlite：’django.db.backends.sqlite3’postgresql：’django.db.backends.postgresql’mysql：’django.db.backends.mysql‘oracle：’django.db.backends.oracle’ 找到DATABASES这个设置，填写以下内容 12345678910DATABASES = &#123; &apos;default&apos;: &#123; &apos;ENGINE&apos;: &apos;django.db.backends.mysql&apos;, &apos;NAME&apos;: &apos;polls&apos;, &apos;USER&apos;: &apos;root&apos;, &apos;PASSWORD&apos;: &apos;123456&apos;, &apos;HOST&apos;: &apos;127.0.0.1&apos;, &apos;PORT&apos;: &apos;3306&apos;, &#125;&#125; NAME： 数据库名字USER：用户名PASSWORD：用户密码HOST：ipPORT：端口 在创建自己的模型之前，我们先运行 1python manage.py migrate 这是为为我们的admin应用创建数据库表格 接下来编写我们的模型： 打开polls/models.py，填写以下代码： 12345678910from django.db import models# Create your models here.class Question(models.Model): question_text = models.CharField(max_length=200) pub_data = models.DateTimeField(&apos;date published&apos;)class Choice(models.Model): question = models.ForeignKey(Question,on_delete=models.CASCADE) choice_text = models.CharField(max_length=200) votes = models.IntegerField(default=0) 这里，将每一个类表示未django.db.modles.Model的子类，每个模型都有一些变量， 这是表示模型里面的数据库的字段每个字段我们都设置了一个类型， 比如CharField,DateTImeFIeld,用来告诉django处理数据的类型。其中我们定义了一个Field名字，在官方文档中， 他是这样解释的： 你可以使用可选的选项来为 Field 定义一个人类可读的名字。这个功能在很多 Django内部组成部分中都被使用了，而且作为文档的一部分。如果某个字段没有提供此名称，Django将会使用对机器友好的名称，也就是变量名。在上面的例子中，我们只为 Question.pub_date定义了对人类友好的名字。对于模型内的其它字段，它们的机器友好名也会被作为人类友好名使用。 Field中有些参数，例如 max_length 这个浅显易懂，就是长度设置，当然也可以设置默认值，例如 :default = 0最后我们定义了ForeignKey，这是一对一关系， 告诉我们每个choice都对应了一个question，后面的参数是：models.CASCADE：对就对象删除后，包含ForeignKey的字段也会被删除models.PROTECT：删除时会引起ProtectedErrormodels.SET_NULL：注意只有当当前字段设置null设置为True才有效，此情况会将ForeignKey字段设置为nullmodels.SET_DEFAULT ：同样，当前字段设置了default才有效，此情况会将ForeignKey 字段设置为default 值moels.SET：此时需要指定set的值models.DO_NOTHING ：什么也不做 写好模型之后我们要去激活我们的模型，在mysite/settings.py中找到这个INSTALLED_APPS在里面添加 12#因为PollsConfig类写在了polls/apps中’polls.apps.PollsConfig‘ 接着，我们运行以下命令： 1234567891011121314151617181920212223242526272829#通过运行 makemigrations 命令，Django 会检测你对模型文件的修改（在这种情况下，你已经取得了新的），并且把修改的部分储存为一次 迁移。python manage.py makemigrations polls#输出Migrations for &apos;polls&apos;: polls/migrations/0001_initial.py: - Create model Choice - Create model Question - Add field question to choice#查看迁移执行的命令python manage.py sqlmigrate polls 0001#输出BEGIN;---- Create model Choice--CREATE TABLE `polls_choice` (`id` integer AUTO_INCREMENT NOT NULL PRIMARY KEY, `choice_text` varchar(200) NOT NULL, `votes` integer NOT NULL);---- Create model Question--CREATE TABLE `polls_question` (`id` integer AUTO_INCREMENT NOT NULL PRIMARY KEY, `question_text` varchar(200) NOT NULL, `pub_data` datetime(6) NOT NULL);---- Add field question to choice--ALTER TABLE `polls_choice` ADD COLUMN `question_id` integer NOT NULL;ALTER TABLE `polls_choice` ADD CONSTRAINT `polls_choice_question_id_c5b4b260_fk_polls_question_id` FOREIGN KEY (`question_id`) REFERENCES `polls_question` (`id`);COMMIT; 关于迁移和官方文档的提醒要点： 1、迁移是 Django 对于模型定义（也就是你的数据库结构）的变化的储存形式 - 没那么玄乎，它们其实也只是一些你磁盘上的文件。如果你想的话，你可以阅读一下你模型的迁移数据，它被储存在 polls/migrations/0001_initial.py 里。别担心，你不需要每次都阅读迁移文件，但是它们被设计成人类可读的形式，这是为了便于你手动修改它们。 2、注意要点： 输出的内容和你使用的数据库有关，上面的输出示例使用的是 PostgreSQL。 数据库的表名是由应用名(polls)和模型名的小写形式( question 和 choice)连接而来。（如果需要，你可以自定义此行为。） 主键(IDs)会被自动创建。(当然，你也可以自定义。) 默认的，Django 会在外键字段名后追加字符串 “_id” 。（同样，这也可以自定义。） 外键关系由 FOREIGN KEY 生成。你不用关心 DEFERRABLE 部分，它只是告诉 PostgreSQL，请在事务全都执行完之后再创建外键关系。 生成的 SQL 语句是为你所用的数据库定制的，所以那些和数据库有关的字段类型，比如 auto_increment (MySQL)、 serial (PostgreSQL)和 integer primary key autoincrement (SQLite)，Django 会帮你自动处理。那些和引号相关的事情 - 例如，是使用单引号还是双引号 - 也一样会被自动处理。 这个 sqlmigrate 命令并没有真正在你的数据库中的执行迁移 - 它只是把命令输出到屏幕上，让你看看 Django 认为需要执行哪些 SQL 语句。这在你想看看 Django 到底准备做什么，或者当你是数据库管理员，需要写脚本来批量处理数据库时会很有用。 再次执行命令： 12345678python manage.py migrate#输出Operations to perform: Apply all migrations: admin, auth, contenttypes, polls, sessionsRunning migrations: Rendering model states... DONE Applying polls.0001_initial... OK 这样，数据库中就自动创建了表格 总结： 编辑 models.py 文件，改变模型。 运行 python manage.py makemigrations 为模型的改变生成迁移文件。 运行 python manage.py migrate 来应用数据库迁移。 5.API使用*此段直接引用于官方文档 12345678910111213141516171819202122232425262728293031323334$ python manage.py shell&gt;&gt;&gt; from polls.models import Choice, Question # Import the model classes we just wrote.# No questions are in the system yet.&gt;&gt;&gt; Question.objects.all()&lt;QuerySet []&gt;# Create a new Question.# Support for time zones is enabled in the default settings file, so# Django expects a datetime with tzinfo for pub_date. Use timezone.now()# instead of datetime.datetime.now() and it will do the right thing.&gt;&gt;&gt; from django.utils import timezone&gt;&gt;&gt; q = Question(question_text=&quot;What&apos;s new?&quot;, pub_date=timezone.now())# Save the object into the database. You have to call save() explicitly.&gt;&gt;&gt; q.save()# Now it has an ID.&gt;&gt;&gt; q.id1# Access model field values via Python attributes.&gt;&gt;&gt; q.question_text&quot;What&apos;s new?&quot;&gt;&gt;&gt; q.pub_datedatetime.datetime(2012, 2, 26, 13, 0, 0, 775217, tzinfo=&lt;UTC&gt;)# Change values by changing the attributes, then calling save().&gt;&gt;&gt; q.question_text = &quot;What&apos;s up?&quot;&gt;&gt;&gt; q.save()# objects.all() displays all the questions in the database.&gt;&gt;&gt; Question.objects.all()&lt;QuerySet [&lt;Question: Question object (1)&gt;]&gt; Question object(1)对于我们了解这个对象的细节没什么帮助。让我们通过编辑 Question 模型的代码（位于 polls/models.py 中）来修复这个问题。给 Question 和 Choice 增加 str() 方法。polls/models.py 1234567891011from django.db import modelsclass Question(models.Model): # ... def __str__(self): return self.question_textclass Choice(models.Model): # ... def __str__(self): return self.choice_text 给模型增加 str() 方法是很重要的，这不仅仅能给你在命令行里使用带来方便，Django 自动生成的 admin 里也使用这个方法来表示对象。 注意：这些都是常规的 Python方法。让我们添加一个自定义的方法，这只是为了演示：polls/models.py 12345678910import datetimefrom django.db import modelsfrom django.utils import timezoneclass Question(models.Model): # ... def was_published_recently(self): return self.pub_date &gt;= timezone.now() - datetime.timedelta(days=1) 新加入的 import datetime 和 from django.utils import timezone 分别导入了 Python 的标准 datetime 模块和 Django 中和时区相关的 django.utils.timezone 工具模块。如果你不太熟悉 Python 中的时区处理，看看 时区支持文档 吧。 保存文件然后通过 python manage.py shell 命令再次打开 Python 交互式命令行： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576&gt;&gt;&gt; from polls.models import Choice, Question# Make sure our __str__() addition worked.&gt;&gt;&gt; Question.objects.all()&lt;QuerySet [&lt;Question: What&apos;s up?&gt;]&gt;# Django provides a rich database lookup API that&apos;s entirely driven by# keyword arguments.&gt;&gt;&gt; Question.objects.filter(id=1)&lt;QuerySet [&lt;Question: What&apos;s up?&gt;]&gt;&gt;&gt;&gt; Question.objects.filter(question_text__startswith=&apos;What&apos;)&lt;QuerySet [&lt;Question: What&apos;s up?&gt;]&gt;# Get the question that was published this year.&gt;&gt;&gt; from django.utils import timezone&gt;&gt;&gt; current_year = timezone.now().year&gt;&gt;&gt; Question.objects.get(pub_date__year=current_year)&lt;Question: What&apos;s up?&gt;# Request an ID that doesn&apos;t exist, this will raise an exception.&gt;&gt;&gt; Question.objects.get(id=2)Traceback (most recent call last): ...DoesNotExist: Question matching query does not exist.# Lookup by a primary key is the most common case, so Django provides a# shortcut for primary-key exact lookups.# The following is identical to Question.objects.get(id=1).&gt;&gt;&gt; Question.objects.get(pk=1)&lt;Question: What&apos;s up?&gt;# Make sure our custom method worked.&gt;&gt;&gt; q = Question.objects.get(pk=1)&gt;&gt;&gt; q.was_published_recently()True# Give the Question a couple of Choices. The create call constructs a new# Choice object, does the INSERT statement, adds the choice to the set# of available choices and returns the new Choice object. Django creates# a set to hold the &quot;other side&quot; of a ForeignKey relation# (e.g. a question&apos;s choice) which can be accessed via the API.&gt;&gt;&gt; q = Question.objects.get(pk=1)# Display any choices from the related object set -- none so far.&gt;&gt;&gt; q.choice_set.all()&lt;QuerySet []&gt;# Create three choices.&gt;&gt;&gt; q.choice_set.create(choice_text=&apos;Not much&apos;, votes=0)&lt;Choice: Not much&gt;&gt;&gt;&gt; q.choice_set.create(choice_text=&apos;The sky&apos;, votes=0)&lt;Choice: The sky&gt;&gt;&gt;&gt; c = q.choice_set.create(choice_text=&apos;Just hacking again&apos;, votes=0)# Choice objects have API access to their related Question objects.&gt;&gt;&gt; c.question&lt;Question: What&apos;s up?&gt;# And vice versa: Question objects get access to Choice objects.&gt;&gt;&gt; q.choice_set.all()&lt;QuerySet [&lt;Choice: Not much&gt;, &lt;Choice: The sky&gt;, &lt;Choice: Just hacking again&gt;]&gt;&gt;&gt;&gt; q.choice_set.count()3# The API automatically follows relationships as far as you need.# Use double underscores to separate relationships.# This works as many levels deep as you want; there&apos;s no limit.# Find all Choices for any question whose pub_date is in this year# (reusing the &apos;current_year&apos; variable we created above).&gt;&gt;&gt; Choice.objects.filter(question__pub_date__year=current_year)&lt;QuerySet [&lt;Choice: Not much&gt;, &lt;Choice: The sky&gt;, &lt;Choice: Just hacking again&gt;]&gt;# Let&apos;s delete one of the choices. Use delete() for that.&gt;&gt;&gt; c = q.choice_set.filter(choice_text__startswith=&apos;Just hacking&apos;)&gt;&gt;&gt; c.delete() 6.Django管理页面首先创建一个管理员python manage.py createsuperuser 接下来会让你输入用户名、邮箱、密码、验证密码 完成后启动项目进入http://127.0.0.1:8000/admin/ ，输入你刚刚设置的账户密码进去后，我们可以通过这个页面进行管理。如果需要管理，我们要告诉他管理什么东西：进入polls/admin 12345from django.contrib import adminfrom .models import Questionadmin.site.register(Question) 现在可以通过admin管理question的内容","path":"2019/04/11/Django2-0使用/","date":"04-11","excerpt":"准备 首先下载安装django1pip3 install djangopycharm可以直接建立django的项目，也可以执行命令1django-admin startproject mysite这样就建立了一个mysite的django项目。下面是新建项目的目录文件列表1234567mysite/ manage.py mysite/ __init__.py settings.py urls.py wsgi.py","tags":[{"name":"Django","slug":"Django","permalink":"https://jijiking51.cn/tags/Django/"}],"preview":"http://img.jijiking51.cn/Django 2.0使用.jpg"},{"title":"Django2.0整合markdown编辑器","text":"测试成功环境：python：3.5.4os：Deepin 15.5Django：2.0IDE：pycharm 1.Django整合Ueditor（百度制作的编辑器）学习于博主： Code人生请按照博主的教程一步一步走，其中下载的DjangoUeditor/DjangoUeditor中的代码导入模块有问题，请完善路径 2.Django整合django-mdeditor1.安装django-mdeditorshell中运行1pip3 install django-mdeditor ##2.新建一个项目 ## 在项目的settings.py的INSTALLED_APPS中添加’mdeditor’, 添加媒体路径到你的设置中： 12MEDIA_ROOT = os.path.join(BASE_DIR, &apos;uploads&apos;)MEDIA_URL = &apos;/media/&apos; 在你的根目录下分别创建对应的文件夹 uploads/editor 将该设置添加到你的urls.py中： 1234567891011121314from django.conf.urls import url, includefrom django.conf.urls.static import staticfrom django.conf import settingsfrom django.contrib import adminfrom django.urls import pathurlpatterns = [ path(&apos;admin/&apos;,admin.site.urls), url(r&apos;mdeditor/&apos;, include(&apos;mdeditor.urls&apos;)),]if settings.DEBUG: # static files (images, css, javascript, etc.) urlpatterns += static(settings.MEDIA_URL, document_root=settings.MEDIA_ROOT) 如果是按照教程的步骤新建的项目，请直接覆盖源代码即可 ##3.添加一个app ##shell在根目录中运行： 1python manage.py startapp Example 打开Example，在models.py中添加 123456from django.db import modelsfrom mdeditor.fields import MDTextFieldclass ExampleModel(models.Model): name = models.CharField(max_length=10) content = MDTextField() 在Example/admin.py中粘贴 123456from django.contrib import admin# Register your models here.from Example.models import ExampleModeladmin.site.register(ExampleModel) 再次回到项目中，在settings.py的INSTALLED_APPS中添加‘Example’, 然后我们运行引用model 12python manage.py makemigrationspython manage.py migrate 最后设置admin用户 1python manage.py createsuperuser 按照提示， 设置用户名，邮箱，密码之后就完成了 4.查看效果运行项目打开http://127.0.0.1:8000/admin/ 输入刚刚设置的账户和密码 点击Add添加你的第一篇文章","path":"2019/04/11/Django2-0整合markdown编辑器/","date":"04-11","excerpt":"测试成功环境：python：3.5.4os：Deepin 15.5Django：2.0IDE：pycharm 1.Django整合Ueditor（百度制作的编辑器）学习于博主： Code人生请按照博主的教程一步一步走，其中下载的DjangoUeditor/DjangoUeditor中的代码导入模块有问题，请完善路径","tags":[{"name":"Django","slug":"Django","permalink":"https://jijiking51.cn/tags/Django/"},{"name":"Markdown","slug":"Markdown","permalink":"https://jijiking51.cn/tags/Markdown/"}],"preview":"http://img.jijiking51.cn/Django2.0整合markdown编辑器.jpg"},{"title":"JAVA_返回引用可变对象的访问器方法避免破坏封装性","text":"如果需要返回一个可变对象的引用， 应该首先对他进克隆（clone）。对象克隆是指存放在另一个位置上的对象副本。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152import java.util.Date;class b&#123; private Date day; public b()&#123; this.day = new Date(); &#125; public Date getDay()&#123; return this.day; &#125;&#125;class a&#123; private Date day ; public a()&#123; this.day = new Date(); &#125; public Date getDay()&#123; //使用clone方法 返回的是一个存放在另一个位置上的对象副本 return (Date)this.day.clone(); &#125;&#125;public class demo&#123; public static void main(String[] args) &#123; a obj = new a(); Date d = obj.getDay(); System.out.println(\"使用了clone避免封装被破坏的a类\"+obj.getDay().getYear()); d.setYear(2000); System.out.println(\"使用了clone避免封装被破坏的a类\"+obj.getDay().getYear()); b obj_B = new b(); Date d_bDate = obj_B.getDay(); System.out.println(\"没有使用了clone避免封装被破坏的b类\"+obj_B.getDay().getYear()); d_bDate.setYear(2000); System.out.println(\"没有使用了clone避免封装被破坏的b类\"+obj_B.getDay().getYear()); &#125;&#125;","path":"2019/04/11/JAVA-返回引用可变对象的访问器方法避免破坏封装性/","date":"04-11","excerpt":"","tags":[{"name":"基础","slug":"基础","permalink":"https://jijiking51.cn/tags/基础/"}],"preview":"http://img.jijiking51.cn/JAVA_返回引用可变对象的访问器方法避免破坏封装性.jpg"},{"title":"Java_如何交换两个对象","text":"java语言中，方法参数有一下几个注意点: 一个方法不能修改一个基本数据类型的参数（即数值型和布尔型） 一个方法可以改变一个对象参数的状态 一个方法不能让对象参数引用一个新的对象 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103class A&#123; String name ; public A(String name)&#123; this.name = name; &#125; public A clone()&#123; return this; &#125;&#125;class WrapperA&#123; A a ; public WrapperA(A a)&#123; this.a = a; &#125;&#125;public class demo&#123; public static void main(String[] args) &#123; //1.验证第一条定义 int number1 = 100; int number2 = 200; swapNumber(number1, number2); //结果是 100 200 并没有改变基本类型 System.out.println(number1+\" \"+number2); //2.验证第二条定义 A testA = new A(\"testA1\"); change(testA); //结果是testA2 改变了引用类型 System.out.println(testA.name); //验证第三条定义 A a1 = new A(\"1\"); A a2 = new A(\"2\"); swapA(a1, a2); /*结果还是 1 2 并没有交换 一个方法并不能让对象参数引用一个新的对象。 原理： 当a1传入swapA时，复制了一个引用对象x，也就是swapA中的a1 swapA中将x指向了a2 但是a1 并没有改变 所以改变的仅仅是复制的引用，原来的引用并没有改变 */ System.out.println(a1.name+\" \"+a2.name); //如果想交换可以使用以下方法 WrapperA wa1 = new WrapperA(a1); WrapperA wa2 = new WrapperA(a2); swapWrapperA(wa1, wa2); a1 = wa1.a; a2 = wa2.a; //a1 和 a2 被改变 System.out.println(a1.name+\" \"+a2.name); &#125; //用于测试第一条定义 static void swapNumber(int a , int b)&#123; a += b; b = a - b; a = a - b; &#125; //用于测试第二条定义 static void change(A a)&#123; a.name = \"testA2\"; &#125; //用于测试第三条定义 static void swapA(A a1 , A a2)&#123; A a3 = a1.clone() ; a1 = a2.clone(); a2 = a3; System.out.println(a1.name); &#125; //交换方法 static void swapWrapperA(WrapperA a1,WrapperA a2)&#123; A a3 = a1.a; a1.a = a2.a; a2.a = a3; &#125;&#125;","path":"2019/04/11/Java-如何交换两个对象/","date":"04-11","excerpt":"","tags":[{"name":"基础","slug":"基础","permalink":"https://jijiking51.cn/tags/基础/"}],"preview":"http://img.jijiking51.cn/Java_如何交换两个对象.jpg"},{"title":"Nginx安装配置并使用keepalived实现高可用双机热备","text":"所用安装包也可以从此处下载 下载nginx 官网：https://nginx.org/（我的是1.8.1） 上传并解压nginx tar -zxvf nginx-1.8.1.tar.gz -C /usr/local/src 编译nginx #进入到nginx源码目录 cd /usr/local/src/nginx-1.8.1 #检查安装环境,并指定将来要安装的路径 ./configure –prefix=/usr/local/nginx #缺包报错 ./configure: error: C compiler cc is not found #使用YUM安装缺少的包 yum -y install gcc pcre-devel openssl openssl-devel（centos命令，如果是其他系统请自行更改） 编译安装 make &amp;&amp; make install 安装完后测试是否正常：/usr/loca/nginx/sbin/nginx查看端口是否有ngnix进程监听netstat -ntlp | grep 80如果启动nginx报错：nginx: [emerg] open() “/etc/nginx.conf” failed (2: no such file or directory) find / -name nginx.conf cp 查找到的nginx.conf位置 启动缺少nginx.conf位置 配置nginx 打开nginx.conf 修改nginx配置文件server { listen 80; server_name xxx.com; #nginx所在服务器的主机名#反向代理的配置location / { #拦截所有请求 root html;proxy_pass http://192.168.0.21:8080; #这里是代理走向的目标服务器：tomcat }} 12#重启nginxkill -HUP `cat /usr/local/nginx/logs/nginx.pid ` 动静分离 删除上面的server配置 按照上面的方法配置一下内容#动态资源 index.jsplocation ~ .*.(jsp|do|action)$ { proxy_pass http://192.168.0.2:8080;} #静态资源location ~ .*.(html|js|css|gif|jpg|jpeg|png)$ { expires 3d;} 负载均衡在http这个节下面配置一个叫upstream的，后面的名字可以随意取，但是要和location下的proxy_pass http://后的保持一致。 123456789101112http &#123; 是在http里面的, 已有http, 不是在server里,在server外面 upstream tomcats &#123; server shizhan02:8080 weight=1;#weight表示多少个 server shizhan03:8080 weight=1; server shizhan04:8080 weight=1; &#125;#卸载server里location ~ .*\\.(jsp|do|action) &#123; proxy_pass http://tomcats; #tomcats是后面的tomcat服务器组的逻辑组号 &#125;&#125; 利用keepalived实现高可靠（HA）HA(High Available), 高可用性集群，是保证业务连续性的有效解决方案，一般有两个或两个以上的节点，且分为活动节点及备用节点。 keepalive是一款可以实现高可靠的软件，通常部署在2台服务器上，分为一主一备。Keepalived可以对本机上的进程进行检测，一旦Master检测出某个进程出现问题，将自己切换成Backup状态，然后通知另外一个节点切换成Master状态。 与上面安装过程一样 12345678910111213下载keepalived官网:https://keepalived.org将keepalived解压到/usr/local/src目录下tar -zxvf keepalived-1.2.19.tar.gz -C /usr/local/src进入到/usr/local/src/keepalived-1.2.19目录cd /usr/local/src/keepalived-1.2.19开始configure./configure --prefix=/usr/local/keepalived#编译并安装make &amp;&amp; make install 修改/etc/keepalived/keepalived.conf 配置虚拟ip 两个节点必须是在同一内网,配置心跳检测 原理： Keepalived并不跟nginx耦合，它俩完全不是一家人 但是keepalived提供一个机制：让用户自定义一个shell脚本去检测用户自己的程序，返回状态给keepalived就可以了 #MASTER节点 12345678910111213141516171819202122232425 vrrp_script chk_health &#123; script \"/usr/local/keepalived/sbin/notify.sh\" interval 1 weight -2 &#125; vrrp_instance VI_1 &#123; state MASTER #指定A节点为主节点 备用节点上设置为BACKUP即可 interface eth0 #绑定虚拟IP的网络接口 virtual_router_id 51 #VRRP组名，两个节点的设置必须一样，以指明各个节点属于同一VRRP组 priority 100 #主节点的优先级（1-254之间），备用节点必须比主节点优先级低 advert_int 1 #组播信息发送间隔，两个节点设置必须一样 mcast_src_ip 192.168.88.200 #本地主机ip authentication &#123; #设置验证信息，两个节点必须一致 auth_type PASS auth_pass 1111 &#125; track_script &#123; chk_health &#125; virtual_ipaddress &#123; #指定虚拟IP, 两个节点设置必须一样 192.168.88.199 #如果两个nginx的ip分别是192.168.88.200,,...201，则此处的虚拟ip跟它俩同一个网段即可 &#125;&#125; #BACKUP节点 12345678910111213141516171819202122232425262728 vrrp_script chk_health &#123; script \"/usr/local/keepalived/sbin/notify.sh\" interval 1 weight -2&#125; vrrp_instance VI_1 &#123; state BACKUP interface eth0 virtual_router_id 51 mcast_src_ip 192.168.88.201 priority 99 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; track_script &#123; chk_health &#125; virtual_ipaddress &#123; 192.168.88.199/24 &#125; &#125; #使用的脚本 123456789#!/bin/shA=`ps -C nginx --no-header |wc -l` #检查是否有nginx运行if [ $A -eq 0 ];then /usr/local/nginx/sbin/nginx #启动nginx sleep 2 #休眠两秒 if [ `ps -C nginx --no-header |wc -l` -eq 0 ];then #如果两秒后nginx没有运行 killall keepalived #关闭keepalived ，将虚拟ip让给BACKUP节点（必须关闭MASTER上的keepalived，BACKUP才能的到VIP） fifi 启动两台机器上的nginx和keepalived /usr/local/nginx/sbin/ngin service keepalived start 测试 将MASTER节点上的notify.sh脚本写错nginx启动路径（例如：/usr/local/nginx/sbin/nginxxxxxxx）， 让keepalived稍后无法启动nginx而自己关闭，这样可以测试是否两个节点可以相互替换。 关闭MASTER节点上的nginx 1/usr/local/nginx/sbin/nginx -s stop 查看虚拟ip占用情况，正确情况应该是MASTER上的虚拟ip消失，而BACKUP上出现你所配置的虚拟ip 1ip -a | grep eth0 在浏览器中打开你配置的虚拟ip ，进行多个测试， 无论是MASTER节点是否存活，只要BACKUP还存活都可以正常运行 如果测试中发现两个节点都出现了虚拟ip的，首先尝试关闭自己的防火墙servcie iptables stop 暂时关闭防火墙chkconfig iptables off 永久关闭防火墙","path":"2019/04/11/Nginx安装配置并使用keepalived实现高可用双机热备/","date":"04-11","excerpt":"所用安装包也可以从此处下载 下载nginx 官网：https://nginx.org/（我的是1.8.1） 上传并解压nginx tar -zxvf nginx-1.8.1.tar.gz -C /usr/local/src 编译nginx #进入到nginx源码目录 cd /usr/local/src/nginx-1.8.1 #检查安装环境,并指定将来要安装的路径 ./configure –prefix=/usr/local/nginx #缺包报错 ./configure: error: C compiler cc is not found #使用YUM安装缺少的包 yum -y install gcc pcre-devel openssl openssl-devel（centos命令，如果是其他系统请自行更改）","tags":[{"name":"踩坑","slug":"踩坑","permalink":"https://jijiking51.cn/tags/踩坑/"},{"name":"配置","slug":"配置","permalink":"https://jijiking51.cn/tags/配置/"},{"name":"高可用","slug":"高可用","permalink":"https://jijiking51.cn/tags/高可用/"}],"preview":"http://img.jijiking51.cn/Nginx安装配置并使用keepalived实现高可用双机热备.jpg"},{"title":"ZooKeeper详解","text":"前言提到ZooKeeper，相信大家都不会陌生。Dubbo，Kafka,Hadoop等等项目里都能看到它的影子。但是你真的了解 ZooKeeper 吗？如果面试官让你给他讲讲 ZooKeeper 是个什么东西，你能回答到什么地步呢？我会用两个篇幅介绍ZooKeeper ，第一篇是概念性的认识，这篇你会得到 ZooKeeper 是什么，ZooKeeper 设计的目标，ZooKeeper 能做什么和ZooKeeper 基本的概念。第二篇我会从实战出发，安装ZooKeeper，写一些ZooKeeper 具体应用场景的代码实现。 一、ZooKeeper是什么ZooKeeper 是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。 官网：http://zookeeper.apache.org/ 源码：https://github.com/apache/zookeeper 二、ZooKeeper 的由来下面这段内容摘自《从Paxos到Zookeeper 》 ，本文中很多的名词介绍也来自本书。 Zookeeper最早起源于雅虎研究院的一个研究小组。在当时，研究人员发现，在雅虎内部很多大型系统基本都需要依赖一个类似的系统来进行分布式协调，但是这些系统往往都存在分布式单点问题。所以，雅虎的开发人员就试图开发一个通用的无单点问题的分布式协调框架，以便让开发人员将精力集中在处理业务逻辑上。关于“ZooKeeper”这个项目的名字，其实也有一段趣闻。在立项初期，考虑到之前内部很多项目都是使用动物的名字来命名的（例如著名的Pig项目),雅虎的工程师希望给这个项目也取一个动物的名字。时任研究院的首席科学家RaghuRamakrishnan开玩笑地说：“在这样下去，我们这儿就变成动物园了！”此话一出，大家纷纷表示就叫动物园管理员吧一一一因为各个以动物命名的分布式组件放在一起，雅虎的整个分布式系统看上去就像一个大型的动物园了，而Zookeeper 正好要用来进行分布式环境的协调一一于是，Zookeeper 的名字也就由此诞生了。 三、ZooKeeper的特性顺序一致性，从同一个客户端发起的事务请求，最终将会严格地按照其发起顺序被应用到Zookeeper中去。 原子性，所有事务请求的处理结果在整个集群中所有机器上的应用情况是一致的，即整个集群要么都成功应用了某个事务，要么都没有应用。 单一视图，无论客户端连接的是哪个 Zookeeper 服务器，其看到的服务端数据模型都是一致的。 可靠性，一旦服务端成功地应用了一个事务，并完成对客户端的响应，那么该事务所引起的服务端状态变更将会一直被保留，除非有另一个事务对其进行了变更。 实时性，Zookeeper 保证在一定的时间段内，客户端最终一定能够从服务端上读取到最新的数据状态。 四、ZooKeeper的设计目标简单的数据结构Zookeeper 使得分布式程序能够通过一个共享的树形结构的名字空间来进行相互协调，即Zookeeper 服务器内存中的数据模型由一系列被称为ZNode的数据节点组成，Zookeeper 将全量的数据存储在内存中，以此来提高服务器吞吐、减少延迟的目的。 可以构建集群Zookeeper 集群通常由一组机器构成，组成 Zookeeper 集群的而每台机器都会在内存中维护当前服务器状态，并且每台机器之间都相互通信。 顺序访问对于来自客户端的每个更新请求，Zookeeper 都会分配一个全局唯一的递增编号，这个编号反映了所有事务操作的先后顺序。 高性能Zookeeper 和Redis一样全量数据存储在内存中，100%读请求压测QPS 12-13W。 五、关于 ZooKeeper 的一些重要概念5.1 Zookeeper 集群：Zookeeper 是一个由多个 server 组成的集群,一个 leader，多个 follower。（这个不同于我们常见的Master/Slave模式）leader 为客户端服务器提供读写服务，除了leader外其他的机器只能提供读服务。每个 server 保存一份数据副本全数据一致，分布式读 follower，写由 leader 实施更新请求转发，由 leader 实施更新请求顺序进行，来自同一个 client 的更新请求按其发送顺序依次执行数据更新原子性，一次数据更新要么成功，要么失败。全局唯一数据视图，client 无论连接到哪个 server，数据视图都是一致的实时性，在一定事件范围内，client 能读到最新数据。 5.2 集群角色Leader：是整个 Zookeeper 集群工作机制中的核心 。Leader 作为整个 ZooKeeper 集群的主节点，负责响应所有对 ZooKeeper 状态变更的请求。主要工作： 事务请求的唯一调度和处理，保障集群处理事务的顺序性。集群内各服务器的调度者。Leader 选举是 Zookeeper 最重要的技术之一，也是保障分布式数据一致性的关键所在。我们以三台机器为例，在服务器集群初始化阶段，当有一台服务器Server1启动时候是无法完成选举的，当第二台机器 Server2 启动后两台机器能互相通信，每台机器都试图找到一个leader，于是便进入了 leader 选举流程. 每个 server 发出一个投票投票的最基本元素是（SID-服务器id,ZXID-事物id）接受来自各个服务器的投票处理投票优先检查 ZXID(数据越新ZXID越大),ZXID比较大的作为leader，ZXID一样的情况下比较SID统计投票这里有个过半的概念，大于集群机器数量的一半，即大于或等于（n/2+1）,我们这里的由三台，大于等于2即为达到“过半”的要求。这里也有引申到为什么 Zookeeper 集群推荐是单数。| 集群数量 | 至少正常运行数量 | 允许挂掉的数量 || ——– | —————————– | ————– || 2 | 2的半数为1，半数以上最少为2 | 0 || 3 | 3的半数为1.5，半数以上最少为2 | 1 || 4 | 4的半数为2，半数以上最少为3 | 1 || 5 | 5的半数为2.5，半数以上最少为3 | 2 || 6 | 6的半数为3，半数以上最少为4 | 2 | 通过以上可以发现，3台服务器和4台服务器都最多允许1台服务器挂掉，5台服务器和6台服务器都最多允许2台服务器挂掉,明显4台服务器成本高于3台服务器成本，6台服务器成本高于5服务器成本。这是由于半数以上投票通过决定的。 改变服务器状态 一旦确定了 leader，服务器就会更改自己的状态，且一半不会再发生变化，比如新机器加入集群、非 leader 挂掉一台。 Follower ：是 Zookeeper 集群状态的跟随者。他的逻辑就比较简单。除了响应本服务器上的读请求外，follower 还要处理leader 的提议，并在 leader 提交该提议时在本地也进行提交。另外需要注意的是，leader 和 follower 构成ZooKeeper 集群的法定人数，也就是说，只有他们才参与新 leader的选举、响应 leader 的提议。 Observer ：服务器充当一个观察者的角色。如果 ZooKeeper 集群的读取负载很高，或者客户端多到跨机房，可以设置一些 observer 服务器，以提高读取的吞吐量。Observer 和 Follower 比较相似，只有一些小区别：首先 observer 不属于法定人数，即不参加选举也不响应提议，也不参与写操作的“过半写成功”策略；其次是 observer 不需要将事务持久化到磁盘，一旦 observer 被重启，需要从 leader 重新同步整个名字空间。 5.3会话（Session）Session 指的是 ZooKeeper 服务器与客户端会话。在 ZooKeeper 中，一个客户端连接是指客户端和服务器之间的一个 TCP 长连接。客户端启动的时候，首先会与服务器建立一个 TCP 连接，从第一次连接建立开始，客户端会话的生命周期也开始了。通过这个连接，客户端能够通过心跳检测与服务器保持有效的会话，也能够向Zookeeper 服务器发送请求并接受响应，同时还能够通过该连接接收来自服务器的Watch事件通知。 Session 的 sessionTimeout 值用来设置一个客户端会话的超时时间。当由于服务器压力太大、网络故障或是客户端主动断开连接等各种原因导致客户端连接断开时，只要在sessionTimeout规定的时间内能够重新连接上集群中任意一台服务器，那么之前创建的会话仍然有效。在为客户端创建会话之前，服务端首先会为每个客户端都分配一个sessionID。由于 sessionID 是 Zookeeper 会话的一个重要标识，许多与会话相关的运行机制都是基于这个 sessionID 的，因此，无论是哪台服务器为客户端分配的 sessionID，都务必保证全局唯一。 5.3.1 会话（Session）在Zookeeper客户端与服务端成功完成连接创建后，就创建了一个会话，Zookeeper会话在整个运行期间的生命周期中，会在不同的会话状态中之间进行切换，这些状态可以分为CONNECTING、CONNECTED、RECONNECTING、RECONNECTED、CLOSE等。 一旦客户端开始创建Zookeeper对象，那么客户端状态就会变成CONNECTING状态，同时客户端开始尝试连接服务端，连接成功后，客户端状态变为CONNECTED，通常情况下，由于断网或其他原因，客户端与服务端之间会出现断开情况，一旦碰到这种情况，Zookeeper客户端会自动进行重连服务，同时客户端状态再次变成CONNCTING，直到重新连上服务端后，状态又变为CONNECTED，在通常情况下，客户端的状态总是介于CONNECTING 和CONNECTED 之间。但是，如果出现诸如会话超时、权限检查或是客户端主动退出程序等情况，客户端的状态就会直接变更为CLOSE状态。 5.3.2 会话创建Session是Zookeeper中的会话实体，代表了一个客户端会话，其包含了如下四个属性 sessionID。会话ID，唯一标识一个会话，每次客户端创建新的会话时，Zookeeper都会为其分配一个全局唯一的sessionID。 TimeOut。会话超时时间，客户端在构造Zookeeper实例时，会配置sessionTimeout参数用于指定会话的超时时间，Zookeeper客户端向服务端发送这个超时时间后，服务端会根据自己的超时时间限制最终确定会话的超时时间。 TickTime。下次会话超时时间点，为了便于Zookeeper对会话实行”分桶策略”管理，同时为了高效低耗地实现会话的超时检查与清理，Zookeeper会为每个会话标记一个下次会话超时时间点，其值大致等于当前时间加上TimeOut。 isClosing。标记一个会话是否已经被关闭，当服务端检测到会话已经超时失效时，会将该会话的isClosing标记为”已关闭”，这样就能确保不再处理来自该会话的心情求了。Zookeeper为了保证请求会话的全局唯一性，在SessionTracker初始化时，调用initializeNextSession方法生成一个sessionID，之后在Zookeeper运行过程中，会在该sessionID的基础上为每个会话进行分配，初始化算法如下 1234567public static long initializeNextSession(long id) &#123; long nextSid = 0; // 无符号右移8位使为了避免左移24后，再右移8位出现负数而无法通过高8位确定sid值 nextSid = (System.currentTimeMillis() &lt;&lt; 24) &gt;&gt;&gt; 8; nextSid = nextSid | (id &lt;&lt; 56); return nextSid;&#125; 5.3.3 会话管理Zookeeper的会话管理主要是通过SessionTracker来负责，其采用了分桶策略（将类似的会话放在同一区块中进行管理）进行管理，以便Zookeeper对会话进行不同区块的隔离处理以及同一区块的统一处理。 5.4 数据节点 Znode在Zookeeper中，“节点”分为两类，第一类同样是指构成集群的机器，我们称之为机器节点；第二类则是指数据模型中的数据单元，我们称之为数据节点一一ZNode。Zookeeper将所有数据存储在内存中，数据模型是一棵树（Znode Tree)，由斜杠（/）的进行分割的路径，就是一个Znode，例如/foo/path1。每个上都会保存自己的数据内容，同时还会保存一系列属性信息。 5.4.1 节点类型在Zookeeper中，node可以分为持久节点和临时节点和顺序节点三大类。可以通过组合生成如下四种类型节点 PERSISTENT持久节点,节点创建后便一直存在于Zookeeper服务器上，直到有删除操作来主动清楚该节点。 PERSISTENT_SEQUENTIAL持久顺序节点,相比持久节点，其新增了顺序特性，每个父节点都会为它的第一级子节点维护一份顺序，用于记录每个子节点创建的先后顺序。在创建节点时，会自动添加一个数字后缀，作为新的节点名，该数字后缀的上限是整形的最大值。3.EPEMERAL临时节点，临时节点的生命周期与客户端会话绑定，客户端失效，节点会被自动清理。同时，Zookeeper规定不能基于临时节点来创建子节点，即临时节点只能作为叶子节点。4.EPEMERAL_SEQUENTIAL临时顺序节点,在临时节点的基础添加了顺序特性。 5.5 版本——保证分布式数据原子性操作每个数据节点都具有三种类型的版本信息，对数据节点的任何更新操作都会引起版本号的变化。 version– 当前数据节点数据内容的版本号cversion– 当前数据子节点的版本号aversion– 当前数据节点ACL变更版本号 上述各版本号都是表示修改次数，如version为1表示对数据节点的内容变更了一次。即使前后两次变更并没有改变数据内容，version的值仍然会改变。version可以用于写入验证，类似于CAS。 5.6watcher事件监听器ZooKeeper允许用户在指定节点上注册一些Watcher，当数据节点发生变化的时候，ZooKeeper服务器会把这个变化的通知发送给感兴趣的客户端 5.7 ACL 权限控制——保障数据的安全ACL是Access Control Lists 的简写， ZooKeeper采用ACL策略来进行权限控制，有以下权限：CREATE:创建子节点的权限READ:获取节点数据和子节点列表的权限WRITE:更新节点数据的权限DELETE:删除子节点的权限ADMIN:设置节点ACL的权限 5.8 Paxos算法Paxos算法是基于消息传递且具有高度容错特性的一致性算法，是目前公认的解决分布式一致性问题最有效的算法之一。（其他算法有二阶段提交、三阶段提交等）篇幅较长 可以参考https://www.cnblogs.com/linbingdong/p/6253479.html 六、ZooKeeper 可以做什么？ 分布式服务注册与订阅 在分布式环境中，为了保证高可用性，通常同一个应用或同一个服务的提供方都会部署多份，达到对等服务。而消费者就须要在这些对等的服务器中选择一个来执行相关的业务逻辑，比较典型的服务注册与订阅，代表：dubbo。分布式配置中心发布与订阅模型，即所谓的配置中心，顾名思义就是发布者将数据发布到ZK节点上，供订阅者获取数据，实现配置信息的集中式管理和动态更新。代表：百度的disconf。github：https://github.com/knightliao/disconf 命名服务在分布式系统中，通过使用命名服务，客户端应用能够根据指定名字来获取资源或服务的地址，提供者等信息。被命名的实体通常可以是集群中的机器，提供的服务地址，进程对象等等——这些我们都可以统称他们为名字（Name）。其中较为常见的就是一些分布式服务框架中的服务地址列表。通过调用ZK提供的创建节点的API，能够很容易创建一个全局唯一的path，这个path就可以作为一个名称。 分布式锁分布式锁，这个主要得益于ZooKeeper为我们保证了数据的强一致性。锁服务可以分为两类，一个是保持独占，另一个是控制时序。所谓保持独占，就是所有试图来获取这个锁的客户端，最终只有一个可以成功获得这把锁。通常的做法是把zk上的一个znode看作是一把锁，通过create znode的方式来实现。所有客户端都去创建 /distribute_lock 节点，最终成功创建的那个客户端也即拥有了这把锁。控制时序，就是所有视图来获取这个锁的客户端，最终都是会被安排执行，只是有个全局时序了。做法和上面基本类似，只是这里 /distribute_lock 已绊预先存在，客户端在它下面创建临时有序节点（这个可以通过节点的属性控制：CreateMode.EPHEMERAL_SEQUENTIAL来指定）。Zk的父节点（/distribute_lock）维持一份sequence,保证子节点创建的时序性，从而也形成了每个客户端的全局时序 Master选举 负载均衡","path":"2019/04/11/ZooKeeper详解/","date":"04-11","excerpt":"前言提到ZooKeeper，相信大家都不会陌生。Dubbo，Kafka,Hadoop等等项目里都能看到它的影子。但是你真的了解 ZooKeeper 吗？如果面试官让你给他讲讲 ZooKeeper 是个什么东西，你能回答到什么地步呢？我会用两个篇幅介绍ZooKeeper ，第一篇是概念性的认识，这篇你会得到 ZooKeeper 是什么，ZooKeeper 设计的目标，ZooKeeper 能做什么和ZooKeeper 基本的概念。第二篇我会从实战出发，安装ZooKeeper，写一些ZooKeeper 具体应用场景的代码实现。","tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"https://jijiking51.cn/tags/zookeeper/"}],"preview":"http://img.jijiking51.cn/ZooKeeper详解.jpg"},{"title":"MybatisGenerator逆向工程","text":"项目介绍：http://www.mybatis.org/generator/XML中的标签意思：http://www.mybatis.org/generator/quickstart.htmlXML示例文件：http://www.mybatis.org/generator/configreference/xmlconfig.html启动方式：http://www.mybatis.org/generator/running/running.html本文采用_From another Java program with an XML configuration的方式启动&nbsp;&nbsp; 详细使用看注释 eBg.xml配置 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE generatorConfiguration PUBLIC \"-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN\" \"http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd\"&gt;&lt;generatorConfiguration&gt;&lt;!-- 设置连接的jar包 --&gt; &lt;classPathEntry location=\"mysql-connector-java-5.1.46-bin.jar\" /&gt; &lt;!-- targetRuntime：用来设置生成的类型 MyBatis3:标准类型，包含了动态查询的Example MyBatis3Simple：简单的增删查改--&gt; &lt;context id=\"DB2Tables\" targetRuntime=\"MyBatis3\"&gt; &lt;!-- jdbcConnection:指定如何链接到目标数据库 --&gt; &lt;jdbcConnection driverClass=\"com.mysql.jdbc.Driver\" connectionURL=\"jdbc:mysql://localhost:3306/mybatis?useSSL=true\" userId=\"root\" password=\"123456\"&gt; &lt;/jdbcConnection&gt; &lt;javaTypeResolver &gt; &lt;property name=\"forceBigDecimals\" value=\"false\" /&gt; &lt;/javaTypeResolver&gt; &lt;!-- javaModelGenerator:指定javaBean的生成策略， targetPackage=\"test.model\"：目标包名 targetProject=\"\\MBGTestProject\\src\"：目标工程 生成的是对象.java文件 --&gt; &lt;javaModelGenerator targetPackage=\"cn.jijiking51.mybatis.bean\" targetProject=\"src\"&gt; &lt;property name=\"enableSubPackages\" value=\"true\" /&gt; &lt;property name=\"trimStrings\" value=\"true\" /&gt; &lt;/javaModelGenerator&gt; &lt;!-- sqlMapGenerator:sql 映射生成策略 生成的是：生成的是对象Mapper.xml文件 eclipse中 只要都是代码文件夹， 包路径相同的话编译的时候会合并到bin中，所以选择的文件路径可以不是conf，但是包名一定要相同 idea中， Mapper.xml 和 Mapper.java 一定要相同路径文件夹 ******这个是否需要取决于下面type选择的模式，只有XMLMAPPER模式需要这个****** --&gt; &lt;sqlMapGenerator targetPackage=\"cn.jijiking51.mybatis.dao\" targetProject=\"conf\"&gt; &lt;property name=\"enableSubPackages\" value=\"true\" /&gt; &lt;/sqlMapGenerator&gt; &lt;!-- javaClientGenerator：指定mapper接口所在的文件位置 生成的是：生成的是对象Mapper.java文件 注意生成xml的文件位置 type=\"ANNOTATEDMAPPER\",生成Java Model 和基于注解的Mapper对象 type=\"MIXEDMAPPER\",生成基于注解的Java Model 和相应的Mapper对象 type=\"XMLMAPPER\",生成SQLMap XML文件和独立的Mapper接口 --&gt; &lt;javaClientGenerator type=\"XMLMAPPER\" targetPackage=\"cn.jijiking51.mybatis.dao\" targetProject=\"src\"&gt; &lt;property name=\"enableSubPackages\" value=\"true\" /&gt; &lt;/javaClientGenerator&gt; &lt;!-- table：制定要逆向分析哪些表:根据表生成javaBean ， table 表名， domainObjectNam --&gt; &lt;table tableName=\"employee\" domainObjectName=\"Employee\"&gt;&lt;/table&gt; &lt;table tableName=\"user\" domainObjectName=\"User\"&gt;&lt;/table&gt; &lt;table tableName=\"tb_class\" domainObjectName=\"Class\"&gt;&lt;/table&gt; &lt;table tableName=\"tb_head_teacher\" domainObjectName=\"Teacher\"&gt;&lt;/table&gt; &lt;/context&gt;&lt;/generatorConfiguration&gt; 启动：注意要修改成自己的xml文件 12345678910111213@Test public void testEbg() throws Exception &#123; List&lt;String&gt; warnings = new ArrayList&lt;String&gt;(); boolean overwrite = true; //唯一要修改的地方就是引入这个xml配置文件 File configFile = new File(\"eBg.xml\"); ConfigurationParser cp = new ConfigurationParser(warnings); Configuration config = cp.parseConfiguration(configFile); DefaultShellCallback callback = new DefaultShellCallback(overwrite); MyBatisGenerator myBatisGenerator = new MyBatisGenerator(config, callback, warnings); myBatisGenerator.generate(null); &#125;","path":"2019/04/11/MybatisGenerator逆向工程/","date":"04-11","excerpt":"项目介绍：http://www.mybatis.org/generator/XML中的标签意思：http://www.mybatis.org/generator/quickstart.htmlXML示例文件：http://www.mybatis.org/generator/configreference/xmlconfig.html启动方式：http://www.mybatis.org/generator/running/running.html本文采用_From another Java program with an XML configuration的方式启动&nbsp;&nbsp;","tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"https://jijiking51.cn/tags/Mybatis/"},{"name":"开发","slug":"开发","permalink":"https://jijiking51.cn/tags/开发/"}],"preview":"http://img.jijiking51.cn/MybatisGenerator逆向工程.jpg"},{"title":"ubuntu18.04安装Anaconda3+tensorflow-gpu1.8.0+cuda9.1+cudnn7.05","text":"参考测试代码来源：https://vimsky.com/article/3872.html18.04图形界面开启与关闭https://blog.csdn.net/happy_lucky52/article/details/82626901ubuntu18.04安装cuda+cudnnhttps://blog.csdn.net/u010801439/article/details/80483036 前提 下载Anaconda下载链接下载3.7 下载cuda下载地址选择9.1版本对对照图片选择，下载列表对应的选择第一个Download为cuda9.1 ，下面的还有三个（有一个没有截出来）为补丁，全部下载 下载cudnn下载链接选择Download cuDNN选择后如果没有账号请创建账号，如果有账号请登录，然后勾选用户协议选择存档的cuDNN版本下载对应的文件 现在我们手里有123456789###anaconda安装文件Anaconda3-2018.12-Linux-x86_64.sh###cuda安装文件以及补丁cuda_9.1.85_387.26_linux.runcuda_9.1.85.1_linux.runcuda_9.1.85.2_linux.runcuda_9.1.85.3_linux.run###cudnn文件cudnn-9.1-linux-x64-v7.tgz 如果文件少了请检查是否缺少步骤 ！！！！！！！！！接下来请关闭图形界面！！！！！！！！！18.04用户请执行以下命令，其他版本用户请自行搜索关闭ubuntu图形界面12sudo systemctl set-default multi-user.targetsudo reboot 安装完毕后用以下命令恢复12sudo systemctl set-default graphical.targetsudo reboot 卸载当前系统安装的NVIDIA驱动 1sudo apt remove --purge nvidia* 安装NVIDIA驱动 查看系统推荐驱动 123456789101112ubuntu-drivers devices###得到的结果== /sys/devices/pci0000:00/0000:00:01.0/0000:01:00.0 ==modalias : pci:v000010DEd0000139Bsv00001558sd00000152bc03sc00i00vendor : NVIDIA Corporationmodel : GM107M [GeForce GTX 960M]driver : nvidia-driver-396 - third-party freedriver : nvidia-driver-410 - third-party freedriver : nvidia-driver-390 - third-party freedriver : nvidia-driver-415 - third-party free recommendeddriver : xserver-xorg-video-nouveau - distro free builtin 安装推荐的驱动 123456###1. 添加NVIDIA源，建议添加源后再次运行上面的命令，可以查看更加完整的驱动推荐sudo add-apt-repository ppa:graphics-drivers/ppa###2. 更新源sudo apt-get update###3. 安装上面推荐的驱动，具体选择根据上面的推荐和tensorflow-gpu的实际需求，对应版本表见下方sudo apt-get install nvidia-*** tensorflow-gpu版本对应关系 安装cuda9.1 ubuntu18.04是7.0的gcc和g++，而cuda需要的是4.8 所以我们进行降级处理 123456789101112###1. 安装gcc和g++ 4.8版本sudo apt-get install gcc-4.8sudo apt-get install g++-4.8###2.更改引用 ###1. 进入/usr/bin cd /usr/bin ###2. 备份 sudo mv gcc gcc.bak sudo mv g++ g++.bak ###3. 重新创建软链 sudo ln -s gcc-4.8 gcc sudo ln -s g++-4.8 g++ 安装cuda_9.1.85_387.26_linux.run 12345sudo sh cuda_9.1.85_387.26_linux.run###按照它的提示选择输入 accept | y###因为我们更改已经安装了NVIDIA驱动，所以在是否安装驱动的选项时选择no，其他的选项全部选择yes###安装完成后会提示nvidia-driver没有安装，其他的安装完成###waring警告是告诉你如何安装上它的nvidia驱动 安装补丁 123sudo sh cuda_9.1.85.1_linux.runsudo sh cuda_9.1.85.2_linux.run sudo sh cuda_9.1.85.3_linux.run 添加环境变量 12345###cuda-x.x 请按照自己安装的版本实际环境更改echo &apos;export PATH=/usr/local/cuda-x.x/bin:$PATH&apos; &gt;&gt; ~/.bashrcecho &apos;export LD_LIBRARY_PATH=/usr/local/cuda-x.x/lib64:$LD_LIBRARY_PATH&apos; &gt;&gt; ~/.bashrc###更新配置source ~/.bashrc 安装cudnn7.05 解压cudnn-9.1-linux-x64-v7.tgz 1tar -zxvf cudnn-9.1-linux-x64-v7.tgz 复制到cuda的目录中 1234sudo cp cuda/include/cudnn.h /usr/local/cuda/include/ sudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64/ sudo chmod a+r /usr/local/cuda/include/cudnn.h sudo chmod a+r /usr/local/cuda/lib64/libcudnn* 安装anaconda 运行安装脚本 1234sh Anaconda3-2018.12-Linux-x86_64.sh###注意事项######除了最后问你是否安装vscode可以选择no，其他的请选择yes，否则请自行添加环境变量source ~/.bashrc 添加清华源 123conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/ conda config --set show_channel_urls yes 创建一个python环境 12conda create -n tensorflow python=3.6conda activate tensorflow 安装tensorflow-gpu，版本请更具需要修改 1conda install -n tensorflow tensorflow-gpu==1.8.0 测试是否安装成功请先运行上面的恢复图形界面代码随后将这段代码粘贴到一个py文件中，使用刚刚创建的python环境运行 12345678import tensorflow as tfwith tf.device(&apos;/gpu:0&apos;): a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name=&apos;a&apos;) b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name=&apos;b&apos;) c = tf.matmul(a, b)with tf.Session() as sess: print (sess.run(c)) 如果安装成功会在最后显示这个结果12[[22. 28.] [49. 64.]] ​","path":"2019/04/11/ubuntu18-04安装Anaconda3-tensorflow-gpu1-8-0-cuda9-1-cudnn7-05/","date":"04-11","excerpt":"参考测试代码来源：https://vimsky.com/article/3872.html18.04图形界面开启与关闭https://blog.csdn.net/happy_lucky52/article/details/82626901ubuntu18.04安装cuda+cudnnhttps://blog.csdn.net/u010801439/article/details/80483036","tags":[{"name":"踩坑","slug":"踩坑","permalink":"https://jijiking51.cn/tags/踩坑/"},{"name":"配置","slug":"配置","permalink":"https://jijiking51.cn/tags/配置/"}],"preview":"http://img.jijiking51.cn/ubuntu18.04安装Anaconda3+tensorflow-gpu1.8.0+cuda9.1+cudnn7.05.jpg"},{"title":"Mysql导入和导出Sql文件","text":"window下1.导出整个数据库mysqldump -u 用户名 -p 数据库名 &gt; 导出的文件名mysqldump -u dbuser -p dbname &gt; dbname.sql2.导出一个表mysqldump -u 用户名 -p 数据库名 表名&gt; 导出的文件名mysqldump -u dbuser -p dbname users&gt; dbname_users.sql 3.导出一个数据库结构mysqldump -u dbuser -p -d –add-drop-table dbname &gt;d:/dbname_db.sql-d 没有数据 –add-drop-table 在每个create语句之前增加一个drop table 4.导入数据库常用source 命令进入mysql数据库控制台，如mysql -u root -pmysql&gt;use 数据库然后使用source命令，后面参数为脚本文件(如这里用到的.sql)mysql&gt;source d:/dbname.sql 导入数据到数据库 mysql -uroot -D数据库名 导入数据到数据库中得某个表 mysql -uroot -D数据库名 表名 mysqldump 命令没找到请将目录切换到mysql的安装目录下的bin目录 linux下一、导出数据库用mysqldump命令（注意mysql的安装路径，即此命令的路径）：1、导出数据和表结构：mysqldump -u用户名 -p密码 数据库名 &gt; 数据库名.sql #/usr/local/mysql/bin/ mysqldump -uroot -p abc &gt; abc.sql敲回车后会提示输入密码 2、只导出表结构mysqldump -u用户名 -p密码 -d 数据库名 &gt; 数据库名.sql #/usr/local/mysql/bin/ mysqldump -uroot -p -d abc &gt; abc.sql 注：/usr/local/mysql/bin/ —&gt; mysql的data目录 二、导入数据库1、首先建空数据库mysql&gt;create database abc; 2、导入数据库方法一：（1）选择数据库mysql&gt;use abc;（2）设置数据库编码mysql&gt;set names utf8;（3）导入数据（注意sql文件的路径）mysql&gt;source /home/abc/abc.sql; 方法二：mysql -u用户名 -p密码 数据库名 &lt; 数据库名.sql #mysql -uabc_f -p abc &lt; abc.sql","path":"2019/04/11/Mysql导入和导出Sql文件/","date":"04-11","excerpt":"window下1.导出整个数据库mysqldump -u 用户名 -p 数据库名 &gt; 导出的文件名mysqldump -u dbuser -p dbname &gt; dbname.sql2.导出一个表mysqldump -u 用户名 -p 数据库名 表名&gt; 导出的文件名mysqldump -u dbuser -p dbname users&gt; dbname_users.sql","tags":[{"name":"备份","slug":"备份","permalink":"https://jijiking51.cn/tags/备份/"}],"preview":"http://img.jijiking51.cn/Mysql导入和导出Sql文件.jpg"},{"title":"eclipse开发Hadoop时异常org.apache.hadoop.security.AccessControlException:","text":"问题原因1org.apache.hadoop.security.AccessControlException: Permission denied: user=min, access=WRITE, inode=&quot;/access_log_copy&quot;:mini:supergroup:-rw-r--r-- 我们可以看到user=min，这是我们当前运行系统的用户名，而这里期望值是Hadoop上面的用户名 解决方法所以有一下几种解决方法： 在JVM变量里面添加HADOOP_USER_NAME，例： 1-DHADOOP_USER_NAME=xxx 这里的xxx是Hadoop上面的用户名eclipse配置如下： 2. 将当前系统的帐号修改为Hadoop上运行的用户名 3. 在构造客户端fs对象时，通过对象传递进去 12345678910/** * 依赖的包名 * import java.net.URI; * import java.net.URISyntaxException; * import org.apache.hadoop.conf.Configuration; * import org.apache.hadoop.fs.FileSystem; */Configuration conf = new Configuration(); conf.set(\"fs.defaultFS\", \"hdfs://192.168.88.137:9000\"); fs = FileSystem.get(new URI(\"hdfs://192.168.88.137:9000\"),conf,\"mini\"); 推荐第一、三种","path":"2019/04/11/eclipse开发Hadoop时异常org-apache-hadoop-security-AccessControlException/","date":"04-11","excerpt":"问题原因1org.apache.hadoop.security.AccessControlException: Permission denied: user=min, access=WRITE, inode=&quot;/access_log_copy&quot;:mini:supergroup:-rw-r--r--","tags":[{"name":"踩坑","slug":"踩坑","permalink":"https://jijiking51.cn/tags/踩坑/"},{"name":"eclipse","slug":"eclipse","permalink":"https://jijiking51.cn/tags/eclipse/"}],"preview":"http://img.jijiking51.cn/eclipse开发Hadoop时异常.jpg"},{"title":"eclipse设置自动补全并取消空格代码补全","text":"在网上找了很久但是都不尽人意，发现此篇文章，成功修改，借鉴一下，重要的不是修改那个文件，对于新版的eclipse关键是找到文件，如果你的没有，就去那个网址下一个吧设置代码提示打开 Eclipse 依次选择 Window -&gt; Perferences -&gt; Java -&gt; Editor -&gt; Content Assist，Auto activation triggers for Java：设置框中默认是”.” 现在将它改为： .abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ_ 有老版本的Eclipse不支持定义这么多触发器，可以通过修改配置文件实现，网上资料很多。 然后你就会发现Eclipse可以使用更智能的代码提示了。但是现在有一个比较大的问题是，Eclipse智能过头了，它总想帮我们完成一些我们不想要的代码补完。比如按“=”和空格以后就会自动补完代码，这对很多人真的不能忍。 幸好Eclipse是开源软件，解决办法是直接修改代码提示功能的源代码，以完成我们需要的功能。 首先打开window-&gt;show view，选择Plug-ins，再找到org.eclipse.jface.text，右键单击，选择import as－&gt; Source Project，导入完成后，在你的workspace就可以看到这个project了。如果没有src这个文件夹，说明你使用的版本中没有带源代码，我正好也是这种情况。 源代码可以去这个地址下载（找了我好久好久） http://archive.eclipse.org/eclipse/downloads/ 在页面上选择你Eclipse版本的连接（我使用的是4.4.2），然后在新页面中下载eclipse-SDK-(***).zip，根据自己的需要选择合适的版本下载，大概200M左右。下载完成以后解压缩，在.\\eclipse\\plugins\\文件夹下找到 org.eclipse.jface.text.source_3.9.2.v20141003-1326.jar （这是对应我使用的Eclipse版本的文件，实际请根据你自己的版本进行选择），将这个文件复制到你自己的Eclipse安装目录下的.\\eclipse\\plugins\\文件夹下，然后重新启动Eclipse。重复上面的操作导入(import)org.eclipse.jface.text，此时就能够看到src文件夹了。 技术分享 在src文件夹下org.eclipse.jface.text.contentassist.CompletionProposalPopup#verifyKey()”函数中有一段代码: if(contains(triggers, key)){…} 将这段代码改为 if(key!=0x20&amp;&amp; key!=‘=‘&amp;&amp; key!=‘;‘&amp;&amp; contains(triggers, key)){…} 还有把这段代码之上的代码 case‘\\t‘:e.doit=false;fProposalShell.setFocus();returnfalse; 修改为 case‘\\t‘:e.doit=false;insertSelectedProposalWithMask(e.stateMask);break; 经过上述操作，这个辅助输入插件已经排除了空格与“=”的选中功能，增加了TAB键的选中功能。最后就是导出修改后的插件，右键点击你的workspace里的工程，选择Export－&gt;Deployable plugins and fragments，点击Next，选择Destination选项卡，选择Directory，选择一个要保存插件的目录，然后Finish。然后就会在你所选的目录下产生一个新的plugins目录，里面有一个jar文件，用它替换掉eclipse/plugins里面的org.eclipse.jface.text，记得覆盖前对原文件进行备份。然后重新启动Eclipse","path":"2019/04/11/eclipse设置自动补全并取消空格代码补全/","date":"04-11","excerpt":"在网上找了很久但是都不尽人意，发现此篇文章，成功修改，借鉴一下，重要的不是修改那个文件，对于新版的eclipse关键是找到文件，如果你的没有，就去那个网址下一个吧设置代码提示打开 Eclipse 依次选择 Window -&gt; Perferences -&gt; Java -&gt; Editor -&gt; Content Assist，Auto activation triggers for Java：设置框中默认是”.”","tags":[{"name":"踩坑","slug":"踩坑","permalink":"https://jijiking51.cn/tags/踩坑/"},{"name":"eclipse","slug":"eclipse","permalink":"https://jijiking51.cn/tags/eclipse/"}],"preview":"http://img.jijiking51.cn/eclipse设置自动补全并取消空格代码补全.jpg"},{"title":"ElasticSearch使用记录","text":"首先执行（每次重启服务器后都需要执行）：sudo sysctl -w vm.max_map_count=262144获取一些基本配置文件12345docker run -p 9200:9200 -p 9300:9300 -e \"discovery.type=single-node\" -v /home/:/root/ --name elasticsearch elasticsearchdocker exec elasticsearch /bin/bash# 复制/usr/share/elasticsearch/下的config、logs两个文件夹内的文件分别到自己本地/home下的两个文件夹内，并且自己创建一个data文件夹# 复制完成后把三个文件夹放置到自己指定的目录下# 关闭容器并且删除！ 修改elasticsearch.yml配置文件，将cluster.name改成school 启动命令：12# -v指定的文件夹路径替换成上面的文件夹路径docker run -d -p 9200:9200 -p 9300:9300 -e \"discovery.type=single-node\" -v /home/h4795/Documents/studytmp/es/config/:/usr/share/elasticsearch/config/ -v /home/h4795/Documents/studytmp/es/logs/:/usr/share/elasticsearch/logs/ -v /home/h4795/Documents/studytmp/es/data/:/usr/share/elasticsearch/data/ --name elasticsearch elasticsearch 安装ik分词插件，ik分词器版本必须和es一致，否则一定会安装失败12345678# 分词器开源地址：https://github.com/medcl/elasticsearch-analysis-ikdocker exec elasticsearch /bin/bashcd binelasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.2.0/elasticsearch-analysis-ik-7.2.0.zip# 退出dockerexit# 重启esdocker restart elasticsearch 创建索引123456789101112// put http://127.0.0.1:9200/school&#123; \"settings\": &#123; \"number_of_shards\": \"5\", \"number_of_replicas\": \"1\", \"analysis\": &#123; \"ik\": &#123; \"tokenizer\": \"ik_max_word\" &#125; &#125; &#125;&#125; 建立字段123456789101112131415161718192021222324252627282930// post http://127.0.0.1:9200/school/_mapping/&#123; \"properties\": &#123; \"id\": &#123; \"type\": \"integer\" &#125;, \"title\": &#123; \"type\": \"text\" &#125;, \"context\": &#123; \"type\": \"text\" &#125;, \"createtime\": &#123; \"type\": \"date\", \"format\": \"yyyy-MM-dd HH:mm:ss || yyyy-MM-dd\" &#125;, \"status\": &#123; \"type\": \"integer\" &#125;, \"kind\": &#123; \"type\": \"integer\" &#125;, \"cid\": &#123; \"type\": \"integer\" &#125;, \"uid\": &#123; \"type\": \"integer\" &#125; &#125;&#125; 通过查询删除数据使用查找的方式,将查找的内容全部删除请求链接: 127.0.0.1:9200/noob/goods/_delete_by_query请求类型: POST请求数据:1234567&#123; \"query\": &#123; \"match\": &#123; \"goodsId\": \"47959547\" &#125; &#125;&#125;","path":"2019/04/11/ElasticSearch使用记录/","date":"04-11","excerpt":"首先执行（每次重启服务器后都需要执行）：sudo sysctl -w vm.max_map_count=262144获取一些基本配置文件12345docker run -p 9200:9200 -p 9300:9300 -e \"discovery.type=single-node\" -v /home/:/root/ --name elasticsearch elasticsearchdocker exec elasticsearch /bin/bash# 复制/usr/share/elasticsearch/下的config、logs两个文件夹内的文件分别到自己本地/home下的两个文件夹内，并且自己创建一个data文件夹# 复制完成后把三个文件夹放置到自己指定的目录下# 关闭容器并且删除！","tags":[{"name":"踩坑","slug":"踩坑","permalink":"https://jijiking51.cn/tags/踩坑/"},{"name":"配置","slug":"配置","permalink":"https://jijiking51.cn/tags/配置/"}],"preview":"http://img.jijiking51.cn/ElasticSearch使用记录.jpg"},{"title":"Java面试_操作系统","text":"线程与进程线程与进程理论 进程和线程以及他们的区别 进程：一个程序在一个数据集上的一次运行过程。系统资源分配的单位。 一个程序在不同数据集合上运行或一个程序在同样数据集上的多次运行都是不同的进程。 进程是独立的，有自己的内存空间和上下文环境，无法获取其他进程的存储空间。同一进程的两段代码不能同时执行，除非引入线程。 线程：进程的一个实体，是被系统独立调度和执行的基本单位，CPU使用的基本单位。 同一进程的线程可以共享同一内存空间。线程是属于进程的，当进程退出时该进程所产生的线程都会被强制退出并清除。线程占用的资源少于进程占用的资源 进程和线程都可以有优先级 进程在内存中的结构 代码区：存放CPU执行的机器指令，代码区是可共享，并且是只读的 数据段：全局变量、静态变量、常量（编译后知道大小）（未初始化的在一个区域(BBS区)，初始化的在相邻区域(数据区)） 全局变量：定义在函数外面，其他文件也能使用（external linkage） 静态变量：static 关键字修饰的变量： 函数外定义：全局变量，只在当前文件中可见（ internal linkage） 函数内定义：全局变量，只在此函数内可见 （C++）类中定义：全局变量，只在此类中可见 栈区：由编译器自动分配释放，存放函数的参数值、返回值和局部变量，在程序运行过程中实时分配和释放，栈区由操作系统自动管理，无须程序员手动管理 堆区：堆是由malloc()函数分配的内存块，使用free()函数来释放内存，堆的申请释放工作由程序员控制，容易产生内存泄漏 进程地址空间：内核地址空间+用户地址空间（代码段、数据段、堆、栈、共享库） 堆和栈的区别 栈：函数参数、返回地址、局部变量（运行入口知道大小） 编译器自动分配释放，存放函数的参数值，局部变量的值等。 申请后的响应：若栈的剩余空间大于申请空间，系统将为程序提供内存，否则提示栈溢出 大小限制：向低地址扩展，连续的内存区域，栈顶地址和栈最大容量是系统事先规定好的。如果申请的空间超过栈的剩余空间将栈溢出 申请效率：系统自动分配，速度快，程序员无法控制 存储的内容：函数调用时进栈顺序：主函数下一条指令的地址（函数调用语句的下一条可执行语句）、函数的各个参数（大多数c编译器中参数是从右往左入栈）、函数的局部变量。 调用结束的出栈顺序：局部变量、函数参数（从左到右）、栈顶指针指向最开始存的地址（即主函数的下一条指令） 堆：运行期间动态分配的内存空间（运行的时候才知道大小） 程序员自己分配释放，分配方式类似于链表 申请后的响应：操作系统有一个记录空闲内存地址的链表，当系统收到程序的申请时会遍历该链表，寻找第一个空间大于所申请空间的堆结点，将该结点从空闲结点链表删除，分配该结点的空间给程序。会在这块内存空间中的首地址处记录本次分配的大小。 这样delete语句才能正确释放本内存空间。由于找到的堆结点的大小不一定正好等于申请的大小，系统会自动将多余的那部分重新放入空闲链表中 大小限制：向高地址扩展，不连续的内存区域，用链表存储，遍历方向是由低地址向高地址。堆大小受限于计算机系统的有效虚拟内存。获得的空间更大更灵活 申请效率：用new分配，速度慢，容易产生内部碎片，使用方便 存储的内容：一般在堆的头部用一个字节放堆的大小 进程状态 创建（信息设置完但资源有限） 运行（占用cpu） 就绪（等待分配cpu） 等待（等待某个是啊金的发送） 终止（进程完成执行） 进程间的通信如何实现 通信的方式有：信号、信号量、消息队列、共享内存、管道、有名管道 管道(pipe)：半双工通信，数据单向流动；只能父子进程通信；速度慢 有名管道(FIFO)：任何进程都能通信；速度慢 信号量（semophore）：计数器，控制多个进程对共享资源的访问（多进程或线程的同步方法）；不能传递复杂消息 信号：用于通知接收进程某个事件已经发送 消息队列：消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递少、管道只能承载无格式字节流以及缓冲区大小受限的缺点；容量受限，第一次读的时候要考虑上一次没有读完数据的问题 需要消息复制，不需考虑同步问题，不适宜信息量大或操作频繁的场合 共享内存：映射一段能被其他进程访问的内存，由一个进程创建，可被多个进程访问，要保持同步。与信号量结合使用，用来达到进程间的同步及互斥，最快的IPC方式 不需要消息复制，信息量大，快捷，在任意数量的进程之间进行高效双向通信的机制。 套接字：可用于不同机器间的进程通信，由ip地址和端口号连接而成 进程调度 选择一个可用的进程到cpu上执行 进程进入系统，会被加入到作业队列（包括系统的所有进程）队列通常用链表实现，头结点指向的链表的第一个和最后一个pcb块的指针，每个pcb包括一个指向就绪队列的下一个pcb的指针域 运行—&gt;就绪：IO请求（–&gt;IO队列–&gt;IO结束）；时间片结束；创建一个子进程（等待子进程结束）；等待中断（中断发生） PCB： 进程标志 进程状态 程序计数器 寄存器 cpu调度信息：进程优先级、调度队列指针、其他调度参数 内存管理信息：基址寄存器 界限寄存器 页表/段表 记账信息：cpu时间、实际使用时间、时间界限、记账数据、作业或进程数量 I/O状态信息：分配给进程的IO设备列表、打开文件列表 线程状态 创建(new)、就绪(runnable/start)、运行(running)、阻塞(blocked)、等待(waiting)、时间等待(time waiting) 和 消亡(dead/terminated)。在给定的时间点上，一个线程只能处于一种状态 线程同步的方式 互斥量 Synchronized/Lock：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问 信号量 Semphare：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量 事件(信号)，Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作 处理机调度 先来先服务（FCFS，First-Come-First-Served）: 此算法的原则是按照作业到达后备作业队列（或进程进入就绪队列）的先后次序来选择作业（或进程）。 短作业优先（SJF,Shortest Process Next）：这种调度算法主要用于作业调度，它从作业后备队列中挑选所需运行时间（估计值）最短的作业进入主存运行。 时间片轮转调度算法（RR，Round-Robin）：当某个进程执行的时间片用完时，调度程序便停止该进程的执行，并将它送就绪队列的末尾，等待分配下一时间片再执行。然后把处理机分配给就绪队列中新的队首进程，同时也让它执行一个时间片。这样就可以保证就绪队列中的所有进程，在一给定的时间内，均能获得一时间片处理机执行时间。 高响应比优先（HRRN，Highest Response Ratio Next）: 按照高响应比（（已等待时间＋要求运行时间）/ 要求运行时间）优先的原则，在每次选择作业投入运行时，先计算此时后备作业队列中每个作业的响应比RP然后选择其值最大的作业投入运行。 优先权(Priority)调度算法: 按照进程的优先权大小来调度，使高优先权进程得到优先处理的调度策略称为优先权调度算法。 多级队列调度算法：多队列调度是根据作业的性质和类型的不同，将就绪队列再分为若干个子队列，所有的作业（或进程）按其性质排入相应的队列中，而不同的就绪队列采用不同的调度算法。 说一说进程同步有哪几种机制 原子操作、信号量机制、自旋锁管程、会合、分布式系统 中断和轮询的特点 对I/O设备的程序轮询的方式，是早期的计算机系统对I/O设备的一种管理方式。它定时对各种设备轮流询问一遍有无处理要求。轮流询问之后，有要求的，则加以处理。在处理I/O设备的要求之后，处理机返回继续工作。尽管轮询需要时间，但轮询要比I/O设备的速度要快得多，所以一般不会发生不能及时处理的问题。当然，再快的处理机，能处理的输入输出设备的数量也是有一定限度的。而且，程序轮询毕竟占据了CPU相当一部分处理时间，因此，程序轮询是一种效率较低的方式，在现代计算机系统中已很少应用。 程序中断通常简称中断，是指CPU在正常运行程序的过程中，由于预先安排或发生了各种随机的内部或外部事件，使CPU中断正在运行的程序，而转到为响应的服务程序去处理。 轮询——效率低，等待时间很长，CPU利用率不高。 中断——容易遗漏一些问题，CPU利用率高。 同步和互斥 同步是进程之间合作完成某功能，是进程之间的直接关系 互斥是多个进程公用某临界资源，是进程之间的间接关系 (互斥是不允许两个线程同时占有一个资源。同步是在互斥的基础上，再加了访问次序，比如生产消费者模式，需要先生成在消费。比如希尔排序，需要大的间隔度排序完，才能排步数小的） 经典同步问题， 生产消费者模式（Java多线程中也有） 线程&amp;锁 什么是死锁？ 死锁产生的条件？ 死锁的概念 在两个或者多个并发进程中，如果每个进程持有某种资源而又等待其它进程释放它或它们现在保持着的资源，在未改变这种状态之前都不能向前推进，称这一组进程产生了死锁。通俗的讲，就是两个或多个进程无限期的阻塞、相互等待的一种状态。 死锁产生的四个必要条件 互斥：至少有一个资源必须属于非共享模式，即一次只能被一个进程使用；若其他申请使用该资源，那么申请进程必须等到该资源被释放为止； 占有并等待：一个进程必须占有至少一个资源，并等待另一个资源，而该资源为其他进程所占有； 非抢占：进程不能被抢占，即资源只能被进程在完成任务后自愿释放 循环等待：若干进程之间形成一种头尾相接的环形等待资源关系 死锁的处理策略；鸵鸟策略、预防策略、避免策略、检测与恢复策略 死锁预防 打破互斥条件。即允许进程同时访问某些资源。但是有的资源是不允许被同时访问的。像打印机等等，这是有资源本身的属性所决定的。所以这种办法并无实用价值 打破不可抢占条件。即允许进程强行从占有者那里多去某些资源。就是说，当一个进程已占有了某些资源，他又申请新的资源，但不能立即被满足时，它必须释放所有占有的全部资源，然后再重新申请。它所释放的资源可以分配给其他进程。这就相当于该进程占有的资源被隐蔽地强占了，这种预防死锁的方法实现起来困难，会减低系统性能。 打破占有且申请条件。可以实行资源与预先分配策略。即进程在运行前一次性的向系统申请他所需要的全部资源，如果某个进程所需要的全部资源得不到满足，则不分配资源，此进程暂不运行。只有当系统能够满足当前进程的全部资源需求时，才一次性的将所申请的资源全部分配给该进。由于运行的进程已占有了它所需要的全部资源，所以不会发生占有资源又申请资源的现象，因此不会发生死锁。但是这种策略也有如下缺点 在许多情况下，一个进程在执行之前不可能知道他所需要的全部资源。这是由于进程在执行时是动态的，不可预测的； 资源利用率低。无论所分配资源和使用到，一个进程只有在占有所需要的全部资源后才能执行。即使有些资源做后才被该进程用到一次，但该进程在生存期间却一直占有他们，造成长期占着不用的状况。这显然是一种极大的资源浪费 降低了进程的并发性。因为资源有限，又加上存在浪费，能分配到所需全部资源的进程个数就必然少了 打破循环等待条件，实行资源有序分配策略。采用这种策略，即把资源实现分类编号，按号分配，使进程在申请，占用资源时不会形成环路。所有进程对资源的请求必须严格按资源序号递增的顺序提出。进程占用了小号资源，才能申请大号资源，就不会产生环路，从而预防了死锁。这种策略与前面的策略相比，资源的利用率额系统吞吐量都有很大提高，但是也存在以下缺点： 限制了进程对资源的请求，同时给系统中所有资源合理编号也是件困难事，并增加了系统开销 为了遵循按编号申请的次序，暂不使用的资源也需要提前申请，从而增加了进程对资源的占用时间 线程如何避免死锁 固定加锁的顺序(针对锁顺序死锁) 开放调用(针对对象之间协作造成的死锁) 在一个锁内尽量不要调用其他带锁的方法 使用定时锁–&gt;tryLock() 如果等待获取锁时间超时，则抛出异常而不是一直等待！ 银行家算法 如何理解分布式锁 分布式锁，是控制分布式系统之间同步访问共享资源的一种方式。在分布式系统中，常常需要协调它们的动作。如果不同的系统或是同一个系统的不同主机之间共享了一个或一组资源，那么访问这些资源的时候，往往需要不出来防止彼此干扰来保证一致性，在这种情况下，便需要使用分布式锁 临界区问题 【共享数据的互斥】 临界区：在该区中进程可能改变共同变量、更新一个表、写一个文件；没有两个进程能同时在临界区内执行。 123456do &#123; 【进入区】 // 请求允许进入其临界区 临界区 【退出区】 剩余区 &#125; while (true); eg. Peterson算法 123456789101112131415int turn; // 表示哪个进程可以进入临界区boolean flag[2]; // 表示哪个进程想要进入临界区 // Pi进程的结构------------------------------- do &#123; // 进入区 flag[i] = true; turn = j; while (flag[i] &amp;&amp; turn == j); // 临界区 flag[i] = false; // Pi最多在Pj进入临界区一次后就能进入---有限等待 // 剩余区&#125; while (true); 满足3个要求： 互斥（进程在临界区内执行，其他进程就不能在其临界区内执行） 前进（如果没有进程在其临界区执行且有进程需进入临界区，那么只有那些不在剩余区内执行的进程可参加选择，以确定谁能下一个进入临界区，且这种不能无线） 有限等待：从一个进程请求允许进入临界区到进入临界区为止，其他进程允许进入其临界区的次数有限 信号量 信号量S是一个整数型变量，信号量分为计数信号量（初始化为可用资源的数量）和二进制信号量（互斥锁）。 除了初始化外，只能通过两个标准【原子】操作：wait()和signal()来访问（这些操作被成为P测试和V增加） 123456789// 进程需要资源的时候 wait(S) &#123; while (S &lt;= 0); // 被阻塞----忙等待 S--; &#125; // 进程释放资源的时候 signal(S) &#123; S++; &#125; 这里定义的信号量【自旋锁】的主要缺点： 忙等待：当一个进程位于其临界区内时，其他试图进入临界区的进程需要在进入区连续第循环，浪费了cpu时钟 优点：进程在等待锁时不需要上下文切换，节省时间（如果锁占用时间短） 克服忙等：进程信号量不为正时不忙等二十阻塞自己，放入一个与信号量相关的等待队列中，状态为等待。 线程同步与阻塞的关系？同步一定阻塞吗？阻塞一定同步吗？ 线程同步与阻塞没有一点关系 同步和异步关注的是消息通信机制(synchronous communication / asynchronous communication)。所谓同步，就是在发出一个调用时，在没有得到结果之前，这个调用就不返回。但是一旦调用返回，就得到返回值了。换句话说，就是由调用者主动等待这个调用的结果。而异步则是相反，调用在发出之后这个调用就直接返回了，所以没有返回结果。换句话说，当一个异步过程调用发出后，调用者不会立即得到结果。而是在调用发出后，被调用者通过状态、通知来通知调用者，或通过回调函数处理这个调用。 阻塞和非阻塞关注的是程序在等待调用结果(消息、返回值)时的状态。阻塞调用是指调用结果返回之前，当前线程会被挂起。调用线程只有在得到结果之后才会返回。非阻塞调用指在不能立即得到结果之前，该调用不会阻塞当前线程 储存器管理 什么是缓冲区溢出？有什么危害？其原因是什么？ 缓冲区溢出是指计算机向缓冲区填充数据的时候超过了缓冲区本身的容量，溢出的数据覆盖在了合法数据上； 危害有以下两点： 程序崩溃，导致拒绝额服务 跳转并且执行一段恶意代码 造成缓冲区溢出的主要原因就是程序中没有检查用户输入的参数 分页和分段有什么区别 段式存储管理是一种符合用户视角的内存分配管理方案。在段式存储管理中，将程序的地址空间划分为若干段（segment），如代码段，数据段，堆栈段；这样每个进程有一个二维地址空间，相互独立，互不干扰。段式管理的优点是：没有内碎片（因为段大小可变，改变段大小来消除内碎片）。但段换入换出时，会产生外碎片（比如4k的段换5k的段，会产生1k的外碎片） 页式存储管理方案是一种用户视角内存与物理内存相分离的内存分配管理方案。在页式存储管理中，将程序的逻辑地址划分为固定大小的页（page），而物理内存划分为同样大小的帧，程序加载时，可以将任意一页放入内存中任意一个帧，这些帧不必连续，从而实现了离散分离。页式存储管理的优点是：没有外碎片（因为页的大小固定），但会产生内碎片（一个页可能填充不满）。 两者的不同点： 目的不同：分页是由于系统管理的需要而不是用户的需要，它是信息的物理单位；分段的目的是为了能更好地满足用户的需要，它是信息的逻辑单位，它含有一组其意义相对完整的信息； 大小不同：页的大小固定且由系统决定，而段的长度却不固定，由其所完成的功能决定； 地址空间不同： 段向用户提供二维地址空间；页向用户提供的是一维地址空间； 信息共享：段是信息的逻辑单位，便于存储保护和信息的共享，页的保护和共享受到限制； 内存碎片：页式存储管理的优点是没有外碎片（因为页的大小固定），但会产生内碎片（一个页可能填充不满）；而段式管理的优点是没有内碎片（因为段大小可变，改变段大小来消除内碎片）。但段换入换出时，会产生外碎片（比如4k的段换5k的段，会产生1k的外碎片）。 什么是虚拟内存 虚拟内存允许执行进程不必完全在内存中。虚拟内存的基本思想是：每个进程拥有独立的地址空间，这个空间被分为大小相等的多个块，称为页(Page)，每个页都是一段连续的地址。这些页被映射到物理内存，但并不是所有的页都必须在内存中才能运行程序。当程序引用到一部分在物理内存中的地址空间时，由硬件立刻进行必要的映射；当程序引用到一部分不在物理内存中的地址空间时，由操作系统负责将缺失的部分装入物理内存并重新执行失败的命令。这样，对于进程而言，逻辑上似乎有很大的内存空间，实际上其中一部分对应物理内存上的一块(称为帧，通常页和帧大小相等)，还有一些没加载在内存中的对应在硬盘上 注意，请求分页系统、请求分段系统和请求段页式系统都是针对虚拟内存的，通过请求实现内存与外存的信息置换。 虚拟内存的应用与优点 虚拟内存很适合在多道程序设计系统中使用，许多程序的片段同时保存在内存中。当一个程序等待它的一部分读入内存时，可以把CPU交给另一个进程使用。虚拟内存的使用可以带来以下好处： 在内存中可以保留多个进程，系统并发度提高 解除了用户与内存之间的紧密约束，进程可以比内存的全部空间还大 页面置换算法有哪些 最佳置换算法（Optimal）：即选择那些永不使用的，或者是在最长时间内不再被访问的页面置换出去。（它是一种理想化的算法，性能最好，但在实际上难于实现）。 先进先出置换算法FIFO：该算法总是淘汰最先进入内存的页面，即选择在内存中驻留时间最久的页面予以淘汰。 最近最久未使用置换算法LRU（Least Recently Used）：该算法是选择最近最久未使用的页面予以淘汰，系统在每个页面设置一个访问字段，用以记录这个页面自上次被访问以来所经历的时间T，当要淘汰一个页面时，选择T最大的页面。 Clock置换算法：也叫最近未用算法NRU（Not RecentlyUsed）。该算法为每个页面设置一位访问位，将内存中的所有页面都通过链接指针链成一个循环队列。当某页被访问时，其访问位置“1”。在选择一页淘汰时，就检查其访问位，如果是“0”，就选择该页换出；若为“1”，则重新置为“0”，暂不换出该页，在循环队列中检查下一个页面，直到访问位为“0”的页面为止。由于该算法只有一位访问位，只能用它表示该页是否已经使用过，而置换时是将未使用过的页面换出去，所以把该算法称为最近未用算法。 最少使用置换算法LFU：该算法选择最近时期使用最少的页面作为淘汰页。 颠簸/抖动 ​ 颠簸本质上是指频繁的页调度行为，具体来讲，进程发生缺页中断，这时，必须置换某一页。然而，其他所有的页都在使用，它置换一个页，但又立刻再次需要这个页。因此，会不断产生缺页中断，导致整个系统的效率急剧下降，这种现象称为颠簸（抖动）。 内存颠簸的解决策略包括： 如果是因为页面替换策略失误，可以修改替换算法来解决这个问题； 如果是因为运行的程序太多，造成程序无法同时将所有频繁访问的页面调入内存，则要降低多道程序的数量； 否则，还剩下两个办法：终止该进程或增加物理内存容量。 局部性原理 时间上的局部性：最近被访问的页在不久的将来还会被访问。 空间上的局部性：内存中被访问的页周围的页也很可能被访问。 CPU中的缓存和操作系统中的缓存分别是什么？ ​ 操作系统的缓存是指快表。在操作系统中，为提高系统的存取速度，在地址映射机制中增加一个小容量的联想寄存器，即快表，用来存放当前访问最频繁的少数活动页面的页号。当某用户需要存取数据时，根据数据所在的逻辑页号在快表中找到其对应的内存块号，再联系页内地址，形成物理地址。如果在快表中没有相应的逻辑页号，则地址映射仍可以通过内存中的页表进行，得到空闲块号后必须将该块号填入快表的空闲块中。如果快表中没有空闲块，则根据淘汰算法淘汰某一行，再填入新的页号和块号。快表查找内存块的物理地址消耗的时间大大降低了，使得系统效率得到了极大的提高。 ​ CPU中的缓存是指高速缓存。CPU的执行速度越来越快，系统架构越来越先进，而主存的结构和存取速度改进则较慢，因此，高速缓存技术将越来越重要。 高速缓冲存储器是位于CPU和内存之间的临时存储器，它的容量比内存小但交换速度快。在高速缓冲存储器中的数据是内存中的一小部分，但这一小部分是短时间内CPU即将访问的。当CPU调用大量数据时，就可避开内存直接从高速缓冲存储器中调用，从而加快读取速度。 存储器管理 存储器多层结构：寄存器，高速缓存，主存，磁盘程序装入与链接 分配方式：连续分配和离散分配 顺序动态分配： 首次适应 循环首次适应 最佳适应（找到刚好合适的） 最坏适应（每次找到最大的） 动态重定位分配： 紧凑法： 将碎片合并成大的空间， 但是影响系统效率 离散分配：分页，分段 分页：是物理大小，由系统决定，页面大小是固定的 分段： 大小是逻辑，用户决定的，段的大小是动态的 分页：页表存储在内存中，cpu先访问页表，再从页表中得到页号得到的物理地址，其中cpu访问两次内存，速度会明显变慢。通常会用高速缓存（“快表”），缓存当前访问到的页号对应的物理页面，如果没有命中，再去内存中访问页表。 分段： 方便编程，信息共享，信息保护，动态增长，动态链接 段页式：段表寄存器记录了段表的大小和起始地址，段表中的每条信息记录了段内页面的页表和起始地址，根据页表可以找到每个页面的位置。 段表=&gt;页表=&gt;最终页面 三次访问内存， 实际会设置高速寄存器，根据段号和页号，查看是否在缓存中命中 I/O管理一.操作系统与设备之间的IO简单来说（详细的请看《现代操作系统》），操作系统通过设备驱动程序访问IO设备。方式有： 轮询方式： CPU主动在各种设备中轮询检查状态，有数据就IO。 中断方式： 设备有数据的时候，发出中断，由CPU决定要不要响应中断，然后中断，去处理设备的IO。CPU不用经常轮询设备状态。被动接收中断就行。 DMA直接存储器访问方式： 如果1个字节的数据中断一次，传1KB的数据得中断1024次，太浪费CPU时间，于是有了DMA方式，CPU只需要把开头和结束的地址告诉DMA，中间由DMA完成数据IO。CPU从字节干预解放到数据块的干预。 通道控制方式： DMA方式只能控制一个设备的一块数据，多块数据还是要CPU干预多次。于是有了通道来控制IO，它比DMA更强大，能控制多块数据，多个设备的IO，更加解放了CPU参与IO过程。 二.操作系统与用户进程间的IO（进程中的线程才是CPU基本的执行/调度单元，下面用线程举例，用socket举例） 设备来的数据放在内核cache中，需要用户线程去内核cache中取数据，复制到自己进程的cache中。有5中读取数据方式： 阻塞： 用户线程调用某些系统函数去内核取数据，直到数据到达内核cache前，该线程处于阻塞状态，等待数据到达。 非阻塞 用户线程去取数据，不管内核cache有没有数据，都直接返回，可能拿到数据，也可能拿不到，不会使线程进入阻塞态。 IO多路复用 多路就是一个线程管理多路IO，线程还是被阻塞调用，其中一路或几路IO有数据了就返回。需要线程遍历全部IO，判断是哪个IO有数据。 例如 socket 的 select() 函数，线程调用 select() 进入阻塞态，任何一个IO有数据了，线程就退出阻塞态，获得机会继续执行。 信号驱动IO 给一个IO注册一个信号和信号触发的回调函数，一旦信号被触发，回调函数里读取数据。 例如给 socket 注册一个“可读”的信号，当数据来了，可读的时候，信号被触发，执行回调函数从内核cache复制数据到用户空间。 异步IO 异步IO中，操作系统完成了数据从内核到用户空间的拷贝后，以信号的方式通知用户线程可以下一步操作。省去了用户线程阻塞下来拷贝数据的过程。 IO管理假设一台服务器需要被1万个客户端连接。方法有： 单路： 最简单的一个线程管理一个客户端的socket IO，那么需要1万的线程，假设每个线程占内存3MB，需要300G内存，单台服务器没那么大的内存，并且操作系统最大线程数有限制，unix下一个进程好像是最多只能开 4096 个线程。 IO 多路复用： socket一旦多起来，单路IO 就扛不住了，需要一个线程管理多个 socket IO，下面都是在一个线程内的情况。 select 一个线程管理多个socket IO，调用 select() 进入阻塞态，任何一个IO有数据则返回，由于不知道是哪个 socket 有数据，需要遍历所有 socket fd 去判断，当1万个 socket 大部分都是有IO的时候，效率较高，如果只是那么几百个有IO，此方法效率较低。 epoll 和 kqueue epoll 是 linux 下的，kqueue 是 unix 下的。 由于 select 需要遍历全部的 socket fd，效率较低，于是有了 epoll, kqueue 方式，kqueue 管理多个IO，阻塞调用等待函数，当有一个或多个IO事件，kqueue 直接返回多个IO事件的 socket fd，不需要遍历全部 socket fd，效率较高。 假设一个 socket 连接的对象是 3 kb，8G的内存可以管理 280w 个连接。 select，epoll，kqueue 原理 已知的情况 内核中注册 socket 的 IO 中断处理的回掉函数，有 IO 了会回调该函数。 select： select 管理多个 socket，select 收到一个来自网卡 IO 中断就返回，不知道这个中断对应是哪个 socket fd 的。需要用户线程遍历判断。 epoll： epoll 收到一个 IO 中断，会去查找这个中断对应哪个 socket fd。 epoll 中建立一个红黑树（平衡二叉树的一种），红黑树查找很高效。 用户注册感兴趣的 socket 事件，就是把这个 socket fd 插入到红黑树中，用中断号做key，可以理解为（中断号，socket fd）的二元组。 用户移除事件就是，删除树上的某个节点。 然后收到一个IO中断，epoll 把网卡数据拷贝到内核cache，根据中断号在红黑树中查找对应的 fd，把 fd 加入到就绪链表中，准备返回给用户线程。用户直接得到就绪的 fd。 kqueue： 收到 socket IO 中断去哈希表中查找对应的 socket fd，再把它放到一个链表里，返回。 用户注册一个感兴趣的事件，就是往哈希表中添加一个 fd。 磁盘调度算法磁盘I/O传输时间Ta = Ts + 1/2r + b/rN Ts 寻道时间(时间最长 最需要优化) 1/2r 旋转延时的时间为磁盘旋转一周的时间的一半 b/rN b 传输的比特数 N 磁道上的比特数 r 磁盘转数 磁盘调度算法通过优化磁盘访问请求顺序来提高磁盘访问性能 寻道时间是磁道访问最耗时的部分 同时会有多个在同一磁盘上的I/O请求 随机处理磁盘访问请求的性能很差 先进先出算法(FIFO) 按顺序处理请求 公平对待所有进程 在有很多进程的情况下 接近随机调度的性能 磁盘访问序列 = 98,183,37,122,14,124,65,67初始磁头位置 53 最短服务时间优先(SSTF) 选择从磁臂当前位置需要移动最少的I/O请求 总是选择最短寻道时间 磁盘访问序列 = 98,183,37,122,14,124,65,67初始磁头位置 53 扫描算法(SCAN)磁臂在一个方向上移动 访问所有未完成的请求 直到磁臂到达该方向上最后的磁道 也称为电梯算法(elevator algorithm) 中间磁道的访问性能较好 两头的比较差 C-SCAN算法改进了这个缺点 磁盘访问序列 = 98,183,37,122,14,124,65,67初始磁头位置 53 循环扫描算法(C-SCAN)限制了仅在一个方向上扫描 当最后一个磁道也被访问过了以后 磁币返回到磁盘的另外一段再次进行 就算对头没有I/O请求也要走到头 浪费了 C-LOOK算法改进了这个缺点 C-LOOK算法磁臂先到达该方向上最后一个请求处 然后立即反转 而不是先到最后点路径上的所有请求 N步扫描(N-Step-SCAN)算法用于解决磁头粘着问题 磁头粘着(Arm Stickiness)现象 SSTF SCAN CSCAN等算法中 可能出现磁头停留在某处不动的情况 进程反复请求对某一磁道的I/O操作 将磁盘请求队列分成长度为N的子队列 按FIFO算法依次处理所有子队列 扫描算法处理每个队列 双队列扫描算法(FSCAN)FSCAN算法是N步扫描算法的简化 只将磁盘请求队列分成两个子队列 可以减少平均等待时间 把磁盘I/O请求分成两个队列 交替使用扫描算法处理一个队列 新生成的磁盘I/O请求放入另一队列中 所有的新请求都将被推迟到下一次扫描时处理 文件管理 文件系统种类 文件系统是操作系统用于明确磁盘或分区上的文件的方法和数据结构；即在磁盘上组织文件的方法。也指用于存储文件的磁盘或分区，或文件系统种类。操作系统中负责管理和存储文件信息的软件机构称为文件管理系统，简称文件系统。文件系统由三部分组成：与文件管理有关软件、被管理文件以及实施文件管理所需数据结构。从系统角度来看，文件系统是对文件存储器空间进行组织和分配，负责文件存储并对存入的文件进行保护和检索的系统。具体地说，它负责为用户建立文件，存入、读出、修改、转储文件，控制文件的存取，当用户不再使用时撤销文件等。 FAT 常PC机使用的文件系统是FAT16。像基于MS-DOS，Win 95等系统都采用了FAT16文件系统。在Win 9X下，FAT16支持的分区最大为2GB。我们知道计算机将信息保存在硬盘上称为“簇”的区域内。使用的簇越小，保存信息的效率就越高。在FAT16的情况下，分区越大簇就相应的要大，存储效率就越低，势必造成存储空间的浪费。并且随着计算机硬件和应用的不断提高，FAT16文件系统已不能很好地适应系统的要求。在这种情况下，推出了增强的文件系统FAT32。同FAT16相比，FAT32主要具有以下特点： 1. 同FAT16相比FAT32最大的优点是可以支持的磁盘大小达到32G，但是不能支持小于512MB的分区。 基于FAT32的Win 2000可以支持分区最大为32GB；而基于 FAT16的Win 2000支持的分区最大为4GB。 2. 由于采用了更小的簇，FAT32文件系统可以更有效率地保存信息。如两个分区大小都为2GB，一个分区采用了FAT16文件系统，另一个分区采用了FAT32文件系统。采用FAT16的分区的簇大小为32KB，而FAT32分区的簇只有4KB的大小。这样FAT32就比FAT16的存储效率要高很多，通常情况下可以提高15%。 FAT32文件系统可以重新定位根目录和使用FAT的备份副本。另外FAT32分区的启动记录被包含在一个含有关键数据的结构中，减少了计算机系统崩溃的可能性。 NTFS NTFS文件系统是一个基于安全性的文件系统，是Windows NT所采用的独特的文件系统结构，它是建立在保护文件和目录数据基础上，同时照顾节省存储资源. 减少磁盘占用量的一种先进的文件系统。使用非常广泛的Windows NT 4.0采用的就是NTFS 4.0文件系统，相信它所带来的强大的系统安全性一定给广大用户留下了深刻的印象。Win 2000采用了更新版本的NTFS文件系统？？NTFS 5.0，它的推出使得用户不但可以像Win 9X那样方便快捷地操作和管理计算机，同时也可享受到NTFS所带来的系统安全性。 NTFS 5.0的特点主要体现在以下几个方面： 1. NTFS可以支持的分区（如果采用动态磁盘则称为卷）大小可以达到2TB。而Win 2000中的FAT32支持分区的大小最大为32GB。 2. NTFS是一个可恢复的文件系统。在NTFS分区上用户很少需要运行磁盘修复程序。NTFS通过使用标准的事物处理日志和恢复技术来保证分区的一致性。发生系统失败事件时，NTFS使用日志文件和检查点信息自动恢复文件系统的一致性。 3. NTFS支持对分区. 文件夹和文件的压缩。任何基于Windows的应用程序对NTFS分区上的压缩文件进行读写时不需要事先由其他程序进行解压缩，当对文件进行读取时，文件将自动进行解压缩；文件关闭或保存时会自动对文件进行压缩。 4. NTFS采用了更小的簇，可以更有效率地管理磁盘空间。在Win 2000的FAT32文件系统的情况下，分区大小在2GB～8GB时簇的大小为4KB；分区大小在8GB～16GB时簇的大小为8KB；分区大小在16GB～32GB时，簇的大小则达到了16KB。而Win 2000的NTFS文件系统，当分区的大小在2GB以下时，簇的大小都比相应的FAT32簇小；当分区的大小在2GB以上时（2GB～2TB），簇的大小都为4KB。相比之下，NTFS可以比FAT32更有效地管理磁盘空间，最大限度地避免了磁盘空间的浪费。 5. 在NTFS分区上，可以为共享资源. 文件夹以及文件设置访问许可权限。许可的设置包括两方面的内容：一是允许哪些组或用户对文件夹. 文件和共享资源进行访问；二是获得访问许可的组或用户可以进行什么级别的访问。访问许可权限的设置不但适用于本地计算机的用户，同样也应用于通过网络的共享文件夹对文件进行访问的网络用户。与FAT32文件系统下对文件夹或文件进行访问相比，安全性要高得多。另外，在采用NTFS格式的Win 2000中，应用审核策略可以对文件夹. 文件以及活动目录对象进行审核，审核结果记录在安全日志中，通过安全日志就可以查看哪些组或用户对文件夹. 文件或活动目录对象进行了什么级别的操作，从而发现系统可能面临的非法访问，通过采取相应的措施，将这种安全隐患减到最低。这些在FAT32文件系统下，是不能实现的。 6. 在Win 2000的NTFS文件系统下可以进行磁盘配额管理。磁盘配额就是管理员可以为用户所能使用的磁盘空间进行配额限制，每一用户只能使用最大配额范围内的磁盘空间。设置磁盘配额后，可以对每一个用户的磁盘使用情况进行跟踪和控制，通过监测可以标识出超过配额报警阈值和配额限制的用户，从而采取相应的措施。磁盘配额管理功能的提供，使得管理员可以方便合理地为用户分配存储资源，避免由于磁盘空间使用的失控可能造成的系统崩溃，提高了系统的安全性。 7. NTFS使用一个“变更”日志来跟踪记录文件所发生的变更。 Ext2 Ext2是 GNU/Linux 系统中标准的文件系统，其特点为存取文件的性能极好，对于中小型的文件更显示出优势，这主要得利于其簇快取层的优良设计。 其单一文件大小与文件系统本身的容量上限与文件系统本身的簇大小有关，在一般常见的 x86 电脑系统中，簇最大为 4KB，则单一文件大小上限为 2048GB，而文件系统的容量上限为 16384GB。 但由于目前核心 2.4 所能使用的单一分割区最大只有 2048GB，实际上能使用的文件系统容量最多也只有 2048GB。 至于Ext3文件系统，它属于一种日志文件系统，是对ext2系统的扩展。它兼容ext2，并且从ext2转换成ext3并不复杂。 Ext3 Ext3是一种日志式文件系统，是对ext2系统的扩展，它兼容ext2。日志式文件系统的优越性在于：由于文件系统都有快取层参与运作，如不使用时必须将文件系统卸下，以便将快取层的资料写回磁盘中。因此每当系统要关机时，必须将其所有的文件系统全部shutdown后才能进行关机。 如果在文件系统尚未shutdown前就关机 （如停电） 时，下次重开机后会造成文件系统的资料不一致，故这时必须做文件系统的重整工作，将不一致与错误的地方修复。然而，此一重整的工作是相当耗时的，特别是容量大的文件系统，而且也不能百分之百保证所有的资料都不会流失。 为了克服此问题，使用所谓‘日志式文件系统 （Journal File System） ’。此类文件系统最大的特色是，它会将整个磁盘的写入动作完整记录在磁盘的某个区域上，以便有需要时可以回溯追踪。 由于资料的写入动作包含许多的细节，像是改变文件标头资料. 搜寻磁盘可写入空间. 一个个写入资料区段等等，每一个细节进行到一半若被中断，就会造成文件系统的不一致，因而需要重整。 然而，在日志式文件系统中，由于详细纪录了每个细节，故当在某个过程中被中断时，系统可以根据这些记录直接回溯并重整被中断的部分，而不必花时间去检查其他的部分，故重整的工作速度相当快，几乎不需要花时间。 Ext4 Linux kernel 自 2.6.28 开始正式支持新的文件系统 Ext4。Ext4 是 Ext3 的改进版，修改了 Ext3 中部分重要的数据结构，而不仅仅像 Ext3 对 Ext2 那样，只是增加了一个日志功能而已。Ext4 可以提供更佳的性能和可靠性，还有更为丰富的功能： 1. 与 Ext3 兼容。执行若干条命令，就能从 Ext3 在线迁移到 Ext4，而无须重新格式化磁盘或重新安装系统。原有 Ext3 数据结构照样保留，Ext4 作用于新数据，当然，整个文件系统因此也就获得了 Ext4 所支持的更大容量。 更大的文件系统和更大的文件。较之 Ext3 目前所支持的最大 16TB 文件系统和最大 2TB 文件，Ext4 分别支持 1EB（1，048，576TB， 1EB=1024PB， 1PB=1024TB）的文件系统，以及 16TB 的文件。 无限数量的子目录。Ext3 目前只支持 32，000 个子目录，而 Ext4 支持无限数量的子目录。 Extents。Ext3 采用间接块映射，当操作大文件时，效率极其低下。比如一个 100MB 大小的文件，在 Ext3 中要建立 25，600 个数据块（每个数据块大小为 4KB）的映射表。而 Ext4 引入了现代文件系统中流行的 extents 概念，每个 extent 为一组连续的数据块，上述文件则表示为“该文件数据保存在接下来的 25，600 个数据块中”，提高了不少效率。 多块分配。当写入数据到 Ext3 文件系统中时，Ext3 的数据块分配器每次只能分配一个 4KB 的块，写一个 100MB 文件就要调用 25，600 次数据块分配器，而 Ext4 的多块分配器“multiblock allocator”（mballoc） 支持一次调用分配多个数据块。 延迟分配。Ext3 的数据块分配策略是尽快分配，而 Ext4 和其它现代文件操作系统的策略是尽可能地延迟分配，直到文件在 cache 中写完才开始分配数据块并写入磁盘，这样就能优化整个文件的数据块分配，与前两种特性搭配起来可以显著提升性能。 快速 fsck。以前执行 fsck 第一步就会很慢，因为它要检查所有的 inode，现在 Ext4 给每个组的 inode 表中都添加了一份未使用 inode 的列表，今后 fsck Ext4 文件系统就可以跳过它们而只去检查那些在用的 inode 了。 日志校验。日志是最常用的部分，也极易导致磁盘硬件故障，而从损坏的日志中恢复数据会导致更多的数据损坏。Ext4 的日志校验功能可以很方便地判断日志数据是否损坏，而且它将 Ext3 的两阶段日志机制合并成一个阶段，在增加安全性的同时提高了性能。 “无日志”（No Journaling）模式。日志总归有一些开销，Ext4 允许关闭日志，以便某些有特殊需求的用户可以借此提升性能。 在线碎片整理。尽管延迟分配. 多块分配和 extents 能有效减少文件系统碎片，但碎片还是不可避免会产生。Ext4 支持在线碎片整理，并将提供 e4defrag 工具进行个别文件或整个文件系统的碎片整理。 inode 相关特性。Ext4 支持更大的 inode，较之 Ext3 默认的 inode 大小 128 字节，Ext4 为了在 inode 中容纳更多的扩展属性（如纳秒时间戳或 inode 版本），默认 inode 大小为 256 字节。Ext4 还支持快速扩展属性（fast extended attributes）和 inode 保留（inodes reservation）。 持久预分配（Persistent preallocation）。P2P 软件为了保证下载文件有足够的空间存放，常常会预先创建一个与所下载文件大小相同的空文件，以免未来的数小时或数天之内磁盘空间不足导致下载失败。Ext4 在文件系统层面实现了持久预分配并提供相应的 API（libc 中的 posix_fallocate（）），比应用软件自己实现更有效率。 默认启用 barrier。磁盘上配有内部缓存，以便重新调整批量数据的写操作顺序，优化写入性能，因此文件系统必须在日志数据写入磁盘之后才能写 commit 记录，若 commit 记录写入在先，而日志有可能损坏，那么就会影响数据完整性。Ext4 默认启用 barrier，只有当 barrier 之前的数据全部写入磁盘，才能写 barrier 之后的数据。（可通过 “mount -o barrier=0” 命令禁用该特性。） ZFS ZFS源自于Sun Microsystems为Solaris操作系统开发的文件系统。ZFS是一个具有高存储容量. 文件系统与卷管理概念整合. 崭新的磁盘逻辑结构的轻量级文件系统，同时也是一个便捷的存储池管理系统。ZFS是一个使用CDDL协议条款授权的开源项目。 HFS 1. HFS文件系统概念 分层文件系统（Hierarchical File System，HFS）是一种由苹果电脑开发，并使用在Mac OS上的文件系统。最初被设计用于软盘和硬盘，同时也可以在在只读媒体如CD-ROM上见到。 2. HFS文件系统开发过程 HFS首次出现在1985年9月17日，作为Macintosh电脑上新的文件系统。它取代只用于早期Mac型号所使用的平面文件系统Macintosh File System（MFS）。因为Macintosh电脑所产生的数据，比其它通常的文件系统，如DOS使用的FAT或原始Unix文件系统所允许存储的数据更多。苹果电脑开发了一种新式更适用的文件系统，而不是采用现有的规格。例如，HFS允许文件名最多有31个字符的长度，支持metadata和双分支（每个文件的数据和资源支分开存储）文件。 尽管HFS象其它大多数文件系统一样被视为专有的格式，因为只有它为大多数最新的操作系统提供了很好的通用解决方法以存取HFS格式磁盘。 在1998年，苹果电脑发布了HFS Plus，其改善了HFS对磁盘空间的地址定位效率低下，并加入了其它的改进。当前版本的Mac OS仍旧支持HFS，但从Mac OS X开始HFS卷不能作为启动用。 3. 构成方式 分层文件系统把一个卷分为许多512字节的“逻辑块”。这些逻辑块被编组为“分配块”，这些分配块可以根据卷的尺寸包含一个或多个逻辑块。HFS对地址分配块使用16位数值，分配块的最高限制数量是65536。 组成一个HFS卷需要下面的五个结构： 4. 卷的逻辑块0和1是启动块，它包含了系统启动信息。例如，启动时载入的系统名称和壳（通常是Finder）文件。 5. 逻辑块2包含主目录块（Master Directory Block，简称MDB）。 6. 逻辑块3是卷位图（Volume Bitmap）的启动块，它追踪分配块使用状态。 7. 总目录文件（Catalog File）是一个包含所有文件的记录和储存在卷中目录的B*-tree。 8. 扩展溢出文件（Extent Overflow File）是当最初总目录文件中三个扩展占用后，另外一个包含额外扩展记录的分配块对应信息的B*-tree。 Linux Linux常见命令 显示文件目录命令ls 如ls 改变当前目录命令cd 如cd /home 建立子目录mkdir 如mkdir xiong 删除子目录命令rmdir 如rmdir /mnt/cdrom 删除文件命令rm 如rm /ucdos.bat 文件复制命令cp 如cp /ucdos /fox 获取帮助信息命令man 如man ls 显示文件的内容less 如less mwm.lx 重定向与管道type 如type readme&gt;&gt;direct，将文件readme的内容追加到文direct中 Linux中显示一个文件最后几行的命令是什么? tail -n 20 filename tail命令语法 tail [ -f ] [ -c Number | -n Number | -m Number | -b Number | -k Number ] [ File ] 参数解释： -f 该参数用于监视File文件增长。 -c Number 从 Number 字节位置读取指定文件 -n Number 从 Number 行位置读取指定文件。 -m Number 从 Number 多字节字符位置读取指定文件，比方你的文件假设包括中文字，假设指定-c参数，可能导致截断，但使用-m则会避免该问题。 -b Number 从 Number 表示的512字节块位置读取指定文件。 -k Number 从 Number 表示的1KB块位置读取指定文件。","path":"2019/04/09/Java面试-操作系统/","date":"04-09","excerpt":"线程与进程线程与进程理论 进程和线程以及他们的区别 进程：一个程序在一个数据集上的一次运行过程。系统资源分配的单位。 一个程序在不同数据集合上运行或一个程序在同样数据集上的多次运行都是不同的进程。 进程是独立的，有自己的内存空间和上下文环境，无法获取其他进程的存储空间。同一进程的两段代码不能同时执行，除非引入线程。 线程：进程的一个实体，是被系统独立调度和执行的基本单位，CPU使用的基本单位。 同一进程的线程可以共享同一内存空间。线程是属于进程的，当进程退出时该进程所产生的线程都会被强制退出并清除。线程占用的资源少于进程占用的资源 进程和线程都可以有优先级 进程在内存中的结构 代码区：存放CPU执行的机器指令，代码区是可共享，并且是只读的 数据段：全局变量、静态变量、常量（编译后知道大小）（未初始化的在一个区域(BBS区)，初始化的在相邻区域(数据区)） 全局变量：定义在函数外面，其他文件也能使用（external linkage） 静态变量：static 关键字修饰的变量： 函数外定义：全局变量，只在当前文件中可见（ internal linkage） 函数内定义：全局变量，只在此函数内可见 （C++）类中定义：全局变量，只在此类中可见 栈区：由编译器自动分配释放，存放函数的参数值、返回值和局部变量，在程序运行过程中实时分配和释放，栈区由操作系统自动管理，无须程序员手动管理 堆区：堆是由malloc()函数分配的内存块，使用free()函数来释放内存，堆的申请释放工作由程序员控制，容易产生内存泄漏 进程地址空间：内核地址空间+用户地址空间（代码段、数据段、堆、栈、共享库） 堆和栈的区别 栈：函数参数、返回地址、局部变量（运行入口知道大小） 编译器自动分配释放，存放函数的参数值，局部变量的值等。 申请后的响应：若栈的剩余空间大于申请空间，系统将为程序提供内存，否则提示栈溢出 大小限制：向低地址扩展，连续的内存区域，栈顶地址和栈最大容量是系统事先规定好的。如果申请的空间超过栈的剩余空间将栈溢出 申请效率：系统自动分配，速度快，程序员无法控制 存储的内容：函数调用时进栈顺序：主函数下一条指令的地址（函数调用语句的下一条可执行语句）、函数的各个参数（大多数c编译器中参数是从右往左入栈）、函数的局部变量。 调用结束的出栈顺序：局部变量、函数参数（从左到右）、栈顶指针指向最开始存的地址（即主函数的下一条指令） 堆：运行期间动态分配的内存空间（运行的时候才知道大小） 程序员自己分配释放，分配方式类似于链表 申请后的响应：操作系统有一个记录空闲内存地址的链表，当系统收到程序的申请时会遍历该链表，寻找第一个空间大于所申请空间的堆结点，将该结点从空闲结点链表删除，分配该结点的空间给程序。会在这块内存空间中的首地址处记录本次分配的大小。 这样delete语句才能正确释放本内存空间。由于找到的堆结点的大小不一定正好等于申请的大小，系统会自动将多余的那部分重新放入空闲链表中 大小限制：向高地址扩展，不连续的内存区域，用链表存储，遍历方向是由低地址向高地址。堆大小受限于计算机系统的有效虚拟内存。获得的空间更大更灵活 申请效率：用new分配，速度慢，容易产生内部碎片，使用方便 存储的内容：一般在堆的头部用一个字节放堆的大小 进程状态 创建（信息设置完但资源有限） 运行（占用cpu） 就绪（等待分配cpu） 等待（等待某个是啊金的发送） 终止（进程完成执行） 进程间的通信如何实现 通信的方式有：信号、信号量、消息队列、共享内存、管道、有名管道 管道(pipe)：半双工通信，数据单向流动；只能父子进程通信；速度慢 有名管道(FIFO)：任何进程都能通信；速度慢 信号量（semophore）：计数器，控制多个进程对共享资源的访问（多进程或线程的同步方法）；不能传递复杂消息 信号：用于通知接收进程某个事件已经发送 消息队列：消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递少、管道只能承载无格式字节流以及缓冲区大小受限的缺点；容量受限，第一次读的时候要考虑上一次没有读完数据的问题 需要消息复制，不需考虑同步问题，不适宜信息量大或操作频繁的场合 共享内存：映射一段能被其他进程访问的内存，由一个进程创建，可被多个进程访问，要保持同步。与信号量结合使用，用来达到进程间的同步及互斥，最快的IPC方式 不需要消息复制，信息量大，快捷，在任意数量的进程之间进行高效双向通信的机制。 套接字：可用于不同机器间的进程通信，由ip地址和端口号连接而成 进程调度 选择一个可用的进程到cpu上执行 进程进入系统，会被加入到作业队列（包括系统的所有进程）队列通常用链表实现，头结点指向的链表的第一个和最后一个pcb块的指针，每个pcb包括一个指向就绪队列的下一个pcb的指针域 运行—&gt;就绪：IO请求（–&gt;IO队列–&gt;IO结束）；时间片结束；创建一个子进程（等待子进程结束）；等待中断（中断发生） PCB： 进程标志 进程状态 程序计数器 寄存器 cpu调度信息：进程优先级、调度队列指针、其他调度参数 内存管理信息：基址寄存器 界限寄存器 页表/段表 记账信息：cpu时间、实际使用时间、时间界限、记账数据、作业或进程数量 I/O状态信息：分配给进程的IO设备列表、打开文件列表 线程状态 创建(new)、就绪(runnable/start)、运行(running)、阻塞(blocked)、等待(waiting)、时间等待(time waiting) 和 消亡(dead/terminated)。在给定的时间点上，一个线程只能处于一种状态 线程同步的方式 互斥量 Synchronized/Lock：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问 信号量 Semphare：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量 事件(信号)，Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作 处理机调度 先来先服务（FCFS，First-Come-First-Served）: 此算法的原则是按照作业到达后备作业队列（或进程进入就绪队列）的先后次序来选择作业（或进程）。 短作业优先（SJF,Shortest Process Next）：这种调度算法主要用于作业调度，它从作业后备队列中挑选所需运行时间（估计值）最短的作业进入主存运行。 时间片轮转调度算法（RR，Round-Robin）：当某个进程执行的时间片用完时，调度程序便停止该进程的执行，并将它送就绪队列的末尾，等待分配下一时间片再执行。然后把处理机分配给就绪队列中新的队首进程，同时也让它执行一个时间片。这样就可以保证就绪队列中的所有进程，在一给定的时间内，均能获得一时间片处理机执行时间。 高响应比优先（HRRN，Highest Response Ratio Next）: 按照高响应比（（已等待时间＋要求运行时间）/ 要求运行时间）优先的原则，在每次选择作业投入运行时，先计算此时后备作业队列中每个作业的响应比RP然后选择其值最大的作业投入运行。 优先权(Priority)调度算法: 按照进程的优先权大小来调度，使高优先权进程得到优先处理的调度策略称为优先权调度算法。 多级队列调度算法：多队列调度是根据作业的性质和类型的不同，将就绪队列再分为若干个子队列，所有的作业（或进程）按其性质排入相应的队列中，而不同的就绪队列采用不同的调度算法。 说一说进程同步有哪几种机制 原子操作、信号量机制、自旋锁管程、会合、分布式系统 中断和轮询的特点 对I/O设备的程序轮询的方式，是早期的计算机系统对I/O设备的一种管理方式。它定时对各种设备轮流询问一遍有无处理要求。轮流询问之后，有要求的，则加以处理。在处理I/O设备的要求之后，处理机返回继续工作。尽管轮询需要时间，但轮询要比I/O设备的速度要快得多，所以一般不会发生不能及时处理的问题。当然，再快的处理机，能处理的输入输出设备的数量也是有一定限度的。而且，程序轮询毕竟占据了CPU相当一部分处理时间，因此，程序轮询是一种效率较低的方式，在现代计算机系统中已很少应用。 程序中断通常简称中断，是指CPU在正常运行程序的过程中，由于预先安排或发生了各种随机的内部或外部事件，使CPU中断正在运行的程序，而转到为响应的服务程序去处理。 轮询——效率低，等待时间很长，CPU利用率不高。 中断——容易遗漏一些问题，CPU利用率高。 同步和互斥 同步是进程之间合作完成某功能，是进程之间的直接关系 互斥是多个进程公用某临界资源，是进程之间的间接关系 (互斥是不允许两个线程同时占有一个资源。同步是在互斥的基础上，再加了访问次序，比如生产消费者模式，需要先生成在消费。比如希尔排序，需要大的间隔度排序完，才能排步数小的） 经典同步问题， 生产消费者模式（Java多线程中也有）","tags":[{"name":"面试","slug":"面试","permalink":"https://jijiking51.cn/tags/面试/"},{"name":"操作系统","slug":"操作系统","permalink":"https://jijiking51.cn/tags/操作系统/"}],"preview":"http://img.jijiking51.cn/20981.jpg"},{"title":"github利用hexo搭建个人博客","text":"准备工作安装gitGitHub Windows安装Node.JSNode.JS确认npm命令已经配置好安装Hexo1npm install hexo-cli -g初始化配置Hexo创建根目录12# 创建博客根目录mkdir blogroot初始化Hexo123456# 进入根目录cd blogroot# 初始化项目hexo init# 安装插件npm install 安装git插件安装配置安装git插件12# 安装git插件npm install hexo-deployer-git --save 修改配置文件123456# 修改根目录下的_config.ymldeploy: type: git // 上传方式 repository: //项目地址 branch: // 上传分支 message: // 上传时默认信息，如果不设置则为上传时的时间 查看效果12345678# 生成文章hexo n# 生成public静态文件hexo g# 本地预览效果hexo s# 将public静态文件上传到githubhexo d github准备创建博客仓库 创建项目 项目名为用户名.github.io 点击项目setting，下翻到GitHub Pages，设置上传的分支（与上面配置里面写的相同），并且按change theme选择主题（默认就行） 配置ssh私钥 右键git bash 123# username和email@email.com替换为自己的git config --global user.name \"username\"git config --global user.email \"email@email.com\" 生成秘钥 12# 输入后一路回车就好ssh-keygen -t rsa -C \"账户邮箱\" 输入eval &quot;$(ssh-agent -s)&quot;，添加密钥到ssh-agent。 再输入ssh-add ~/.ssh/id_rsa，添加生成的SSH key到ssh-agent。 github的个人setting中找到SSH and GPG keys，添加新的ssh，打开C:\\Users\\Administrator.ssh\\id_rsa.pub 文件，将里面的内容张贴到里面 输入ssh -T git@github.com，出现用户名则表示成功 配置个人域名 github点击settings，拉到下面Custom domain处 ，填写自己域名 本地的source中添加CNAME文件（更新博客的时候保证每次都带有这个文件），检查项目下是否出现了CNAME文件，内容是填写的域名（不要加http，www），如果没有就创建一个新的文件并填写对应内容 ping一下github分配的博客页面，得到一个IP，在自己的域名解析中，将www和@的都解析到这个IP上 坑配置好github Page后报错Page build failed: Date is not a valid datetime,这是非jekyll生成的站点，要添加.nojekyll空文件在repository的根目录下，关闭针对jekyll的检查。 方法： ​ 在github根目录下创建空文件.nojekyll,同样，我们要在source中添加这个文件 更换主题使用gal主题 获取主题 1git clone https://github.com/ZEROKISEKI/hexo-theme-gal.git themes/gal 将clone下来的文件/_source/的tags和categories文件夹拷贝到博客根目录下的source文件夹下 在博客根目录下下载对应插件 12345npm install hexo-renderer-sass --save npm install hexo-renderer-scss --savenpm install hexo-generator-json-content --save 添加内容到根目录下的_config.yml 123456789101112131415161718192021jsonContent: dateFormat: MM-DD pages: title: true text: true path: true date: true excerpt: true preview: true posts: title: true text: true path: true date: true excerpt: true tags: [&#123; name: tag.name, slug: tag.slug, permalink: tag.permalink &#125;] preview: true 开启搜索，404，分类，标签页面 1234hexo new page \"search\" // 搜索功能的必须步骤hexo new page \"404\" // 开启404页面hexo new page \"categories\" // 开启分类页面hexo new page \"tags\" // 开启标签页面 配置分类和标签页面 12345678910111213141516171819202122232425262728293031323334# 修改根目录下的source/categories/index.md文件---title: 文章分类date: 2017-05-27 13:47:40---# 添加 type: \"categories\"---title: 文章分类date: 2017-05-27 13:47:40type: \"categories\"---# 修改根目录下source/tags/index.md文件---title: 标签date: 2017-05-27 14:22:08---# 添加type: \"tags\"---title: 文章分类date: 2017-05-27 13:47:40type: \"tags\"---# 以后写文章头部示例---title: 测试date: 2019-04-2 14:02:57categories: - demotags:- 测试标签1- 测试标签2--- 其他配置参考gal项目wiki","path":"2019/04/09/github利用hexo搭建个人博客/","date":"04-09","excerpt":"准备工作安装gitGitHub Windows安装Node.JSNode.JS确认npm命令已经配置好安装Hexo1npm install hexo-cli -g初始化配置Hexo创建根目录12# 创建博客根目录mkdir blogroot初始化Hexo123456# 进入根目录cd blogroot# 初始化项目hexo init# 安装插件npm install","tags":[{"name":"踩坑","slug":"踩坑","permalink":"https://jijiking51.cn/tags/踩坑/"},{"name":"hexo","slug":"hexo","permalink":"https://jijiking51.cn/tags/hexo/"},{"name":"个人博客","slug":"个人博客","permalink":"https://jijiking51.cn/tags/个人博客/"}],"preview":"http://img.jijiking51.cn/42992.jpg"}]}